{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "from os.path import basename, dirname, join, exists\n",
    "import sys\n",
    "from importlib import reload\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import time\n",
    "\n",
    "# standard python plotting utilities\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# standard geospatial python utilities\n",
    "# import pyproj # for converting proj4string\n",
    "# import shapely\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# mapping utilities\n",
    "import contextily as ctx\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# import flopy\n",
    "# import flopy.utils.binaryfile as bf\n",
    "from importlib import reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37edc965",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "\n",
    "git_dir = join(doc_dir, 'GitHub')\n",
    "## Set up directory referencing\n",
    "gwfm_dir = dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel'\n",
    "\n",
    "bas_dir = join(gwfm_dir, 'BAS6')\n",
    "proj_dir = join(gwfm_dir,'Mapping')\n",
    "plt_dir = join(proj_dir,'figures/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd85c3-52bb-4762-a2d0-4ee7159b45c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path(fxn_dir):\n",
    "    \"\"\" Insert fxn directory into first position on path so local functions supercede the global\"\"\"\n",
    "    if fxn_dir not in sys.path:\n",
    "        sys.path.insert(0, fxn_dir)\n",
    "# flopy github path - edited\n",
    "add_path(doc_dir+'/GitHub/flopy')\n",
    "import flopy \n",
    "\n",
    "# other functions\n",
    "py_dir = join(doc_dir,'GitHub/CosumnesRiverRecharge/python_utilities')\n",
    "add_path(py_dir)\n",
    "\n",
    "# from mf_utility import get_layer_from_elev\n",
    "# from map_cln import gdf_bnds, plt_cln\n",
    "import map_obs_plt as mop\n",
    "from map_obs_plt import plt_bc_hk, plot_head_simple, plot_dtw_simple\n",
    "from map_cln import gdf_bnds\n",
    "\n",
    "# reload(mop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f222b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = 'C://WRDAPP/GWFlowModel'\n",
    "# run_dir = 'F://WRDAPP/GWFlowModel'\n",
    "loadpth = run_dir +'/Cosumnes/Regional/'\n",
    "\n",
    "# model_nam = 'historical_simple_geology'\n",
    "model_nam = 'historical_simple_geology_reconnection'\n",
    "\n",
    "\n",
    "model_ws = loadpth+model_nam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55536e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_only = ['DIS','BAS6','UPW','OC','SFR','LAK',\n",
    "            'RCH', 'WEL'\n",
    "            ]\n",
    "m = flopy.modflow.Modflow.load('MF.nam', model_ws= model_ws, \n",
    "                                exe_name='mf-owhm', version='mfnwt',\n",
    "                              load_only = load_only\n",
    "                              )\n",
    "\n",
    "if 'LPF' in m.get_package_list():\n",
    "    gel_nam = 'LPF'\n",
    "else:\n",
    "    gel_nam = 'UPW'\n",
    "gel = m.__getattr__(gel_nam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f583ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gel = flopy.modflow.ModflowUpw.load(join(model_ws, 'MF.upw'), model=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92950cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_dir = gwfm_dir+'/SFR_data/'\n",
    "# grid_sfr = gpd.read_file(sfr_dir+'/final_grid_sfr/grid_sfr.shp')\n",
    "# grid_sfr['Kz'] = m.sfr.reach_data.strhc1\n",
    "m_domain = gpd.read_file(gwfm_dir+'/DIS_data/NewModelDomain/GWModelDomain_52_9deg_UTM10N_WGS84.shp')\n",
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n",
    "grid_p['easting'] = grid_p.geometry.centroid.x\n",
    "grid_p['northing'] = grid_p.geometry.centroid.y\n",
    "\n",
    "lak_grid_clip = gpd.read_file(gwfm_dir+'/Levee_setback/lak_grid_clip/lak_grid_clip.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d10dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr = m.sfr\n",
    "sfrdf = pd.DataFrame(sfr.reach_data)\n",
    "grid_sfr = grid_p.set_index(['row','column']).loc[list(zip(sfrdf.i+1,sfrdf.j+1))].reset_index(drop=True)\n",
    "grid_sfr = pd.concat((grid_sfr,sfrdf),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_fxn_dir = doc_dir+'/GitHub/mapping/01_python_scripts'\n",
    "# if map_fxn_dir not in sys.path:\n",
    "#     sys.path.append(map_fxn_dir)\n",
    "# # sys.path\n",
    "# from basic_mapping import gdf_bnds, pnt_2_tup, lab_pnt, plt_cln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1150ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shapely.geometry import Polygon\n",
    "# def gdf_bnds(df, ax, buf=1):\n",
    "#     \"\"\" Take a geodataframe plus a buffer and set the axis limits, and return the bounding box\"\"\"\n",
    "#     lim = df.geometry.unary_union.buffer(buf).bounds\n",
    "#     bnds = Polygon([(lim[0],lim[1]), (lim[2],lim[1]), (lim[2],lim[3]),(lim[0],lim[3])])\n",
    "#     bnds = gpd.GeoDataFrame([0], geometry = [bnds], crs = df.crs)\n",
    "#     ax.set_xlim(lim[0], lim[2])\n",
    "#     ax.set_ylim(lim[1], lim[3])\n",
    "#     return(bnds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5df6e0",
   "metadata": {},
   "source": [
    "# Head plots and contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847dc808",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdobj = flopy.utils.HeadFile(model_ws+'/MF.hds')\n",
    "spd_stp = hdobj.get_kstpkper()\n",
    "times = hdobj.get_times()\n",
    "cbc = model_ws+'/MF.cbc'\n",
    "\n",
    "strt_date = pd.to_datetime(m.dis.start_datetime)\n",
    "dates = strt_date+(np.asarray(times)-1).astype('timedelta64[D]')\n",
    "\n",
    "dt_ref = pd.DataFrame(dates, columns=['dt'])\n",
    "dt_ref['kstpkper'] = spd_stp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ebd075",
   "metadata": {},
   "outputs": [],
   "source": [
    "rech = m.rch.rech.array[:,0,:,:]\n",
    "rech_avg = pd.Series(rech.mean(axis=(1,2)))[1:]\n",
    "# rech_avg.index=dt_ref.dt[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2632a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pumping to array\n",
    "pump = np.zeros((m.dis.nper,m.dis.nrow,m.dis.ncol))\n",
    "for n in np.arange(0,m.dis.nper):\n",
    "    wel_n = m.wel.stress_period_data[n]\n",
    "    pump[n, wel_n.i, wel_n.j] += wel_n.flux*-1\n",
    "pump_rate = pump/(m.dis.delr[0]*m.dis.delc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(rech.mean(axis=0), vmax=0.001)\n",
    "# plt.imshow(pump_rate.mean(axis=0), vmax=0.005)\n",
    "\n",
    "# plt.colorbar(shrink=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59403b5",
   "metadata": {},
   "source": [
    "## Water Budget check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43b20d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_wb(model_ws, dt_ref):\n",
    "    # load summary water budget\n",
    "    wb = pd.read_csv(model_ws+'/flow_budget.txt', delimiter=r'\\s+')\n",
    "\n",
    "    wb['kstpkper'] = list(zip(wb.STP-1,wb.PER-1))\n",
    "    wb = wb.merge(dt_ref, on='kstpkper').set_index('dt')\n",
    "\n",
    "    # calculate change in storage\n",
    "    wb['dSTORAGE'] = wb.STORAGE_OUT - wb.STORAGE_IN\n",
    "    # calculate total gw flow, sum GHB, CHD\n",
    "    wb['GW_OUT'] = wb.GHB_OUT + wb.CHD_OUT\n",
    "    wb['GW_IN'] = wb.GHB_IN + wb.CHD_IN\n",
    "    wb = wb.loc[:,~wb.columns.str.contains('GHB|CHD')]\n",
    "    \n",
    "    wb_cols = wb.columns[wb.columns.str.contains('_IN|_OUT')]\n",
    "    wb_cols = wb_cols[~wb_cols.str.contains('STORAGE|IN_OUT')]\n",
    "    wb_out_cols= wb_cols[wb_cols.str.contains('_OUT')]\n",
    "    wb_in_cols = wb_cols[wb_cols.str.contains('_IN')]\n",
    "    # only include columns with values used\n",
    "    wb_out_cols = wb_out_cols[np.sum(wb[wb_out_cols]>0, axis=0).astype(bool)]\n",
    "    wb_in_cols = wb_in_cols[np.sum(wb[wb_in_cols]>0, axis=0).astype(bool)]\n",
    "\n",
    "    return(wb, wb_out_cols, wb_in_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb, out_cols, in_cols = clean_wb(model_ws, dt_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85bbc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wb.WEL_OUT.sum(), wb.RCH_IN.sum()\n",
    "# wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a9e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_ann = wb.resample('AS-Oct').sum(numeric_only=True)\n",
    "fig,ax = plt.subplots( sharex=True)\n",
    "plt.axhline(0, color='black')\n",
    "wb_ann[out_cols].multiply(-1).plot( kind='bar', ax=ax, stacked=True)\n",
    "wb_ann[in_cols].plot( kind='bar', ax=ax, stacked=True)\n",
    "plt.legend(loc=(1.05,0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa8ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,1, figsize=(6.5,4), sharex=True)\n",
    "wb.plot(y='PERCENT_ERROR', ax=ax[0])\n",
    "wb[in_cols].multiply(1E-6).plot(y=in_cols, ax=ax[1], legend=True)\n",
    "wb[out_cols].multiply(1E-6).plot(y=out_cols, ax=ax[2], legend=True)\n",
    "\n",
    "ax[1].set_ylabel('Inflow\\n($10^6 m^3/day$)')\n",
    "ax[2].set_ylabel('Outflow\\n($10^6 m^3/day$)')\n",
    "\n",
    "# ax[1].set_ylim(0,1E3)\n",
    "# ax[2].set_ylim(0,1E5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab800bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,ax= plt.subplots(2,1, figsize=(6.5, 4), sharex=True, dpi=300)\n",
    "# in_labels = ['Foothills GW Inflow','Boundary GW Inflow','GW Recharge', 'Stream Leakge to GW']\n",
    "# wb[in_cols].multiply(1E-6).plot(y=in_cols, ax=ax[0], legend=True, label=in_labels)\n",
    "# out_labels = ['Foothills GW Outflow','GW Pumping','Boundary GW Outflow','GW Leakage to Streams']\n",
    "# wb[out_cols].multiply(1E-6).plot(y=out_cols, ax=ax[1], legend=True, label=out_labels)\n",
    "\n",
    "in_labels = ['GW Recharge', 'Stream Leakge to GW','GW Inflow']\n",
    "wb[in_cols].multiply(1E-6).plot(y=['RCH_IN','SFR_IN', 'GW_IN'], ax=ax[0], legend=True, \n",
    "                                label=in_labels, color=['tab:green','tab:blue','tab:brown'])\n",
    "out_labels = ['GW Pumping','GW Outflow', 'GW ET']\n",
    "wb[out_cols].multiply(1E-6).plot(y=['WEL_OUT','GW_OUT','ET_OUT'], ax=ax[1], legend=True, \n",
    "                                 label=out_labels, color=['black','tab:brown', 'green'])\n",
    "\n",
    "ax[0].set_ylabel('Inflow\\n($10^6 m^3/day$)')\n",
    "ax[1].set_ylabel('Outflow\\n($10^6 m^3/day$)')\n",
    "plt.xlabel('Date')\n",
    "# plt.savefig(join(plt_dir, 'total_water_budget_time_series.png'),  bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabe4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdobj = flopy.utils.HeadFile(model_ws+'/MF.hds')\n",
    "# plt.contour(hdobj.get_data((0,0))[-1])\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa761962",
   "metadata": {},
   "source": [
    "# Sim vs Obs Head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221dd51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ws = loadpth+'historical_simple_geology'\n",
    "model_ws = loadpth+'historical_simple_geology_reconnection'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "hobout = pd.read_csv(model_ws+'/MF.hob.out',delimiter=r'\\s+', header = 0,names = ['sim_val','WSE','obs_nam'],\n",
    "                     dtype = {'sim_val':float,'obs_val':float,'obs_nam':object},\n",
    "                    na_values=[-9999.])\n",
    "# if only one obs exists correct naming convention\n",
    "one_obs = ~hobout.obs_nam.str.contains('.0')\n",
    "hobout.loc[one_obs,'obs_nam'] = hobout.loc[one_obs,'obs_nam']+'.'+str(1).zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "# get boundary values for plotting a 1:1\n",
    "hobmax = hobout.loc[:,['sim_val','WSE']].max().min()\n",
    "hobmin = hobout.loc[:,['sim_val','WSE']].min().max()\n",
    "\n",
    "# plot observed vs simulated values\n",
    "hobout.plot.scatter(x='WSE', y='sim_val',marker='.',ax=ax)\n",
    "ax.plot([hobmin,hobmax],[hobmin,hobmax],'red')\n",
    "ax.set_xlabel('Observed Values (m)')\n",
    "ax.set_ylabel('Simulated Values (m)')\n",
    "# plt.xlabel('Observed Values (m)')\n",
    "# plt.ylabel('Simulated Values (m)')\n",
    "\n",
    "# lim2 = hobout.loc[:,['WSE']].max().min()\n",
    "# lim1 = hobout.loc[:,['WSE']].min().max()\n",
    "# ax.set_ylim(lim1,lim2)\n",
    "\n",
    "fig_nam = plt_dir+'GSP_WaterBudget/sim_vs_obs_heads'\n",
    "\n",
    "# plt.savefig(fig_nam+'.png',dpi=600,bbox_inches='tight')\n",
    "# plt.savefig(fig_nam+'.svg',dpi=600,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mak_hob_gpd(hobout):\n",
    "    all_obs = pd.read_csv(model_ws+'/input_data/all_obs_grid_prepared.csv',index_col=0)\n",
    "    all_obs.index = all_obs.index.rename('date')\n",
    "    all_obs = all_obs.reset_index()\n",
    "    # join more indepth obs data to output simulated heads\n",
    "    obs_data = hobout.join(all_obs.set_index('obs_nam'),on=['obs_nam'], how='right')\n",
    "    obs_data = obs_data.dropna(subset=['node'])\n",
    "#     obs_data.loc[:,['row','column','node']] = obs_data.loc[:,['row','column','node']].astype(int)\n",
    "    obs_data[['row','column','node']] = obs_data[['row','column','node']].astype(int)\n",
    "    # add hk to plot unit\n",
    "    obs_data['hk'] = gel.hk.array[obs_data.layer-1, obs_data.row-1, obs_data.column-1]\n",
    "    # obs_data.index = obs_data.index\n",
    "    obs_grid = obs_data.join(grid_p.set_index(['row','column']).loc[:,['easting','northing']], \n",
    "                             on=['row','column'])\n",
    "    # # convert back to geospatial\n",
    "    hob_gpd = gpd.GeoDataFrame(obs_grid, geometry = gpd.points_from_xy(obs_grid.easting, obs_grid.northing),\n",
    "                              crs = grid_p.crs)\n",
    "    hob_gpd['error'] = hob_gpd.WSE - hob_gpd.sim_val\n",
    "    hob_gpd['abs_error'] = hob_gpd.error.abs()\n",
    "    \n",
    "    if 'date' in hob_gpd.columns:\n",
    "        hob_gpd = hob_gpd.set_index('date')\n",
    "        hob_gpd.index = pd.to_datetime(hob_gpd.index)    \n",
    "        #     groupby values by season\n",
    "        hob_gpd.loc[(hob_gpd.index.month > 2)&(hob_gpd.index.month < 6),'season'] = 'spring'\n",
    "        hob_gpd.loc[(hob_gpd.index.month > 8)&(hob_gpd.index.month < 12),'season'] = 'fall'\n",
    "    \n",
    "    return(hob_gpd)\n",
    "    # set date\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb6b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hob_gpd = mak_hob_gpd(hobout)\n",
    "\n",
    "hob_seasonal = hob_gpd.groupby(['node','season']).mean(numeric_only=True)\n",
    "hob_seasonal = gpd.GeoDataFrame(hob_seasonal, geometry = gpd.points_from_xy(hob_seasonal.easting, hob_seasonal.northing))\n",
    "hob_seasonal = hob_seasonal.reset_index()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stns = hob_gpd.drop_duplicates('site_code', keep='last').reset_index().drop(columns=['date','gwe'])\n",
    "stns['botm_elev'] = m.dis.botm[stns.layer-1, stns.row-1, stns.column-1]\n",
    "stns.crs = hob_gpd.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d006a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hob_gpd['Statistic'] = 0.01\n",
    "hob_gpd['StatFlag'] = 'SD'\n",
    "# locations with significant difference between RPE GSE and the DEM should have additional uncertainty included\n",
    "hob_gpd['Statistic'] += np.round(np.abs(hob_gpd.dem_wlm_gse),4)\n",
    "hob_gpd['Weight'] = 1/(hob_gpd.Statistic**2)\n",
    "\n",
    "soswr = (np.sum(np.abs(hob_gpd.sim_val-hob_gpd.WSE)*hob_gpd.Weight))\n",
    "print('Sum of absolute difference of OBS and SIM: %.2e' %soswr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_hob_map(y, s, nd_chk=None):\n",
    "    fig,ax=plt.subplots(figsize=(8, 8))\n",
    "    m_domain.plot(ax=ax,color='None')\n",
    "    mapview = flopy.plot.PlotMapView(model=m,ax=ax)\n",
    "#     csa = mapview.plot_array(gel.hk.array[1,:,:], norm=mpl.colors.LogNorm())\n",
    "#     cb = plt.colorbar(csa, shrink=0.5,ax=ax)\n",
    "#     cb.set_label('Horiz. Cond. (m/d)')\n",
    "\n",
    "#     csa = mapview.plot_array(-pump_rate.mean(axis=0), vmin=-np.quantile(pump_rate, .95))\n",
    "    csa = mapview.plot_array(rech.mean(axis=0)- pump_rate.mean(axis=0), vmin=-np.quantile(pump_rate, .95))\n",
    "    cb = plt.colorbar(csa, shrink=0.5,ax=ax)\n",
    "    cb.set_label('Recharge (m/d)')\n",
    "\n",
    "    hob_gpd_plt = hob_gpd[(hob_gpd.index.year==y)&(hob_gpd.season==s)]\n",
    "\n",
    "    if nd_chk != None:\n",
    "        hob_gpd_plt = hob_gpd_plt[hob_gpd_plt.node.isin(nd_chk)]\n",
    "    # hob_gpd.plot('error',scheme='EqualInterval', k= 6, ax=ax,legend=True,cmap='magma')\n",
    "    hob_gpd_plt.plot('error',markersize='abs_error',scheme='Quantiles', k = 6, ax=ax,\n",
    "                      legend=True,cmap='bwr',legend_kwds={'loc':(1.1,0.9),'title':'Error (Obs - Sim)'})\n",
    "    hob_gpd_plt.apply(lambda x: ax.annotate(str(x.node), xy=(x.geometry.x, x.geometry.y), ha='right'),axis=1);\n",
    "    # stns[stns.botm_elev > stns.screen_elev].plot(color='red',marker='x',ax=ax)\n",
    "#     grid_sfr.plot(ax=ax,color='black')\n",
    "#     contour_set = mapview.contour_array(hdobj.get_data((0,int(hob_gpd_plt.spd.mean()))),\n",
    "#                                 masked_values=[-999.99],  ax=ax)\n",
    "#     hcb = plt.colorbar(contour_set, shrink = 0.5,ax=ax)\n",
    "#     hcb.set_label('Head (m)')\n",
    "#     ax.clabel(contour_set, contour_set.levels[0::2], inline=True, fontsize=8)\n",
    "#     foothills.plot(ax=ax, alpha=0.5, edgecolor='black', color='grey')\n",
    "    \n",
    "    gdf_bnds(hob_gpd_plt, ax=ax, buf=2E3)\n",
    "    return(hob_gpd_plt)\n",
    "\n",
    "    # ax.legend(loc=(1,0.5))\n",
    "hob_gpd_plt = plt_hob_map(2019, 'fall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_chk = [15343, 16733, 11448, 8437, 15314, 14626] +[3103, 5642, 6112, 10746, 6458]\n",
    "# nd_chk = [2926, 8437, 12944, 13407]\n",
    "nd_chk = [15314, 15343, 13407, 12944, 14626]\n",
    "nd_chk = [6458, 8437, 9580, 11448, 15314, 20055]\n",
    "hob_gpd_chk = plt_hob_map(2019, 'fall', nd_chk=nd_chk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chk = hob_gpd_chk.groupby('node').mean(numeric_only=True)\n",
    "df_chk['rech'] = rech.sum(axis=0)[df_chk.row.astype(int)-1, df_chk.column.astype(int)-1]\n",
    "df_chk[['sim_val','WSE','avg_screen_depth', 'hk', 'rech', 'layer','abs_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd445b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hobout = pd.read_csv(model_ws+'/MF.hob.out',delimiter=r'\\s+', header = 0,names = ['sim_val','WSE','obs_nam'],\n",
    "                     dtype = {'sim_val':float,'obs_val':float,'obs_nam':object},\n",
    "                    na_values=[-9999.])\n",
    "# if only one obs exists correct naming convention\n",
    "one_obs = ~hobout.obs_nam.str.contains('.0')\n",
    "hobout.loc[one_obs,'obs_nam'] = hobout.loc[one_obs,'obs_nam']+'.'+str(1).zfill(5)\n",
    "\n",
    "hob_gpd = mak_hob_gpd(hobout)\n",
    "\n",
    "# find sites with long time series of OBS\n",
    "hobs_long = (hob_gpd.groupby('site_code').count()>=int(m.dis.nper/365)*2)\n",
    "hobs_long = hobs_long.index[hobs_long.WSE].values\n",
    "# hobs_long.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df448fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get layer, row, column for extracting time series head data\n",
    "# hob_kij = hob_gpd.drop_duplicates('node')[['node','layer','row','column']]\n",
    "# hob_kij[['layer','row','column']] -=1\n",
    "# hob_kij['kij'] = list(hob_kij[['layer','row','column']].astype(int).itertuples(index=False,name=None)) #hob_ts\n",
    "\n",
    "# load times series to check if making changes to hob layer\n",
    "# hob_ts = pd.DataFrame(hdobj.get_ts(hob_kij.kij.tolist()),columns=np.append(['spd'],hob_kij.node.values)) \n",
    "# hob_ts['date'] = strt_date+hob_ts.spd.astype('timedelta64[D]')\n",
    "# hob_ts = hob_ts.drop(columns='spd')\n",
    "# ts_long = hob_ts.melt(id_vars='date', var_name='node',value_name='sim_new')\n",
    "# ts_long.node = ts_long.node.astype(int)\n",
    "# hob_ts_chk = hob_gpd.join(ts_long.set_index(['date','node']), on=['date','node'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hob_gpd.site_code.unique().shape, voi.shape\n",
    "# hob_long = hob_gpd[hob_gpd.site_code.isin(hobs_long)]\n",
    "# hob_long = hob_ts_chk.melt(value_vars=['sim_val','WSE', 'sim_new'], id_vars=['node'], ignore_index=False)\n",
    "hob_long = hob_gpd.melt(value_vars=['sim_val','WSE'], id_vars=['node'], ignore_index=False)\n",
    "\n",
    "\n",
    "# # a few wells have duplicates in a node (same with site_code), temp fix\n",
    "# issue was actually the NA values\n",
    "hob_long = hob_long.reset_index().drop_duplicates(['date','node','variable']).set_index('date')\n",
    "# # hob_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b426a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# well_ref = hob_gpd.drop_duplicates('site_code')[['site_code','node']].sort_values('node')\n",
    "# well_ref[well_ref.site_code.str.contains(\"MW\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fde414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chk_lng = hob_long.groupby('node').count().variable\n",
    "# chk_lng = chk_lng[chk_lng>50].index\n",
    "# sns.relplot(hob_long[hob_long.node.isin(chk_lng)], x='date',y='value', \n",
    "sns.relplot(hob_long.dropna(subset='value'), x='date',y='value', \n",
    "            hue='variable',  col='node',\n",
    "#             col_wrap=10, # for powerpoint\n",
    "            col_wrap=4,\n",
    "           facet_kws={'sharex':True, 'sharey':False}\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ce3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# voi = hob_gpd[hob_gpd.site_code.isin(hobs_long)].node.unique()\n",
    "# # voi = 22825\n",
    "# # def obs_sim_node(voi):\n",
    "# ny = 3\n",
    "# nx = int(np.ceil(len(voi)/ny))\n",
    "# fig,ax=plt.subplots(nx,ny,figsize=(12,3*nx))\n",
    "# for i,voi_n in enumerate(voi):\n",
    "#     ax_n = ax[int(i / ny), i % ny] if (nx > 1) else ax[i]\n",
    "#     hob_n = hob_gpd[hob_gpd.node==voi_n]\n",
    "#     hob_n.reset_index().plot(x='date',y='WSE',kind='scatter', ax=ax_n,\n",
    "#                                                   marker='x', s=40, legend=False)\n",
    "#     hob_n.reset_index().plot(x='date',y='sim_val',kind='scatter', ax=ax_n, \n",
    "#                                                   marker='o', s=40, legend=False)\n",
    "#     # add time series of simulated data to see true peaks\n",
    "# #     ts_i = pd.DataFrame(hdobj.get_ts(hob_kij[hob_kij.node==voi_n].kij.values[0]),columns=['spd','sim_val']) \n",
    "#     ts_i['dt'] = dt_ref.dt\n",
    "#     ts_i.plot(x='dt',y='sim_val', ax=ax_n, legend=False)\n",
    "\n",
    "#     ax_n.set_xlabel('')\n",
    "#     ax_n.set_ylabel('')\n",
    "#     S_n = format(gel.ss.array[hob_n.layer.iloc[0],hob_n.row.iloc[0],hob_n.column.iloc[0]],'.1e')\n",
    "#     K_n = format(gel.hk.array[hob_n.layer.iloc[0],hob_n.row.iloc[0],hob_n.column.iloc[0]], '.1e')\n",
    "\n",
    "#     ax_n.set_title(str(voi_n)+' K'+K_n+' S'+S_n+'\\n'+hob_n.site_code.iloc[0])\n",
    "# ax_n.legend(['Observed','Simulated'])\n",
    "# ax[0,0].legend(['Observed','Simulated'])\n",
    "\n",
    "# # fig.text(-0.03, 0.2, 'Head (m)',rotation='vertical',size=26)\n",
    "# # fig.text(0.35, -0.05, 'Date',size=26)\n",
    "# fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8943d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghb_dir = join(gwfm_dir, 'GHB_data')\n",
    "year = strt_date.year # 2016\n",
    "filename = glob.glob(ghb_dir+'/final_WSEL_arrays/spring'+str(year)+'_kriged_WSEL.tsv')[0]\n",
    "# convert from ft to meters\n",
    "hd_strt = np.loadtxt(filename)*0.3048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e43cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc2bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdobj = flopy.utils.HeadFile(model_ws+'/MF.hds')\n",
    "fig, ax = plt.subplots(figsize=(6.5, 3.5), dpi=300) # was 40, 20 before\n",
    "\n",
    "plt.aspect=10\n",
    "\n",
    "head = hdobj.get_data(kstpkper = spd_stp[0])\n",
    "head_new = hdobj.get_data(kstpkper = spd_stp[1400])\n",
    "\n",
    "rownum = 50\n",
    "# rownum = 0\n",
    "\n",
    "mcs = flopy.plot.PlotCrossSection(model=m, line={'Row' : rownum})\n",
    "# colnum = 150\n",
    "# mcs = flopy.plot.PlotCrossSection(model=m, line={'Column' : colnum})\n",
    "\n",
    "linecollection = mcs.plot_grid(linewidth = 0.3)\n",
    "ax.add_collection(linecollection)\n",
    "\n",
    "mcs.plot_array(a=gel.hk.array, norm = mpl.colors.LogNorm())\n",
    "\n",
    "wt = mcs.plot_surface(a=hd_strt[:,:], color='black')\n",
    "wt = mcs.plot_surface(a=head[:,:,:], color='blue')\n",
    "wt = mcs.plot_surface(a=head_new[:,:,:],color='red')\n",
    "\n",
    "plt.xlabel('Distance from southwestern edge (m)')\n",
    "plt.ylabel('Elevation (m)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c88bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.dis.nlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48741e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_new[-1,50,173], head_new[-1,50,200], head_new[-1,50,229]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ebba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_new[-1,50,175::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hob_gpd_chk[hob_gpd_chk.node==16733].column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b0429",
   "metadata": {},
   "source": [
    "# Plot stream water budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff84c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vka = gel.vka.array\n",
    "sfrdf = pd.DataFrame(m.sfr.reach_data)\n",
    "grid_sfr = grid_p.set_index(['row','column']).loc[list(zip(sfrdf.i+1,sfrdf.j+1))].reset_index(drop=True)\n",
    "grid_sfr = pd.concat((grid_sfr,sfrdf),axis=1)\n",
    "# group sfrdf by vka quantiles\n",
    "# sfr_vka = vka[grid_sfr.k, grid_sfr.i, grid_sfr.j]\n",
    "# for p in vka_quants.index:\n",
    "#     facies = vka_quants.loc[p]\n",
    "#     grid_sfr.loc[(sfr_vka< facies.vka_max)&(sfr_vka>= facies.vka_min),'facies'] = facies.facies\n",
    "#     # add color for facies plots\n",
    "# grid_sfr = grid_sfr.join(gel_color.set_index('geology')[['color']], on='facies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_sfr = pd.DataFrame().from_records(m.sfr.reach_data).rename(columns={'i':'row','j':'column'})\n",
    "# grid_sfr[['row','column']] += 1 # convert to 1 based to match with SFR output\n",
    "# pd_sfr = grid_sfr.set_index(['iseg','ireach'])[['rchlen','strtop', 'facies']]\n",
    "# pd_sfr['Total distance (m)'] = pd_sfr['rchlen'].cumsum()\n",
    "\n",
    "def clean_sfr_df(model_ws, pd_sfr=None):\n",
    "    sfrout = flopy.utils.SfrFile(join(model_ws, m.name+'.sfr.out'))\n",
    "    sfrdf = sfrout.get_dataframe()\n",
    "    sfrdf = sfrdf.join(dt_ref.set_index('kstpkper'), on='kstpkper').set_index('dt')\n",
    "    # convert from sub-daily to daily using mean, lose kstpkper\n",
    "    sfrdf = sfrdf.groupby(['segment','reach']).resample('D').mean(numeric_only=True)\n",
    "    sfrdf = sfrdf.reset_index(['segment','reach'], drop=True)\n",
    "    sfrdf[['row','column']]-=1 # convert to python\n",
    "    sfrdf['month'] = sfrdf.index.month\n",
    "    sfrdf['WY'] = sfrdf.index.year\n",
    "    sfrdf.loc[sfrdf.month>=10, 'WY'] +=1\n",
    "    # add column to track days with flow\n",
    "    sfrdf['flowing'] = 1\n",
    "    sfrdf.loc[sfrdf.Qout <= 0, 'flowing'] = 0\n",
    "    if pd_sfr is not None:\n",
    "    #     sfrdf = pd_sfr.join(sfrdf.set_index(['row','column']),on=['row','column'],how='inner',lsuffix='_all')\n",
    "        sfrdf = sfrdf.join(pd_sfr ,on=['segment','reach'],how='inner',lsuffix='_all')\n",
    "\n",
    "    # create different column for stream losing vs gaining seeapge\n",
    "    sfrdf['Qrech'] = np.where(sfrdf.Qaquifer>0, sfrdf.Qaquifer,0)\n",
    "    sfrdf['Qbase'] = np.where(sfrdf.Qaquifer<0, sfrdf.Qaquifer*-1,0 )\n",
    "    # booleans for plotting\n",
    "    sfrdf['gaining'] = (sfrdf.gradient == 0)\n",
    "    sfrdf['losing'] = (sfrdf.gradient >= 0)\n",
    "    sfrdf['connected'] = (sfrdf.gradient < 1)\n",
    "    return(sfrdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrdf = clean_sfr_df(model_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_sum = sfrdf.groupby(['segment','reach','row','column','layer']).mean().reset_index()\n",
    "# sfr_seg_sum = sfrdf.groupby(['segment']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "# grid_p.merge(sfr_sum, on=['row','column']).plot('Qin', legend=True)\n",
    "grid_p.merge(sfr_sum, on=['row','column']).plot('Qaquifer', legend=True, ax=ax)\n",
    "# hob_gpd_chk.plot('Error', ax=ax, legend=True)\n",
    "hob_gpd_chk.plot('error',markersize='abs_error',scheme='Quantiles', k = 6, ax=ax,\n",
    "                  legend=True,cmap='bwr',legend_kwds={'loc':(1.2,0.8),'title':'Error (Obs - Sim)'})\n",
    "hob_gpd_chk.apply(lambda x: ax.annotate(str(x.node), xy=(x.geometry.x, x.geometry.y), ha='right'),axis=1);\n",
    "gdf_bnds(hob_gpd_chk, ax=ax, buf = 1E3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d35606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

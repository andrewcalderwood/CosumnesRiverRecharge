{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosumnes Model \n",
    "@author: Andrew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "from os.path import exists, join, dirname, basename\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from scipy.stats import gmean, hmean\n",
    "\n",
    "# standard python plotting utilities\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard geospatial python utilities\n",
    "# import pyproj # for converting proj4string\n",
    "# import shapely\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# mapping utilities\n",
    "import contextily as ctx\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel'\n",
    "gwfm_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flopy_dir = doc_dir+'/GitHub/flopy/'\n",
    "if flopy_dir not in sys.path:\n",
    "    sys.path.append(flopy_dir)\n",
    "# sys.path\n",
    "import flopy \n",
    "\n",
    "from importlib import reload\n",
    "# importlib.reload\n",
    "# reload(flopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "end_date = '2018-01-2'\n",
    "# end_date = '2018-01-02'\n",
    "strt_date = '2018-01-01'\n",
    "\n",
    "dates = pd.date_range(strt_date, end_date)\n",
    "\n",
    "# The number of periods is the number of dates \n",
    "nper = 1\n",
    "\n",
    "# Each period has a length of one because the timestep is one day, have the 1st stress period be out of the date range\n",
    "# need to have the transient packages start on the second stress period\n",
    "perlen = np.ones(nper)\n",
    "# Steady or transient periods\n",
    "steady = np.zeros(nper)\n",
    "steady[0] = 1 # first period is steady state, rest are transient\n",
    "steady = steady.astype('bool').tolist()\n",
    "# Reduce the number of timesteps to decrease run time\n",
    "nstp = np.ones(nper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maribeth's model parameters, had to switch nrow and ncol due to her issue in xul, yul\n",
    "nrow=100\n",
    "ncol=230\n",
    "delr=200\n",
    "delc=200\n",
    "rotation=52.9\n",
    "\n",
    "# The number of layers should be 1 for the Mehrten formation, 1 for the laguna plus the number of TPROGS layers,\n",
    "# where the Laguna formation will be clipped by the TPROGS layers\n",
    "nlay = 320\n",
    "\n",
    "\n",
    "# There is essentially no difference bewtween WGS84 and NAD83 for UTM Zone 10N\n",
    "# proj4_str='EPSG:26910'\n",
    "proj4_str='+proj=utm +zone=10 +ellps=WGS84 +datum=WGS84 +units=m +no_defs '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flopy.utils.geometry import Polygon, LineString, Point\n",
    "# Original model domain, 44.7 deg angle\n",
    "# m_domain = gpd.read_file(gwfm_dir+'\\\\GWModelDomain_UTM10N\\\\GWModelDomain_Rec_UTM10N.shp')\n",
    "# New model domain 52.9 deg\n",
    "m_domain = gpd.read_file(gwfm_dir+'/DIS_data/NewModelDomain\\\\GWModelDomain_52_9deg_UTM10N_WGS84.shp')\n",
    "\n",
    "# Need to check this when changing model domains\n",
    "xul, yul = list(m_domain.geometry.values[0].exterior.coords)[1]\n",
    "list(m_domain.geometry.values[0].exterior.coords)\n",
    "# m_domain.geometry.values[0].exterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Flopy GitHub \"Technically you need to create both a SpatialReference object and a ModelGrid object, but in practice the code looks very similar and can easily be implemented in one line.\"\n",
    "WGS84 Zone 10N has EPSG: 32610  \n",
    "Lower left corner of model is   \n",
    "Zone 10 N  \n",
    "Easting: 661211.18 m E  \n",
    "Northing: 4249696.50 m N  \n",
    "angle is approximate 53 degrees  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Users may change loadpath \n",
    "The default loadpath is set to an existing external hard drive for Andrew as F://\n",
    "If the script doesn't find an external harddrive F:// then it will default to the C:// Drive in WRDAPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dir = 'F:/WRDAPP'\n",
    "c_dir = 'C:/WRDAPP'\n",
    "\n",
    "if os.path.exists(ext_dir):\n",
    "    loadpth = ext_dir \n",
    "elif os.path.exists(c_dir):\n",
    "    loadpth = c_dir \n",
    "\n",
    "loadpth = loadpth +'/GWFlowModel/Cosumnes/Regional/permeameter_upscaling/'\n",
    "\n",
    "tprogs_id= '' # tprogs data with conditioning data in the model\n",
    "\n",
    "ptype = 'horizontal'\n",
    "# ptype = 'horizontal_y'\n",
    "\n",
    "# ptype = 'vertical'\n",
    "param_id = ''\n",
    "param_id = '_maples'\n",
    "\n",
    "model_ws = join(loadpth, ptype+param_id)\n",
    "print(model_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple model to speed up loading but still be able to apply functions\n",
    "nlay, nrow, ncol = (320, 100,230)\n",
    "delc, delr= (200, 200)\n",
    "rotation=52.9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "m = flopy.modflow.Modflow(modelname = 'MF', exe_name = 'mf2005', \n",
    "                          version = 'mf2005', model_ws=model_ws)\n",
    "#lenuni = 1 is in ft, lenuni = 2 is in meters\n",
    "# itmuni is time unit 5 = years, 4=days, 3 =hours, 2=minutes, 1=seconds\n",
    "dis = flopy.modflow.ModflowDis(nrow=nrow, ncol=ncol, \n",
    "                               nlay=nlay, delr=delr, delc=delc,\n",
    "                               model=m, lenuni = 2, itmuni = 4,\n",
    "                               xul = xul, yul = yul,rotation=rotation, proj4_str=proj4_str,\n",
    "                              nper = nper, perlen=perlen, nstp=nstp, steady = steady,\n",
    "                              start_datetime = strt_date)\n",
    "xll, yll = 645500.0, 4227700.0\n",
    "m.modelgrid.set_coord_info(xoff=xll, yoff=yll, proj4='EPSG:32610', angrot=rotation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.modelgrid.set_coord_info(xoff=xoff, yoff=yoff, proj4='EPSG:32610', angrot=angrot)\n",
    "mg = m.modelgrid\n",
    "# Write model grid to shapefile for later use\n",
    "# mg.write_shapefile(gwfm_dir+'/DIS_data/grid/grid.shp', epsg = '32610')\n",
    "# mg.write_shapefile(gwfm_dir+'/DIS_data/44_7_grid/44_7_grid.shp', epsg = '32610')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model grid as geopandas object\n",
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Maribeth's grid aligned with Alisha's TPROGS model\n",
    "dem_data = np.loadtxt(gwfm_dir+'\\DIS_data\\dem_52_9_200m_linear.tsv', delimiter = '\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alter existing botm for just TPROGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rectangular set up of botm from -80 to 80\n",
    "botm = np.zeros((nlay, nrow, ncol))\n",
    "for n, elev in enumerate(np.arange(-80,80,0.5)):\n",
    "    botm[len(botm)-1-n,:,:] = elev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the elevation of the top layer based on the DEM\n",
    "m.dis.top = 80\n",
    "# Bottom of model based on geology\n",
    "m.dis.botm = botm\n",
    "chk = dis.check()\n",
    "chk.summary_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ibound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified ibound, only no flow cell if it is below the bottom of the Mehrten Formation\n",
    "# Specify no flow boundary based on rough approx of geology (upper basin volcanics)\n",
    "ibound = np.ones([nlay, nrow,ncol])\n",
    "strt = np.ones((nlay, nrow, ncol), dtype = np.float32)\n",
    "# The model should start in hydraulic connection\n",
    "strt[:,:,:] = m.dis.top[:,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic package, BAS\n",
    "\n",
    "# ibound < 0 is constant head\n",
    "# ibound = 0 is inactive cell\n",
    "# ibound > 0 is active cell\n",
    "# strt is array of starting heads\n",
    "bas = flopy.modflow.ModflowBas(model = m, ibound=ibound, strt = strt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas.check()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in TPROGS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"C:\\Users\\ajcalder\\Box\\research_cosumnes\\Large_TPROGS_run\\TPROGS_realizations\\tsim_Cosumnes_Full_Model.asc1\"\n",
    "# create tprogs directory reference to 100 large tprogs runs ascii files\n",
    "# tprogs_dir = os.path.dirname(gwfm_dir)+'/Large_TPROGS_run/Archive/TPROGS_realizations/'\n",
    "# tprogs_dir = os.path.dirname(gwfm_dir)+'/Large_TPROGS_run/TPROGS_realizations/'\n",
    "# tprogs_dir = os.path.dirname(gwfm_dir)+'/Large_TPROGS_run/New_realizations/'\n",
    "\n",
    "# # get all file names\n",
    "# tprogs_files = glob.glob(tprogs_dir+'*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_tprogs_dir = gwfm_dir+'/UPW_data/tprogs_final' + tprogs_id+'/'\n",
    "tprogs_files = glob.glob(mf_tprogs_dir+'*')\n",
    "# tprogs_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gel_dir = gwfm_dir+'/UPW_data'\n",
    "if 'ZonePropertiesInitial.csv' in os.listdir(model_ws):\n",
    "    params = pd.read_csv(model_ws+'/ZonePropertiesInitial.csv',index_col='Zone')\n",
    "else:\n",
    "    params = pd.read_csv(gel_dir+'/ZonePropertiesInitial.csv',index_col='Zone')\n",
    "    params.to_csv(model_ws+'/ZonePropertiesInitial.csv')\n",
    "# convert from m/s to m/d\n",
    "params['K_m_d'] = params.K_m_s * 86400    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if param_id == '_maples':\n",
    "    params = pd.read_csv(gel_dir+'/ZonePropertiesInitial_Maples.csv',index_col='Zone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprogs_fxn_dir = doc_dir+'/GitHub/CosumnesRiverRecharge/tprogs_utilities'\n",
    "if tprogs_fxn_dir not in sys.path:\n",
    "    sys.path.append(tprogs_fxn_dir)\n",
    "# sys.path\n",
    "import tprogs_cleaning as tc\n",
    "\n",
    "# reload(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0\n",
    "tprogs_info = [80, -80, 320]\n",
    "\n",
    "tprogs_line = np.loadtxt(tprogs_files[t])\n",
    "masked_tprogs= tc.tprogs_cut_elev(tprogs_line, m.dis.top.array, tprogs_info)\n",
    "K, Sy, Ss, porosity = tc.int_to_param(masked_tprogs, params, porosity=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(K[160])\n",
    "plt.colorbar(shrink=0.5)\n",
    "plt.show()\n",
    "plt.imshow(K[:,50], aspect=1/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LPF/UPW package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk = np.copy(K)\n",
    "vka = np.copy(K)\n",
    "sy = np.copy(Sy)\n",
    "ss = np.copy(Ss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuff breccia is very dense, hard and low water yielding. It is supposedly responsible for the many \"haystack\" hills in the eastern part of the county\n",
    "\n",
    "DWR report has a few final well pumping rates, drawdowns and specific capacities but limited.\n",
    "\n",
    "Fleckenstein et al. 2006 found the Mehrten had\n",
    "Kh = 1 to 1.8 x10^-5 m/s\n",
    "Kv = 1 to 1.8 x10^-7 m/s\n",
    "Sy = 0.15 to 0.2\n",
    "Ss = 1e-4 to 1e-3 m^-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layvka 0 means vka is vert K, non zero means its the anisotropy ratio between horiz and vert\n",
    "layvka = 0\n",
    "\n",
    "# LAYTYP MUST BE GREATER THAN ZERO WHEN IUZFOPT IS 2\n",
    "# 0 is confined, >0 convertible, <0 convertible unless the THICKSTRT option is in effect\n",
    "# laytyp = np.ones(nlay)  \n",
    "laytyp = np.zeros(nlay)\n",
    "# Laywet must be 0 if laytyp is confined laywet = [1,1,1,1,1]\n",
    "laywet = np.zeros(len(laytyp))\n",
    "laywet[laytyp==1] = 1\n",
    "#ipakcb = 55 means cell-by-cell budget is saved because it is non zero (default is 53)\n",
    "\n",
    "# until upscaling is begun then vertical and horiz K are the same for TPROGS\n",
    "# upw = flopy.modflow.ModflowUpw(model = m, hk =hk, layvka = layvka, vka = hk, sy=sy, ss=ss,\n",
    "#             laytyp=laytyp, ipakcb=55)\n",
    "\n",
    "lpf = flopy.modflow.ModflowLpf(model = m, hk =hk, layvka = layvka, vka = vka, sy=sy, ss=ss,\n",
    "                               laytyp=laytyp, laywet = laywet, ipakcb=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lpf.write_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHD Package Time variant head\n",
    "May need to remove Mehrten formation and leave Laguna as bottom to avoid having very low conductivity layer causing water mounding, but still need Laguna formation to balance out the layer in the bottom layer with TPROGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chd = flopy.modflow.ModflowChd(model=m,ipakcb=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model top constant head boundary\n",
    "chd_df_all = grid_p.copy()\n",
    "chd_df_all = chd_df_all.drop(['geometry','node'],axis=1)\n",
    "chd_df_all.row -= 1\n",
    "chd_df_all.column -=1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a gradient of 0.001 converged but still had large water budget error\n",
    "if ptype=='horizontal':\n",
    "    chd_right = chd_df_all[chd_df_all.column ==ncol-1].copy()\n",
    "    chd_right = pd.concat((chd_right.row.repeat(nlay), chd_right.column.repeat(nlay)), axis=1)\n",
    "    chd_right['layer'] = np.tile(np.arange(0,nlay), nrow)\n",
    "    chd_right['head'] = 80\n",
    "\n",
    "    chd_left = chd_df_all[chd_df_all.column ==0].copy()\n",
    "    chd_left = pd.concat((chd_left.row.repeat(nlay), chd_left.column.repeat(nlay)), axis=1)\n",
    "    chd_left['layer'] = np.tile(np.arange(0,nlay), nrow)\n",
    "#     chd_left['head'] = 80 - 0.001*(delr*ncol) # 46 m head drop is a little extreme\n",
    "    chd_left['head'] = 80 - 0.0001*(delr*ncol) # trying 1/10 smaller for error # 4.6 m head drop is more reasonable\n",
    "\n",
    "    chd_df = pd.concat((chd_right, chd_left))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a gradient of 0.001 converged but still had large water budget error\n",
    "if ptype=='horizontal_y':\n",
    "    chd_right = chd_df_all[chd_df_all.row ==nrow-1].copy()\n",
    "    chd_right = pd.concat((chd_right.row.repeat(nlay), chd_right.column.repeat(nlay)), axis=1)\n",
    "    chd_right['layer'] = np.tile(np.arange(0,nlay), ncol)\n",
    "    chd_right['head'] = 80\n",
    "\n",
    "    chd_left = chd_df_all[chd_df_all.row ==0].copy()\n",
    "    chd_left = pd.concat((chd_left.row.repeat(nlay), chd_left.column.repeat(nlay)), axis=1)\n",
    "    chd_left['layer'] = np.tile(np.arange(0,nlay), ncol)\n",
    "#     chd_left['head'] = 80 - 0.001*(delr*ncol) # 46 m head drop is a little extreme\n",
    "    chd_left['head'] = 80 - 0.0001*(delc*nrow) # trying 1/10 smaller for error # 4.6 m head drop is more reasonable\n",
    "\n",
    "    chd_df = pd.concat((chd_right, chd_left))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applied a gradient of only 0.01 to avoid excess pushing of flow as suggested by Graham\n",
    "if ptype=='vertical':\n",
    "    chd_df = chd_df_all.copy()\n",
    "    chd_df['layer'] = 0\n",
    "    chd_df['head'] = m.dis.top.array[chd_df.row, chd_df.column]\n",
    "    # model bottom constant head boundary\n",
    "\n",
    "    chd_bot = chd_df.copy()\n",
    "    chd_bot.layer = m.dis.nlay-1\n",
    "    # if head at bottom = -80 m then there is a head gradient of 1\n",
    "    chd_bot['head'] = m.dis.botm.array[chd_bot.layer[0], chd_bot.row, chd_bot.column]\n",
    "    # for a head gradient of 0.1 the head at the bottom must be 64m\n",
    "    # h = 80 - 0.1*160\n",
    "    h = 80 - 0.01*160 # check to see impact of lower gradient\n",
    "    chd_bot['head'] = h\n",
    "\n",
    "    chd_df = pd.concat((chd_df, chd_bot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep format for MF input: layer, row, column, shead, ehead\n",
    "chd_arr = chd_df.loc[:,['layer','row','column','head','head']].values\n",
    "chd.stress_period_data =  {0: chd_arr}\n",
    "chd.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chd.write_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output control\n",
    "# default unit number for heads is 51, cell by cell is 53 and drawdown is 52\n",
    "# (0,0) is (stress period, time step)\n",
    "\n",
    "# For later model runs when all the data is needed to be saved\n",
    "spd = { (j,0): ['save head', 'save budget'] for j in np.arange(0,nper,1)}\n",
    "\n",
    "# get the first of each month to print the budget\n",
    "month_intervals = (pd.date_range(strt_date,end_date, freq=\"MS\")-pd.to_datetime(strt_date)).days\n",
    "\n",
    "for j in month_intervals:\n",
    "    spd[j,0] = ['save head', 'save budget','print budget']\n",
    "    \n",
    "oc = flopy.modflow.ModflowOc(model = m, stress_period_data = spd, compact = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_outer = 200\n",
    "max_inner = 100\n",
    "\n",
    "solver = flopy.modflow.ModflowPcgn(m, iter_mo = max_outer, iter_mi=max_inner, close_r=1e-05, close_h=1e-06, ipunit=28) \n",
    "#                                 relax = 0.99, ifill=1)\n",
    "#                                adamp=1, damp=0.7, damp_lb=0.1, rate_d=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.write_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_package_list()\n",
    "# m.remove_package('DATA')\n",
    "# m.remove_package('LAK')\n",
    "# m.remove_package('WEL')\n",
    "# m.remove_package('RCH')\n",
    "# m.remove_package('NWT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# m.check()\n",
    "# lak.check()\n",
    "# upw.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadpth = 'C:/WRDAPP/GWFlowModel/Cosumnes_Blodgett_10yr/'\n",
    "# model_ws = loadpth+'WEL_SFR_RCH_layercake'\n",
    "# m = flopy.modflow.Modflow.load('MF.nam',model_ws = model_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.model_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the MODFLOW data files\n",
    "m.write_input()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Q = -kiA = -k\\frac{h1-h2}{L}A $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_v = pd.read_csv(join(loadpth,'vertical','flow_budget.txt'), delimiter=r'\\s+')\n",
    "wb_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_flux = (wb_v['CHD_IN']+wb_v['CHD_OUT'])/2\n",
    "\n",
    "h1 = 80\n",
    "h2 = 80 - 0.01*160 # check to see impact of lower gradient\n",
    "l = 160\n",
    "# calculate darcian velocity by dividing by area of model in the horizontal plane\n",
    "avg_q = avg_flux/(delc*nrow*delr*ncol)\n",
    "\n",
    "# permeameter calculated vertical conductivity\n",
    "p_vka = avg_q*l/(h1-h2)\n",
    "p_vka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmean(vka, axis=(0,1,2)) # if harmonic is applied directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal\n",
    "Model took almost 1 hr with 1E-4 residual close and 1E-5 head close but still had 7.9% error -> it looks like the lower head value was still at 34m somehow which probably caused the extreme error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_h = pd.read_csv(join(loadpth,'horizontal','flow_budget.txt'), delimiter=r'\\s+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_flux = (wb_h['CHD_IN']+wb_h['CHD_OUT'])/2\n",
    "\n",
    "h1 = 80\n",
    "h2 = 80 - 0.0001*(delr*ncol)\n",
    "l = delr*ncol\n",
    "# calculate darcian velocity by dividing by area of model in the vertical plane\n",
    "avg_q = avg_flux/(delc*nrow*160)\n",
    "\n",
    "# permeameter calculated vertical conductivity\n",
    "p_hk = avg_q*l/(h1-h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(hk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horiztonal y-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_h_y = pd.read_csv(join(loadpth,'horizontal_y','flow_budget.txt'), delimiter=r'\\s+')\n",
    "wb_h_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_flux = (wb_h_y['CHD_IN']+wb_h_y['CHD_OUT'])/2\n",
    "\n",
    "h1 = 80\n",
    "h2 = 80 - 0.0001*(delc*nrow)\n",
    "l = delr*ncol\n",
    "# calculate darcian velocity by dividing by area of model in the vertical plane\n",
    "avg_q = avg_flux/(delr*ncol*160)\n",
    "\n",
    "# permeameter calculated vertical conductivity\n",
    "p_hk_y = avg_q*l/(h1-h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hk_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(hk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_out = [['HK', np.nanmean(hk), p_hk.values[0]],\n",
    "         ['HK_Y', np.nanmean(hk, axis=(0,1,2)), p_hk_y.values[0]],\n",
    " ['VKA', hmean(vka, axis=(0,1,2)), p_vka.values[0]]]\n",
    "df_out = pd.DataFrame(k_out, columns=['name', 'calculated', 'permeameter'])\n",
    "df_out.to_csv(join(gwfm_dir, 'UPW_data', 'permeameter_regional.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translatation of DEM to SFR usable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj # for converting proj4string\n",
    "import pandas as pd\n",
    "import shapely \n",
    "import shapefile\n",
    "import geopandas as gpd\n",
    "from flopy.utils import Raster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_dir = os.getcwd()\n",
    "while basename(usr_dir) != 'Users':\n",
    "    temp = basename(usr_dir)\n",
    "    usr_dir = dirname(usr_dir)\n",
    "usr_dir += '/' + temp\n",
    "\n",
    "gwfm_dir = usr_dir+'/Box/research_cosumnes/GWFlowModel/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_name = os.path.join(os.getcwd(),'polygon\\polygon.shp')\n",
    "mb_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rivers and creeks in the larger area encompassing Cosumnes River in both South American and Cosumnes Subbasins\n",
    "rivers = gpd.read_file(\"Sac_valley_rivers/Sac_valley_rivers.shp\")\n",
    "mb = gpd.read_file(mb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers.plot()\n",
    "mb.plot()\n",
    "rivers = rivers.to_crs('EPSG:32610')\n",
    "rivers.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers_clip = gpd.clip(rivers, mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers_clip.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream segments, there is a new segment each time two rivers/creeks join one another\n",
    "cr_line = shapely.geometry.MultiLineString(cr.geometry.values)\n",
    "dc_line = shapely.geometry.MultiLineString(dc.geometry.values)\n",
    "cc_line = shapely.geometry.MultiLineString(cc.geometry.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from shapely.geometry import shape, mapping\n",
    "cr_line.crs = \"epsg:32610\"\n",
    "line = cr_line\n",
    "m.modelgrid.epsg\n",
    "\n",
    "crs = \"epsg:32610\"\n",
    "\n",
    "# line = line.next()\n",
    "\n",
    "geom = shape(line)\n",
    "\n",
    "# # length of the LineString\n",
    "length = geom.length\n",
    "\n",
    "# # creation of the resulting shapefile\n",
    "schema = {'geometry': 'Point','properties': {'id': 'int'}}\n",
    "\n",
    "with fiona.open('sfr_points/sfr_points.shp', 'w', 'ESRI Shapefile', schema, crs=crs) as output:\n",
    "#     # create points every 100 meters along the line\n",
    "    for i, distance in enumerate(range(0, int(length), 1)):\n",
    "         point = geom.interpolate(distance)   \n",
    "         output.write({'geometry':mapping(point),'properties': {'id':i}}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reaches are determined by where the model grid intersects a stream segment\n",
    "sfr_p = gpd.read_file('sfr_points/sfr_points.shp')\n",
    "sfr_p.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gets the corresponding polygons that contain the points\n",
    "grid_sfr = gpd.sjoin(grid_p, sfr_p, how = \"inner\", op= \"intersects\")\n",
    "# Essentially returns all the points as they all exist within the grid\n",
    "# sfr_grid = gpd.sjoin(sfr_p, grid_p, how = \"inner\", op= \"intersects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HEC RAS model XS tif view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "# src = rasterio.open(\"C:\\\\Users\\\\ajcalder\\\\Box\\\\Thalweg_data\\\\XS.tif\")\n",
    "src = rasterio.open(\"C:\\\\Users\\\\ajcalder\\\\Box\\\\Research_Calderwood\\\\Cos\\\\Terrain\\\\Terrain.Cos.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band1 = src.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize = (12,12))\n",
    "t = band1[:,:]\n",
    "t[t==-9999.]= float('NaN')\n",
    "plt.imshow(t)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(band1, vmin = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating cross section calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_ind = rivers_clip[rivers_clip.GNIS_Name == 'Cosumnes River']\n",
    "cr = rivers_clip.loc[cr_ind.index,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shapely\n",
    "try:\n",
    "    import flopy\n",
    "    from flopy.utils import Raster\n",
    "except:\n",
    "    fpth = os.path.abspath(os.path.join('..', '..'))\n",
    "    sys.path.append(fpth)\n",
    "    import flopy\n",
    "    from flopy.utils import Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spath = \"C://Users/ajcalder/Box/Research_Calderwood/dem\"\n",
    "\n",
    "raster_name = spath+'/USGS_ten_meter_dem/regional_10m.tif'\n",
    "\n",
    "rio10_utm = Raster.load(raster_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import linemerge\n",
    "geom = linemerge(cr.geometry.values)\n",
    "\n",
    "geom = geom.simplify(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geom = linemerge(cr.geometry.values)\n",
    "geom_up = geom.parallel_offset(100,'left', resolution = 32, join_style = 2)\n",
    "# right hand side offsets are returned in the reverse direction\n",
    "geom_down = geom.parallel_offset(100,'right', resolution = 32, join_style = 2)\n",
    "# simplifying the line increased the closeness of the total length of the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_down.length, geom_up.length, geom.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(np.linspace(1,3,3))\n",
    "temp['geometry'] = geom\n",
    "temp.geometry[1] = geom_up\n",
    "temp.geometry[2] = geom_down\n",
    "tempg = gpd.GeoDataFrame(temp)\n",
    "print(tempg)\n",
    "# tempg.plot(markersize = 0.01, column =0, legend = True)\n",
    "# shows that the parallel offset is doing what is should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from shapely.geometry import shape, mapping\n",
    "from shapely.ops import linemerge\n",
    "\n",
    "\n",
    "# how often to interpolate a point\n",
    "dline = 1000\n",
    "# # length of the LineString\n",
    "length = int(geom.length)\n",
    "\n",
    "pointup = np.zeros((int(length/dline)+1,2))\n",
    "pointdown = np.zeros((int(length/dline)+1,2))\n",
    "\n",
    "for i, distance in enumerate(range(0, int(length), dline)):\n",
    "    pointup[i,:] = geom_up.interpolate(distance).coords[:][0]\n",
    "    # Making it negative because it is flipped\n",
    "    pointdown[i,:] = geom_down.interpolate(-distance).coords[:][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString\n",
    "transects = pd.DataFrame(np.zeros((len(pointup),1)), columns = ['line'])\n",
    "transect = LineString([pointup[0], pointdown[0]])\n",
    "# transects.loc[0]= transect\n",
    "transects['geometry'] = transect\n",
    "for i in np.arange(0,len(pointup)):\n",
    "    transects.geometry[i] = LineString([pointup[i],pointdown[i]])\n",
    "    \n",
    "transects.line  = np.linspace(1,len(pointup),len(pointup))\n",
    "# transects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transg = gpd.GeoDataFrame(transects)\n",
    "transg = transg.drop_duplicates('geometry')\n",
    "transg = transg.drop(index = np.max(transg.index))\n",
    "transg = transg.drop(index = 0)\n",
    "transg.plot(column = 'line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transp = transg.geometry.buffer(5)[:]\n",
    "# buffer of 1 didn't capture enough pixels, buffer of 10 captured so it was 2-3 wide, buffer of 5 is just about 1 wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "r10 = rasterio.open(raster_name)\n",
    "dem10 = r10.read(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r10 = Raster.load(raster_name)\n",
    "# transp.values[10]\n",
    "# r10.plot()\n",
    "# test = r10.crop(transp.values[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r10.sample_polygon(transp.values[0], band = 1, invert = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r10.crop(transp.values[0], invert = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect='equal')\n",
    "\n",
    "ax = r10.plot(ax=ax)\n",
    "plt.colorbar(ax.images[0], shrink=0.7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = Raster.load(\"C:\\\\Users\\\\ajcalder\\\\Box\\\\Research_Calderwood\\\\Cos\\\\Terrain\\\\Terrain.Cos.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transp3 = transg.geometry.buffer(1.5)[:]\n",
    "# buffer of 1 didn't capture enough pixels, buffer of 10 captured so it was 2-3 wide, buffer of 5 is just about 1 wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos.sample_polygon(transp3.values[0], band = 1, invert = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos.sample_polygon(transp.values[0], band = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constantine 2001 cross sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Left value is site, right is distance downstream in kilometers\n",
    "xsm = pd.read_csv('setup_data\\\\XS_Constantine_manual.csv', sep = ',', skiprows = 1)\n",
    "xsm_refh = xsm.columns.values.astype(float)\n",
    "temp = np.vstack((xsm_refh[0::2], xsm_refh[1::2]))\n",
    "\n",
    "xsm_ref = pd.DataFrame(np.transpose(temp), columns = ['Site','Distance_m'])\n",
    "xsm_ref.Distance_m *=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "\n",
    "print(ctx.providers.keys())\n",
    "ctx.providers.Esri.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpath = \"C:\\\\Users\\\\ajcalder\\\\Box\\\\Thalweg_data\\\\thalweg_profile\\\\thalweg_profile.shp\"\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "\n",
    "\n",
    "\n",
    "tg = gpd.read_file(tpath)\n",
    "tg.crs = 'epsg:26910'\n",
    "tg = tg.rename(columns = {'Distance (':'Distance_m'})\n",
    "tg.Distance_m = np.round(tg.Distance_m, -1)\n",
    "# tg.loc[tg.Distance_m <= 840\n",
    "match = tg.merge(xsm_ref, on = 'Distance_m')\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "# extent for ctx axes comes from minx, maxx, miny, maxy\n",
    "minx, miny, maxx, maxy = tg.geometry.total_bounds\n",
    "ax.axis([minx, maxx, miny, maxy])\n",
    "\n",
    "match.plot(ax=ax)\n",
    "ctx.add_basemap(ax, source = ctx.providers.Esri.WorldImagery, crs=tg.crs.to_string(), alpha = 0.6)\n",
    "# ctx.add_basemap(ax, source = ctx.providers.Esri.WorldStreetMap, crs=tg.crs.to_string())\n",
    "\n",
    "plt.xlabel('Easting (m)')\n",
    "plt.ylabel('Northing (m)')\n",
    "\n",
    "plt.savefig('Plots/Model_SFR_UZF_Progress/Constantine XS Locations.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,12))\n",
    "# for i in np.arange(0,len(xsm)):\n",
    "#     plt.plot(xsm.iloc[:,i], xsm.iloc[:,i+1], ax=ax)\n",
    "plt.xlabel('Distance from left bank (m)')\n",
    "plt.ylabel('Elevation (m)')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.plot(xsm.iloc[:,0::2], xsm.iloc[:,1::2])\n",
    "plt.savefig('Plots/Model_SFR_UZF_Progress/Constantine_original_XS.png', dpi = 300, pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shapely.geometry import LineString\n",
    "# lp.geometry.iloc[0] = LineString([(0,0),(1,0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString\n",
    "i = 0\n",
    "# Number of cross sections\n",
    "numxs = int(len(xsm.columns))\n",
    "# i is the cross-section number\n",
    "lp = pd.DataFrame(np.linspace(1,int(numxs/2),int(numxs/2)))\n",
    "lp['geometry'] = LineString([(0,0),(0,1)])\n",
    "\n",
    "for i in np.arange(0,numxs,2):\n",
    "    # Number of points in each cross section\n",
    "    numl = np.sum(pd.notna(xsm.iloc[:,i]))\n",
    "    # Create empty array to fill with coordinates\n",
    "    lines = np.zeros((numl,2))\n",
    "    # j is the number of points in each individual cross-section\n",
    "    for j in np.arange(0,numl):\n",
    "        lines[j,:] = (xsm.iloc[j,i], xsm.iloc[j,i+1])\n",
    "    lm = LineString(lines)\n",
    "    tol = 0.0\n",
    "    deltol = 0.0001\n",
    "    count = 0\n",
    "    lms = LineString(lm).simplify(tolerance = tol)\n",
    "    while len(list(lms.coords))>10:\n",
    "        lms = LineString(lm).simplify(tolerance = tol)\n",
    "        tol += deltol\n",
    "        count += 1\n",
    "    lp.geometry.iloc[int(i/2)] = LineString(lms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(lm.coords)), len(list(lms.coords)))\n",
    "len(list(LineString(lm).simplify(tolerance = 0.4).coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lpg = gpd.GeoDataFrame(lp[:])\n",
    "# print(lpg)\n",
    "lpg.plot(markersize = 0.01, column =0, figsize = (10,10))\n",
    "# len(list(lms1.coords))\n",
    "plt.xlabel('Distance from left bank (m)')\n",
    "plt.ylabel('Elevation (m)')\n",
    "\n",
    "plt.savefig('Plots/Model_SFR_UZF_Progress/Constantine_simplified_XS_plot.png', dpi = 300, pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing this kind of plotting messes with the scale of the XS so do not do if printing output\n",
    "# lpg.geometry = lpg.scale(xfact=1,yfact=10)\n",
    "# lpg.plot(column = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(0, len(lp)):\n",
    "#     print(len(list(lp.geometry.iloc[i].coords)))\n",
    "# lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xscoords = np.zeros((10,numxs))\n",
    "filler = np.zeros(2)\n",
    "filler[:] = np.nan\n",
    "for i in np.arange(0, numxs,2):\n",
    "    coordtemp = np.array(list(lp.geometry.iloc[int(i/2)].coords))\n",
    "    while len(coordtemp)<10:\n",
    "        coordtemp = np.vstack((coordtemp,filler))\n",
    "    xscoords[:,i:i+2] = coordtemp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs_pd, xs_pd.loc[:,29]\n",
    "xs_pd.iloc[1,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_pd = pd.DataFrame(xscoords, columns = xsm_refh)\n",
    "xs_pd = xs_pd.drop(index = [0,9])\n",
    "for i in np.arange(0,len(xs_pd.columns),2):\n",
    "    xs_pd.iloc[:,i] -= xs_pd.iloc[0,i]\n",
    "xs_pd.loc[:,8:]\n",
    "xs_pd.to_csv('8pointXS.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match.to_file('8pointXS_locs\\\\8pointXS_locs.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Michigan Bar USGS Flow-Depth-Width Cross Section from manual measurement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units are ft, ft2, ft3/s or ft/s\n",
    "mb4 = pd.read_csv('setup_data\\\\michigan_bar_field_measurements.tsv', skiprows = 14, sep = '\\t', \n",
    "                  usecols = ['measurement_nu', 'measurement_dt','gage_height_va', 'discharge_va', 'chan_width',\n",
    "                             'chan_area','chan_velocity'], \n",
    "                  parse_dates = ['measurement_dt'])\n",
    "mb4 = mb4.drop(index = 0)\n",
    "mb4 = mb4.dropna(axis = 0)\n",
    "mb4 = mb4.loc[mb4.measurement_dt > '2000-01-01 00:00:00']\n",
    "mb4.gage_height_va = mb4.gage_height_va.astype('float')\n",
    "mb4.discharge_va = mb4.discharge_va.astype('float')\n",
    "mb4.chan_width = mb4.chan_width.astype('float')\n",
    "\n",
    "# mb4.plot.scatter('gage_height_va', 'discharge_va')\n",
    "mb4 = mb4.sort_values(by = 'gage_height_va')\n",
    "mblowest = mb4.iloc[0][['gage_height_va','discharge_va','chan_width']]\n",
    "\n",
    "# mb4.loc[mb4.gage_height_va.diff()>0.03].plot.scatter('gage_height_va', 'discharge_va')\n",
    "# Perform a rolling mean to create a more continuous data set that won't cause issues due to sharpness\n",
    "mb4r = mb4.rolling(window = 20).mean()\n",
    "# Remove NAs create by rolling mean\n",
    "mb4r = mb4r.dropna()\n",
    "# Works better to consecutively remove close points in case the first clearing gives sufficient room around some points\n",
    "mb4rl = mb4r.loc[mb4.gage_height_va.diff()>0.02]\n",
    "mb4rl = mb4rl.loc[mb4.gage_height_va.diff()>0.04]\n",
    "mb4rl = mb4rl.loc[mb4.gage_height_va.diff()>0.06]\n",
    "\n",
    "mb4rl = mb4rl.append(mblowest)\n",
    "mb4rl = mb4rl.sort_values(by = 'gage_height_va')\n",
    "\n",
    "mb4rl.gage_height_va = mb4rl.gage_height_va.values/3.28\n",
    "mb4rl.discharge_va = mb4rl.discharge_va.values/((3.28^3)/86400)\n",
    "mb4rl.chan_wdith = mb4rl.chan_width.values/3.28\n",
    "\n",
    "# mb4rl.plot.scatter('gage_height_va', 'discharge_va')\n",
    "len(mb4rl)\n",
    "mb4rl.to_csv('michigan_bar_icalc4_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabfile set up for SFR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the tab files the left column is time (in model units) and the right column is flow (model units)\n",
    "# Time is days, flow is cubic meters per day\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# USGS presents flow in cfs (cubic feet per second)\n",
    "inflow = pd.read_csv('USGS_MB_2017_oct.tsv', delimiter = '\\t')\n",
    "# inflow = pd.read_csv('USGS_MB_2018_01_01_to_2019_12_31_daily.tsv', delimiter = '\\t')\n",
    "\n",
    "inflow.columns\n",
    "flow_cfs = inflow['9996_00060_00003'].values.astype('float')\n",
    "flow_cmd = flow_cfs * (86400/(3.28**3))\n",
    "\n",
    "# np.arange(0,len(flow_cmd))\n",
    "time_flow = np.vstack((np.arange(0,len(flow_cmd)),flow_cmd))\n",
    "time_flow = np.transpose(time_flow)\n",
    "np.savetxt('data/MF.tab',time_flow, delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

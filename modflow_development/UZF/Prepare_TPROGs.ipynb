{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import time\n",
    "\n",
    "# unique functions for this notebook\n",
    "import numpy.ma as ma\n",
    "from scipy.stats import hmean\n",
    "from scipy.stats import gmean\n",
    "\n",
    "# standard python plotting utilities\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import pyproj # for converting proj4string\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# mapping utilities\n",
    "import contextily as ctx\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run installed version of flopy or add local path\n",
    "import flopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while os.path.basename(doc_dir) != 'Documents':\n",
    "    doc_dir = os.path.dirname(doc_dir)\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = os.path.dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel'\n",
    "gwfm_dir\n",
    "# upw dir\n",
    "upw_dir = gwfm_dir+'/UPW_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the simpler model with less load required\n",
    "# use the simpler model with less load required\n",
    "# loadpth = gwfm_dir+'/JupyterNotebooks/WEL/data'\n",
    "\n",
    "load_only = ['BAS6','DIS']\n",
    "m = flopy.modflow.Modflow.load('MF.nam', model_ws= model_ws, \n",
    "                                exe_name='mf-owhm', version='mfnwt',\n",
    "                               load_only = load_only\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = m.dis.nrow\n",
    "ncol = m.dis.ncol\n",
    "nlay = m.dis.nlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model grid as geopandas object\n",
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n",
    "# grid_p = gpd.read_file(gwfm_dir+'/DIS_data/44_7_grid/44_7_grid.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load kriged water table data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raster cropping will be done in outside script so the only part read in will be the final array\n",
    "ghb_dir = gwfm_dir+'/GHB_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strtyear = 2013\n",
    "endyear = 2019\n",
    "kriged_fall = np.zeros((int(endyear-strtyear),nrow,ncol))\n",
    "kriged_spring = np.zeros((int(endyear-strtyear),nrow,ncol))\n",
    "\n",
    "kriged_NW = np.zeros((int(endyear-strtyear)*2,ncol))\n",
    "kriged_SE = np.zeros((int(endyear-strtyear)*2,ncol))\n",
    "# keep track of which place in array matches to year\n",
    "year_to_int = np.zeros((endyear-strtyear,2))\n",
    "\n",
    "t=0\n",
    "for year in np.arange(strtyear,endyear):\n",
    "    \n",
    "    # load and place spring kriged data in np array, load spring first\n",
    "    filename = glob.glob(ghb_dir+'/final_WSEL_arrays/spring'+str(year)+'_kriged_WSEL.tsv')[0]\n",
    "    df_grid = np.loadtxt(filename)\n",
    "    kriged_spring[t,:,:] = df_grid\n",
    "    \n",
    "    # load and place fall kriged data in np array\n",
    "    filename = glob.glob(ghb_dir+'/final_WSEL_arrays/fall'+str(year)+'_kriged_WSEL.tsv')[0]\n",
    "    df_grid = np.loadtxt(filename)\n",
    "    kriged_fall[t,:,:] = df_grid\n",
    "\n",
    "    \n",
    "    # save NW  dataframe\n",
    "    kriged_NW[t] = kriged_spring[t,0,:]\n",
    "    kriged_NW[2*t] = kriged_fall[t,0,:]\n",
    "    # save SE data frame\n",
    "    kriged_SE[t] = kriged_spring[t,0,:]\n",
    "    kriged_SE[2*t] = kriged_fall[t,0,:]\n",
    "    \n",
    "    year_to_int[t,0] = t\n",
    "    year_to_int[t,1] = year\n",
    "    t+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.arange(strtyear, endyear),'mean water elevation by year',np.nanmean(df_grid,axis=(0,1)))\n",
    "# 2015 represents the lowest water, 2018 the highest, 2016 median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in TPROGS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprogs_dir = os.path.dirname(gwfm_dir)+'/Large_TPROGS_run/New_realizations/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"C:\\Users\\ajcalder\\Box\\research_cosumnes\\Large_TPROGS_run\\TPROGS_realizations\\tsim_Cosumnes_Full_Model.asc1\"\n",
    "# create tprogs directory reference to 100 large tprogs runs ascii files\n",
    "tprogs_dir = os.path.dirname(gwfm_dir)+'/Large_TPROGS_run/TPROGS_realizations_final/'\n",
    "\n",
    "# get all file names\n",
    "tprogs_line_files = glob.glob(tprogs_dir+'*')\n",
    "\n",
    "mf_tprogs_dir = gwfm_dir+'/UPW_data/tprogs_final/'\n",
    "tprogs_files = glob.glob(mf_tprogs_dir+'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"C:\\Users\\ajcalder\\Box\\research_cosumnes\\Large_TPROGS_run\\TPROGS_realizations\\tsim_Cosumnes_Full_Model.asc1\"\n",
    "# create tprogs directory reference to 100 large tprogs runs ascii files\n",
    "tprogs_dir = os.path.dirname(gwfm_dir)+'/Large_TPROGS_run/New_realizations/'\n",
    "\n",
    "# get all file names\n",
    "tprogs_line_files = glob.glob(tprogs_dir+'*asc*')\n",
    "\n",
    "mf_tprogs_dir = gwfm_dir+'/UPW_data/tprogs_final_no_conditioning/'\n",
    "tprogs_files = glob.glob(mf_tprogs_dir+'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neither for the original large or new tprogs data did I sort tprogs_line_files\n",
    "# this means that they are out of order because singular digits (1,2) are included with the 10s, 20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "# # takes ~1.5 hours to reshape and save to new folder\n",
    "# for n in np.arange(0,len(tprogs_line_files)):\n",
    "#     tprogs_line = np.loadtxt(tprogs_line_files[n],skiprows = 1)\n",
    "#     tprogs_arr = np.reshape(tprogs_line, (320, 100, 230 )) #z,x,y\n",
    "\n",
    "#     name = mf_tprogs_dir+'/tsim_realization'+str(n).zfill(3)+'.tsv'\n",
    "#     np.savetxt(name,np.reshape(tprogs_arr, (320*100,230)), delimiter = '\\t')\n",
    "                   \n",
    "# resample_time = time.time() - t0\n",
    "# print(\"Resample time, nearest neighbor: {:.3f} sec\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprogs_line = np.loadtxt(tprogs_line_files[0],skiprows = 1)\n",
    "tprogs_arr = np.reshape(tprogs_line, (320, 100, 230 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprogs_arr = np.reshape(tprogs_line, (320, 100,230))\n",
    "tprogs_elev = np.copy(tprogs_arr)\n",
    "plt.scatter(np.where(tprogs_arr<0)[1],np.where(tprogs_arr<0)[2],0.2)\n",
    "# # the bottom layer of the tprogs model is at -50 m amsl and the top layer is 50 m amsl\n",
    "# t = 0\n",
    "# for k in np.arange(-80,80,0.5):\n",
    "#     tprogs_elev[t,dem_data<k]= np.NaN\n",
    "#     t+=1\n",
    "# masked_tprogs = ma.masked_invalid(tprogs_elev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tprogs_cut_elev(tprogs_line)[180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Maribeth's grid aligned with Alisha's TPROGS model\n",
    "# dem_data = np.loadtxt(gwfm_dir+'\\DIS_data\\dem_52_9_200m_nearest.tsv', delimiter = '\\t')\n",
    "dem_data = np.loadtxt(gwfm_dir+'\\DIS_data\\dem_52_9_200m_linear.tsv', delimiter = '\\t')\n",
    "# dem_data = np.loadtxt(gwfm_dir+'\\DIS_data\\dem_44_7_200m_linear_missing_right_corner.tsv', delimiter = '\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tprogs_cut_elev(tprogs_line):\n",
    "    tprogs_arr = np.reshape(tprogs_line, (320, 100,230))\n",
    "    tprogs_elev = np.copy(tprogs_arr)\n",
    "    # the bottom layer of the tprogs model is at -50 m amsl and the top layer is 50 m amsl\n",
    "    t = 0\n",
    "    for k in np.arange(-80,80,0.5):\n",
    "        tprogs_elev[t,dem_data<k]= np.NaN\n",
    "        t+=1\n",
    "    masked_tprogs = ma.masked_invalid(tprogs_elev)\n",
    "    return(masked_tprogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.ma as ma\n",
    "def tprogs_cut_saturated(tprogs,kriged):\n",
    "    tprogs_unsat = np.copy(tprogs)\n",
    "    # the bottom layer of the tprogs model is at -80 m amsl and the top layer is 80 m amsl\n",
    "    # set any tprogs cells below the average fall water table depth as np.nan\n",
    "    t = 0\n",
    "    for k in np.arange(-80,80,0.5):\n",
    "        tprogs_unsat[t,kriged>k]= np.NaN\n",
    "        t+=1\n",
    "    masked_tprogs = ma.masked_invalid(tprogs_unsat)\n",
    "    return(masked_tprogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_param(tprogs):\n",
    "    tprogs[tprogs<0] *= -1\n",
    "    tprogs = tprogs.astype(float)\n",
    "    tprogs_K = np.copy(tprogs)\n",
    "    tprogs_Sy = np.copy(tprogs)\n",
    "    tprogs_Ss = np.copy(tprogs)\n",
    "    # hydraulic parameters from fleckenstein 2006\n",
    "    # I-IV gravel, sand, muddy sand, mud\n",
    "    # K in m/s, Sy, Ss\n",
    "    params = np.asarray([[4e-3,1.5e-3,2.5e-4,6.5e-6],\n",
    "                         [0.25,0.2,0.15,0.1],\n",
    "                         [2.0e-5,8e-5,2e-4,5e-4]])\n",
    "    for n in np.arange(1,5):\n",
    "        tprogs_K[tprogs==n]= params[0,n-1]\n",
    "    for n in np.arange(1,5):\n",
    "        tprogs_Sy[tprogs==n]= params[1,n-1]\n",
    "    for n in np.arange(1,5):\n",
    "        tprogs_Ss[tprogs==n]= params[2,n-1]\n",
    "            \n",
    "    return(tprogs_K,tprogs_Sy,tprogs_Ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary botm array for tprogs\n",
    "botm = np.array([[np.arange(-80,80,0.5)]*230]*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0\n",
    "tprogs_line = np.loadtxt(tprogs_files[t])\n",
    "masked_tprogs=tprogs_cut_elev(tprogs_line)\n",
    "K, Sy, Ss= int_to_param(masked_tprogs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kriged_fall_avg = np.nanmean(kriged_fall,axis=0)\n",
    "kriged_spring_avg = np.nanmean(kriged_spring,axis=0)\n",
    "kriged_fall_spring_avg = (kriged_fall_avg+kriged_spring_avg)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsat_tprogs_fall = tprogs_cut_saturated(K,kriged_fall_avg)\n",
    "unsat_tprogs_spring = tprogs_cut_saturated(K,kriged_spring_avg)\n",
    "unsat_tprogs_fall_spring = tprogs_cut_saturated(K,kriged_fall_spring_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(kriged_fall_avg-kriged_spring_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average percent error between fall and spring\n",
    "harm_err = np.mean(np.abs((hmean(unsat_tprogs_fall,axis=0)-hmean(unsat_tprogs_spring,axis=0)))/hmean(unsat_tprogs_fall,axis=0))\n",
    "# calculate the average percent error between fall and spring\n",
    "geom_err = np.mean(np.abs((gmean(unsat_tprogs_fall,axis=0)-gmean(unsat_tprogs_spring,axis=0)))/gmean(unsat_tprogs_fall,axis=0))\n",
    "harm_err,geom_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,3))\n",
    "im=ax[0].imshow(hmean(unsat_tprogs_fall,axis=0)*86400,norm=mpl.colors.LogNorm())\n",
    "plt.colorbar(im,ax=ax[0],orientation = 'horizontal')\n",
    "im=ax[1].imshow(gmean(unsat_tprogs_fall,axis=0)*86400,norm=mpl.colors.LogNorm())\n",
    "plt.colorbar(im,ax=ax[1],orientation = 'horizontal')\n",
    "fig.suptitle('Fall')\n",
    "plt.show()\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,3))\n",
    "im=ax[0].imshow(hmean(unsat_tprogs_spring,axis=0)*86400,norm=mpl.colors.LogNorm())\n",
    "plt.colorbar(im,ax=ax[0],orientation = 'horizontal')\n",
    "im=ax[1].imshow(gmean(unsat_tprogs_spring,axis=0)*86400,norm=mpl.colors.LogNorm())\n",
    "plt.colorbar(im,ax=ax[1],orientation = 'horizontal')\n",
    "fig.suptitle('Spring')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(unsat_tprogs_fall.data[100,:,:])\n",
    "plt.show()\n",
    "plt.imshow(unsat_tprogs_spring.data[100,:,:])\n",
    "plt.show()\n",
    "plt.imshow(unsat_tprogs_fall_spring.data[100,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nansum(unsat_tprogs_fall.data-unsat_tprogs_spring.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def side_by_side_XS(fall_arr,spring_arr, fall_spring_arr, row,  aspect):\n",
    "    fig,ax = plt.subplots(1,3,figsize=(15,3))\n",
    "    im=ax[0].imshow(fall_arr[:,row,:], norm=mpl.colors.LogNorm(),aspect = aspect, origin='lower')\n",
    "    plt.colorbar(im,ax=ax[0],orientation = 'horizontal')\n",
    "    ax[0].set_title('Fall')\n",
    "    im=ax[1].imshow(spring_arr[:,row,:], norm=mpl.colors.LogNorm(),aspect = aspect, origin='lower')\n",
    "    plt.colorbar(im,ax=ax[1],orientation = 'horizontal')\n",
    "    ax[1].set_title('Spring')\n",
    "    im=ax[2].imshow(fall_spring_arr[:,row,:], norm=mpl.colors.LogNorm(),aspect = aspect, origin='lower')\n",
    "    plt.colorbar(im,ax=ax[2],orientation = 'horizontal')\n",
    "    ax[2].set_title('Fall-Spring Avg')\n",
    "    fig.suptitle('Row '+ str(row))\n",
    "    plt.show()\n",
    "    \n",
    "temp = unsat_tprogs_fall\n",
    "temp2 = unsat_tprogs_spring\n",
    "temp3 = unsat_tprogs_fall_spring\n",
    "side_by_side_XS(temp, temp2,temp3, row=0, aspect=1/4)\n",
    "side_by_side_XS(temp, temp2, temp3, row=50, aspect=1/4)\n",
    "side_by_side_XS(temp, temp2, temp3, row=99, aspect=1/4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the UZF package these cross sections will make up the upscaled vertical hydraulic conductivity. If there are cells without any tprogs cells then it will assume the background hydraulic conductivity to avoid sampling a random cell that could be very high and cause falsely large recharge rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "uzf_dir = gwfm_dir+'/UZF_data'\n",
    "geom_nam = uzf_dir+'/upscaled_tprogs_for_unsaturated_zone/tprogs_geom_k_m_d'+str(n).zfill(3)+'.tsv'\n",
    "harm_nam = uzf_dir+'/upscaled_tprogs_for_unsaturated_zone/tprogs_harm_k_m_d'+str(n).zfill(3)+'.tsv'\n",
    "\n",
    "np.savetxt(geom_nam, gmeanupscale*86400, delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmeanupscale.mean()*86400, gmeanupscale.mean()*86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hmeanupscale*86400,norm=mpl.colors.LogNorm())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(gmeanupscale*86400,norm=mpl.colors.LogNorm())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # col, row, layer 230, 100, 320\n",
    "# # tprogs_arr = np.reshape(tprogs_line, (230, 100,320))\n",
    "# tprogs_arr = np.reshape(tprogs_line, (320, 100, 230 ))\n",
    "\n",
    "# fig, ax = plt.subplots(1,3, figsize=(12,6))\n",
    "# #first layer\n",
    "# im = ax[0].imshow(tprogs_arr[:,:,0])\n",
    "# fig.colorbar(im, ax=ax[0], orientation = 'horizontal')\n",
    "# # first row\n",
    "# im = ax[1].imshow(tprogs_arr[:,0,:])\n",
    "# fig.colorbar(im, ax=ax[1], orientation = 'horizontal')\n",
    "# # first column\n",
    "# im = ax[2].imshow(tprogs_arr[0,:,:])\n",
    "# fig.colorbar(im, ax=ax[2], orientation = 'horizontal')\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "\n",
    "# im=ax.imshow(np.flipud(np.transpose(tprogs[:,59,:])),norm=mpl.colors.LogNorm(), aspect=1/10)\n",
    "plt.imshow(np.flipud(tprogs[:,50,:]),norm=mpl.colors.LogNorm(),aspect=1/4)\n",
    "# plt.imshow(tprogs[:,50,:],norm=mpl.colors.LogNorm())\n",
    "plt.title('aspect is 1/100 for z to y')\n",
    "# fig.colorbar(im, ax=ax, shrink = 0.1)\n",
    "plt.show()\n",
    "# plt.imshow(tprogs[0,:,:],norm=mpl.colors.LogNorm())\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

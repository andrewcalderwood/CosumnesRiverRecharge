{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e5d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import dirname, basename\n",
    "import glob\n",
    "\n",
    "import calendar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e75e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while os.path.basename(doc_dir) != 'Documents':\n",
    "    doc_dir = os.path.dirname(doc_dir)\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = os.path.dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel/'\n",
    "proj_dir = gwfm_dir+'/Levee_setback/air2stream_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5273e803",
   "metadata": {},
   "source": [
    "# Load RBI stream temperature and discharge data\n",
    "Temperature data was daily averaged already in RBI spreadsheets.  \n",
    "Flow data was daily averaged as well, RBI notes in their reports that any flow above 200 CFS is estimated using a rating curve based on HEC-RAS model results for Rooney and Mahon (i.e., stream flow was only measured below 200 CFS).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load temperature data from RBI\n",
    "tmp = pd.read_excel(proj_dir+'/RBI_data_cleaned/00_manual_joined_data.xlsx',\n",
    "                    sheet_name='Temperature',na_values='-')\n",
    "# convert to long format to create dates\n",
    "tmp = tmp.melt(id_vars = ['Site_ID','Day','WY','Measurement'])\n",
    "# create a numeric month for date creation/year adjustment\n",
    "tmp['month'] = [list(calendar.month_name).index(tmp.variable[n]) for n in np.arange(0,len(tmp))]\n",
    "# calculate year by adjusting water year\n",
    "tmp['year'] = tmp['WY'].copy()\n",
    "tmp.loc[tmp.month>9,'year'] -= 1\n",
    "\n",
    "# 0 values were used as NA values in some years\n",
    "tmp.loc[tmp.value==0, 'value'] = np.NaN\n",
    "tmp = tmp.dropna(subset=['value'])\n",
    "\n",
    "# create date column\n",
    "tmp['date'] = tmp['year'].astype(str).str.cat(tmp[['month','Day']].astype(str), sep='-')\n",
    "tmp['date'] = pd.to_datetime(tmp.date)\n",
    "\n",
    "# pivot wider\n",
    "tmp_out = tmp.pivot(index='date',values='value',columns='Site_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed79f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load flow data from RBI\n",
    "flw = pd.read_excel(proj_dir+'/RBI_data_cleaned/00_manual_joined_data.xlsx', \n",
    "                    sheet_name='Flow', header=[0,1],na_values='-')\n",
    "# melt longer flow data to get average data out\n",
    "flw = flw.melt(id_vars = [flw.columns[0]])\n",
    "# rename columns\n",
    "flw.columns=['Date','Site_ID','Statistic','value']\n",
    "# create datetime column\n",
    "flw.Date = pd.to_datetime(flw.Date)\n",
    "# filter to average flows\n",
    "flw = flw[flw.Statistic.isin(['Average','Estimated'])]\n",
    "# filter to flashboard dam monitoring sites only\n",
    "flw = flw[~(flw.Site_ID=='Michigan Bar')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flw.pivot_table(columns = ['Statistic'], values='value')\n",
    "flw_adj = flw.pivot(index=['Date','Site_ID'],columns = ['Statistic'], values='value')\n",
    "flw_adj.loc[flw_adj.Estimated.notna(), 'Average'] = flw_adj.loc[flw_adj.Estimated.notna(), 'Estimated']\n",
    "flw_out = flw_adj.drop(columns='Estimated').reset_index('Site_ID').pivot(columns=['Site_ID'],values='Average')\n",
    "# flw.pivot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d05e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_out.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flw_out.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dfe060",
   "metadata": {},
   "source": [
    "# Michigan Bar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03168551",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = proj_dir+'/Michigan_bar_daily_discharge_temperature_2012_2016.csv'\n",
    "if len(glob.glob(fn))==0:\n",
    "    mb = pd.read_csv(proj_dir+'/Michigan_bar_discharge_temperature_2012_2016.csv',index_col=None)\n",
    "    mb['dt'] = pd.to_datetime(mb.date.str.cat(mb[['time']], sep=' '))\n",
    "    mb_daily = mb.set_index('dt').resample('D').mean()\n",
    "    mb_daily.to_csv(proj_dir+'/Michigan_bar_daily_discharge_temperature_2012_2016.csv')\n",
    "elif len(glob.glob(fn))==1:\n",
    "    mb = pd.read_csv(proj_dir+'/Michigan_bar_daily_discharge_temperature_2012_2016.csv')\n",
    "    mb.dt = pd.to_datetime(mb.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb.set_index('dt').plot(y='temperature_C')\n",
    "mb.set_index('dt').plot(y='Discharge_cfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c7a675",
   "metadata": {},
   "source": [
    "# Air temperature\n",
    "CSU - Only CDEC station with active data during necessary period and ~13 miles away. 38.555, -121.416, elevation of 25 ft.\n",
    "Michigan bar is at an elevation of 168 ft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e06775",
   "metadata": {},
   "outputs": [],
   "source": [
    "csu = pd.read_csv(proj_dir+'CSU_air_temperature.csv',parse_dates=['OBS DATE'])\n",
    "csu = csu[['OBS DATE','VALUE']].rename(columns={'VALUE':'Temperature_F'}).set_index('OBS DATE')\n",
    "# convert fahrenheit to celsius\n",
    "csu['SacState'] = (csu.Temperature_F - 32)/1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csu = csu['SacState'].resample('D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c202e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cimis = pd.read_csv(proj_dir+'CIMIS_multi_station_daily.csv', parse_dates=['Date'])\n",
    "cimis = cimis.dropna(subset=['Stn Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b0310",
   "metadata": {},
   "outputs": [],
   "source": [
    "airtmp = cimis[['Date','Stn Name','Avg Air Temp (C)']].pivot(columns='Stn Name', values='Avg Air Temp (C)', index='Date')\n",
    "# add sac state data for comparison\n",
    "airtmp = airtmp.join(csu)\n",
    "\n",
    "airtmp = airtmp.dropna(how='all')\n",
    "\n",
    "\n",
    "# airtmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dbdc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(1,2,figsize=(12,8), sharex=True)\n",
    "\n",
    "ax_n = axes[0]\n",
    "airtmp.plot(ax=ax_n)\n",
    "ax_n.set_ylabel(' Temp (C)')\n",
    "ax_n = axes[1]\n",
    "airtmp.std(axis=1).plot(ax=ax_n)\n",
    "ax_n.set_ylabel('Std Dev Temp (C)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0020742",
   "metadata": {},
   "source": [
    "On a long term scale the temperatures look like they overlap but the standard deviation suggests typical variations of 0 to 2.5 degrees celsius in magnitude. However, what is more important is if the temperatures are following the same diurnal cycles as the water temperature as the parameters can be adjusted assuming a change in the rate of heat exchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(1,2,figsize=(12,4), sharex=True)\n",
    "\n",
    "ax_n = axes[0]\n",
    "airtmp.plot(ax=ax_n)\n",
    "ax_n.set_ylabel(' Temp (C)')\n",
    "ax_n = axes[1]\n",
    "airtmp.std(axis=1).plot(ax=ax_n)\n",
    "ax_n.set_ylabel('Std Dev Temp (C)')\n",
    "\n",
    "ax_n.set_xlim('2005-10-01','2006-09-30')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf42e7a",
   "metadata": {},
   "source": [
    "On an annual scale it looks like the Fair Oaks and Sacramento stations generally follow change in temperature well, but are primarily offset. This may be because the CIMIS stations should be sited on a grass area of 30x30 ft, hopefully this is more representative of a natural environment. I will go with the CIMIS station data because it also has enough data available to do a full heat budget for the river if needed.  \n",
    "**CIMIS data at Fair Oaks will be used for air2stream**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7576e0ae",
   "metadata": {},
   "source": [
    "# air2stream input\n",
    "\n",
    "Always daily scale and the air2stream model automatically calculates the calibration fit on weekly,monthly and annual scales with some adjustment for data available threshold set by user (e.g., must have at least 60% of days with water temperature data).  \n",
    "The air temperature (Ta) and discharge (Q) datasets should be complete. The water temperature (Tw) data set can have no-data values specified by the user in the input (e.g., -999).  \n",
    "\n",
    "Typeofseries explanation:  \n",
    "cc = continuous calibration  \n",
    "cv = continuous validation  \n",
    "\n",
    "Main input file follows style:  \n",
    "Name = IDair_IDwater_typeofseries.txt, example = MAH_2369_cc.txt  \n",
    "Columns:  \n",
    "year month day airtemp watertemp discharge\n",
    "\n",
    "-If validation is less than 1 year it is skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd791019",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_dir = doc_dir+'/GitHub/CosumnesRiverRecharge/'\n",
    "run_dir = git_dir+'Projects/Levee_setback/air2stream/Cosumnes/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a364f",
   "metadata": {},
   "source": [
    "## Michigan Bar Test\n",
    "Test case with Michigan Bar data from 2012-2016, dataset of interest is at Rooney, Mahon from 2003-2011 off and on. Michigan Bar data doesn't have any missing discharge data comapred to Rooney/Mahon\n",
    "\n",
    "There was a short period of air temperature data missing (4/15-4/18-4/20). I linearly interpolated the data as this was a short period (<3 days) and would have much less impact on the weekly/monthly estimates. The validation was not completed because it considered validation period less than 1 year.  \n",
    "Computation time was 34 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b977efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mb_input.dt.diff().plot()\n",
    "mb_input[mb_input.dt.diff()>'1 day']\n",
    "# there is a break in days at 1122, 1124\n",
    "# 4/15 to 4/18 to 4/20 and \n",
    "mb_input[1118:1125]\n",
    "# let's say that about a week of data is acceptable to be filled in linearly if there are only a few periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121d2f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_input = mb.join(airtmp['Fair Oaks'], on='dt')\n",
    "\n",
    "# acceptable to linearly interpolate some air temperature data to avoid data gaps if short\n",
    "# mb_input = mb_input.dropna(subset=['Fair Oaks'])\n",
    "mb_input = mb_input.set_index('dt').interpolate(method='linear').reset_index()\n",
    "\n",
    "\n",
    "# round input \n",
    "mb_input = mb_input.round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2cc1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# partition available data into calibration and validation datasets\n",
    "# assumes 80% is a good mix for calibration data (John Hermann suggested this in class)\n",
    "cal_percent = 0.70\n",
    "cal_end = mb_input.dt.min()+ (mb_input.dt.max()-mb_input.dt.min())*cal_percent\n",
    "mb_cal = mb_input[mb_input.dt < cal_end]\n",
    "mb_val = mb_input[mb_input.dt >= cal_end]\n",
    "def prep_input(df):\n",
    "    df[['year','month','day']] = df.dt.astype(str).str.split('-',expand=True)\n",
    "    df = df[['year','month','day','Fair Oaks', 'temperature_C', 'Discharge_cfs']]\n",
    "    return(df)\n",
    "\n",
    "mb_cal = prep_input(mb_cal)\n",
    "mb_cal.to_csv(run_dir+'131_MHB_cc.txt', sep=' ', index=False, header=False)\n",
    "\n",
    "mb_val = prep_input(mb_val)\n",
    "mb_val.to_csv(run_dir+'131_MHB_cv.txt', sep=' ', index=False, header=False)\n",
    "# # np.savetxt(run_dir+'131_MHB_cc.txt', mb_input.values.astype(float), fmt='%10.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b1b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e87517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flw_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d9e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_cal.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d601981",
   "metadata": {},
   "source": [
    "# Post-processing\n",
    "Forward run is same input with process changed fro PSO to forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca2d907",
   "metadata": {},
   "source": [
    "year, month, day, observed air temperature, observed water temperature,simulated water temperature  \n",
    "observed water temperature aggregated at the time scale chosen in file 'input.txt' (e.g., 1m)   \n",
    "simulated water temperature aggregated at the time scale chosen in file 'input.txt' (e.g., 1m)   \n",
    "discharge at daily time scale  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2606fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters with lowest error\n",
    "params_out = pd.read_csv(glob.glob(run_dir+'output_8/1*')[0], delimiter = r'\\s+', header=None)\n",
    "cols = ['year','month','day', 'Ta_obs','Tw_obs', 'Tw_sim','Tw_obs_agg','Tw_sim_agg', 'Q']\n",
    "# validation\n",
    "cv_out = pd.read_csv(glob.glob(run_dir+'output_8/*cv*')[0], delimiter = r'\\s+', header=None, names = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  calibration\n",
    "cc_out = pd.read_csv(glob.glob(run_dir+'output_8/*cc*')[0], delimiter = r'\\s+', header=None, names = cols)\n",
    "# drop missing dates\n",
    "cc_out = cc_out[cc_out.day!=-999]\n",
    "# create date column\n",
    "cc_out['date'] = pd.to_datetime(cc_out[['year','month','day']], format='%Y%m%d')\n",
    "cc_out = cc_out.set_index('date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,1, figsize=(6,10), sharex=True)\n",
    "\n",
    "\n",
    "cc_out.plot(y='Q', ax = axes[0], legend=False)\n",
    "axes[0].set_ylabel('Discharge (cfs)')\n",
    "cc_out.plot(y='Ta_obs', ax = axes[1], legend=False)\n",
    "axes[1].set_ylabel('Air Temperature (C)')\n",
    "\n",
    "ax_n = axes[2]\n",
    "cc_out.plot(y='Tw_obs', ax=ax_n, label='Observed')\n",
    "cc_out.plot(y='Tw_sim', ax=ax_n, label='Simulated')\n",
    "ax_n.set_ylabel('Water Temperature (C)')\n",
    "\n",
    "ax_n = axes[3]\n",
    "cc_out.plot(y='Tw_obs_agg', ax=ax_n, label='Observed')\n",
    "cc_out.plot(y='Tw_sim_agg', ax=ax_n, label='Simulated')\n",
    "ax_n.set_ylabel('Aggregated\\nWater Temperature (C)')\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

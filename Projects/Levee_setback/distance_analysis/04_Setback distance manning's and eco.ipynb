{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38509e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "from os.path import dirname, basename, exists, join\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import time\n",
    "\n",
    "# standard python plotting utilities\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import pyproj # for converting proj4string\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# mapping utilities\n",
    "import contextily as ctx\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3059fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "    \n",
    "git_dir = join(doc_dir,'GitHub','CosumnesRiverRecharge')\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = join(dirname(doc_dir),'Box/research_cosumnes/GWFlowModel')\n",
    "\n",
    "flopy_dir = doc_dir+'/GitHub/flopy'\n",
    "if flopy_dir not in sys.path:\n",
    "    sys.path.insert(0, flopy_dir)\n",
    "\n",
    "import flopy \n",
    "import flopy.utils.binaryfile as bf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set box directory for output figures and data\n",
    "box_dir = gwfm_dir+'/Levee_setback/levee_setback_distance_analysis/'\n",
    "\n",
    "fig_dir = box_dir+'figures/'\n",
    "data_dir = box_dir+'data_output/'\n",
    "\n",
    "chan_dir = box_dir+'channel_data/'\n",
    "gis_dir = chan_dir+'GIS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df4324",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dir = 'F:/WRDAPP'\n",
    "c_dir = 'C:/WRDAPP'\n",
    "\n",
    "if os.path.exists(ext_dir):\n",
    "    loadpth = ext_dir \n",
    "elif os.path.exists(c_dir):\n",
    "    loadpth = c_dir \n",
    "\n",
    "loadpth = loadpth +'/GWFlowModel/Cosumnes/levee_setback/'\n",
    "model_ws = loadpth+'flood_depth_analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2339e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 100\n",
    "ncol = 230\n",
    "nlay = 1\n",
    "delr = 200\n",
    "delc = 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# burn river shapefile into the 10 meter dem and then read it out to find the cells where it is\n",
    "# from flopy.utils import Raster\n",
    "# # Full size dem of northern sac valley\n",
    "raster_name = gwfm_dir+\"/DEM_data/USGS_ten_meter_dem/modeldomain_10m_transformed.tif\"\n",
    "\n",
    "# # rio10_utm = Raster.load(raster_name)\n",
    "# rio10_utm = rasterio.open(raster_name)\n",
    "# dem_10m = rio10_utm.read((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f27790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_sfr = gpd.read_file(gwfm_dir+'/SFR_data/final_grid_sfr/grid_sfr.shp')\n",
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n",
    "\n",
    "m_domain = gpd.read_file(gwfm_dir+'/DIS_data/NewModelDomain/GWModelDomain_52_9deg_UTM10N_WGS84.shp')\n",
    "grid_sfr = gpd.read_file(gwfm_dir+'/SFR_data/final_grid_sfr/grid_sfr.shp')\n",
    "# load sacramento river, creeks\n",
    "rivers = gpd.read_file(gwfm_dir+'/SFR_data/Sac_valley_rivers/Sac_valley_rivers.shp')\n",
    "cr = gpd.overlay(rivers.loc[rivers.GNIS_Name=='Cosumnes River'].to_crs('epsg:32610'), m_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95639645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiLineString, LineString, Point, shape, mapping\n",
    "from shapely.ops import linemerge\n",
    "import fiona\n",
    "\n",
    "cr_line = MultiLineString(cr.geometry.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef100729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(join(chan_dir, 'setback_locs.hdf5'), \"r\")\n",
    "local_str_setbacks = f['setbacks']['local'][:]\n",
    "str_setbacks = f['setbacks']['regional'][:]\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e822a1d",
   "metadata": {},
   "source": [
    "### Parallel XS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c88bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "geom = shape(cr_line)\n",
    "\n",
    "# # length of the LineString\n",
    "length = int(geom.length)\n",
    "sfr_sp = gpd.GeoDataFrame(pd.DataFrame(np.zeros((length,1)),columns=['id']))\n",
    "sfr_sp['geometry'] = shapely.geometry.Point(0,0)\n",
    "# enumerate keeps track of the count in addition to the object being iterated on\n",
    "for i, distance in enumerate(range(0, length, 1)):\n",
    "    point = geom.interpolate(distance)\n",
    "    sfr_sp.loc[i,'geometry'] = point\n",
    "    sfr_sp.loc[i,'id'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_sp['Easting'] = sfr_sp.geometry.x.values\n",
    "sfr_sp['Northing'] = sfr_sp.geometry.y.values\n",
    "\n",
    "point = sfr_sp.loc[:,['Easting','Northing']].values\n",
    "\n",
    "with rasterio.open(raster_name) as src:\n",
    "    sfr_sp['z_ft'] = [sample[0] for sample in src.sample(point)]\n",
    "    \n",
    "sfr_sp['z_m'] = sfr_sp.loc[:,'z_ft']*0.3048\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b55ec",
   "metadata": {},
   "source": [
    "Find XS every 1000 meters avoids too much overlap in XS,  after calculating depth there is some discontinuity but WSE is uniform with slope, so the numebr could be reduced to 2000m which would also aid muskingum-cunge routing requirements (coarser time step allowed).   \n",
    "I also realized that I should simplify the river feature to linearize it and avoid XS occuring on oddities where there is a large turn in the channel for a short distance. Adding a 500m tolerance simplify additionally reduces overlap and produces good XS locations/angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef68eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_transects(geom, dline = 2000, xs_width = 3305*2):\n",
    "    \"\"\" \n",
    "    Function to make regular transects for a line object (geom : shapely polyline) \n",
    "    at some longitudinal distance (dline : distance in meters)\n",
    "    max width needed is 3200 m +100m from original channel + 5 to allow full 3200 both direction\n",
    "    \"\"\"\n",
    "    # tolerance is distance which simplified points can be from the original\n",
    "    geom = geom.simplify(500)\n",
    "\n",
    "    # how often to interpolate a point, 200 m matches model grid\n",
    "    dline_long = np.copy(dline)\n",
    "    # # length of the LineString\n",
    "    length = int(geom.length)\n",
    "\n",
    "    num_xs = np.floor(length/dline).astype(int)\n",
    "    transects = pd.DataFrame(np.zeros((num_xs,1)), columns = ['line'])\n",
    "    transects['geometry'] = LineString([(0,0),(0,1)]) #initiate LineString geometry column\n",
    "\n",
    "\n",
    "    for i, distance in enumerate(range(0, int(length), dline)):\n",
    "        short_line = LineString([geom.interpolate(distance),geom.interpolate(distance+dline)])\n",
    "        geom_left = short_line.parallel_offset(xs_width/2,'left', resolution = 32, join_style = 2)\n",
    "        geom_right = short_line.parallel_offset(xs_width/2,'right', resolution = 32, join_style = 2)\n",
    "        perp_line = LineString([list(geom_left.coords)[0], list(geom_right.coords)[0]])\n",
    "        transects.loc[i,'geometry'] = perp_line\n",
    "\n",
    "    # save output\n",
    "    transg = gpd.GeoDataFrame(transects)\n",
    "    transg = transg.drop_duplicates('geometry')\n",
    "    transg['line'] = np.arange(0,len(transg))\n",
    "    transg.crs = 'epsg:32610'\n",
    "    return(transg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d56ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linemerge is essential because it joins linesegments by matching (x,y) so the line is continuous\n",
    "geom = linemerge(cr.geometry.unary_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bcc2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_width = 3305*2\n",
    "transg200 = make_transects(geom = linemerge(cr.geometry.unary_union), dline = 200, xs_width = xs_width)\n",
    "transg200.to_file(gis_dir+'/transect_lines_subsegments.shp')\n",
    "\n",
    "transg = make_transects(geom = linemerge(cr.geometry.unary_union), dline = 2000, xs_width = xs_width)\n",
    "transg.to_file(gis_dir+'/transect_lines.shp')\n",
    "# check cross section lines are paralle\n",
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "transg200.plot(color='red', ax=ax)\n",
    "transg.plot(ax=ax)\n",
    "cr.plot(ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transect2pts(transg, dline = 10, xs_width = 3305*2):\n",
    "    \"\"\" \n",
    "    Convert line transects (transg : geodataframe) to points \n",
    "    at a regular interval along the transect (dline : distance in meters)\n",
    "    \"\"\"\n",
    "\n",
    "    xs_all = gpd.GeoDataFrame(pd.DataFrame(columns=['xs_num','dist_from_right_m','geometry']))\n",
    "\n",
    "    for j in np.arange(0,len(transg)):\n",
    "        xs = gpd.GeoDataFrame(pd.DataFrame(np.zeros((int(xs_width/dline),2)), columns=['xs_num','dist_from_right_m']))\n",
    "        xs['geometry'] = Point([(0,0)])\n",
    "        xs['xs_num'] = j\n",
    "\n",
    "        # pick one geometry at a time\n",
    "        geom = transg.iloc[j].geometry\n",
    "\n",
    "        # # # length of the LineString\n",
    "        length = int(geom.length)\n",
    "        # create discrete points for each lien\n",
    "        for i, distance in enumerate(range(0, int(length), dline)):\n",
    "            point = geom.interpolate(distance)\n",
    "            xs.loc[i,'geometry'] = point\n",
    "            xs.loc[i,'dist_from_right_m'] = i\n",
    "        # append individual cross section to all dataframe\n",
    "    #     xs_all = xs_all.append(xs)\n",
    "        xs_all = pd.concat([xs_all, xs], axis=0, join='outer', ignore_index=True)\n",
    "    # remove na values\n",
    "    xs_all = xs_all.dropna(subset=['xs_num'])\n",
    "    return(xs_all)\n",
    "xs_all = transect2pts(transg, dline = 10, xs_width = 3305*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3147dc",
   "metadata": {},
   "source": [
    "Sample DEM for every XS point for an elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6784e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_pts(xs_all, raster_name):\n",
    "    \"\"\"\n",
    "    Given a geodataframe of points sample elevations from a raster\n",
    "    \"\"\"\n",
    "    src = rasterio.open(raster_name)\n",
    "    xmin, xmax = src.bounds[0], src.bounds[2]\n",
    "    ymin, ymax = src.bounds[1], src.bounds[3]\n",
    "\n",
    "    xs_all.crs='epsg:32610'\n",
    "    xs_all['Easting'] = xs_all.geometry.x\n",
    "    xs_all['Northing'] = xs_all.geometry.y\n",
    "    # filter to points that truly overlap the DEM\n",
    "    xs_all = xs_all.cx[xmin:xmax, ymin:ymax]\n",
    "\n",
    "    # point = xs_all.loc[:,['Easting','Northing']].values # old\n",
    "    point = list(zip(xs_all.geometry.x, xs_all.geometry.y)) # same error\n",
    "\n",
    "    print(os.path.basename(raster_name))\n",
    "    with rasterio.open(raster_name) as src:\n",
    "        xs_all['z_m'] = [sample[0] for sample in list(src.sample(point))]\n",
    "\n",
    "    # convert distance from right from 1/10 of meters because points were every 10 meters\n",
    "    # the distance was set with the index but really it should be 3200 meters not just 320 meters\n",
    "    xs_all.dist_from_right_m *= 10\n",
    "    # remove any NA values picked up from DEM raster\n",
    "    xs_all.loc[xs_all['z_m'] == src.meta['nodata'], ['z_m']] = np.nan\n",
    "    xs_all.index = np.arange(0,len(xs_all))\n",
    "    return(xs_all)\n",
    "xs_all = sample_pts(xs_all, raster_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0849a7e3",
   "metadata": {},
   "source": [
    "## XS Cleaning\n",
    "There isn't going to be a clear way to distinguish the levees and the XS shows bumpiness. The best solution will be to assume that levee setback will involve a cut and fill approach such that the ground surface elevation after setback is the mean of the elevation from before, but then this won't allow variable flooding based on elevation...\n",
    "\n",
    "It will take looking at the XS in different regions.\n",
    "It might be doable to fill in the channel as Sierra suggested which would raise the river above the levee and then install new \"levee walls\" at the desired distance. Filling in just the channel requires: 1. Going to the center line 2. go out some distance to account for channel width 3. set those values as a fraction of the levee height to insure more overbank flooding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate elevations for subsegments ( 200 m)\n",
    "xs_all200 = transect2pts(transg200, dline = 10, xs_width = 3305*2)\n",
    "xs_all200 = sample_pts(xs_all200, raster_name)\n",
    "\n",
    "xs_all200.drop(['geometry'],axis=1).to_csv(chan_dir+'XS_point_subsegments_elevations.csv')\n",
    "\n",
    "# convert to dataframe for easier plotting\n",
    "xs_all_df200 = pd.DataFrame(xs_all200)\n",
    "# pivot based on XS number and save only elevation in z_m\n",
    "xs_all_df200 = xs_all_df200.pivot_table(index='dist_from_right_m',columns='xs_num',values='z_m')\n",
    "xs_all_df200.to_csv(chan_dir+'Elevation_by_XS_number_subsegments_meters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f0ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xs_all.drop(['geometry'],axis=1).to_csv(chan_dir+'XS_point_elevations.csv')\n",
    "\n",
    "# convert to dataframe for easier plotting\n",
    "xs_all_df = pd.DataFrame(xs_all)\n",
    "# pivot based on XS number and save only elevation in z_m\n",
    "xs_all_df = xs_all_df.pivot_table(index='dist_from_right_m',columns='xs_num',values='z_m')\n",
    "xs_all_df.to_csv(chan_dir+'Elevation_by_XS_number_meters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xs_all_df.plot()\n",
    "plt.legend(ncol=4, loc=(1,0.01), title='XS Number')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63cf758",
   "metadata": {},
   "source": [
    "The process will be too complicated too directly edit the raster, so individual cross-sections will be edited by applying a rolling mean in the floodplain in the 200-400 m around the main channel to \"flatten\" any levee like structure. Then new 'levee walls' will be placed at the desired setback distance.\n",
    "\n",
    "Helen suggested looking at the historical 100 year flood to estimate the levee height they would have designed for, or look at the physical characteristics to design it. Levee construction began in 1930s, biggest flood was in 1907 at 71,000 cfs (estiamted) with a gage height of 16 ft at Michigan Bar so levee's would most likely be designed to at least 16 ft.\n",
    "\n",
    "For each levee setback we should imagine that the channel is partially filled in, but rather than uniformly removing all levee walls within the floodplain, we breach the levee wall in 200 m sections for every 2km to allow flood water to inundate the floodplain and then new levees are constructed at the specified distance to bring ground level to 16 ft above channel bottom. In real life this height could probably be steadily lowered as there is so much room in the floodplain to accomdate the volume that a lower levee height suffices.\n",
    "1. Rolling mean is used to fill in channel with earth from levee or nearby.\n",
    "2. New levees are continuously installed at specified distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d3e7f",
   "metadata": {},
   "source": [
    "\n",
    "It doesn't look like I will see much floodplain inundation, but I won't know until I estimate depth. Start with 2-3,000 is 1 year flood and 20,000 cfs is 5 year. The floodplain connection flow is estimated to be 2-3,000 cfs by Whipple in one paper on floodplain inundation at Oneto-Denier, and as 23 cms or 800 cfs in the flood typology paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_all = pd.read_csv(chan_dir+'XS_point_elevations.csv')\n",
    "\n",
    "xs_all_df = pd.read_csv(chan_dir+'Elevation_by_XS_number_meters.csv',index_col='dist_from_right_m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b2ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xs_channel_smooth(xs_all_df, roll_window = 400, dline = 10):\n",
    "    \"\"\" \n",
    "    Apply a rolling mean to center window (roll_window) of channel (xs_all_df) \n",
    "    to represent incision infill and reduction of bank/levee height,\n",
    "    40 observations is equal to 400 meters\n",
    "    \"\"\"\n",
    "    xs_roll_mean = xs_all_df.rolling(int(roll_window/dline), center=True).mean()\n",
    "    channel_middle = int(len(xs_all_df)/2)*dline\n",
    "    channel_bool = (xs_all_df.index >= channel_middle - (roll_window/2))& (xs_all_df.index <= channel_middle + (roll_window/2))\n",
    "    xs_all_df.loc[channel_bool,:] = xs_roll_mean.loc[channel_bool,:]\n",
    "    return(xs_all_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_levee_smooth200 = xs_channel_smooth(xs_all_df200, roll_window = 400, dline = 10)\n",
    "# save for flow-recharge notebook\n",
    "# xs_levee_smooth200.to_csv(chan_dir+'xs_levee_smooth_subsegments.csv')\n",
    "\n",
    "\n",
    "xs_levee_smooth = xs_channel_smooth(xs_all_df, roll_window = 400, dline = 10)\n",
    "# # save for flow-recharge notebook\n",
    "# xs_levee_smooth.to_csv(chan_dir+'xs_levee_smooth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "xs_levee_smooth.plot(ax=ax)\n",
    "ax.legend(ncol=4, loc=(1,0.01), title='XS Number')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a0840",
   "metadata": {},
   "source": [
    "## How to update XS to include changes in levees\n",
    "The goal here is to provide a more physical representation of XS that just stopping the XS calculation in Manning's. Here the wetted perimiter of the channel would be larger at deeper depths.\n",
    "\n",
    "This was implemented as a function called xs_setback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5a05c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_test = xs_levee_smooth.copy()\n",
    "# rather than saving a version of the xs for each setback just add this adjustment\n",
    "n=5\n",
    "# the channel should fall within the center 400m so that minimum can be used to set new levee height\n",
    "thalweg = xs_test.loc[channel_middle-roll_window/2:channel_middle+roll_window/2].min()\n",
    "# check to see XS elevation at setback distance to determine if it should be raised to needed levee height\n",
    "levee_diff = xs_test.loc[3100-setbacks[n],:] - thalweg\n",
    "# where XS height is less than 20 ft above channel bottom then raise to 20 ft above\n",
    "xs_test.loc[3100-setbacks[n],:][levee_diff< 20*0.3048] = thalweg + 16*0.3048\n",
    "levee_diff = xs_test.loc[3300+setbacks[n],:] - thalweg\n",
    "xs_test.loc[3300+setbacks[n],:][levee_diff< 20*0.3048] = thalweg + 16*0.3048\n",
    "\n",
    "xs_test.iloc[:,24].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744292d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(6,3))\n",
    "xs_levee_smooth.min().plot(ax=ax, label='Adj XS')\n",
    "xs_all_df.min().plot(ax=ax, color='red',label='XS')\n",
    "grid_sfr.assign(river_km = np.cumsum(grid_sfr.length_m/dline_long)).plot(x='river_km',y='z',kind='line',ax=ax, label='Model')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f6785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dem data for cropping above land surface\n",
    "dem_data = np.loadtxt(gwfm_dir+'/DIS_data/dem_52_9_200m_linear.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac9d9d",
   "metadata": {},
   "source": [
    "# Mannings equation\n",
    "The assumption of levee setback is that as the setback distance increases so does the wetted xs perimeter which increases the hydraulic radius (there is more roughness impacting the water) so the velocity will be lower. This analysis is independent of varying geology, and river reach under the assumption that any recontoured reach would undergo restoration resulting in similar reach rougnesses of the floodplain (small bushes, trees). And it will assume the existing average bed slope of the lower Cosumnes river applies.  \n",
    "This analysis could be done by running a HEC-RAS model at all of these different setback distances, but here the goal is to determine the trend and general distance at which diminishing returns occur.  The analysis will be completed first for a typical winter flood event of 2,000 cfs which is near floodplain connectivity (need to approximate area and velocity of channel as starting point or else will need to cycle through several areas/wetted perimeters - better to just use multiple areas that connect to multiple possibles flood sizes )  \n",
    "The width will range from 0 to 3200 meters in both direction but I coud have depth be dependent on the actual elevations  \n",
    "Manning Equation for SI units  \n",
    "$ Q = VA = (\\frac{1.00}{n}) A  {R}^{2/3} \\sqrt{S} $  \n",
    "$ R = \\frac{A}{Wp}$  \n",
    "hydraulic radius r is XS area divided by wetted perimeter  \n",
    "[Manning's eqn reference](http://www.fsl.orst.edu/geowater/FX3/help/8_Hydraulic_Reference/Manning_s_Equation.htm)  \n",
    "Avg manning's n for in channel is 0.048  - clean, winding, some pools and shoals, but some weeds and stones, lower stages, more ineffective, slopes and sections\n",
    "Floodplains have much broader range, due to variability in vegetation type: tall grass is 0.035 but dense willows is 0.15  \n",
    "[Manning's n reference](http://www.fsl.orst.edu/geowater/FX3/help/8_Hydraulic_Reference/Mannings_n_Tables.htm)  \n",
    "\n",
    "Slope for Cosumnes could be considered the 0.0006 which is the mean for all reaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03cbd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "fxn_dir = git_dir+'/python_utilities'\n",
    "if fxn_dir not in sys.path:\n",
    "    sys.path.append(fxn_dir)\n",
    "# sys.path\n",
    "# import muskingum_recharge as mr\n",
    "\n",
    "from importlib import reload\n",
    "# reload(mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from muskingum_recharge import min_Q, mannings, calc_depth_arr, gridded_interpolation, xs_setback, mannings_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid x,y coords for interpolation output\n",
    "# x_out = grid_p.geometry.centroid.x.values\n",
    "# y_out = grid_p.geometry.centroid.y.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2227f4",
   "metadata": {},
   "source": [
    "## Return period floods (5, 20, 50,100 yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_flows = pd.read_csv(box_dir+'michigan_bar_peak_flows.tsv', delimiter='\\t', comment='#')\n",
    "peak_flows = peak_flows.drop(0)\n",
    "peak_flows = peak_flows.dropna(subset=['peak_va'])\n",
    "peak_flows = peak_flows[['peak_dt','peak_va','gage_ht']]\n",
    "peak_flows.peak_va = pd.to_numeric(peak_flows.peak_va)\n",
    "annual_max_df_sorted = peak_flows.sort_values('peak_va', ascending=True)\n",
    "\n",
    "# code from hydro-informatics exercsises\n",
    "n = annual_max_df_sorted.shape[0]\n",
    "annual_max_df_sorted.insert(0, \"rank\", range(1, 1 + n))\n",
    "annual_max_df_sorted[\"pr\"] = (n - annual_max_df_sorted[\"rank\"] + 1) / (n + 1)\n",
    "annual_max_df_sorted[\"return-period\"] = 1 / annual_max_df_sorted[\"pr\"]\n",
    "annual_max_df_sorted[\"period_int\"] = annual_max_df_sorted[\"return-period\"].astype(int)\n",
    "\n",
    "# annual_max_df_sorted[annual_max_df_sorted.period_int==50]\n",
    "\n",
    "# identify relevant return period flows\n",
    "per_id = []\n",
    "for per in [1,2, 5, 10, 20, 50, 100]:\n",
    "    per_id = per_id + [np.argmin(np.abs((annual_max_df_sorted['return-period']-per).values))]\n",
    "per_table = annual_max_df_sorted.iloc[per_id][['peak_dt','return-period','peak_va']].round(2)\n",
    "per_table = per_table.rename(columns={'peak_va':'Discharge (cfs)'})\n",
    "\n",
    "annual_max_df_sorted.plot(x='return-period',y='peak_va', figsize=(6,3), legend=False)\n",
    "\n",
    "display(per_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7146b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick calculations for the publication on flow regime\n",
    "# 93000*(0.3048**3)\n",
    "# slope = (49700-37500)/(57.50-19.17)\n",
    "# ((20-19.17)*slope + 37500)*(0.3048**3)\n",
    "# # 22500*(0.3048**3)\n",
    "# 400*(0.3048**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.optimize import fsolve, least_squares, minimize, minimize_scalar\n",
    "\n",
    "# fsolve(mannings, [2], args = (Q_cms, xs_elevs), xtol=1E-5)\n",
    "# least_squares(mannings, [2], args = (Q_cms, xs_elevs), bounds = (0, 10), ftol=1E-5)\n",
    "# minimize(mannings, [1.], args = (Q_cms, xs_elevs), bounds=[(0,10)], tol=1E-5)\n",
    "\n",
    "# # res = minimize_scalar(mannings,  args = (Q_cms, xs_elevs), bounds=(0,10), method='bounded')\n",
    "# res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5cd2f3",
   "metadata": {},
   "source": [
    "# Iterate across all levee setbacks here\n",
    "Checking issue where inundated area seems to decrease in some areas when setback is increased. it's okay for inundated area to decrease because when setback increases the depth is decreased and so there will be some cells that are now above the flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_daily = pd.read_csv(gwfm_dir+'/SFR_data/MB_daily_flow_cfs_2010_2019.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ee88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mb_daily.plo/t(x='datetime',y='flow_cfs', legend=False)\n",
    "# mb_daily[(mb_daily.flow_cfs > 20000)].plot(x='datetime',y='flow_cfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddcd638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cms to cmh sustained for about 0.6 hour based on how long flood wave travels 2 km\n",
    "# \n",
    "# total_vol = 40*60*60*0.6\n",
    "total_vol = 40*60*60*24*7 # if flow occurred for 7 days\n",
    "\n",
    "# calculate area for setbacks\n",
    "max_area = str_setbacks[-1,:,:].sum()*200*200\n",
    "# area from high flow cells within 3000m setback\n",
    "max_area = 16640000.0\n",
    "\n",
    "# even if we had that recharge rate for a full week, theoretically we only recharge 0.07 m of water\n",
    "# if we limit the recharge volume to only those local cells then we would only see 1.45 m distributed\n",
    "\n",
    "total_vol/max_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_daily['flow_cms'] = mb_daily.flow_cfs * (0.3048**3)\n",
    "mb_daily.plot(x='datetime',y='flow_cms', legend=False)\n",
    "plt.ylabel('Flow (cms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d6c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=3\n",
    "# mb_daily[mb_daily.flow_cfs > per_table['Discharge (cfs)'].iloc[n]]\n",
    "# mb_daily[mb_daily.flow_cfs > 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_cfs = 93000 #  115 year\n",
    "# Q_cfs = 39400 # 23 year return period\n",
    "Q_cfs = 22500 # 5 year\n",
    "# Q_cfs = 2000 # 1ish year\n",
    "\n",
    "Q_cms = Q_cfs*(0.3048**3) # convert to cubic meters per second\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ab913",
   "metadata": {},
   "source": [
    " will need to iterative solve for Area, area is the sum of area between depth and ground surface\n",
    " \n",
    " As we iterate down the XS we need to account for water lost to recharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find minimum from channel center\n",
    "xs_mins = xs_levee_smooth.loc[3100:3300].min(axis=0)\n",
    "xs_mins.index = xs_mins.index.astype(int)\n",
    "# xs_mins.interpolate(method='linear').plot()\n",
    "slope = xs_mins.diff().rolling(2, center=True, closed='right').mean().bfill()/2000*-1\n",
    "adj_xs_mins = np.append(xs_mins[0], (xs_mins[0]-slope.cumsum()*2000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0441c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nseg = 20\n",
    "setback = 8*200\n",
    "xs_elevs = xs_setback(xs_levee_smooth.iloc[:,nseg].copy(), setback, 30)\n",
    "\n",
    "def depth_match(xs_elevs, nseg, setback):\n",
    "    \"\"\" For a XS find the depth that best matches the flow given with stepwise global sampling\"\"\"\n",
    "    q_test = 0\n",
    "    dec = 10\n",
    "    di=1\n",
    "    df = 1E-6\n",
    "    # 3 decimal places is enough to be within 1 cms\n",
    "    for dec in [10, 1, 0.1, 0.01]:\n",
    "        # set range of values to test above last value if too low or below if too high\n",
    "        if q_test < Q_cms:\n",
    "            d_test = np.arange(df, df + dec, dec/10)\n",
    "        else:\n",
    "            d_test = np.arange(df - dec, df, dec/10)\n",
    "        # calculate flow for depth range\n",
    "        q_test = [mannings([d], xs_elevs, n, slope.iloc[nseg]) for d in d_test]\n",
    "        print(df,q_test)\n",
    "        # find depth with minimum error\n",
    "        di = np.argmin(np.abs(np.subtract(q_test, Q_cms)))\n",
    "        q_test = q_test[di]\n",
    "        # add the decimal place to the depth\n",
    "        df += np.copy(di)*dec/10\n",
    "    return(df)\n",
    "\n",
    "d_out = depth_match(xs_elevs, nseg, setback)\n",
    "d_out, mannings([d_out], xs_elevs, n, slope.iloc[nseg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be23409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar, minimize\n",
    "from scipy.optimize import basinhopping\n",
    "\n",
    "n= 0.048\n",
    "\n",
    "# setback = 3000\n",
    "# depths = np.zeros(xs_levee_smooth.shape[1])\n",
    "depths = np.zeros((len(setbacks), xs_levee_smooth.shape[1]))\n",
    "q_check = np.zeros(depths.shape)\n",
    "\n",
    "# iterate across all setbacks\n",
    "for nseg in np.arange(0, xs_levee_smooth.shape[1]): #xs_levee_smooth.shape[1]\n",
    "    # setbacks don't go past 3000, enumerate includes 3200 which we don't want\n",
    "    for s,setback in enumerate(setbacks): \n",
    "        # for a given setback imagine there is an impenetrable levee blocking overbank flow\n",
    "#         xs_elevs = xs_levee_smooth.iloc[:,nseg][3100-setback:3300+setback]\n",
    "        xs_elevs = xs_setback(xs_levee_smooth.iloc[:,nseg].copy(), setback)\n",
    "    \n",
    "        # solve for depth that matches given flow\n",
    "        res = minimize_scalar(min_Q, args = (xs_elevs, n, slope.iloc[nseg], Q_cms), \n",
    "                                  bounds=(0.1,10), method='Golden', tol=1E-3)\n",
    "        if res.fun>0.05*Q_cms: # greater than 5% difference try to fix with bounded solving\n",
    "            print(str(nseg),' ', s, '%.2f'%res.fun, 'iter %i'%res.nit, ', ',res.success, 'd %.2f'%res.x)\n",
    "        if mannings(res.x, xs_elevs, n, slope.iloc[nseg]) > Q_cms*1.05:\n",
    "            res = minimize_scalar(min_Q, args = (xs_elevs, n, slope.iloc[nseg], Q_cms), \n",
    "                          bounds=(0.1,res.x-0.1), method='bounded', tol=1E-3)\n",
    "        if mannings(res.x, xs_elevs, n, slope.iloc[nseg]) < Q_cms*0.95:\n",
    "            res = minimize_scalar(min_Q, args = (xs_elevs, n, slope.iloc[nseg], Q_cms), \n",
    "                          bounds=(res.x+0.1,10), method='bounded', tol=1E-3)\n",
    "        # changing tolerance doesn't improve function error\n",
    "        depths[s, nseg] = res.x\n",
    "#         depths[s,nseg] = depth_match(xs_elevs, nseg, setback)\n",
    "        q_check[s,nseg] = mannings(depths[s,nseg], xs_elevs, n, slope.iloc[nseg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25bef18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_arr = np.zeros((len(setbacks), nrow, ncol))\n",
    "for s,setback in enumerate(setbacks):\n",
    "# s, setback = 2, 400\n",
    "#     wse_all = pd.DataFrame(xs_levee_smooth[3100-setback:3300+setback].min()+depths[s,:], columns=['wse_m'])\n",
    "    wse_all = pd.DataFrame(xs_levee_smooth.min()+depths[s,:], columns=['wse_m'])\n",
    "    d_arr[s,:,:] = calc_depth_arr(wse_grid, wse_all)\n",
    "    \n",
    "d_arr_out = np.reshape(d_arr, (len(setbacks)*nrow, ncol))\n",
    "np.savetxt(box_dir+'channel_data/depth_array_'+str(Q_cfs)+'cfs.tsv', d_arr_out, delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34326c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# s1 = 1\n",
    "# s2 = 2\n",
    "# print('Flood cells matching in setback ',s1,' and ',s2,' :',((d_arr[s2,:]>0) &(d_arr[s1,:]>0)).sum(), \n",
    "#       'flood cells in setback ',s1,':', (d_arr[s1,:]>0).sum())\n",
    "# # plt.imshow(d_arr[1,:])\n",
    "# # plt.show()\n",
    "# plt.imshow(d_arr[s1,:])\n",
    "# plt.show()\n",
    "# plt.imshow(d_arr[s2,:])\n",
    "# plt.show()\n",
    "# plt.imshow(d_arr[s1,:]*((d_arr[s2,:]>0) &(d_arr[s1,:]>0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1545619",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_arr = np.zeros((len(setbacks), xs_levee_smooth.shape[1]))\n",
    "for s,setback in enumerate(setbacks):\n",
    "    for nseg in np.arange(0,xs_levee_smooth.shape[1]):\n",
    "        # for a given setback imagine there is an impenetrable levee blocking overbank flow\n",
    "        xs_elevs = xs_setback(xs_levee_smooth.iloc[:,nseg].copy(), setback, 30)\n",
    "        # solve for depth that matches given flow\n",
    "        V_arr[s, nseg] = mannings_v(depths[s, nseg], 0, xs_elevs) # output is Q_calc - Q so if Q=0 then output is Q_calc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2, figsize=(10,3))\n",
    "ax_n= ax[0]\n",
    "pd.DataFrame(V_arr,index=setbacks).plot(cmap='viridis', legend=False, ax = ax_n)\n",
    "ax_n.set_xlabel('Setback distance (m)')\n",
    "ax_n.set_ylabel('Manning Eqn\\nVelocity (m/s)')\n",
    "\n",
    "ax_n= ax[1]\n",
    "pd.DataFrame(V_arr[0,:]/V_arr,index=setbacks).plot(cmap='viridis', legend=False, ax = ax_n)\n",
    "ax_n.set_xlabel('Setback distance (m)')\n",
    "ax_n.set_ylabel('Times reduction \\nin velocity \\n(increase in travel time)')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d3e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(2,1, figsize=(8,4),sharex=True)\n",
    "ax_n = ax[0]\n",
    "wse_plt = np.zeros(depths.shape)\n",
    "for s,setback in enumerate(setbacks):\n",
    "    wse_plt[s,:] = (xs_levee_smooth[3100-setback:3300+setback].min()+depths[s,:])\n",
    "#     (xs_levee_smooth[3100-setback:3300+setback].min()+depths[s,:]).plot(ax=ax_n,  label=setback)\n",
    "\n",
    "pd.DataFrame(wse_plt,index=setbacks).transpose().plot(cmap='viridis',legend=False, ax = ax_n)\n",
    "\n",
    "# ax_n.plot(xs_levee_smooth.min()+depths)\n",
    "# ax_n.set_xlabel('XS Number - Upstream to Downstream')\n",
    "ax_n.set_ylabel(' Water Surface\\nElevation (m)')\n",
    "ax_n.legend(ncol=4)\n",
    "\n",
    "print(' %.5F is the slope' % (15/(62*1000)), 'which matches the mean slope of the streambed')\n",
    "\n",
    "ax_n = ax[1]\n",
    "# ax_n.plot(depths)\n",
    "pd.DataFrame(depths,index=setbacks).transpose().plot(cmap='viridis',legend=False, ax = ax_n)\n",
    "\n",
    "# for s,setback in enumerate(setbacks):\n",
    "#     ax_n.plot(depths[s,:], cmap='magma')\n",
    "ax_n.set_xlabel('XS Number - Upstream to Downstream')\n",
    "ax_n.set_ylabel('Depth (m)')\n",
    "\n",
    "# plt.savefig(fig_dir+ 'water surface elevation-depth profile (m) at' + str(Q_cfs)+'cfs.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot different setback XS for middle segment\n",
    "plt_xs = np.arange(0,setbacks.shape[0],2)\n",
    "ny = 3\n",
    "nx = int(np.ceil(plt_xs.shape[0]/ny))\n",
    "\n",
    "fig,ax = plt.subplots(nx,ny, figsize=(ny*4,nx*2),sharex=True, sharey=True)\n",
    "\n",
    "nxs = int(xs_levee_smooth.shape[1]/2)\n",
    "nxs= 20\n",
    "\n",
    "for n, s in enumerate(plt_xs):\n",
    "    setback = setbacks[s]\n",
    "    ax_n = ax[int(n / ny), n % ny] if (nx > 1) else ax[i]\n",
    "    xs_elevs = xs_setback(xs_levee_smooth.iloc[:,nxs].copy(), setback=setback)\n",
    "    # plot levee setback adjusted XS\n",
    "    xs_elevs.plot(ax=ax_n)\n",
    "    # plot original cross-section    \n",
    "    mid = np.mean(xs_levee_smooth.index) # location that should be channel bottom based on NHD line\n",
    "\n",
    "    xs_all_df.iloc[:,nxs][mid-100-setback:mid+100+setback].plot(ax=ax_n)\n",
    "    depths_plt = depths[s,:]\n",
    "    ws = xs_elevs.min() +depths_plt[nxs]\n",
    "    ax_n.plot([mid-100-setback, mid+100+setback],[ws,ws], label='setback')\n",
    "\n",
    "    ax_n.set_title(str(setback))#+' , '+ str(np.round(ws,2))\n",
    "    ax_n.set_xlabel('')\n",
    "    xs_A = (ws - xs_elevs)[(ws - xs_elevs)>0].sum()*10\n",
    "    print('XS '+str(setback)+' area: %.2f' %xs_A, 'm^2',end=',')\n",
    "    print('V %.2f' %V_arr[s, nxs], 'Q %.2f' %(V_arr[s,nxs]*xs_A) )\n",
    "#         n+=1\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.text(-0.01, 0.4, 'Elevation (m)', rotation=90, size=16)\n",
    "fig.text(0.4, -0.03, 'Distance from right (m)', size=16)\n",
    "\n",
    "# plt.savefig(fig_dir +str(setback)+'setback_XS_with_depth_' +str(Q_cfs)+ 'cfs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecc06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# depths_plt = depths[0,:]\n",
    "\n",
    "# nx,ny = 12,5\n",
    "plt_xs = np.arange(0,xs_levee_smooth.shape[1],4)\n",
    "ny = 4\n",
    "nx = int(np.ceil(plt_xs.shape[0]/ny))\n",
    "setback = 3200\n",
    "s=16\n",
    "fig,ax = plt.subplots(nx,ny, figsize=(ny*4,nx*2),sharex=True, sharey=False)\n",
    "n=0\n",
    "for n,nxs in enumerate(plt_xs):\n",
    "# for i in np.arange(0,nx):\n",
    "#     for j in np.arange(0,ny):\n",
    "#         ax_n = ax[i,j]\n",
    "    ax_n = ax[int(n / ny), n % ny] if (nx > 1) else ax[i]\n",
    "    xs_elevs = xs_setback(xs_levee_smooth.iloc[:,nxs].copy(), setback=setback)\n",
    "    xs_elevs.plot(ax=ax_n)    \n",
    "    mid = np.mean(xs_levee_smooth.index) # location that should be channel bottom based on NHD line\n",
    "    xs_all_df.iloc[:,nxs][mid-100-setback:mid+100+setback].plot(ax=ax_n)\n",
    "    for s,setback in enumerate(setbacks):\n",
    "        depths_plt = depths[s,:]\n",
    "        ws = xs_levee_smooth.iloc[:,nxs][3100-setback:3300+setback].min() +depths_plt[nxs]\n",
    "        ax_n.plot([mid-100-setback, mid+100+setback],[ws,ws], label='setback')\n",
    "\n",
    "    ax_n.set_title(nxs)\n",
    "#         n+=1\n",
    "fig.tight_layout()\n",
    "# plt.savefig(fig_dir +str(setback)+'setback_XS_with_depth_' +str(Q_cfs)+ 'cfs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab79bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

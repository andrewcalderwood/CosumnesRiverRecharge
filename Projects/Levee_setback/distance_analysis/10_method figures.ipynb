{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3fe4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename, dirname, join, exists\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# 1d so the smoothing is specific to each realization\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b6557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, zoomed_inset_axes, mark_inset\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e0b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "    \n",
    "git_dir = join(doc_dir,'GitHub','CosumnesRiverRecharge')\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = join(dirname(doc_dir),'Box/research_cosumnes/GWFlowModel')\n",
    "\n",
    "\n",
    "def add_path(fxn_dir):\n",
    "    if fxn_dir not in sys.path:\n",
    "        sys.path.append(fxn_dir)\n",
    "        \n",
    "flopy_dir = doc_dir+'/GitHub/flopy'\n",
    "if flopy_dir not in sys.path:\n",
    "    sys.path.insert(0, flopy_dir)\n",
    "\n",
    "import flopy \n",
    "import flopy.utils.binaryfile as bf\n",
    "\n",
    "\n",
    "add_path(doc_dir+'/GitHub/CosumnesRiverRecharge/tprogs_utilities')\n",
    "add_path(doc_dir+'/GitHub/CosumnesRiverRecharge/python_utilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d67c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from map_cln import gdf_bnds, pnt_2_tup, lab_pnt, plt_cln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68763658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set box directory for output figures and data\n",
    "box_dir = gwfm_dir+'/Levee_setback/levee_setback_distance_analysis/'\n",
    "\n",
    "# tprogs_id = '' # original tprogs with conditioning data in output tsim\n",
    "# tprogs_id = '_no_conditioning'\n",
    "tprogs_id = '_no_cond_c3d'\n",
    "\n",
    "proj_dir = join(box_dir, tprogs_id)\n",
    "\n",
    "data_dir = join(proj_dir,'data_output/')\n",
    "fig_dir = join(box_dir,'figures/')\n",
    "\n",
    "chan_dir = box_dir+'channel_data/'\n",
    "gis_dir = chan_dir+'GIS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c462da",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_dir = join(box_dir,'figures','methods') # directory for figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6dc3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 100\n",
    "ncol = 230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc1f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_data = np.loadtxt(gwfm_dir+'\\DIS_data\\dem_52_9_200m_mean.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n",
    "\n",
    "m_domain = gpd.read_file(gwfm_dir+'/DIS_data/NewModelDomain/GWModelDomain_52_9deg_UTM10N_WGS84.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e672a-1db5-466d-a0db-1ad10e9cf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(join(chan_dir, 'setback_locs.hdf5'), \"r\")\n",
    "local_str_setbacks = f['setbacks']['local'][:]\n",
    "str_setbacks = f['setbacks']['regional'][:]\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b740aa",
   "metadata": {},
   "source": [
    "# Map overview figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dir = join(gwfm_dir,'Mapping')\n",
    "sfr_dir = join(gwfm_dir,'SFR_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers = gpd.read_file(join(sfr_dir,\"Sac_valley_rivers/Sac_valley_rivers.shp\"))\n",
    "rivers = rivers.to_crs('EPSG:32610')\n",
    "\n",
    "mb_regional = gpd.read_file(join(gwfm_dir,\"DIS_data/NewModelDomain/GWModelDomain_52_9deg_UTM10N_WGS84.shp\"))\n",
    "# mb = gpd.read_file(join(gwfm_dir,\"DIS_data/NewModelDomain/GWModelDomain_52_9deg_UTM10N_WGS84.shp\"))\n",
    "rivers_clip = gpd.clip(rivers, mb_regional)\n",
    "\n",
    "soam = gpd.read_file(join(map_dir,\"so_am_subbasin/so_am_subbasin.shp\"))\n",
    "soam = soam.to_crs('EPSG:32610')\n",
    "cos = gpd.read_file(join(map_dir,\"cos_subbasin/cos_subbasin.shp\"))\n",
    "cos = cos.to_crs('EPSG:32610')\n",
    "\n",
    "ca = gpd.read_file(join(map_dir,\"ca_state_boundary/CA_State_TIGER2016.shp\"))\n",
    "ca = ca.to_crs('EPSG:32610')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc99ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = rivers_clip[rivers_clip.GNIS_Name=='Cosumnes River']\n",
    "mr = rivers_clip[rivers_clip.GNIS_Name=='Mokelumne River']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded52f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transg = gpd.read_file(join(chan_dir,'GIS','transect_lines_3300.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e67f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr = gpd.read_file(gwfm_dir+'/SFR_data/final_grid_sfr/grid_sfr.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a640e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_buf = grid_sfr.buffer(3200).unary_union\n",
    "sfr_buf = gpd.GeoDataFrame(pd.DataFrame([0]), geometry=[sfr_buf], crs=grid_sfr.crs)\n",
    "sfr_buf = gpd.overlay(sfr_buf, m_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb6384",
   "metadata": {},
   "outputs": [],
   "source": [
    "prms_gis = join(gwfm_dir,'PRMS','GIS')\n",
    "ws_gdf = gpd.read_file(join(prms_gis, \"NHD_H_18040013_HU8_Shape\\Shape\\WBDHU8.shp\"))\n",
    "ws_gdf=ws_gdf.to_crs(m_domain.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716bf68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_gdf.area[0]/1000/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33c3fd1",
   "metadata": {},
   "source": [
    "## References calcs\n",
    "Information on pumping is taken from the South American Subbasin GSP.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_late = 120\n",
    "\n",
    "\n",
    "sasb_pump = 221618 # all uses pumping AF/year average 1995-2018\n",
    "sasb_pump*= 43560*(0.3048**3) # convert to m3/year\n",
    "sasb_pump /= 1E6 # convert to MCM\n",
    "print('All pump %.2f' %sasb_pump)\n",
    "print('%% of all pump %.2f' %(100*long_late/sasb_pump))\n",
    "\n",
    "ag_pump = 96200 # avg ag pumping AF/year 2009-2018\n",
    "ag_pump *= 43560*(0.3048**3)\n",
    "ag_pump /= 1E6\n",
    "print('Ag pump %.2f' %ag_pump)\n",
    "print('%% of ag pump %.2f' %(100*long_late/ag_pump))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "120.8+21.5+495.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "638/273.36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04152e8",
   "metadata": {},
   "source": [
    "### Average climate\n",
    "Rainfall Fiddletown (FDL) is in the upper watershed for rainfall.  \n",
    "Ham Station (HMS) at 5500 ft and Podesta (PDT) at 7200 ft are in the upper watershed for snow depth.  \n",
    "It is necessary to note the spatial coverage of snow is limited (only 20% of area).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83433de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdec_dir = join(gwfm_dir, 'UZF_data', 'watershed_cdec_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average rainfall, inches\n",
    "fdl = pd.read_excel(join(cdec_dir, 'FDL_rain.xlsx'), parse_dates=['DATE TIME'], na_values=['---'])\n",
    "fdl = fdl.set_index('DATE TIME')\n",
    "fdl.resample('AS-Oct').sum(numeric_only=True).mean()*2.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c5dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average snow, inches\n",
    "hms = pd.read_excel(join(cdec_dir, 'HMS_snow.xlsx'), parse_dates=['DATE TIME'], na_values=['---'])\n",
    "hms = hms.set_index('DATE TIME')\n",
    "hms.resample('AS-Oct').sum(numeric_only=True).mean()*2.54"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b026a4b",
   "metadata": {},
   "source": [
    "# Regional map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ae2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor='none', edgecolor='black', linestyle = '--', alpha=1., label='Watershed Extent'),\n",
    "    Patch(facecolor='none', edgecolor='black',alpha=1., label='Model Extent'),\n",
    "    Patch(facecolor='none', edgecolor='tab:blue', linestyle = '--',label='Levee Setback\\nof 3200 m'),\n",
    "    Line2D([0], [0],color='tab:blue',label='Cosumnes River'),\n",
    "    Line2D([0], [0],color='black',label='Stream Channel\\nCross-sections'),\n",
    "#     Line2D([0], [0], marker='.', linestyle='', color='blue', label='Monitoring Well'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f994e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not useful, only limited levees on American R.\n",
    "# levees = gpd.read_file(join(map_dir, 'Department_of_Water_Resources_Assets','Levees.shp')).to_crs(m_domain.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots()\n",
    "# # levees.plot(ax=ax)\n",
    "# m_domain.plot(ax=ax, edgecolor='black',color='none')\n",
    "# transg.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b5f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ref_map(axins):\n",
    "    ca.plot(ax = axins,alpha = 0.2, edgecolor='black')\n",
    "    axins.annotate(text='California', xy=lab_pnt(ca), \n",
    "                xytext = (6,-30), textcoords = 'offset points',\n",
    "                bbox=dict(boxstyle=\"square,pad=0.3\", fc=\"lightgrey\", ec=\"black\", lw=2), zorder=1)\n",
    "    # second one is smaller inset\n",
    "    axins.tick_params(labelleft=False, labelbottom=False, left = False, bottom = False)\n",
    "\n",
    "    ws_gdf.plot(color='none',ax=axins, linestyle='--')\n",
    "    m_domain.plot(color=\"none\",edgecolor='black',ax=axins)\n",
    "    return axins\n",
    "\n",
    "\n",
    "def main_map(ax):\n",
    "    ## main figure ##\n",
    "    plt_bnds = gdf_bnds(m_domain,ax=ax, buf=200)\n",
    "\n",
    "    ws_gdf.plot(color='none',ax=ax, linestyle='--')\n",
    "    m_domain.plot(color=\"none\",edgecolor='black',ax=ax)\n",
    "\n",
    "    cr.plot(ax=ax, color='tab:blue')\n",
    "    # mr.plot(ax=ax, color='tab:blue')\n",
    "    sfr_buf.plot(ax=ax, color='none',edgecolor='tab:blue', linestyle='--')\n",
    "    transg.plot(ax=ax, color='black', linewidth=1)\n",
    "\n",
    "    ctx.add_basemap(ax=ax, source = ctx.providers.Esri.WorldImagery, attribution=False, attribution_size=6,\n",
    "                    crs = 'epsg:26910', alpha=0.7)\n",
    "\n",
    "    x, y, arrow_length = 0.7, 0.15, 0.1\n",
    "    ax.annotate('N', xy=(x, y), xytext=(x, y-arrow_length),\n",
    "                arrowprops=dict(facecolor='black', width=5, headwidth=15),\n",
    "                ha='center', va='center', fontsize=20, \n",
    "                xycoords=ax.transAxes)\n",
    "\n",
    "    fontprops = fm.FontProperties(size=18)\n",
    "    scalebar = AnchoredSizeBar(ax.transData,\n",
    "                               10000, '10 km', 'lower right', pad=0.3, sep=2,color='black',\n",
    "                               frameon=False, size_vertical=5E2, fontproperties=fontprops)\n",
    "    ax.add_artist(scalebar)\n",
    "    ax.tick_params(labelleft=False, labelbottom=False, left = False, bottom = False)\n",
    "\n",
    "    # ax.legend(handles=legend_elements, loc='upper left')\n",
    "    ax.legend(handles=legend_elements, loc=(0.6,0.2))\n",
    "\n",
    "\n",
    "## inset figure ##\n",
    "# fig, axins =plt.subplots(dpi=300)\n",
    "\n",
    "# axins = ref_map(axins)\n",
    "# # first one is CA map\n",
    "# ax = inset_axes(axins, width=\"100%\", height=\"100%\", bbox_to_anchor=(0.8, -.1, 1.3, 1.3),\n",
    "#                   bbox_transform=axins.transAxes, loc=2)\n",
    "\n",
    "# main_map(ax=ax)\n",
    "    \n",
    "# mark_inset(axins, ax, loc1=2, loc2=3, fc=\"none\", ec=\"black\")\n",
    "\n",
    "# plt.savefig(join(method_dir, 'regional_domain_map.png'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78fb1f1-76a5-472a-bfe2-b65ffd4e3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5, 6.5), dpi=300)\n",
    "\n",
    "main_map(ax=ax)\n",
    "\n",
    "axins = inset_axes(ax, width=\"35%\", height=\"35%\", \n",
    "                   loc='upper left',\n",
    "                   bbox_to_anchor=(-.01, .01, 1, 1),\n",
    "                  bbox_transform=ax.transAxes, \n",
    "                   # loc=2\n",
    "                  )\n",
    "ref_map(axins)\n",
    "\n",
    "plt.savefig(join(fig_dir, 'regional_domain_map.png'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938f549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save shapefiles to a directory for Helen to use for mapping\n",
    "# gis_map = join(box_dir, 'gis_map_overview')\n",
    "# ca.to_crs('epsg:4269').to_file(join(gis_map, 'CA_boundary.shp'))\n",
    "# ws_gdf.to_file(join(gis_map, 'HUC8_watershed_boundary.shp'))\n",
    "# m_domain.to_file(join(gis_map, 'model_domain_boundary.shp'))\n",
    "# cr.to_file(join(gis_map, 'cosumnes_river_stream_line.shp'))\n",
    "# transg.to_file(join(gis_map, 'channel_transect_lines.shp'))\n",
    "\n",
    "# sfr_buf_all = pd.DataFrame()\n",
    "# for d in np.arange(200,3400, 200):\n",
    "#     sfr_buf = grid_sfr.buffer(d).unary_union\n",
    "#     sfr_buf = gpd.GeoDataFrame(pd.DataFrame([0]), geometry=[sfr_buf], crs=grid_sfr.crs)\n",
    "#     sfr_buf = gpd.overlay(sfr_buf, m_domain)\n",
    "#     sfr_buf['setback_m'] = d\n",
    "#     sfr_buf_all = pd.concat((sfr_buf_all, sfr_buf))\n",
    "# # save files\n",
    "# sfr_buf_all.drop(columns=[0]).to_file(join(gis_map, 'sfr_grid_setback_distances.shp'))\n",
    "# grid_sfr.to_file(join(gis_map, 'sfr_grid_cells.shp'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XS 23, 24 (1-based) seem to be where the XS might be an issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c09968",
   "metadata": {},
   "source": [
    "# Flood type and cross-section figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8256cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "setbacks = np.arange(0, 3400,200)\n",
    "# original XS data\n",
    "xs_all_df = pd.read_csv(chan_dir+'Elevation_by_XS_number_meters.csv',index_col='dist_from_center_m')\n",
    "# smoothed XS data used for setback analysis\n",
    "xs_levee_smooth = pd.read_csv(chan_dir+'xs_levee_smooth.csv', index_col='dist_from_center_m')\n",
    "# adjust distance so channel is 0\n",
    "# xs_levee_smooth.index -= 3300\n",
    "# xs_all_df.index -= 3300\n",
    "\n",
    "num_segs = xs_all_df.shape[1]\n",
    "\n",
    "# load array identifying row,col to XS id (1,28)\n",
    "xs_arr = np.loadtxt(chan_dir+'XS_num_grid_reference.tsv')\n",
    "\n",
    "# load flood typology characteristics (based on daily data 1908 - 2014) - median values \n",
    "#\"cms_pk\" for peak discharge, \"pk_loc\" for time to peak, and \"log_no_d\" for duration\n",
    "flood_type = pd.read_csv(join(box_dir, 'whipple_grp6_w97ftmedians.csv'),index_col='Group.1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_lab(gdf, text, ax, offset = (0,0)):\n",
    "    xy = gdf.geometry.unary_union.centroid.coords[0]\n",
    "    ax.annotate(text=text, xy=xy, ha='center', va = 'bottom', xytext = offset, textcoords='offset points',\n",
    "                arrowprops = {'shrinkA':1,'arrowstyle':'simple', 'color':'black'},\n",
    "                bbox=dict(boxstyle=\"square,pad=0.3\", fc=\"lightgrey\", ec=\"black\", lw=2))\n",
    "# def plt_lab(xy, text, ax, offset = (0,0)):\n",
    "#     ax.annotate(text=text, xy=xy, ha='center', va = 'bottom', xytext = offset, textcoords=('data', 'offset points'),\n",
    "#                 arrowprops = {'shrinkA':1, 'arrowstyle':'simple', 'color':'black'},\n",
    "#                 bbox=dict(boxstyle=\"square,pad=0.3\", fc=\"lightgrey\", ec=\"black\", lw=1))\n",
    "def plt_lab(xy, text, ax, offset = (0,0)):\n",
    "    ax.annotate(text=text, xy=xy, ha='center', va = 'bottom', xytext = offset, textcoords=('data', 'offset points'),\n",
    "                arrowprops = dict(headwidth=3, headlength=2, width=0.5, color='black'),\n",
    "                bbox=dict(boxstyle=\"square,pad=0.3\", fc=\"lightgrey\", ec=\"black\", lw=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d6a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_hydrograph(ft, ax):\n",
    "    # typical winter baseflow, peak flow, peak location, total time (days)\n",
    "    # flow of 23 m3/s listed by Whipple as floodplain cutoff\n",
    "    q_base = 23\n",
    "    q_peak = flood_type.loc[ft,'cms_pk']\n",
    "    # total duration in days \n",
    "    T = int(10**flood_type.loc[ft,'log_no_d'])\n",
    "    p_l = flood_type.loc[ft,'pk_loc']\n",
    "    tp = int(p_l*T)\n",
    "    q_rise = np.linspace(q_base, q_peak, tp)\n",
    "    q_fall = np.linspace(q_peak, q_base, (T-tp+1))\n",
    "    q_in = np.append(q_rise, q_fall[1:])\n",
    "    ax.plot(q_in)\n",
    "    # annotation with type label\n",
    "    plt_lab((tp*3, q_in[tp*3]), flood_type.loc[ft,'Typology'], ax, offset=(50, -0.05*q_peak)) \n",
    "\n",
    "    ax.vlines(x = tp-1, ymin=q_base, ymax = q_peak, linestyle='--',color='grey')\n",
    "    ax.set_xlabel('Days')\n",
    "    ax.set_ylabel('Flow ($m^3/s$)')\n",
    "    return(q_in)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93530bc",
   "metadata": {},
   "source": [
    "## XS figure\n",
    "2 subplots, the one on the right shows an example model XS with the original data and rolling average of elevation, vertical lines for each setback distance, elevations of flood depth for each corresponding peak flow. The left plot will show the triangular hydrograph for the three plots, but plot with curved lines rather than straight to show a more realistic hydrograph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79538d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from muskingum_recharge import min_Q, mannings, calc_depth_arr, gridded_interpolation, xs_setback, mannings_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b604f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating curves for each segment and setback\n",
    "xs_flow_all = pd.read_csv(join(chan_dir,'all_xs_50pt_rating_curves.csv'))\n",
    "# xs_flow_all = pd.read_csv(join(chan_dir,'all_xs_smooth_50pt_rating_curves.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3654ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_match(seg_flow, flow):\n",
    "    \"\"\" Given a XS (nseg, setback) return the expected depth (m) given a flow (cms)\"\"\"\n",
    "    # find flows above and below the input flow\n",
    "    flow_diff = (seg_flow.flow_cms-flow)\n",
    "    f_high = flow_diff[flow_diff>0].argsort().index[0]\n",
    "    f_low = flow_diff[flow_diff<0].argsort().index[-1]\n",
    "    match_d = seg_flow.loc[[f_low, f_high]].sort_values('flow_cms')\n",
    "    # linearly interpolate to calculate exact depth\n",
    "    flow_slope = (match_d.iloc[1].flow_cms-match_d.iloc[0].flow_cms)/(match_d.iloc[1].depth_m-match_d.iloc[0].depth_m)\n",
    "    out_depth = match_d.iloc[0].depth_m + (flow-match_d.iloc[0].flow_cms)/flow_slope\n",
    "    return(out_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd45f90-0cf1-4959-8208-e1bd8743aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_xlabel(ax_n):\n",
    "    ax_n.set_xticks(np.arange(-3300,3500,200), minor=True)\n",
    "    xleft = np.arange(-3300,-800,800)\n",
    "    xright = np.arange(900,3500,800)\n",
    "    ax_n.set_xticks(np.append(xleft, xright), np.append(xleft+100, xright-100))\n",
    "    # ax_n.set_ylim(xs_all_df.iloc[:,nseg].min()*0.8, xs_all_df.iloc[:,nseg].max()*1.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_all_plt = xs_all_df.copy()\n",
    "# xs_all_plt = xs_levee_smooth.copy()\n",
    "\n",
    "nseg = int(xs_all_plt.shape[1]/2)\n",
    "# nseg = 24 # shows well had different flood depths inundate area\n",
    "# nseg= 20 # shows flow filling side channels and some floodplain\n",
    "nseg = 22\n",
    "\n",
    "fig,ax = plt.subplots(2,1, figsize=(6.5,6), dpi=300)\n",
    "ax_n = ax[1]\n",
    "\n",
    "setback = 3200\n",
    "seg_flow = xs_flow_all[(xs_flow_all.nseg==nseg)&(xs_flow_all.setback==setback)]\n",
    "   \n",
    "## Plot Example Cross-section ##\n",
    "xs_all_df.iloc[:,nseg].plot(ax=ax_n, label='Cross Section', color='black')\n",
    "# plot was getting too messy with the original and filled XS\n",
    "# xs_levee_smooth.iloc[:,nseg].plot(ax=ax_n, label='Cross Section',  color='black')\n",
    "# plot streambed thickness\n",
    "# ax[1].fill_between(xs_levee_smooth.index, xs_levee_smooth.iloc[:,nseg], \n",
    "#                    xs_levee_smooth.iloc[:,nseg]-2, color='brown', alpha=0.5, label='Streambed Thickness')\n",
    "\n",
    "## Plot hydrographs ##\n",
    "for ft in [1,2,3]:\n",
    "    q_in = plt_hydrograph(ft, ax[0])\n",
    "    # add depth to XS plot\n",
    "    d = depth_match(seg_flow, flood_type.loc[ft,'cms_pk'])\n",
    "    fld_elev = (xs_all_plt.iloc[:,nseg].min()+d)*np.ones(xs_levee_smooth.shape[0])\n",
    "    fld_elev[fld_elev<xs_all_plt.iloc[:,nseg]] = np.nan\n",
    "    plt.plot(xs_all_plt.index, fld_elev, label=flood_type.loc[ft,'Typology']) # color='blue'\n",
    "    # wetted perimeter\n",
    "    wp = xs_all_plt.iloc[:,nseg].copy()\n",
    "    wp[wp>np.nanmean(fld_elev)] = np.nan\n",
    "    plt.plot(xs_all_plt.index, wp, color='brown')\n",
    "\n",
    "# plt.plot(xs_all_plt.index, fld_elev, label='Flood Elevation', color='tab:green') #color='blue', \n",
    "plt.plot(xs_all_plt.index, wp, color='brown', label='Wetted Perimeter')\n",
    "\n",
    "ax_n.set_xlabel('Distance from river center (m)')\n",
    "ax_n.set_ylabel('Elevation (m AMSL)')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "clean_xlabel(ax_n)\n",
    "# ax_n.set_xticks(np.arange(-3300,3500,200), minor=True)\n",
    "# xleft = np.arange(-3300,-800,800)\n",
    "# xright = np.arange(900,3500,800)\n",
    "# ax_n.set_xticks(np.append(xleft, xright), np.append(xleft+100, xright-100))\n",
    "ax_n.set_ylim(xs_all_df.iloc[:,nseg].min()*0.8, xs_all_df.iloc[:,nseg].max()*1.2)\n",
    "\n",
    "# plot vertical lines at each setback\n",
    "for ns, s in enumerate(setbacks[::4]):\n",
    "    ax_n.axvline(s+100, linewidth=0.1)\n",
    "    ax_n.axvline(s-3300, linewidth=0.1)\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(join(fig_dir, 'flood_types_channel_cross_section.png'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a29c4-3c50-425f-a73e-69cb1946b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = 1\n",
    "\n",
    "ny = 4\n",
    "nx = int(len(setbacks[1:])/ny)\n",
    "fig,axes =plt.subplots(nx,ny, figsize=(8,8), sharex=True, sharey=True)\n",
    "# setback = 3200\n",
    "for n, setback in enumerate(setbacks[1:]):\n",
    "# for n, setback in enumerate([200]):\n",
    "    ax = axes[int(n/ny), n%ny]\n",
    "    seg_flow = xs_flow_all[(xs_flow_all.nseg==nseg)&(xs_flow_all.setback==setback)]\n",
    "     \n",
    "    # xs_elevs = xs_all_df.loc[-setback-100:setback+100, str(nseg)]\n",
    "    xs_elevs = xs_setback(xs_all_df.iloc[:, nseg].copy(), setback, levee_ft=30)\n",
    "    xs_elevs.plot(ax=ax, label='Cross Section', color='black')\n",
    "    \n",
    "    # add depth to XS plot\n",
    "    d = depth_match(seg_flow, flood_type.loc[ft,'cms_pk'])\n",
    "    fld_elev = (xs_elevs.min()+d)*np.ones(xs_elevs.shape[0])\n",
    "    fld_elev[fld_elev<xs_elevs] = np.nan\n",
    "    ax.plot(xs_elevs.index, fld_elev, label=flood_type.loc[ft,'Typology']) # color='blue'\n",
    "    ax.set_xlabel(None)\n",
    "\n",
    "for n in np.arange(0,ny):\n",
    "    ax = axes[-1,n]\n",
    "    clean_xlabel(ax)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "fig.supylabel('Elevation (m)')\n",
    "fig.supxlabel('Distance from channel (m)')\n",
    "fig.tight_layout(h_pad=0.1, w_pad=-0.1)\n",
    "ax.set_ylim(xs_all_df.iloc[:,nseg].min()*0.8, xs_all_df.iloc[:,nseg].max()*1.2);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f956af2-6396-4b02-99d2-fc5ed5e8baf7",
   "metadata": {},
   "source": [
    "# Demonstration of overlay of HCP and flood depth to get recharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b86ea44-ce49-45e0-b739-ce350d6d5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['lightgray', 'blue']\n",
    "cm_scale = [0, 1]\n",
    "cmap=mpl.colors.ListedColormap(colors)\n",
    "norm=mpl.colors.BoundaryNorm(cm_scale, len(colors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a6cf9f-e799-40f7-9c3b-7553c81a0e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_percentile=6\n",
    "hf_tot_in =  np.loadtxt(data_dir+'surface_highflow_by_realization_'+str(flow_percentile)+'.tsv',delimiter = '\\t')\n",
    "hf_tot = np.reshape(hf_tot_in, (100, nrow, ncol))\n",
    "# hf_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6b644-8542-461e-9862-99eb414a582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tprogs near surface data\n",
    "soil_thick=2\n",
    "# fn = chan_dir+'/tprogs_geomK_'+str(soil_thick)+'m_depth.tsv' # old version with linear dem and old function for sampling tprogs\n",
    "fn = chan_dir+'/tprogs_geomK_'+str(soil_thick)+'m_depth_dem_mean.tsv'\n",
    "# units of m/day\n",
    "soil_K_out = np.loadtxt(fn, delimiter='\\t')\n",
    "soil_K = np.reshape(soil_K_out, (100, nrow, ncol))\n",
    "# convert soil conductivity from m/d to m/s and apply vertical anisotropy factor\n",
    "vani = 100\n",
    "soil_K = (soil_K/vani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe027266-89c9-48be-a6d1-f56d8abd447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_in = 2\n",
    "region='regional'\n",
    "# spatial view\n",
    "f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "rch_hf_all = f['array']['all'][:]\n",
    "f.close()\n",
    "f = h5py.File(join(data_dir,'hdf5', 'depth_avg_arr'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "d_all = f['array']['all'][:]\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3cbb43-de16-443d-b117-64dbbe9b14d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t= 5\n",
    "s = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c93c6d-e012-4de1-af5a-c2ccf3932a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sfr_setback(grid_sfr, grid_p, s):\n",
    "    setback = s*200\n",
    "\n",
    "    # grid_sfr = gpd.read_file(gwfm_dir+'/SFR_data/final_grid_sfr/grid_sfr.shp')\n",
    "    sfr_union = gpd.GeoDataFrame(pd.DataFrame([0]), geometry = [grid_sfr.unary_union], crs=grid_sfr.crs)\n",
    "    sfr_union.geometry = sfr_union.buffer(setback).exterior\n",
    "    # grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n",
    "    \n",
    "    setback_grid = gpd.sjoin(sfr_union, grid_p, how='left')\n",
    "    setback_outer = np.zeros((nrow,ncol))\n",
    "    setback_outer[setback_grid.row-1, setback_grid.column-1] = 1\n",
    "    setback_outer = ma.masked_where(setback_outer==0,setback_outer)\n",
    "    return(setback_outer)\n",
    "\n",
    "setback_outer = sfr_setback(grid_sfr, grid_p, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb7c08-4bdd-4e7d-9bf4-8a329e4e8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = ['High Conductivity Pathways', 'Floodplain Inundation','Floodplain Recharge']\n",
    "title = ['(A)', '(B)','(C)']\n",
    "def floodplain_annotate(ax, setback_outer, title=['(A)', '(B)','(C)']):\n",
    "\n",
    "    for n in np.arange(0,len(title)):\n",
    "        ax_n = ax[n]\n",
    "        ax_n.imshow(setback_outer, cmap='gray') # works when dpi=600\n",
    "        ax_n.plot(grid_sfr.column-1, grid_sfr.row-1, color='black', linewidth=0.5, linestyle='-.')\n",
    "        ax_n.annotate(text = title[n], xy=(0.1,0.8), xycoords='axes fraction',\n",
    "                      bbox={'facecolor': 'lightgray', 'alpha': 0.9, 'pad': 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4ed818-39bf-4a04-96d5-4c53a5f66425",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot for the methods to show overlay of HCP, flood depth to recharge\n",
    "\n",
    "# fig, ax = plt.subplots(3,1, dpi=600,figsize=(8,6), sharex=True)\n",
    "def ex_depth_rch(t,s, fig,ax, cbar_log=True):\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "    \n",
    "    ## plot HCPs\n",
    "    ax_n = ax[0]\n",
    "    # im = ax_n.imshow(hf_tot[t],cmap=cmap)\n",
    "    # # color bar on all rows, with two discrete labels\n",
    "    # cbar=plt.colorbar(mappable = im, ax=ax_n,  ticks = [0.25,.75], shrink= 0.6)\n",
    "    # cbar.ax.set_yticklabels(['Low K', 'HCP'])\n",
    "    im_K = ax_n.imshow(soil_K[t], \n",
    "                     norm= mpl.colors.LogNorm(),\n",
    "                     cmap='viridis', alpha=0.7,\n",
    "                    )\n",
    "    if cbar_log:\n",
    "        plt.colorbar(im, ax=ax_n, orientation='vertical', label='Vertical Conductivity (m/d)',\n",
    "                     shrink=0.6,location='right')\n",
    "    \n",
    "    ## plot flood depth\n",
    "    ax_n = ax[1]\n",
    "    nf = 2 \n",
    "    d_plt = np.ma.masked_invalid(d_all[t, s])\n",
    "    # vmax for depth/recharge are manually specified\n",
    "    im_d = ax_n.imshow(d_plt, vmax=2.5,\n",
    "                     # norm = mpl.colors.LogNorm(vmin = 1E-2, vmax = np.nanmax(d_plt)),\n",
    "                     cmap= 'cool',#'viridis_r', \n",
    "                     zorder=1\n",
    "                    )\n",
    "    if cbar_log:\n",
    "        plt.colorbar(im, ax=ax_n, orientation='vertical', label='Depth (m)', shrink=0.6,location='right')\n",
    "    ## plot recharge\n",
    "    ax_n = ax[2]\n",
    "    temp = rch_hf_all[t,s]*1E-6\n",
    "    im_rch = ax_n.imshow(np.ma.masked_where(temp==0, temp), vmax=3.5,\n",
    "                     cmap = 'plasma' ) #'YlOrRd': hard to see yellow, # plasma was nice, magma/inferno are intense with black\n",
    "    if cbar_log:\n",
    "        plt.colorbar(im, ax=ax_n, orientation='vertical', label='Total Recharge (MCM)', \n",
    "                     shrink=0.6,location='right')\n",
    "    \n",
    "\n",
    "    # fig.tight_layout(h_pad=-.3) #pad=0.4, w_pad=0.5,\n",
    "    return(im_K, im_d, im_rch)\n",
    "    # plt.savefig(join(fig_dir, 'example_vka_depth_recharge'+str(s*200)+'.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693d414-4f39-481b-b5d9-fbcc1c89651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_cbar(fig,ax, im_K, im_d, im_rch):\n",
    "    cbar0 = ax[0].ravel()\n",
    "    cbar1 = ax[1].ravel()\n",
    "    cbar2 = ax[2].ravel()\n",
    "    shrink=0.6\n",
    "    plt.colorbar(im_K, ax=cbar0, orientation='vertical', label='Vertical Conductivity\\n(m/d)', \n",
    "                 shrink=shrink,location='right')\n",
    "    plt.colorbar(im_d, ax=cbar1, orientation='vertical', label='Depth (m)', shrink=shrink,location='right')\n",
    "    plt.colorbar(im_rch, ax=cbar2, orientation='vertical', label='Total Recharge (MCM)', \n",
    "                         shrink=shrink,location='right')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7501b9-8fce-4567-9d54-67d7e89a5370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# took manual adjustments to find 11, 6.5 with h_pad-1 to work\n",
    "fig,ax = plt.subplots(3,2, dpi=600,figsize=(10.5,6), sharex=True)\n",
    "im_K, im_d, im_rch = ex_depth_rch(t, 3, fig,ax[:,0], cbar_log=False)\n",
    "setback_outer = sfr_setback(grid_sfr, grid_p, 3)\n",
    "floodplain_annotate(ax[:,0], setback_outer, title=['(A)', '(C)','(E)'])\n",
    "    \n",
    "im_K, im_d, im_rch = ex_depth_rch(t, 6, fig,ax[:,1], cbar_log=False)\n",
    "setback_outer = sfr_setback(grid_sfr, grid_p, 6)\n",
    "floodplain_annotate(ax[:,1], setback_outer, title=['(B)', '(D)','(F)'])\n",
    "\n",
    "fig.tight_layout(h_pad=-1.5, w_pad=1)\n",
    "ex_cbar(fig,ax, im_K, im_d, im_rch )\n",
    "\n",
    "# fig.tight_layout(h_pad=-.3) #pad=0.4, w_pad=0.5,\n",
    "\n",
    "plt.savefig(join(fig_dir, 'example_vka_depth_recharge_side_by_side.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e17ebb7-830b-45b6-86ed-dce2de0bd1d9",
   "metadata": {},
   "source": [
    "**Summary values** (from Helen)\n",
    "- state total HCP area, flooded HCP area, state how much recharge occurred under the large and long flood,\n",
    "    - try express as fractions in terms of %of total area\n",
    "- Also calculate the recharge in background area and compare it total HCP recharge and total non HCP recharge   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dae573-003d-4dca-9e3b-a6a651cbe1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rch_summary(t,s):\n",
    "    # area of HCP in setback\n",
    "    hf_sum = (hf_tot[t]*str_setbacks[s]).sum()\n",
    "    s_area = str_setbacks[s].sum()\n",
    "    # area of HCP inundated divided by HCP area in setback\n",
    "    hf_frac = (hf_tot[t]*(d_all[t,s]>=0.1)).sum()/hf_sum\n",
    "    # area of HCP inundated divided by total setback area\n",
    "    hf_frac = (hf_tot[t]*(d_all[t,s]>=0.1)).sum()/s_area\n",
    "    print('Setback distance of %.i m:' %(s*200))\n",
    "    print('HCP area as fraction of setback area %.2f%%' %(hf_sum*100/s_area))\n",
    "    print('Flooded HCP area as fraction of total HCP %.2f%%' %(hf_frac*100))\n",
    "    \n",
    "    rch_sum = (rch_hf_all[t,s]*1E-6).sum()\n",
    "    print('Total recharge %.2f MCM' %rch_sum)\n",
    "    \n",
    "    rch_hcp = (rch_hf_all[t,s]*1E-6*hf_tot[t]).sum()\n",
    "    print('Total HCP recharge %.2f MCM' %rch_hcp, 'and fraction is %.1f %%' %(rch_hcp*100/rch_sum))\n",
    "    rch_non_hcp = (rch_hf_all[t,s]*1E-6*(~hf_tot[t].astype(bool))).sum()\n",
    "    print('Total non HCP recharge %.2f MCM' %rch_non_hcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b8a23-c836-483a-b426-0725d879e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "rch_summary(t,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685814ad-3925-4fdf-b4c8-dbd69ec82fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rch_summary(t,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a4a1e-5ac7-4ed5-9698-30b1aa0e4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rch_summary(t,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa93811",
   "metadata": {},
   "source": [
    "# Geology figure\n",
    "\n",
    "3d figure of geology to show the 4 different facies (mud, sandy mud, sand and gravel), with data above the DEM cropped and the Cosumnes River highlighted in blue. Secondary figure showing the facies categorized as coarse vs fine and zoomed in to a smaller area to show a connected body travels vertically, ideally with an example of a coarse body that is isolated so is removed. \n",
    "\n",
    "I checked the imapct Connec3D without coarse above land surface and the percentage of CCO kept only went down from 97.6 to 96.1 so there is not a significant impact. That just means there is a lot of connectivity in the subsurface and we might need to use the volumetric filtering to create a cleaner plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82167be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tprogs_cleaning as tc\n",
    "import pyvista as pv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb026aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# directory with a few CCO files for method's figure plotting\n",
    "cco_dir = join(proj_dir,'CCO_for_plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a98ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tprogs_id = '_no_conditioning'\n",
    "mf_tprogs_dir = gwfm_dir+'/UPW_data/tprogs_final' + tprogs_id+'/'\n",
    "tprogs_files = glob.glob(mf_tprogs_dir+'*')\n",
    "# tprogs_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcbc47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_dim = (320, 100, 230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477febb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "tprogs_line = np.loadtxt(tprogs_files[t])\n",
    "# convert any negatives representing input data to same value\n",
    "tprogs_arr = np.abs(np.reshape(tprogs_line, (320, 100,230)))\n",
    "conn_arr = np.zeros((320, 100,230))\n",
    "# new array where sand, gravel (1,2) are 1-coarse and sandy mud, mud are 0-fine\n",
    "conn_arr[(tprogs_arr == 1)|(tprogs_arr == 2)] = 1\n",
    "# new directory for each set of plots\n",
    "gel3d_dir = join(method_dir, 'r'+str(t).zfill(3))\n",
    "os.makedirs(gel3d_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f2d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connec3D Connected Components Output file\n",
    "cco_in = np.loadtxt(join(cco_dir, 'r'+str(t).zfill(3)+'.CCO'))\n",
    "# reshape to array format\n",
    "# cco = np.reshape(cco_in, arr_dim)\n",
    "# account for transposing before input\n",
    "cco = np.reshape(cco_in, np.flip(arr_dim))\n",
    "cco = np.transpose(cco)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7272092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cco_vert(cco, dem_data):\n",
    "    # identify the connected components, each has a unique number\n",
    "    z,y,x = np.where(cco>0)\n",
    "    val = cco[z,y,x]\n",
    "    # np.transpose((z,y,x,val))\n",
    "    # create a dataframe of the locations of connected components\n",
    "    df = pd.DataFrame(np.transpose((z,y,x,val)),columns=['z','y','x','cc'])\n",
    "    # find ground elevation at each connected point\n",
    "    df['dem'] = dem_data[df.y.astype(int),df.x.astype(int)]\n",
    "    # calculate elevation from tprogs layer\n",
    "    df['elev'] = 80-z*0.5\n",
    "    # check whether each layer is above land surface\n",
    "    df['above_gse'] = (df.elev > df.dem) \n",
    "    # check wehether each layer is 30 m below land surface (100 ft)\n",
    "#     df['below_30'] = (df.elev <= df.dem - 60)\n",
    "    df['below_30'] = (df.elev <= - 79)\n",
    "    df_sum = df.groupby('cc').sum()\n",
    "    # find connected components that are above ground and connect deeper than 30m below\n",
    "    df_conn = df_sum[(df_sum.above_gse>0).values & (df_sum.below_30 >0).values].index\n",
    "    # check if top and bottom connected is in cco array\n",
    "    cco_vert = np.isin(cco, df_conn)\n",
    "    return(cco_vert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b975ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprogs_info = [80, -80, 320]\n",
    "\n",
    "\n",
    "cco_vert = get_cco_vert(cco, dem_data).astype(int)\n",
    "# tprogs_cleaning.get_tprogs_for_elev(dem_data)\n",
    "tprogs_lay = tc.elev_to_tprogs_layers(elev=dem_data, tprogs_info=tprogs_info)\n",
    "# elev_to_tprogs_layers?\n",
    "rows = np.where(np.ones(tprogs_lay.shape)==1)[0]\n",
    "cols = np.where(np.ones(tprogs_lay.shape)==1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ca077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom elevations array of tprogs\n",
    "bot_elev = np.reshape(np.flip(np.arange(-80,80,0.5)), (320, 1,1))\n",
    "bot_elev = np.repeat(np.repeat(bot_elev, 100, axis=1), 230, axis=2)\n",
    "\n",
    "# make any data above the DEM a -1 and crop out\n",
    "cco_vert[bot_elev>dem_data] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7daba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfarr2grid(arr):\n",
    "    grid = pv.UniformGrid()\n",
    "    # Set the grid dimensions: shape because we want to inject our values on the\n",
    "    # I have to add 1 to each dimension to have it be built on the cells\n",
    "    grid.dimensions = [101, 231, 321]\n",
    "    # real origin, but incorrect because of no rotation\n",
    "    # simple origin that allows easier data output cleaning\n",
    "    grid.origin = (0, 0, 0) # bottom left corner of the dataset\n",
    "    grid.spacing = (200,200,0.5)\n",
    "    arr_in = np.moveaxis(arr,0,2).flatten(order='F').astype(int)\n",
    "    grid.cell_data[\"facies\"] = arr_in\n",
    "\n",
    "    return(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "river_arr = np.zeros(arr_dim)\n",
    "r_lay = tprogs_lay[grid_sfr.row.astype(int)-1, grid_sfr.column.astype(int)-1]\n",
    "river_arr[r_lay-2, grid_sfr.row.astype(int)-1, grid_sfr.column.astype(int)-1] = 1\n",
    "river = mfarr2grid(river_arr)\n",
    "river = river.threshold(value = [0.9, 1.1], scalars='facies') #, preference='cell'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29002be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot of regional scale model with all facies and cropped by DEM\n",
    "tprogs_cco = tprogs_arr.copy()\n",
    "tprogs_cco[bot_elev>dem_data]=0\n",
    "\n",
    "tprogs_cco_grid = mfarr2grid(tprogs_cco)\n",
    "tprogs_active = tprogs_cco_grid.threshold(value = [0.9, 4.1], scalars='facies') #, preference='cell'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55366aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot of regional model as coarse vs fine and cropped by DEM\n",
    "grid = mfarr2grid(cco_vert)\n",
    "active = grid.threshold(value = [-.1, 1.1], scalars='facies') #, preference='cell'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921fd41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying the local plotting area\n",
    "reach = grid_sfr[grid_sfr.reach == grid_sfr.reach.median()]\n",
    "l_row = reach.row.astype(int).iloc[0]\n",
    "l_col = reach.column.astype(int).iloc[0]\n",
    "# array to multiply others\n",
    "nlocal = 20\n",
    "local_cells = np.zeros(cco.shape).astype(bool)\n",
    "local_cells[:,l_row-nlocal:l_row+nlocal, l_col-nlocal:l_col+nlocal] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600edd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a subset of the regional model coarse facies to show an example vertical pathway\n",
    "local_arr = np.copy(cco_vert)\n",
    "# crop to local cells\n",
    "local_arr *= local_cells\n",
    "# remove cells above dem\n",
    "local_arr[bot_elev>dem_data]=0\n",
    "# local_arr[:,l_row-nlocal:l_row+nlocal, l_col-nlocal:l_col+nlocal] +=1\n",
    "local_grid = mfarr2grid(local_arr)\n",
    "local_active = local_grid.threshold(value = [0.9, 1.1], scalars='facies') #, preference='cell'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e88b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter cco by the number of cells in each\n",
    "# find the largest cco number in the local area\n",
    "cco_count, cco_num = np.histogram(cco[local_cells], bins=np.unique(cco[local_cells]))\n",
    "cco_largest = cco_num[1:][np.argmax(cco_count[1:])]\n",
    "# extrapolate out to the larger area before filtering\n",
    "cco_local_out = np.zeros(cco.shape)\n",
    "cco_local_out[cco==cco_largest] =1\n",
    "# crop to local cells\n",
    "cco_local_out *= local_cells\n",
    "# remove cells above dem\n",
    "cco_local_out[bot_elev>dem_data]=0\n",
    "cco_local_grid = mfarr2grid(cco_local_out)\n",
    "\n",
    "cco_local_active = cco_local_grid.threshold(value = [0.9, 1.1], scalars='facies') #, preference='cell'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locally plot all facies\n",
    "tprogs_local = tprogs_arr.copy()\n",
    "tprogs_local[cco_local_out!=1] *=0\n",
    "tprogs_local_grid = mfarr2grid(tprogs_local)\n",
    "tprogs_local_active = tprogs_local_grid.threshold(value = [0.9, 2.1], scalars='facies') #, preference='cell'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a538052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pv_rot(mesh):\n",
    "    mesh.rotate_z(90)\n",
    "    mesh.rotate_x(10)\n",
    "    # it seems that the tprogs data is somehow flipped when importing it into pyvista\n",
    "    # because it requires an extra 180 degree rotation\n",
    "#     mesh.rotat_y(10)\n",
    "    mesh.rotate_y(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c5d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_plt(grid, fig_nam, grid2=None):\n",
    "    plotter = pv.Plotter(notebook=False, \n",
    "#                          lighting=None,\n",
    "                         off_screen=True # if true then screenshots work\n",
    "                        )\n",
    "    plotter.background_color='white'\n",
    "    # show_egdes should be done locally but not regionally\n",
    "    # but if I add lighting then I might not need edges\n",
    "    mesh = plotter.add_mesh(grid, scalars=\"facies\", cmap='viridis', lighting=True)\n",
    "    pv_rot(mesh)\n",
    "\n",
    "    plotter.set_scale(1, 1, 50)\n",
    "    if grid2 is not None:\n",
    "        mesh = plotter.add_mesh(grid2, color='black')\n",
    "        pv_rot(mesh)\n",
    "    plotter.show(screenshot=fig_nam + '.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_plt(active, join(gel3d_dir,'tprogs_coarse_active'))\n",
    "grid_plt(tprogs_active, join(gel3d_dir,'tprogs_facies_active'), river)\n",
    "#A screenshot is unable to be taken as the render window is not current or rendering is suppressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb129570",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_plt(local_active, join(gel3d_dir,'tprogs_local_facies_active'))\n",
    "grid_plt(tprogs_local_active, join(gel3d_dir,'tprogs_local_largest_cco_active'))\n",
    "\n",
    "# on the local scale we can start to distinguish paths but it isn't very clear still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc194290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not worth plotting just the coarse regionally because it's hard to distinguish a single pathway\n",
    "coarse = active.threshold(value = [0.9, 1.1], scalars='facies') #, preference='cell'\n",
    "grid_plt(coarse, join(gel3d_dir,'coarse_active'))\n",
    "\n",
    "# coarse = local_grid.threshold(value = [0.9, 1.1], scalars='facies') #, preference='cell'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0a07e",
   "metadata": {},
   "source": [
    "## testing for surface cropping\n",
    "I wanted to create a pyvista surface using the DEM surface but it didn't seem to create a surface but lines. I ended up just preprocessing with arrays and using the threshold function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y = np.where(dem_data)\n",
    "# z = dem_data[x,y]\n",
    "# x *= 200\n",
    "# y *= 200\n",
    "# surface\n",
    "# Create and plot structured grid\n",
    "# surface = pv.StructuredGrid(x, y, z)\n",
    "# grid.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb1d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotter = pv.Plotter(notebook=False, lighting=None)\n",
    "# plotter.background_color='gray'\n",
    "# mesh = plotter.add_mesh(surface, \n",
    "#                 )\n",
    "# plotter.set_scale(1, 1, 50)\n",
    "# mesh.rotate_z(90)\n",
    "# mesh.rotate_x(10)\n",
    "# mesh.rotate_y(10)\n",
    "# plotter.show()\n",
    "\n",
    "# Create a grid around that surface\n",
    "# grid = pv.create_grid(surface)\n",
    "\n",
    "# kills the kernel when done incorrectly\n",
    "# Clip the grid using the surface\n",
    "# model = grid.clip_surface(surface)\n",
    "\n",
    "# Compute height and display it\n",
    "# model.elevation().plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

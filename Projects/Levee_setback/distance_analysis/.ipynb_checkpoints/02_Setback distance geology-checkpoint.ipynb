{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "from os.path import basename, dirname, join, exists\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import time\n",
    "\n",
    "# standard python plotting utilities\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import pyproj # for converting proj4string\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# mapping utilities\n",
    "import contextily as ctx\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "    \n",
    "# dir of all gwfm data\n",
    "gwfm_dir = join(dirname(doc_dir),'Box/research_cosumnes/GWFlowModel')\n",
    "\n",
    "flopy_dir = doc_dir+'/GitHub/flopy'\n",
    "if flopy_dir not in sys.path:\n",
    "    sys.path.insert(0, flopy_dir)\n",
    "import flopy \n",
    "\n",
    "import flopy.utils.binaryfile as bf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set box directory for output figures and data\n",
    "box_dir = gwfm_dir+'/Levee_setback/levee_setback_distance_analysis/'\n",
    "\n",
    "# tprogs_id = '' # original tprogs with conditioning data in output tsim\n",
    "tprogs_id = '_no_conditioning'\n",
    "\n",
    "data_dir = box_dir+ tprogs_id+'/data_output/'\n",
    "fig_dir = box_dir+tprogs_id+'/figures/'\n",
    "#\n",
    "chan_dir = box_dir+'channel_data/'\n",
    "gis_dir = chan_dir+'GIS/'\n",
    "\n",
    "check_stream_loc = False\n",
    "# fig_dir = box_dir+'north_shifted_stream_distance_analysis/figures/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting head raster and contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dir = 'F:/WRDAPP'\n",
    "c_dir = 'C:/WRDAPP'\n",
    "\n",
    "if os.path.exists(ext_dir):\n",
    "    loadpth = ext_dir \n",
    "elif os.path.exists(c_dir):\n",
    "    loadpth = c_dir \n",
    "\n",
    "loadpth = loadpth +'/GWFlowModel/Cosumnes/levee_setback/setback_distance_analysis/'\n",
    "model_ws = loadpth+'Permeameter_for_velocity' + tprogs_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = 'MF.nam'\n",
    "# name = 'MF_child.nam'\n",
    "m = flopy.modflow.Modflow.load(name, model_ws=model_ws, \n",
    "                                exe_name='mf2005', version='mf2005')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbb = flopy.utils.CellBudgetFile(model_ws+'/MF.upw.cbc')\n",
    "cbb = flopy.utils.CellBudgetFile(model_ws+'/MF.cbc')\n",
    "\n",
    "hdobj = flopy.utils.HeadFile(model_ws+'/MF.hds')\n",
    "spd_stp = hdobj.get_kstpkper()\n",
    "times = hdobj.get_times()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dates to match totim\n",
    "# strt_date = pd.to_datetime(m.dis.start_datetime)\n",
    "# end_date = strt_date+pd.DateOffset(months=m.dis.nper-1)\n",
    "# dates = strt_date+pd.to_timedelta(zb_df.index-1, unit = 'days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe referencing between date, totim and kstp,kper\n",
    "# time_spd = pd.DataFrame(np.transpose(np.array([times,spd_stp],dtype='object')),columns = ['totim','spd_stp'])\n",
    "# time_spd.index = dates\n",
    "# time_spd.totim = pd.to_numeric(time_spd.totim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SFR grid for buffering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dem data for cropping above land surface\n",
    "dem_data = np.loadtxt(gwfm_dir+'/DIS_data/dem_52_9_200m_linear.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr = gpd.read_file(gwfm_dir+'/SFR_data/final_grid_sfr/grid_sfr.shp')\n",
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n",
    "local_setback = gpd.read_file(gwfm_dir+'/levee_setback/local_levee_setback_rectangles/local_levee_setback_rectangles.shp')\n",
    "local_setback = local_setback.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if check_stream_loc == True:\n",
    "    # offset river by 3000 m (15 cells northwest) to verify analysis\n",
    "    new_sfr_geom = grid_p.set_index(['row','column']).loc[list(zip(grid_sfr.row-15, grid_sfr.column))].reset_index()\n",
    "    fig,ax=plt.subplots()\n",
    "    new_sfr_geom.plot(ax=ax)\n",
    "    grid_sfr.plot(ax=ax)\n",
    "    # m_domain.plot(ax=ax)\n",
    "        # analysis checking results when channel is moved\n",
    "    fig_dir = box_dir+'figures/north_shifted_stream_distance_analysis/'\n",
    "    data_dir = box_dir+'data_output/north_shifted_stream_distance_analysis/'\n",
    "\n",
    "    grid_sfr[['row','column','node','geometry']] = new_sfr_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regional zones by splitting up grid into 3 sections (upper, middle and lower cosumnes)\n",
    "nmx=3\n",
    "local_setback = grid_p.copy()\n",
    "local_setback['id'] = 1\n",
    "for n in np.arange(1,nmx):\n",
    "    local_setback.loc[local_setback.column > n*grid_p.column.max()/nmx, 'id'] = n+1\n",
    "# dissolve grid regions into group polygons\n",
    "local_setback = local_setback.dissolve('id').reset_index()\n",
    "# match previous structure for easier code reuse\n",
    "local_setback['location'] = ['Lower','Middle','Upper']\n",
    "local_setback = local_setback.drop(columns=['node','row','column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random puts them too close together \n",
    "# grid_sfr.loc[np.random.randint(0,len(grid_sfr),size=(5))].plot()\n",
    "# better to pick 5 unique locations based on regional setting\n",
    "# Oneto-Denier (~200), Mahon Ranch (150), Teichert (100), Rooney (80), Michigan Bar (10)\n",
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "# grid_sfr.loc[[10, 80, 100, 150, 200]].plot('reach',ax=ax, legend=True)\n",
    "local_setback.plot(color=\"None\",edgecolor='black', ax=ax)\n",
    "ctx.add_basemap(source = ctx.providers.Esri.WorldImagery, crs = 'epsg:26910', attribution=False,ax=ax)\n",
    "\n",
    "plt.ticklabel_format(style='plain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 3D array of cells included in river setback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## instead of trying to crop the shapefile with the straightlines, just join the local rectangle to the model grid\n",
    "## then after calculating all the levee setbacks simply apply a logical array based on where the rectangles are\n",
    "local_setback_grid = gpd.overlay(grid_p, local_setback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf_sfr = grid_sfr.copy()\n",
    "setbacks = np.arange(0, 3400,200)\n",
    "str_setbacks = np.zeros((len(setbacks),m.dis.nrow,m.dis.ncol))\n",
    "str_setbacks_local = np.zeros((len(setbacks),m.dis.nrow,m.dis.ncol))\n",
    "\n",
    "# grid_sfr.plot()\n",
    "for n in np.arange(0,len(setbacks)):\n",
    "    buf_sfr.geometry = grid_sfr.buffer(setbacks[n])\n",
    "    grid_sfr_buf = gpd.sjoin(grid_p,buf_sfr, how='right', lsuffix = 'grid', rsuffix = 'sfr',predicate='within')\n",
    "    grid_sfr_buf = grid_sfr_buf.drop_duplicates('node_grid')\n",
    "    # clip to local setback sites\n",
    "    grid_sfr_buf_clipped = gpd.sjoin(grid_sfr_buf,local_setback, predicate='intersects',how='right')\n",
    "    # individually identify local setback sites in arrays\n",
    "    for t in np.arange(0,3):\n",
    "        clip_vals = grid_sfr_buf_clipped.loc[grid_sfr_buf_clipped.id==t+1,:]\n",
    "        str_setbacks_local[n,clip_vals.row_grid.values-1,clip_vals.column_grid.values-1] = t+1\n",
    "    str_setbacks[n, grid_sfr_buf.row_grid.values-1,grid_sfr_buf.column_grid.values-1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out local sites only for setback analysis\n",
    "local_grid_bool = np.zeros((m.dis.nrow,m.dis.ncol))\n",
    "for n,s in enumerate(local_setback_grid.location.unique()):\n",
    "    df = local_setback_grid[local_setback_grid.location==s]\n",
    "    local_grid_bool[df.row-1, df.column-1] = n+1\n",
    "# crop setbacks to the polygon widths\n",
    "local_str_setbacks = str_setbacks*local_grid_bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_grid_bool = np.zeros((m.dis.nrow,m.dis.ncol))\n",
    "# local_grid_bool[local_setback_grid.row-1, local_setback_grid.column-1] = 1\n",
    "plt.imshow(local_str_setbacks[16,:,:])\n",
    "plt.colorbar(shrink=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to set bounds of raster, but need to adjust to account for angle\n",
    "#doesn't work with angle\n",
    "# xmin, ymin, xmax, ymax = grid_p.geometry.total_bounds\n",
    "# xmax, ymax = grid_p.geometry.bounds.max().loc[['maxx','maxy']]\n",
    "# xmin, ymin = grid_p.geometry.bounds.min().loc[['maxx','maxy']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_setbacks_labeled(str_setbacks, label):\n",
    "    str_setbacks_plt = np.copy(str_setbacks)\n",
    "    # make non-setback cells masked\n",
    "    str_setbacks_plt = np.ma.masked_where(str_setbacks_plt==0, str_setbacks_plt)\n",
    "    # flip cumsum to make first setback 1 and last setback 10\n",
    "    str_setbacks_plt = (str_setbacks_plt.sum(axis=0)-(len(setbacks)+1))*-1\n",
    "\n",
    "    # plot setbacks labeled \n",
    "    fig,ax = plt.subplots(figsize=(12,6))\n",
    "    cmap = plt.get_cmap('viridis',len(setbacks)+1)\n",
    "    im=ax.imshow(str_setbacks_plt,  cmap=cmap, origin='upper',aspect=1)\n",
    "    plt.colorbar(mappable = im, ax = ax, ticks = np.arange(0,len(setbacks)+1), shrink=0.7)\n",
    "    plt.savefig(fig_dir+'setback_distances_raster_'+label+'.png',dpi=600)\n",
    "    np.savetxt(chan_dir+ label+'_str_setback_id_arr.tsv', str_setbacks_plt, delimiter='\\t')\n",
    "\n",
    "plt_setbacks_labeled(str_setbacks,'regional')\n",
    "# plt_setbacks_labeled(local_str_setbacks, 'local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "# convert arrays of setback locations to hdf5 files \n",
    "f = h5py.File(join(chan_dir, 'setback_locs.hdf5'), \"w\")\n",
    "\n",
    "grp = f.require_group('setbacks') # makes sure group exists\n",
    "grp.attrs['description'] = 'Arrays identifying the cells included in each setback broken by layer'\n",
    "dset = grp.require_dataset('local', local_str_setbacks.shape, dtype='f', compression=\"gzip\", compression_opts=4)\n",
    "dset[:] = local_str_setbacks\n",
    "dset = grp.require_dataset('regional', str_setbacks.shape, dtype='f', compression=\"gzip\", compression_opts=4)\n",
    "dset[:] = str_setbacks\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical Groundwater Velocity Analysis\n",
    "Two methods:\n",
    "1. Simply count the number of cells (area/volume) at land surface within the setback\n",
    "2. Count the total number of groups of cells (requires upscaling?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "# mapview = flopy.plot.PlotMapView(model=m,ax=ax)\n",
    "# linecollection = mapview.plot_grid(linewidths = 0.1)\n",
    "\n",
    "extcbb = flopy.utils.postprocessing.get_extended_budget(cbb)\n",
    "\n",
    "(qx, qy, qz) = flopy.utils.postprocessing.get_specific_discharge(vectors = extcbb, model=m)\n",
    "# mapview.plot_vector(qx, qy, istep=10, jstep=10)\n",
    "qz *= -1\n",
    "qy *= -1\n",
    "qx *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get percentiles to determine which to plot\n",
    "qz_quants = np.percentile(qz, [0,25,50,75,99,99.9])\n",
    "qz_quants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add local path to sys.path for importing scripts\n",
    "# sys.path.append(git_dir+'/01_python_scripts')\n",
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elev_to_tprogs_layers(elev, tprogs_top_elev, tprogs_bot_elev, num_lays):\n",
    "    \"\"\"\n",
    "    function to get the tprogs layers based on the given elevation\n",
    "    Example\n",
    "    layer 0 is 80 meters, layer 1 is 79.5 meters, layer -1 is -80 meters\n",
    "    \"\"\"\n",
    "    lay_thick = (tprogs_top_elev - tprogs_bot_elev)/num_lays\n",
    "    elev_round = np.round((elev) * (1/lay_thick)) / (1/lay_thick) # dem rounded to the layer thickness\n",
    "    elev_round[elev_round >= tprogs_top_elev] = tprogs_top_elev# any elevation above the top is set to the top\n",
    "    # subtract the calculated row from top elev divided by layer thickness to get to index 0 at top and index 320 and bottom\n",
    "    elev_indices = tprogs_top_elev/lay_thick - elev_round*(1/lay_thick) \n",
    "    return(elev_indices.astype(int))\n",
    "\n",
    "# tprogs_cleaning.get_tprogs_for_elev(dem_data)\n",
    "tprogs_lay = elev_to_tprogs_layers(elev=dem_data,tprogs_top_elev=80, tprogs_bot_elev=-80, num_lays=320)\n",
    "# elev_to_tprogs_layers?\n",
    "rows = np.where(np.ones(tprogs_lay.shape)==1)[0]\n",
    "cols = np.where(np.ones(tprogs_lay.shape)==1)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 50th percentile means 50% would be connected and 75th would mean 25% are connected; but sand and gravel take up 24% of the domain volume (by TPROGs) so this should be the upper limit of cells connected, at least the 76th percentile must be used. And according to the paper by Thomas on 3D connectivity only 13% are needed for connection, so the actual value of connected cells should be less than 24% but greater than 13%. The 85th percentile seems to be a good alternative to look for truly the most high flow. Alisha suggested reviewers will ask why a certain perctile was used, thus I should apply the 87th to align with Thomas or use the absolute maximum of 99th per Alisha suggestion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean length for gravel and sands is 1300 and 1100 m in the X direction and 450 m in the Y direction (general setback) direction. Initially plotting for 1 realization seems to show and increase in slope after 400m, suggesting mean lengths are a good indicator for setback distances and that setback should be at least the mean length at the 85th percentile, increasing the percentile to 95th showed a bigger increase in slope at 1000m. It may be worth testing this hypothesis for the 85th and 95th percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/realization'+ str(0).zfill(3)+'/'\n",
    "run_ws = model_ws+folder\n",
    "\n",
    "# iterable part\n",
    "cbb = flopy.utils.CellBudgetFile(run_ws+'/MF.cbc')\n",
    "# load velocity in z direction\n",
    "extcbb = flopy.utils.postprocessing.get_extended_budget(cbb)\n",
    "\n",
    "(qx, qy, qz) = flopy.utils.postprocessing.get_specific_discharge(vectors = extcbb, model=m)\n",
    "# convert flow to positive as it is all moving in the downward, -z direction\n",
    "# q = qz * -1 # not a good indicator at all\n",
    "# much better to use magntiude of velocity vector\n",
    "q = np.sqrt(qx**2 + qy**2 + qz**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['lightgray', 'blue']\n",
    "scale = [0, 1]\n",
    "cmap=mpl.colors.ListedColormap(colors)\n",
    "norm=mpl.colors.BoundaryNorm(scale, len(colors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get high conductivity at ground surface\n",
    "q_plt = np.zeros((100,230))\n",
    "q_plt[rows,cols] = q[tprogs_lay[rows,cols],rows,cols] \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(3,1,figsize=(10,6), sharex=True)\n",
    "fig.tight_layout(h_pad=2)\n",
    "# cmap = mpl.cm.get_cmap('viridis', 2)    # 2 discrete colors\n",
    "\n",
    "percentile_check = [87, 95, 99]\n",
    "for n,i in enumerate(percentile_check):\n",
    "    # split cells into low and high conductivity, based on chosen flow percentile\n",
    "    q_lay = np.zeros((100,230))\n",
    "    q_lay[q_plt >= np.percentile(q_plt,i)] = 1\n",
    "    im = ax[n].imshow(q_lay,cmap=cmap)\n",
    "    ax[n].set_title(str(i)+'th Percentile')\n",
    "\n",
    "# color bar on all rows, with two discrete labels\n",
    "cbar=plt.colorbar(mappable = im, ax=ax,  ticks = [0.25,.75], shrink= 0.7)\n",
    "cbar.ax.set_yticklabels(['Low flow facies', 'High flow facies'])\n",
    "# fig.tight_layout()\n",
    "plt.savefig(fig_dir+'Comparison of high flow facies at ground surface with 87, 95, 99th percentiles.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_percentile = 95\n",
    "\n",
    "# split cells into low and high conductivity, based on chosen flow percentile\n",
    "q_lay = np.zeros((320, 100,230))\n",
    "q_lay[q >= np.percentile(q,flow_percentile)] = 1\n",
    "\n",
    "\n",
    "# get high conductivity at ground surface\n",
    "q_plt = np.zeros((100,230))\n",
    "q_plt[rows,cols] = q_lay[tprogs_lay[rows,cols],rows,cols] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plt_high_recharge_setback(qz_lay, str_setbacks,label):\n",
    "    nx = 5\n",
    "    ny = int(len(setbacks)/nx)\n",
    "    fig, ax = plt.subplots(ny,nx,figsize=(10,6), sharex=True,sharey=True)\n",
    "    fig.tight_layout(h_pad=1) # space between plots\n",
    "#     cmap = mpl.cm.get_cmap('viridis', 2)    # 2 discrete colors\n",
    "    buf_sfr = grid_sfr.copy()\n",
    "\n",
    "    n=0\n",
    "    for x in np.arange(0,ny):\n",
    "        for y in np.arange(0,nx):\n",
    "            temp = np.zeros(qz_lay.shape)\n",
    "            temp[str_setbacks[n,:,:].astype('bool')] = qz_lay[str_setbacks[n,:,:].astype('bool')]\n",
    "            mapview = flopy.plot.PlotMapView(model=m,ax=ax[x,y])\n",
    "            im = mapview.plot_array(temp, cmap=cmap)\n",
    "            ax[x,y].ticklabel_format(style='plain')\n",
    "#             im = ax[x,y].imshow(temp,cmap=cmap)\n",
    "            ax[x,y].set_title(str(200+200*n)+'m Setback')\n",
    "            grid_sfr.plot(ax=ax[x,y], color='black')\n",
    "            sfr_union = gpd.GeoDataFrame(pd.DataFrame([0]), geometry = [grid_sfr.unary_union], crs='epsg:3310')\n",
    "            sfr_union.geometry = sfr_union.buffer(setbacks[n])\n",
    "            sfr_union.plot(color=\"None\", edgecolor='black',ax=ax[x,y], linewidth = 0.2)\n",
    "#             sfr_union.plot(color=\"None\", edgecolor='black',ax=ax[x,y])\n",
    "            n+=1\n",
    "\n",
    "    # color bar on all rows, with two discrete labels\n",
    "    cbar=plt.colorbar(mappable = im, ax=ax,  ticks = [0.25,.75], shrink= 0.7)\n",
    "    cbar.ax.set_yticklabels(['Low flow facies', 'High flow facies'])\n",
    "\n",
    "#     plt.savefig(fig_dir+'Comparison of ' + str(flow_percentile)+'th flow facies for '+ label+' setback distances.png',dpi=600)\n",
    "plt_high_recharge_setback(q_plt, str_setbacks,label='regional')\n",
    "# plt_high_recharge_setback(q_plt, local_str_setbacks,label='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots of setback distance and high flow cells at ground surface make the 99th percentile look very sparse and the 95th percentile look more reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to vectorize the raster to find:\n",
    "1. The number of unique high flow groups\n",
    "2. The area of each high flow group\n",
    "3. The mean, max, min, median and variance of area\n",
    "3. Location? Not needed as it will be summed anyway  \n",
    "\n",
    "In a dataframe there will be one one row for each realization times the number of setbacks with columns for the mean, median, max, min, and variance of the area of high flow cells.\n",
    "Need to iterate over 1. realization 2. setbacks to adjust what are considered high flow cells 3. count groups and area of high flow cells. Must iterate over setback first because a setback may split a group into two or cut off part of a group unlike the cumulative area analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             qz_lay_setback = np.zeros((100,230)) # overlap high flow cells with setback distance\n",
    "#             qz_lay_setback[str_setbacks[0,:,:].astype('bool')] = qz_lay[str_setbacks[0,:,:].astype('bool')]\n",
    "# #             hf = qz_lay[str_setbacks[n,:,:].astype('bool')]\n",
    "#             hf_tot[r,n] = qz_lay_setback.sum() # hf.sum()\n",
    "#             qz_lay_setback_local = np.zeros((100,230)) # overlap high flow cells with local setback distance\n",
    "#             qz_lay_setback_local[local_str_setbacks[0,:,:].astype('bool')] = qz_lay[local_str_setbacks[0,:,:].astype('bool')]\n",
    "#             #hf_local = qz_lay[local_str_setbacks[n,:,:].astype('bool')]\n",
    "#             hf_tot_local[r,n] = qz_lay_setback_local.sum()#hf_local.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highflow_at_groundsurface(run_ws, flow_percentile):\n",
    "    ''' take Cell by Cell budget file and finds high flow cells by percentile\n",
    "    then finds those that outcrop at ground surface'''\n",
    "    cbb = flopy.utils.CellBudgetFile(run_ws+'/MF.cbc')\n",
    "    # load velocity in z direction\n",
    "    extcbb = flopy.utils.postprocessing.get_extended_budget(cbb)\n",
    "    (qx, qy, qz) = flopy.utils.postprocessing.get_specific_discharge(vectors = extcbb, model=m)\n",
    "    # convert flow to positive as it is all moving in the downward, -z direction\n",
    "    # q = qz * -1 # not a good indicator at all\n",
    "    # much better to use magntiude of velocity vector\n",
    "    q = np.sqrt(qx**2 + qy**2 + qz**2)\n",
    "    # split cells into low and high conductivity, based on chosen flow percentile\n",
    "    q_lay = np.zeros((320, 100,230))\n",
    "    q_lay[q >= np.percentile(q,flow_percentile)] = 1\n",
    "\n",
    "    # get high conductivity at ground surface\n",
    "    q_plt = np.zeros((100,230))\n",
    "    q_plt[rows,cols] = q_lay[tprogs_lay[rows,cols],rows,cols] \n",
    "\n",
    "    return(q_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_hf_setback(q_lay, str_setbacks):\n",
    "    q_lay_setback = np.zeros((100,230)) # overlap high flow cells with setback distance\n",
    "    q_lay_setback[str_setbacks.astype('bool')] = q_lay[str_setbacks.astype('bool')]\n",
    "    #             hf = qz_lay[str_setbacks[n,:,:].astype('bool')]\n",
    "    return(q_lay_setback) # hf.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import Polygon\n",
    "from rasterio.features import shapes, rasterize\n",
    "# from shapely.geometry import MultiPoint\n",
    "#, LineString, linemerge, polygonize, unary_union\n",
    "# import pprint\n",
    "\n",
    "def calc_area_stats(r, s, l, q_lay, stat_cols):\n",
    "    ''' for a given realizaiton and setback, find unique cell groups and take summary stats'''\n",
    "    # The function shapes from rasterio requires uint8 format\n",
    "    q_lay_uint = q_lay.astype(rasterio.uint8)\n",
    "    # 'Values of False or 0 will be excluded from feature generation'\n",
    "    out = shapes(q_lay_uint, mask=q_lay.astype(bool), connectivity = 8)\n",
    "    alldata = list(out)\n",
    "    cell_stats = pd.DataFrame(np.zeros((1,len(stat_cols))), columns=stat_cols)\n",
    "    num_cells = np.zeros((len(alldata)))\n",
    "    # iterate over all high flow cell groups\n",
    "    for i in np.arange(0,len(alldata)):\n",
    "        # coordinates are in terms of row and column number\n",
    "        grp_coords = alldata[i][0].get('coordinates')[0]\n",
    "        # the polygon area corresponds to the number of cells included\n",
    "        grp_poly = Polygon(grp_coords)\n",
    "        # grp_poly = MultiPoint(temp) # method to check corners\n",
    "        num_cells[i] = grp_poly.area\n",
    "    if len(num_cells)!=0: #if a realization has no cells then leave as zeros\n",
    "        # calculate statistics for given realization, setback\n",
    "        cell_stats = cell_stats.assign(Num_Grps = len(num_cells), Mean = num_cells.mean(), Median = np.median(num_cells), \n",
    "                                       Min = num_cells.min(),Max = num_cells.max(), Variance = num_cells.var(),\n",
    "                                       Realization = r, Setback = s)\n",
    "    if 'Location' in stat_cols:\n",
    "        cell_stats.Location = l\n",
    "    return(cell_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def high_flow_count(flow_percentile, str_setbacks, local_str_setbacks):\n",
    "    tic = time.time()\n",
    "    # will count total number of cells for each setback distance and for all 100 realizations\n",
    "    hf_tot = np.zeros((100,len(setbacks)))\n",
    "    # layer for each local setback\n",
    "    num_sites = len(np.unique(local_str_setbacks))-1\n",
    "    hf_tot_local = np.zeros((num_sites, 100,len(setbacks)))\n",
    "    hf_all = np.zeros((100, 100, 230)) # map high flow for each realization\n",
    "    \n",
    "    # dataframe for grouping and area analysis\n",
    "    stat_cols = ['Num_Grps','Mean','Median','Min','Max','Variance','Realization', 'Setback']\n",
    "    cell_stats_all = pd.DataFrame(np.zeros((100*len(str_setbacks),len(stat_cols))), columns=stat_cols)\n",
    "    local_cols = stat_cols+['Location']\n",
    "    cell_stats_all_local = pd.DataFrame(np.zeros((num_sites*100*len(str_setbacks),len(local_cols))), columns=local_cols)\n",
    "    \n",
    "    k=0 # counter \n",
    "    kl = 0 # local counter\n",
    "    for r in np.arange(0,100):\n",
    "        print('Realization', r, ' time since start ',(time.time()-tic)/60)\n",
    "        folder = '/realization'+ str(r).zfill(3)+'/'\n",
    "        run_ws = model_ws+folder\n",
    "        \n",
    "        q_lay = highflow_at_groundsurface(run_ws, flow_percentile)\n",
    "        hf_all[r,:] = np.copy(q_lay)\n",
    "        # complete analysis for regional and local setbacks\n",
    "        for n in np.arange(0,len(setbacks)):\n",
    "            # overlay high flow cells with setback distance\n",
    "            q_lay_setback = overlay_hf_setback(q_lay, str_setbacks[n,:,:])\n",
    "            # calculate total cells in each setback\n",
    "            hf_tot[r,n] = q_lay_setback.sum()\n",
    "            # calculate high flow groups and summary statistics\n",
    "            cell_stats_all.iloc[k] = calc_area_stats(r,n, 0, q_lay_setback, stat_cols)\n",
    "            # iterate over local setbacks\n",
    "            for l in np.unique(local_str_setbacks)[1:].astype(int):\n",
    "                arr = np.zeros(local_str_setbacks[n,:,:].shape)\n",
    "                arr[local_str_setbacks[n,::]==l] = 1\n",
    "                q_lay_setback_local = overlay_hf_setback(q_lay, arr)\n",
    "                hf_tot_local[l-1,r,n] = q_lay_setback_local.sum()\n",
    "                cell_stats_all_local.iloc[kl] = calc_area_stats(r,n,l, q_lay_setback_local, local_cols)\n",
    "                kl+=1\n",
    "            k +=1\n",
    "    hf_tot_df = pd.DataFrame(hf_tot, columns = setbacks)\n",
    "    hf_tot_local = np.reshape(hf_tot_local, (num_sites*100,len(setbacks)))\n",
    "    hf_tot_local_df = pd.DataFrame(hf_tot_local, columns = setbacks)\n",
    "    hf_all_out = np.reshape(hf_all, (100*100, 230))\n",
    "    np.savetxt(data_dir+'surface_highflow_by_realization_'+str(flow_percentile)+'.tsv', hf_all_out, delimiter = '\\t')\n",
    "    \n",
    "    # save counted high flow cells to a csv\n",
    "    hf_tot_df.to_csv(data_dir+'surface_highflow_by_distance_regional_'+str(flow_percentile)+'.csv', index=False)\n",
    "    hf_tot_local_df.to_csv(data_dir+'surface_highflow_by_distance_local_'+str(flow_percentile)+'.csv', index=False)\n",
    "    # save grouping analysis and area statistics\n",
    "    cell_stats_all.to_csv(data_dir+'surface_highflow_cells_statistics_regional'+str(flow_percentile)+'.csv', index=False)\n",
    "    cell_stats_all_local.to_csv(data_dir+'surface_highflow_cells_statistics_local'+str(flow_percentile)+'.csv', index=False)\n",
    "\n",
    "    toc = time.time()\n",
    "    print('Total time was', (toc-tic)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ws "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "high_flow_count(95, str_setbacks, local_str_setbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check impact of lower hydraulic gradient 0.01 instead of 0.1 on flow result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = 95\n",
    "label='regional'\n",
    "hf_tot_1 = pd.read_csv(data_dir+'surface_highflow_by_distance_'+label+'_'+str(percentile)+'.csv')\n",
    "\n",
    "flow_percentile=95\n",
    "hf_all_in =  np.loadtxt(data_dir+'surface_highflow_by_realization_'+str(flow_percentile)+'.tsv',delimiter = '\\t')\n",
    "hf_all1 = np.reshape(hf_all_in, (100, 100, 230))[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tic = time.time()\n",
    "# will count total number of cells for each setback distance and for all 100 realizations\n",
    "hf_tot = np.zeros((len(setbacks)))\n",
    "# layer for each local setback\n",
    "num_sites = len(np.unique(local_str_setbacks))-1\n",
    "hf_all = np.zeros((100, 230)) # map high flow for each realization\n",
    "\n",
    "# dataframe for grouping and area analysis\n",
    "stat_cols = ['Num_Grps','Mean','Median','Min','Max','Variance','Realization', 'Setback']\n",
    "cell_stats_all = pd.DataFrame(np.zeros((len(str_setbacks),len(stat_cols))), columns=stat_cols)\n",
    "\n",
    "k=0 # counter \n",
    "kl = 0 # local counter\n",
    "for r in [0]:\n",
    "    print('Realization', r, ' time since start ',(time.time()-tic)/60)\n",
    "    folder = '/realization'+ str(r).zfill(3)+'/'\n",
    "    run_ws = model_ws+ '_VHG_0.01'+'/'\n",
    "\n",
    "    q_lay = highflow_at_groundsurface(run_ws, flow_percentile)\n",
    "    hf_all[:] = np.copy(q_lay)\n",
    "    # complete analysis for regional and local setbacks\n",
    "    for n in np.arange(0,len(setbacks)):\n",
    "        # overlay high flow cells with setback distance\n",
    "        q_lay_setback = overlay_hf_setback(q_lay, str_setbacks[n,:,:])\n",
    "        # calculate total cells in each setback\n",
    "        hf_tot[n] = q_lay_setback.sum()\n",
    "        # calculate high flow groups and summary statistics\n",
    "        cell_stats_all.iloc[k] = calc_area_stats(r,n, 0, q_lay_setback, stat_cols)\n",
    "        # iterate over local setbacks\n",
    "        for l in np.unique(local_str_setbacks)[1:].astype(int):\n",
    "            arr = np.zeros(local_str_setbacks[n,:,:].shape)\n",
    "            arr[local_str_setbacks[n,::]==l] = 1\n",
    "            kl+=1\n",
    "        k +=1\n",
    "# hf_tot_df = pd.DataFrame(hf_tot, columns = setbacks)\n",
    "\n",
    "toc = time.time()\n",
    "print('Total time was', (toc-tic)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no difference between cumulative high flow cells\n",
    "hf_tot-hf_tot_1.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no difference between ground surface array\n",
    "plt.imshow(hf_all-hf_all1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Andrew Calderwood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename, dirname, join, exists\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from time import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as lines\n",
    "\n",
    "# from pandas.tseries import converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "    \n",
    "# dir of all gwfm data\n",
    "gwfm_dir = join(dirname(doc_dir),'Box/research_cosumnes/GWFlowModel')\n",
    "\n",
    "flopy_dir = doc_dir+'/GitHub/flopy'\n",
    "if flopy_dir not in sys.path:\n",
    "    sys.path.insert(0, flopy_dir)\n",
    "import flopy \n",
    "import flopy.utils.binaryfile as bf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set box directory for output figures and data\n",
    "box_dir = gwfm_dir+'/Levee_setback/levee_setback_distance_analysis/'\n",
    "\n",
    "# tprogs_id = '' # original tprogs with conditioning data in output tsim\n",
    "# tprogs_id = '_no_conditioning'\n",
    "tprogs_id = '_no_cond_c3d'\n",
    "\n",
    "\n",
    "data_dir = box_dir+ tprogs_id+'/data_output/'\n",
    "fig_dir = box_dir+tprogs_id+'/figures/'\n",
    "\n",
    "chan_dir = box_dir+'channel_data/'\n",
    "gis_dir = chan_dir+'GIS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_dir = join(doc_dir, 'GitHub','CosumnesRiverRecharge')\n",
    "fxn_dir = git_dir+'/python_utilities'\n",
    "if fxn_dir not in sys.path:\n",
    "    sys.path.append(fxn_dir)\n",
    "# sys.path\n",
    "# import muskingum_recharge as mr\n",
    "\n",
    "from importlib import reload\n",
    "# reload(mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 100\n",
    "ncol = 230\n",
    "rows = np.repeat(np.arange(0,nrow),ncol)\n",
    "cols = np.tile(np.arange(0,ncol),nrow)\n",
    "\n",
    "# dem data for cropping above land surface\n",
    "# dem_data = np.loadtxt(gwfm_dir+'/DIS_data/dem_52_9_200m_linear.tsv')\n",
    "dem_data = np.loadtxt(gwfm_dir+'/DIS_data/dem_52_9_200m_mean.tsv')\n",
    "\n",
    "zs = gpd.read_file(gwfm_dir+'/DIS_data/grid_elevation_m_statistics.shp')\n",
    "# columns with different quantiles 0 to 100% of elevation\n",
    "q_cols = zs.columns[zs.columns.str.contains('perc')]\n",
    "df_elevs = zs[q_cols]\n",
    "\n",
    "# convert quantile dataframe to a 3D array\n",
    "arr_elev = np.zeros((df_elevs.shape[1], zs.row.max(),zs.column.max()))\n",
    "for n in np.arange(0,df_elevs.shape[1]):\n",
    "    arr_elev[n, zs.row-1, zs.column-1] = df_elevs.iloc[:,n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No flow routing, recharge loss only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_cfs = 22500 # 5 year\n",
    "# # Q_cfs = 2000 # 1ish year\n",
    "\n",
    "# Q_cms = Q_cfs*(0.3048**3) # convert to cubic meters per second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import muskingum_recharge\n",
    "reload(muskingum_recharge)\n",
    "\n",
    "from muskingum_recharge import min_Q, mannings, calc_depth_arr, xs_setback, gridded_interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(join(chan_dir, 'setback_locs.hdf5'), \"r\")\n",
    "local_str_setbacks = f['setbacks']['local'][:]\n",
    "str_setbacks = f['setbacks']['regional'][:]\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setbacks = np.arange(0, 3400,200)\n",
    "# smoothed XS data used for setback analysis\n",
    "xs_levee_smooth = pd.read_csv(chan_dir+'xs_levee_smooth.csv', index_col='dist_from_right_m')\n",
    "num_segs = xs_levee_smooth.shape[1]\n",
    "\n",
    "# load array identifying row,col to XS id (1,28)\n",
    "xs_arr = np.loadtxt(chan_dir+'XS_num_grid_reference.tsv')\n",
    "\n",
    "# load flood typology characteristics (based on daily data 1908 - 2014) - median values \n",
    "#\"cms_pk\" for peak discharge, \"pk_loc\" for time to peak, and \"log_no_d\" for duration\n",
    "flood_type = pd.read_csv(join(box_dir, 'whipple_grp6_w97ftmedians.csv'),index_col='Group.1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_cms = flood_type.loc[1,'cms_pk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_thick=2\n",
    "# fn = chan_dir+'/tprogs_geomK_'+str(soil_thick)+'m_depth.tsv' # from linear dem but also seems off\n",
    "fn = chan_dir+'/tprogs_geomK_'+str(soil_thick)+'m_depth_dem_mean.tsv' # mean dem with newest cleaning function\n",
    "\n",
    "# units of m/day\n",
    "soil_K_out = np.loadtxt(fn, delimiter='\\t')\n",
    "soil_K = np.reshape(soil_K_out, (100, nrow, ncol))\n",
    "# convert soil conductivity from m/d to m/s and apply vertical anisotropy factor\n",
    "vani = 100\n",
    "soil_K = (soil_K/vani)/86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_percentile=87 # for permeameter (flow threshold)\n",
    "flow_percentile=6 # for connec3d (points of connectivity)\n",
    "\n",
    "hf_tot_in =  np.loadtxt(data_dir+'surface_highflow_by_realization_'+str(flow_percentile)+'.tsv',delimiter = '\\t')\n",
    "hf_tot = np.reshape(hf_tot_in, (100, nrow, ncol))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I checked the new soil maps against the HCP maps and they align now.\n",
    "# plt.imshow(soil_K[0])\n",
    "# plt.show()\n",
    "# plt.imshow(hf_tot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find minimum from channel center\n",
    "xs_mins = xs_levee_smooth.loc[3100:3300].min(axis=0)\n",
    "xs_mins.index = xs_mins.index.astype(int)\n",
    "# xs_mins.interpolate(method='linear').plot()\n",
    "slope = xs_mins.diff().rolling(2, center=True, closed='right').mean().bfill()/2000*-1\n",
    "adj_xs_mins = np.append(xs_mins[0], (xs_mins[0]-slope.cumsum()*2000))\n",
    "\n",
    "# (xs_mins.diff()/-2000).plot()\n",
    "# slope.plot()\n",
    "# plt.show()\n",
    "xs_mins.plot()\n",
    "plt.plot(adj_xs_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the minimum elevation for each subsegment applied outward across the transects\n",
    "xs_mins_arr = np.loadtxt(chan_dir+'subsegments_xs_mins.tsv', delimiter='\\t')\n",
    "# need to correct segment definition to where the xs_mins subsegment data is\n",
    "xs_arr[np.isnan(xs_mins_arr)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating curves for each segment and setback\n",
    "xs_flow_all = pd.read_csv(join(chan_dir,'all_xs_50pt_rating_curves.csv'))\n",
    "\n",
    "def depth_match(seg_flow, flow):\n",
    "    \"\"\" Given a XS (nseg, setback) return the expected depth (m) given a flow (cms)\"\"\"\n",
    "    # find flows above and below the input flow\n",
    "    flow_diff = (seg_flow.flow_cms-flow)\n",
    "    f_high = flow_diff[flow_diff>0].argsort().index[0]\n",
    "    f_low = flow_diff[flow_diff<0].argsort().index[-1]\n",
    "    match_d = seg_flow.loc[[f_low, f_high]].sort_values('flow_cms')\n",
    "    # linearly interpolate to calculate exact depth\n",
    "    flow_slope = (match_d.iloc[1].flow_cms-match_d.iloc[0].flow_cms)/(match_d.iloc[1].depth_m-match_d.iloc[0].depth_m)\n",
    "    out_depth = match_d.iloc[0].depth_m + (flow-match_d.iloc[0].flow_cms)/flow_slope\n",
    "    return(out_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nseg = 10\n",
    "setback=3200\n",
    "seg_flow = xs_flow_all[(xs_flow_all.nseg==nseg)&(xs_flow_all.setback==setback)]\n",
    "# seg_flow\n",
    "depth_match(seg_flow, flow=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in flood_type.index:\n",
    "# 1, 2, 3 are floods long enough to apply to analysis\n",
    "ft=2\n",
    "# typical winter baseflow, peak flow, peak location, total time (days)\n",
    "# flow of 23 m3/s listed by Whipple as floodplain cutoff\n",
    "q_base = 23 # 200*(0.3048**3)\n",
    "q_peak = flood_type.loc[ft,'cms_pk']\n",
    "# total duration in days \n",
    "T = int(10**flood_type.loc[ft,'log_no_d'])\n",
    "p_l = flood_type.loc[ft,'pk_loc']\n",
    "tp = int(p_l*T)\n",
    "\n",
    "q_rise = np.linspace(q_base, q_peak, tp)\n",
    "q_fall = np.linspace(q_peak, q_base, (T-tp+1))\n",
    "q_in = np.append(q_rise, q_fall[1:])\n",
    "plt.plot(q_in)\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Flow ($m^3/s$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow loss procedure\n",
    "1. Allocate arrays for:  \n",
    "    1. flow (n realizations, n setbacks, n segments +1)  \n",
    "    2. depth (n setbacks, nrow, ncol)  \n",
    "    3. water surface elevation (n setbacks, nrow, ncol)  \n",
    "    4. recharge (n realizations, n setbacks, nrow, ncol)  \n",
    "2. Primary iteration:  \n",
    "    1. Given a cross-section with a specified width for a given setback  \n",
    "    2. Calculate the depth in the channel from the flow with Manning Equation  \n",
    "    3. Add depth to cross-section minimum elevation to calculate water surface elevation for the given setback and segment  \n",
    "3. Secondary Iteration:  \n",
    "    1. Given a segment identify which cells have a water surface elevation above ground surface (i.e., inundated)  \n",
    "    2. Calculate recharge based on inundated area, hydraulic gradient due to flood depth and vertical conductivity  \n",
    "    3. Sum of recharge by segment  \n",
    "    4. Calculate flow leaving the segment by subtracting recharge from flow entering the segment  \n",
    "4. Optional Iteration:\n",
    "    1. Apply a sequence of flows that include the rising limb and falling limb in addition to the peak flow\n",
    "    2. Calculate total recharge from this continuous event\n",
    "5. Outermost Iteration:  \n",
    "    Complete these depth, recharge, flow calculations for each subsurface realization  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "# depths = np.zeros((len(setbacks), xs_levee_smooth.shape[1]))\n",
    "Q = np.zeros((100, len(setbacks), xs_levee_smooth.shape[1]+1))\n",
    "Q[:,:,0] = Q_cms\n",
    "# save depth arrays for each setbacks\n",
    "d_arr = np.zeros((len(setbacks), nrow, ncol))\n",
    "wse_arr = np.zeros((len(setbacks), nrow, ncol))\n",
    "# save high recharge flows\n",
    "rch_hf_arr = np.zeros((100, len(setbacks), nrow, ncol))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than focusing on improving the solver iteration which isn't that bad (21 iterations isn't great but it could be worse), I should work on solution: updating roughness based on cross-section width, include levee wall roughness in wetted perimeter. Look at sensitivity of vertical conductivity. Summarize recharge by time period of flood (travel time is 13.2 hours/45 km per Whipple, about 0.3 hrs per 1 km) which is about 0.6 hrs per 2km to multiply by the recharge rate.   \n",
    "The current set up with a flow minus recharge makes sense if we assume a temporary steady state is reached (true for sub half hour), but if I want to start calculating volumes for transient events then I need to account for the duration.\n",
    "\n",
    "Whipple notes a floodplain inundation threshold of 23 m3/s at MHB where the lowest lying floodplain areas connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using rating curve method with linear interpolation is 15x faster than minimize scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs a singular flow value\n",
    "from time import time\n",
    "# takes ~45 minutes\n",
    "t=0\n",
    "tic = time()\n",
    "n = 0.048 # assume constant roughness for now\n",
    "\n",
    "for t in np.arange(0,1):\n",
    "    # iterate across all cross-sections\n",
    "    for nseg in np.arange(0,xs_levee_smooth.shape[1]):\n",
    "        # iterate across all setbacks\n",
    "        for s,setback in enumerate(setbacks):\n",
    "            # for a given setback imagine there is an impenetrable levee blocking overbank flow\n",
    "#             xs_elevs = xs_levee_smooth.iloc[:,nseg][3100-setback:3300+setback]\n",
    "            xs_elevs = xs_setback(xs_levee_smooth.iloc[:,nseg], setback)\n",
    "            # solve for depth that matches given flow\n",
    "            if Q[t, s,nseg] >0:\n",
    "                res = minimize_scalar(min_Q, args = (xs_elevs, n, slope.iloc[nseg], Q[t, s,nseg]), bounds=(0,10), method='bounded')\n",
    "                depth = res.x\n",
    "#                 seg_flow = xs_flow_all[(xs_flow_all.nseg==nseg)&(xs_flow_all.setback==setback)]\n",
    "#                 depth = depth_match(seg_flow, flow=Q[t, s,nseg])\n",
    "            else:\n",
    "                depth = 0\n",
    "            # join depth calculated at cross-section to corresponding model cells and corresponding setback\n",
    "#             wse_arr[s,(xs_arr==nseg)&(str_setbacks <= s+1)] = depth + xs_elevs.min()\n",
    "#             d_arr[s,(xs_arr==nseg)&(str_setbacks <= s+1)] = depth\n",
    "            wse_arr[s,(xs_arr==nseg)&(str_setbacks[s]==1)] = depth + xs_elevs.min()\n",
    "            d_arr[s,(xs_arr==nseg)&(str_setbacks[s]==1)] = depth \n",
    "        # identify wse above surface elevation \n",
    "        d_arr = d_arr* (wse_arr > dem_data)\n",
    "        # calculate vertical seepage with Darcy's equation assuming a saturated zone thickness similar to the lake bed in modflow\n",
    "        # hydraulic conductivity is in m/s, hydraulic gradient is unitless, area is 200x200 m^2\n",
    "        rch_hf_arr[t,:,:,:] += (xs_arr==nseg)*(soil_K[t,:,:])*hf_tot[t,:,:] *(200*200)*((d_arr* + soil_thick)/soil_thick)\n",
    "        Q[t, :, nseg+1] = Q[t, :, nseg] - np.nansum(rch_hf_arr[t,:, xs_arr==nseg], axis=(0))\n",
    "        \n",
    "toc = time()\n",
    "print((toc-tic)/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find difference between water surface and cell elevations\n",
    "diff = wse_arr[tp-1,-1,:] - arr_elev\n",
    "diff[diff<0] = np.nan\n",
    "# find the highest elevation above which there is water\n",
    "bot_q = np.argmin(diff, axis=0)[rows,cols] - 1\n",
    "bot_q[bot_q<0] = 0\n",
    "top_q = np.argmin(diff, axis=0)[rows,cols] \n",
    "# find percentage of interim quantile\n",
    "perc_q = (dem_data[rows,cols] - arr_elev[bot_q, rows,cols])/(arr_elev[top_q, rows,cols] +1E-3 - arr_elev[bot_q, rows,cols])\n",
    "# percent of cell area covered by flood\n",
    "perc_A = np.reshape(bot_q + perc_q, (nrow,ncol))/10\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,3))\n",
    "n = 150\n",
    "ax.plot(arr_elev[0][:,n], label='min')\n",
    "ax.plot(dem_data[:,n], label='dem')\n",
    "ax.plot(arr_elev[10][:,n], label='max')\n",
    "ax.legend()\n",
    "fig,ax=plt.subplots()\n",
    "ax.imshow(perc_A)\n",
    "plt.colorbar(ax.images[0], shrink=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xs_mins_arr - arr_elev[0],vmin=-10, vmax=10)\n",
    "plt.colorbar(shrink=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wse_temp = np.zeros((nrow,ncol))\n",
    "# nseg = 27\n",
    "# s=0\n",
    "# depth = 1\n",
    "# for s in np.arange(0,17):\n",
    "#     for nseg in [27]:#np.arange(0,27):\n",
    "#         fp_zon = (xs_arr==nseg)&(str_setbacks[s]==1)\n",
    "# #         wse_temp[fp_zon] = depth + xs_mins_arr[fp_zon]\n",
    "# #         if any(np.isnan(xs_mins_arr[fp_zon])):\n",
    "# #             print('Seg',str(nseg),'Setback',str(s), xs_mins_arr[fp_zon])\n",
    "# #         # calculate depth of water at different elevation percentiles for segment and setback\n",
    "# #         diff = wse_temp*fp_zon - arr_elev\n",
    "# #         # when depth is negative remove\n",
    "# #         diff[diff<0] = 0 #np.NaN\n",
    "# #         # only keep cells where water level is above lowest elevation\n",
    "# #         diffmax = np.nanmax(diff, axis=0)\n",
    "#         print(np.nanmax(xs_mins_arr[fp_zon]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_h5(Q, rch_hf_arr, d_arr, h5_fn):\n",
    "    # convert arrays of annual rates to hdf5 files individually\n",
    "    f = h5py.File(h5_fn, \"w\")\n",
    "    grp = f.require_group('array') # makes sure group exists\n",
    "    grp.attrs['units'] = 'cubic meters/second'\n",
    "    grp.attrs['description'] = 'Each layer of the array is a day in the event'\n",
    "    dset = grp.require_dataset('flow', Q.shape, dtype='f', compression=\"gzip\", compression_opts=4)\n",
    "    dset[:] = Q\n",
    "    dset = grp.require_dataset('rch_hf', rch_hf_arr.shape, dtype='f', compression=\"gzip\", compression_opts=4)\n",
    "    dset[:] = rch_hf_arr\n",
    "    dset = grp.require_dataset('depth', d_arr.shape, dtype='f', compression=\"gzip\", compression_opts=4)\n",
    "    dset[:] = d_arr\n",
    "    f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def realization_recharge(t, str_setbacks, region):\n",
    "    # allocate arrays - num flow steps, num setbacks, num segments\n",
    "    Q = np.zeros((q_in.shape[0], len(setbacks), xs_levee_smooth.shape[1]+1))\n",
    "    # set inflow for segment 1 across all setbacks and for all times\n",
    "    # rate of cubic meters per second\n",
    "    Q[:,:,0] = np.repeat(q_in.reshape(-1,1), len(setbacks), axis=1)\n",
    "    # save depth arrays for each setbacks\n",
    "    d_arr = np.zeros((q_in.shape[0], len(setbacks), nrow, ncol))\n",
    "    wse_arr = np.zeros((len(setbacks), nrow, ncol))\n",
    "    cell_frac = np.zeros((q_in.shape[0], len(setbacks), nrow, ncol))\n",
    "    # save high recharge flows\n",
    "    rch_hf_arr = np.zeros((q_in.shape[0], len(setbacks), nrow, ncol))\n",
    "\n",
    "    tic = time()\n",
    "    n = 0.048 # assume constant roughness for now\n",
    "\n",
    "    # iterate across streamflows\n",
    "    for qn in np.arange(0, q_in.shape[0]):\n",
    "        # iterate across all cross-sections\n",
    "        for nseg in np.arange(0,xs_levee_smooth.shape[1]):\n",
    "            # iterate across all setbacks\n",
    "            for s,setback in enumerate(setbacks):\n",
    "                # for a given setback imagine there is an impenetrable levee blocking overbank flow\n",
    "    #             xs_elevs = xs_levee_smooth.iloc[:,nseg][3100-setback:3300+setback]\n",
    "                xs_elevs = xs_setback(xs_levee_smooth.iloc[:,nseg], setback)\n",
    "                # boolean of row,col cells that fall within the segment and setback\n",
    "#                 fp_zon = (xs_arr==nseg)&(str_setbacks <= s+1)\n",
    "                fp_zon = (xs_arr==nseg)&(str_setbacks[s]==1)\n",
    "                # solve for depth that matches given flow, assume less than 1 cms is too small to calculate\n",
    "                if Q[qn, s,nseg] >1:\n",
    "                    # solve for depth that matches given flow\n",
    "#                     res = minimize_scalar(min_Q, args = (xs_elevs, n, slope.iloc[nseg], Q[qn, s,nseg]), \n",
    "#                                               method='Golden', tol=1E-3)\n",
    "#                     # if large flow error, likely stuck in local minimum try setting higher or lower\n",
    "#                     if mannings(res.x, xs_elevs, n, slope.iloc[nseg]) > Q[qn, s,nseg]*1.05:\n",
    "#                         res = minimize_scalar(min_Q, args = (xs_elevs, n, slope.iloc[nseg], Q[qn, s,nseg]), \n",
    "#                                       bounds=(1E-3,res.x-0.1), method='bounded')\n",
    "#                     if mannings(res.x, xs_elevs, n, slope.iloc[nseg]) < Q[qn, s,nseg]*0.95:\n",
    "#                         res = minimize_scalar(min_Q, args = (xs_elevs, n, slope.iloc[nseg], Q[qn, s,nseg]), \n",
    "#                                       bounds=(res.x+0.1,10), method='bounded')\n",
    "#                     if res.fun>0.05*Q[qn, s,nseg]: # greater than 5% difference try to fix with bounded solving\n",
    "#                         print(str(nseg),' ', s, '%.2f'%res.fun, 'iter %i'%res.nit, ', ',res.success, 'd %.2f'%res.x)\n",
    "#                     depth = np.copy(res.x)\n",
    "                    seg_flow = xs_flow_all[(xs_flow_all.nseg==nseg)&(xs_flow_all.setback==setback)]\n",
    "                    depth = depth_match(seg_flow, flow=Q[qn, s, nseg])\n",
    "                else:\n",
    "                    depth = 0\n",
    "                # join depth calculated at cross-section to corresponding model cells and corresponding setback\n",
    "                # add elevation to minimum to apply segment midpoint as elevation rather than lowest point\n",
    "#                 wse_arr[s, fp_zon] = depth + xs_elevs.min() + slope.iloc[nseg]*1000\n",
    "                wse_arr[s, fp_zon] = depth + xs_mins_arr[fp_zon]\n",
    "#                 if any(np.isnan(xs_mins_arr[fp_zon])):\n",
    "#                     print('Seg',str(nseg),'Setback',str(s), xs_mins_arr[fp_zon])\n",
    "                # calculate depth of water at different elevation percentiles for segment and setback\n",
    "                diff = wse_arr[s,:]*fp_zon - arr_elev\n",
    "                # when depth is negative remove\n",
    "                diff[diff<0] = 0 #np.NaN\n",
    "                # only keep cells where water level is above lowest elevation\n",
    "                diffmax = np.nanmax(diff, axis=0)\n",
    "                # keep cells where diffmax >0 \n",
    "                x,y = np.where(diffmax>0)\n",
    "                # find the highest elevation above which there is water, subtract 1 uses lower percentile\n",
    "                # where the wse was below the minimum ignore\n",
    "                bot_q = np.argmin(diff, axis=0)[x,y] - 1\n",
    "                bot_q[bot_q<0] = 0\n",
    "                top_q = np.argmin(diff, axis=0)[x,y]\n",
    "                # find percentage of interim quantile\n",
    "                perc_q = (wse_arr[s, x,y] - arr_elev[bot_q, x,y])/(arr_elev[top_q, x,y] +1E-3 - arr_elev[bot_q, x,y])\n",
    "                # percent of cell area covered by flood\n",
    "                cell_frac[qn, s,x,y] = (bot_q + perc_q)/10\n",
    "                # depth for each cell is difference between water surface and average flooded ground elevation\n",
    "                d_arr[qn, s,fp_zon] = np.nanmean(diff, axis=0)[fp_zon] #depth \n",
    "                # identify wse above surface elevation \n",
    "#                 d_arr[qn,:] = d_arr[qn,:] * cell_frac[qn] # caused overflow error\n",
    "            # calculate vertical seepage with Darcy's equation assuming a saturated zone thickness similar to the lake bed in modflow\n",
    "            # hydraulic conductivity is in m/s, hydraulic gradient is unitless, area is 200x200 m^2\n",
    "            q_seep = (soil_K[t,:,:])*hf_tot[t,:,:]*(200*200)*((d_arr[qn,:] + soil_thick)/soil_thick)\n",
    "            rch_hf_arr[qn,:,:,:] += (xs_arr==nseg) * q_seep * cell_frac[qn]\n",
    "            # identify when the flow is less than the recharge predicted and recharge > 0 \n",
    "            dry = (Q[qn, :, nseg] < np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=0)) & (np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=0)>0)\n",
    "            if any(dry):\n",
    "                # where the cells will end dry, reduce recharge so it sums to the flow into segment\n",
    "    #             scale = (Q[qn, :, nseg][dry]/np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=(0))[dry])\n",
    "                scale = (Q[qn, :, nseg]/(np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=(0)))) \n",
    "                scale = np.where(scale > 1, 1,scale) # only scale when flow is less than recharge\n",
    "#             if any(scale<1):\n",
    "#                 rch_hf_arr[qn, :,xs_arr==nseg][:,dry] *= scale\n",
    "                rch_hf_arr[qn, :,xs_arr==nseg] *= scale\n",
    "                print('scale', np.round(np.median(scale),2))\n",
    "            Q[qn, :, nseg+1] = Q[qn, :, nseg] - np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=(0))\n",
    "            if any(Q[qn,:,nseg+1]<0):\n",
    "                print(qn, nseg+1)\n",
    "                \n",
    "    \n",
    "    base_fn = join(data_dir, region, 'type'+str(ft), 'r'+str(t).zfill(3)+'_')\n",
    "    arr_to_h5(Q, rch_hf_arr, d_arr, base_fn+'output.hdf5')\n",
    "    # saving all of the flow at all steps, setbacks is needed to post-process\n",
    "#     Q_out = np.reshape(Q, ((q_in.shape[0]*len(setbacks), xs_levee_smooth.shape[1]+1)))\n",
    "#     np.savetxt(base_fn+'flow.tsv', Q_out)\n",
    "    # for recharge we want to aggregate across time steps but look at differences across setbacks\n",
    "#     rch_out = np.reshape(np.nansum(rch_hf_arr, axis=0), (len(setbacks)*nrow, ncol))\n",
    "#     np.savetxt(base_fn+'recharge.tsv', rch_out)\n",
    "    toc = time()\n",
    "    print((toc-tic)/3600)\n",
    "    return(Q, rch_hf_arr, d_arr, cell_frac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all 84 steps should only take 1 second\n",
    "(.0002*84)*60\n",
    "# flow_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 0.048\n",
    "# nseg=13\n",
    "# s=7\n",
    "# setback = setbacks[s]\n",
    "\n",
    "# xs_elevs = xs_setback(xs_levee_smooth.iloc[:,nseg].copy(), setback)\n",
    "# Q_chk = mannings(3.03, xs_elevs, n, slope.iloc[nseg])\n",
    "# print('Q calc %.2f' %Q_chk, 'Q in %.2f' %Q[qn,s,nseg])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check why the addition of dry segment check didn't fix negative flows\n",
    "qn = 0\n",
    "nseg = 24\n",
    "\n",
    "# identify when the flow is less than the recharge predicted and recharge > 0\n",
    "dry = (Q[qn, :, nseg] < np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=0)) & (np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=0)>0)\n",
    "# where the cells will end dry, reduce recharge so it sums to the flow into segment\n",
    "# scale = (Q[qn, :, nseg][dry]/np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=(0))[dry])\n",
    "if any(dry):\n",
    "    print('Recharge exceeds flow')\n",
    "print('Flow nseg -1   ',np.round(Q[qn, :, nseg-1],2))\n",
    "print('Recharge nseg-1',np.round(np.nansum(rch_hf_arr[qn,:, xs_arr==nseg-1], axis=0),2))\n",
    "# the flow into the next segment isn't equally the flow in the previous minus recharge with the dry adjustment\n",
    "print('Flow nseg     ',np.round(Q[qn, :, nseg],2))\n",
    "print('Recharge nseg  ',np.round(np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=0),2))\n",
    "\n",
    "# even though flow is negative there is somehow depth at these locations\n",
    "print('Depth nseg    ',np.round(np.nanmax(d_arr[qn,:,xs_arr==nseg], axis=0),2))\n",
    "# this may be an issue with how the minimum XS elevation is defined, bascially the min XS value should be consistent\n",
    "print('Flow nseg +1  ', np.round(Q[qn, :, nseg+1],2))\n",
    "# once flow hits negative then there is no longer depth so no more recharge at least\n",
    "# when flow is less than recharge and greater than 0 then scaling is appropriate\n",
    "# I'm get at least a couple of NAs in the scaling which will cause issues\n",
    "\n",
    "# if flow is already negative then this scaling function does not help, it would be adding flow from recharge which is wrong\n",
    "# scale = (Q[qn, :, nseg][dry]/np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=(0))[dry])\n",
    "scale = (Q[qn, :, nseg]/np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=(0)))\n",
    "scale = np.where(scale > 1, 1,scale)\n",
    "print('Scale nseg     ', scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a couple realizations failed to write output including 48\n",
    "t=5\n",
    "Q, rch_hf_arr, d_arr, cell_frac = realization_recharge(t, str_setbacks, 'regional')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2, figsize=(8,3))# time series\n",
    "# select segments all times\n",
    "for n in [0,5, 10,15,20,25]:\n",
    "    ax[0].plot(Q[:,-1,n], label=n)\n",
    "ax[0].legend(title='segment')\n",
    "# plt.show()\n",
    "# first time all segs\n",
    "# longitudinal losses\n",
    "for n in [0,5, 10,15,20,25]:\n",
    "    ax[1].plot(Q[n,-1, :],label=n)\n",
    "ax[1].legend(title='day')\n",
    "# rch_hf_arr.sum(axis=(2,3))[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate recharge for each flow and setback, daily average in m3/s\n",
    "rch_q_sum = pd.DataFrame(np.sum(rch_hf_arr, axis=(2,3)), columns= setbacks).transpose()\n",
    "# calculate sum for all flows (daily average)\n",
    "rch_sum = rch_q_sum.sum(axis=1)\n",
    "# convert to AF/day and will have the total AF recharged because already summed by day\n",
    "rch_sum_AF = rch_sum*86400/((0.3048**3)*43560)\n",
    "\n",
    "# if we divide by the setback area we will get the depth of recharge per setback area\n",
    "setback_area = [np.sum(str_setbacks[s]== s)*200*200 for s in np.arange(0,len(setbacks)) ]\n",
    "\n",
    "# (rch_sum_AF/setback_area).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp = 5\n",
    "# s = 5\n",
    "# fig,ax=plt.subplots(1,2,figsize=(8,4))\n",
    "# for s in [0,5,10,15]:\n",
    "#     temp = np.zeros(xs_levee_smooth.shape[1])\n",
    "#     for nseg in np.arange(0,xs_levee_smooth.shape[1]):\n",
    "# #         temp[nseg] = np.nanmean(wse_arr[tp,s][xs_arr==nseg])\n",
    "#         temp[nseg] = np.nanmean(d_arr[tp,s][xs_arr==nseg])\n",
    "# #     ax[1].plot(temp)\n",
    "#     ax[1].plot(xs_levee_smooth.min().values,label=s)\n",
    "#     ax[0].plot(temp,label=s)\n",
    "    \n",
    "    \n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp = 5\n",
    "# s = 5\n",
    "# temp = np.zeros(xs_levee_smooth.shape[1])\n",
    "# for nseg in np.arange(0,xs_levee_smooth.shape[1]):\n",
    "#     temp[nseg] = np.nanmean(wse_arr[tp,s][xs_arr==nseg])\n",
    "# plt.plot(temp, label='WSE')\n",
    "# xs_levee_smooth.min().plot(label='Channel Bottom')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['lightgray', 'blue']\n",
    "scale = [0, 1]\n",
    "cmap=mpl.colors.ListedColormap(colors)\n",
    "norm=mpl.colors.BoundaryNorm(scale, len(colors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking inactive to try to improve mapping\n",
    "d_mask = ma.masked_where(d_arr==0, d_arr )\n",
    "\n",
    "s = 6\n",
    "fig, ax = plt.subplots(figsize=(16,16))\n",
    "# ax.imshow(d_mask[0,16])\n",
    "im=ax.imshow(d_mask[tp,s])\n",
    "plt.colorbar(im, shrink=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr = gpd.read_file(gwfm_dir+'/SFR_data/final_grid_sfr/grid_sfr.shp')\n",
    "sfr_union = gpd.GeoDataFrame(pd.DataFrame([0]), geometry = [grid_sfr.unary_union], crs=grid_sfr.crs)\n",
    "sfr_union.geometry = sfr_union.buffer(setback).exterior\n",
    "# sfr_union.plot(color=\"None\", edgecolor='black',ax=ax_n, linewidth = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setback_grid = gpd.sjoin(sfr_union, grid_p, how='left')\n",
    "setback_outer = np.zeros((nrow,ncol))\n",
    "setback_outer[setback_grid.row-1, setback_grid.column-1] = 1\n",
    "setback_outer = ma.masked_where(setback_outer==0,setback_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# show change in activated pathways by either setback distance impact on flooded area or\n",
    "# flood flow impact\n",
    "fig,ax=plt.subplots(3,3, figsize=(6.5, 6.5), sharex=True, sharey=True, dpi=300)\n",
    "# fig.tight_layout(hspsace=0.2, wspace=0.2)\n",
    "plt.subplots_adjust(hspace=-0.75, wspace=0.05)\n",
    "\n",
    "s=6\n",
    "# initial, peak, half way receded\n",
    "for i,qn in enumerate([0, tp, int(tp+(T-tp)/2)]):\n",
    "#     ax[i,0].imshow(hf_tot[t])\n",
    "    im = ax[i,0].imshow(hf_tot[t],cmap=cmap)\n",
    "\n",
    "    ax[i,1].imshow(d_arr[qn,s,:]>0, cmap=cmap)\n",
    "#     ax[i,1].imshow(d_mask[qn,s,:])\n",
    "\n",
    "    ax[i,2].imshow(rch_hf_arr[qn,s,:]>0, cmap=cmap)\n",
    "    for n in np.arange(0,3):\n",
    "        ax[i,n].scatter(setback_grid.column-1, setback_grid.row-1, color='black', s=0.1)\n",
    "    \n",
    "# axis labels\n",
    "ax[0,0].set_ylabel('Initial\\nFlow')\n",
    "ax[1,0].set_ylabel('Peak\\nFlow')\n",
    "ax[2,0].set_ylabel('Receding\\nFlow')\n",
    "\n",
    "# color bar on all rows, with two discrete labels\n",
    "# cbar=plt.colorbar(mappable = im, ax=ax[2,0],  ticks = [0.25,.75], shrink= 0.7, orientation='horizontal')\n",
    "# cbar.ax.set_yticklabels(['Low flow facies', 'High flow facies'])\n",
    "\n",
    "# titles\n",
    "ax[0,0].set_title('High Conductivity\\nPathways')\n",
    "ax[0,1].set_title('Inundated\\nFloodplain')\n",
    "ax[0,2].set_title('Activated\\nPathways')\n",
    "\n",
    "plt.setp(ax, xticks=[], yticks=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(3,1,figsize=(8,8), sharex=True)\n",
    "# # plot baseflow\n",
    "# Q_plt = pd.DataFrame(Q[0,:,:], index=setbacks, columns = np.arange(0,(num_segs+1)*2,2)).transpose()\n",
    "# Q_plt.plot(color='lightgray', legend=False, ax=ax[0])\n",
    "\n",
    "# # plot peak\n",
    "# Q_plt = pd.DataFrame(Q[tp-1,:,:], index=setbacks, columns = np.arange(0,(num_segs+1)*2,2)).transpose()\n",
    "# Q_plt.plot(color='lightgray', legend=False, ax=ax[1])\n",
    "\n",
    "# # plot midway through recession\n",
    "# Q_plt = pd.DataFrame(Q[tp-1+int((T-tp)/2),:,:], index=setbacks, columns = np.arange(0,(num_segs+1)*2,2)).transpose()\n",
    "# Q_plt.plot(color='lightgray', legend=False, ax=ax[2])\n",
    "\n",
    "# plt.xlabel('Distance downstream (km)')\n",
    "# plt.ylabel('Discharge ($m^3/s$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time for running 100 realizations in parallel\n",
    "#4.8 hrs for type1, 17377/3600 (81 steps)\n",
    "# 2.7 hrs for type2 (34 steps)\n",
    "# 1.3 hrs for type3 (14 steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamflow data\n",
    "Routing flow down channel: original intent was to focus on a few sizes of streamflows based on return periods (e.g., 5, 20 years) but I could run this every day with variable streamflow for the past 10 years to identify the number of days when floodplains are activated. The next level would be to run this with inundation maps for everyday.\n",
    "\n",
    "Need to start with singular flow events to test the difficulty of running iterative flow with leakage dependent on flood depth and number of high flow cells. It's easy to think the work would be more interesting if everything was in a complex model but often the simpler more fundamental work is what is meaningful therefore I should work for parsimony by testing a singular flow and using a Darcy recharge before going more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosumnes River at Michigan Bar, daily flow cfs\n",
    "# from 10/1/1983 to 10/1/2010\n",
    "# inflow_15 = pd.read_csv('data\\MI_bar_15min.csv', parse_dates = True, \n",
    "#                 index_col = 0, sep = ',', header = 'infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groundwater level data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muskingum Parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K is the travel time for the river and $N_{steps}$ is the number of sub reaches so that the total travel time adds to K  \n",
    "Value of X ranges from 0 for reservoir-type storage to 0.5 for a full wedge. When X = 0 there is no wedge so no backwater (e.g., level-pool reservoir). **In natural stream X is between 0 and 0.3 with a mean near 0.2.** Great accuracy is not needed due to insensitivity.  \n",
    "US ACE (1990) criterion for number of routing reaches:\n",
    "$$ \\frac{1}{2(1-X)} \\leq \\frac{K}{N_{steps}\\Delta t} \\leq \\frac{1}{2X} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(xs_levee_smooth.columns)\n",
    "rchlen = 2 # length of 2 km\n",
    "# actual length of XS\n",
    "L_XS = rchlen*N\n",
    "\n",
    "# reaches every 1 km\n",
    "L = 45 # kilomters\n",
    "K = 13.2*(L_XS/L) # hourly\n",
    "print('Travel time %.2f' %K ,' hours for %.1f' %L_XS,'km')\n",
    "\n",
    "X = 0.1 # weighting between wedge and pool storage, 0 is pool, 0.5 for a full wedge\n",
    "l = 1/(2*(1-X))\n",
    "r = 1/(2*X)\n",
    "# N = 62 # reaches of 1 km\n",
    "delt = 0.5 # hours\n",
    "m = K/(N*delt)\n",
    "\n",
    "print('Reach travel time and acceptable range')\n",
    "print('%.3f' %l,'<= %.3f' %m,'<= %.3f' %r)\n",
    "K_rch = K/N # travel time for a reach of length total length/ number of reaches\n",
    "# print('Max reach storage (ft^3/min):', Smax/K) # (ft^3/min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the given travel time for the lower Cosumnes River with 1 km length reaches requires 0.5 hourly steps and X = 0.1  \n",
    "x is in the downstream longitudinal channel direction and y (stage) is in the vertical direction away from the streambed.  \n",
    "Celerity equation:  \n",
    "$$ c_k = \\frac{dx}{dt} = \\frac{dQ}{dA} = \\frac{1}{B}\\frac{dQ}{dy} $$\n",
    "\n",
    "Muskingum Cunge\n",
    "Variation of kinematic wave. Cunge (1969) showed when K and del t are constant it is an approximate solution of the kinematic wave. It can be considered an approxmiation of the a modified diffusion equation if \n",
    "$$ K = \\frac{ \\Delta X}{ c_k}  = \\frac{\\Delta X}{(dQ / dA )}  $$\n",
    "OR $$ \\Delta x = \\frac{K}{c_k} $$\n",
    "$$X = \\frac{1}{2}(1-(\\frac{Q}{B c_k S_o\\Delta X)}  $$\n",
    "\n",
    "Froude Number, V = flow velocity, surface wave speed =  sqrt(g*y), g = gravity, y= depth:\n",
    "$$ Fr = \\frac{V}{\\sqrt{gy} }$$\n",
    "$$ Fr<1.0 subcritical flow $$ $$ Fr = 1.0 critical flow $$ $$Fr> 1.0 supercritical flow $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# froude number <1 subcritical, 1 citical, >1 super critical\n",
    "# V = flow velocity, surface wave speed =  sqrt(g*y), g = gravity, y= depth\n",
    "# Fr = V/npsqrt(9.81*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in flood_type.index:\n",
    "# 1, 2, 3 are floods long enough to apply to analysis\n",
    "n=2\n",
    "# typical winter baseflow, peak flow, peak location, total time (days)\n",
    "q_base = 200*(0.3048**3)\n",
    "q_peak = flood_type.loc[n,'cms_pk']\n",
    "# total duration in days \n",
    "T = int(10**flood_type.loc[n,'log_no_d'])*24\n",
    "p_l = flood_type.loc[n,'pk_loc']\n",
    "tp = int(p_l*T)\n",
    "\n",
    "q_rise = np.linspace(q_base, q_peak, tp)\n",
    "q_fall = np.linspace(q_peak, q_base, (T-tp))\n",
    "q_in = np.append(q_rise, q_fall)\n",
    "plt.plot(q_in)\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Flow ($m^3/s$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# toc = time()\n",
    "# print(np.round(toc-tic,2))\n",
    "folder = '/r' + str(t).zfill(3)+'/'\n",
    "folder\n",
    "# np.savetxt(basedir+folder+'rch_hf_arr_cms.tsv', np.reshape(rch_hf_arr, (len(setbacks)*nrow,ncol)), delim='\\t')\n",
    "# np.savetxt(basedir+folder+'Q_cms.tsv', Q, delim='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Adj_Muskingum(I, XS, K, X, slope, hf_tot, soil_K, soil_thick, xs_arr):\n",
    "    \"\"\" \n",
    "    Given an upstream inflow route flow downstream with Muskingum and adjust for recharge losses to groundwater\n",
    "    assuming losing system\n",
    "    Input:\n",
    "    I = Inflow at uppermost reach\n",
    "    XS = XS data for all stream segments, dim = (XS distances, No. stream segments)\n",
    "    K = Muskingum travel time\n",
    "    X = Muskingum storage weighting (0 = none, 0.5 = reservoir)\n",
    "    soil_K = streambed hydraulic conductivity, dim = (NROW, NCOL)\n",
    "    soil_thick = streambed thickness, dim = (NROW, NCOL)\n",
    "    xs_arr = relates array location to stream segment, dim = (NROW,NCOL)\n",
    "    \n",
    "    Output:\n",
    "    Q = discharge for each segment\n",
    "    S = storage for each segment\n",
    "    mb = mass balance error\n",
    "    e = excess storage removed from channel\n",
    "    swe = surface water elevation\n",
    "    dh = hydraulic gradient between stream and groundwater\n",
    "    qA = groundwater seepage from each segment\n",
    "    rch_arr = array of groundwater recharge for model domain, dim = (NROW, NCOL, time)\n",
    "    d_arr = array of flood depth for model domain, dim = (NROW, NCOL, time)\n",
    "    \"\"\"\n",
    "    T = len(I)\n",
    "    N = XS.shape[1]\n",
    "    # N rows and T columns\n",
    "    dim = [N+1, T]\n",
    "    dim2 = [N, T]\n",
    "    Q = np.zeros(dim)\n",
    "    S = np.zeros(dim2)\n",
    "    mb = np.zeros(dim2)\n",
    "    e = np.zeros(dim2)\n",
    "    swe = np.zeros(dim2)\n",
    "    dh = np.zeros(dim2)\n",
    "    qA = np.zeros(dim2)\n",
    "    rch_arr = np.zeros((nrow, ncol, T))\n",
    "    d_arr = np.zeros((nrow, ncol, T))\n",
    "    wse_arr = np.zeros((nrow, ncol, T))\n",
    "\n",
    "    Q[0,:] = I # set first row as historic inflow\n",
    "    Q[1:,0] = Q[0,0] # assume initial inflow equals outflow all reaches\n",
    "    S[:,0] = K*Q[1,0] # assume initial storage equals outflow because no wedge storage\n",
    "    \n",
    "    # Muskingum coefficients\n",
    "    C1 = (delt - 2*K*X)/(2*K*(1-X)+delt)\n",
    "    C2 = (delt + 2*K*X)/(2*K*(1-X)+delt)\n",
    "    C3 = (2*K*(1-X)-delt)/(2*K*(1-X)+delt)\n",
    "#     print('C1:', C1,'C2:', C2, 'C3:', C3)\n",
    "    \n",
    "    for j in range(0,T-1):\n",
    "        for i in np.arange(0, N):\n",
    "#         # solve for depth that matches given flow\n",
    "            if Q[i,j] >0:\n",
    "                d0 = [d_arr[(xs_arr==i), j-1].max()]\n",
    "            # flow needs to be in cubic meters per second not hour for Manning\n",
    "                res = minimize_scalar(min_Q, args = (XS.iloc[:,i], n, slope.iloc[i], Q[i, j]/(60*60)), \n",
    "                                      bounds=(0.1,10), method='bounded', tol=1E-3) \n",
    "                depth = res.x #[0]\n",
    "            else:\n",
    "                depth = 0\n",
    "    #         # join depth calculated at cross-section to corresponding model cells and corresponding setback\n",
    "            wse_arr[(xs_arr==i), j] = depth + XS.iloc[:,i].min()\n",
    "            d_arr[(xs_arr==i), j] = depth \n",
    "            # identify wse above surface elevation \n",
    "            d_arr[(xs_arr==i), j] = d_arr[(xs_arr==i), j] * (wse_arr[(xs_arr==i), j] > dem_data[(xs_arr==i)])\n",
    "            # update to allow for gw disconnection\n",
    "    #         dh[:, j] =  (swe[:,j] - gwe)/(elev - gwe)\n",
    "            # calculate vertical seepage with Darcy's equation assuming a saturated zone thickness similar to the lake bed in modflow\n",
    "            # hydraulic conductivity is in m/s, hydraulic gradient is unitless, area is 200x200 m^2\n",
    "            # need to convert HK from m/s to m/h\n",
    "            rch_arr[:,:, j] += (xs_arr==i)*(soil_K*(60*60))*hf_tot *(200*200)*((d_arr[:,:,j] * + soil_thick)/soil_thick)\n",
    "#             Q[i+1,j ] = Q[i, j] - np.nansum(rch_arr[xs_arr==i, j], axis=(1,2))\n",
    "            # groundwater seepage term\n",
    "#             q = k[i]*dh[i,j]*perimeter_base*rchlen # darcian groundwater flow\n",
    "            qA[i,j] = np.nansum(rch_arr[xs_arr==i, j], axis=(0)) \n",
    "            # calculate flow into next segment\n",
    "            Q[i+1,j+1] = np.clip(C1*Q[i,j+1] + C2*Q[i,j] + C3*Q[i+1,j] - qA[i,j], 0, 1E15)\n",
    "            # calculate storage in stream channel\n",
    "            S[i,j+1] = S[i,j] + K*(X*(Q[i,j+1]-Q[i,j])+(1-X)*(Q[i+1,j+1]-Q[i+1,j]))\n",
    "            \n",
    "#         if current storage is greater than max\n",
    "#             if S[i,j] > Smax:\n",
    "#                 # calculate the excess storage\n",
    "#                 e[i,j] = S[i,j] - Smax\n",
    "#                 # remove the excess storage from the outflow because it\n",
    "#                 # is considered overbank flow\n",
    "#                 Q[i,j] = Q[i,j] - e[i,j]/(K*(1-X))\n",
    "#                 # reduce storage by amount that went overbank\n",
    "#                 S[i,j] = S[i,j] - e[i,j]\n",
    "                \n",
    "            # mass balance check\n",
    "            mb[i,j] = S[i,j] + K*(X*(Q[i,j+1]-Q[i,j])+(1-X)*(Q[i+1,j+1]-Q[i+1,j])) - S[i,j+1]\n",
    "#         swe[:, j+1] = np.linspace(TWC_stage(Q[i+1,j+1]), MB_stage(Q[i+1,j+1]), 48)\n",
    "#         dh[:, j+1] =  swe[:,j+1] - gwe[:,j+1]\n",
    "    return(Q, S, rch_arr, d_arr, qA, mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "# setback=200\n",
    "# # xs_elevs.iloc[:,9].plot()\n",
    "# xs_levee_smooth.loc[3100-setback:3300+setback,:].iloc[:,1].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I = inflow_15_reg.Discharge_cfs.values\n",
    "# need to convert to cfm from cfs\n",
    "# I0 = I*60\n",
    "# need to convert from cms to cmh\n",
    "Q0= q_in*60*60\n",
    "\n",
    "r=0\n",
    "setback = 0\n",
    "n = 0.048 # assume constant roughness for now\n",
    "\n",
    "# takes 23 minutes to run about 1E3 time steps for 1 realization\n",
    "t1 = datetime.now()\n",
    "xs_elevs = xs_levee_smooth.loc[3100-setback:3300+setback,:]\n",
    "\n",
    "tQ, tS, rch_arr, d_arr, qA, mb = Adj_Muskingum(Q0, xs_elevs, K_rch, X, slope, hf_tot[r,:,:], soil_K[r,:,:], soil_thick, xs_arr)\n",
    "t2 =  datetime.now()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stps= [0, 60, 150, 250, 600]\n",
    "fig,ax = plt.subplots(1,len(stps), sharex=True, sharey=True, figsize=(16,8))\n",
    "for n, i in enumerate(stps):\n",
    "#     im = ax[n].imshow(rch_arr[:,:,i])\n",
    "    im = ax[n].imshow(d_arr[:,:,i])\n",
    "fig.tight_layout()\n",
    "fig.colorbar(im, shrink=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the floodwave is moving too slowly\n",
    "# it says it is traveling 10*2000 m in 600*0.5 hours\n",
    "# and it should be about\n",
    "print('Travel time out %.2f'%((600*0.5)/(10*2)), 'hours per km')\n",
    "fig,ax = plt.subplots(2,1, sharex=True)\n",
    "for i in [0,10,20,27]:\n",
    "    ax[0].plot(tQ[i,:], label = str(i))\n",
    "    ax[1].plot(qA[i,:], label = str(i))\n",
    "\n",
    "plt.legend(title='Segment')\n",
    "# plt.xlim([120,250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_dir = gwfm_dir+'/SFR_data/'\n",
    "# discharge is m3/day\n",
    "mb = pd.read_csv(sfr_dir+ 'michigan_bar_icalc4_data.csv')\n",
    "mb.discharge_va /= 86400\n",
    "\n",
    "mb_diff = mb.diff(axis=0)\n",
    "mb['ck'] = mb_diff.discharge_va/(mb_diff.gage_height_va * mb.chan_width )\n",
    "mb['delX'] = K/mb.ck\n",
    "mb['Fr'] = mb.discharge_va/(mb.gage_height_va *mb.chan_width)/ np.sqrt(mb_diff.gage_height_va * 9.80665 )\n",
    "\n",
    "fig,axes=plt.subplots(1,2, figsize=(8,3))\n",
    "mb.plot(x = 'discharge_va',y='Fr', label='Fr',legend=False, ax=axes[0])\n",
    "ax.set_ylabel('Froude Number')\n",
    "mb.plot(x = 'discharge_va',y='ck',  label='ck',legend=False, ax=axes[1])\n",
    "axes[1].set_ylabel('Celerity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Muskingum(I, N, K, X):\n",
    "    T = len(I)\n",
    "    # N rows and T columns\n",
    "    dim = [N+1, T]\n",
    "    dim2 = [N, T]\n",
    "    Q = np.zeros(dim)\n",
    "    S = np.zeros(dim2)\n",
    "    mb = np.zeros(dim2)\n",
    "    e = np.zeros(dim2)\n",
    "    \n",
    "    Q[0,:] = I # set first row as historic inflow\n",
    "    Q[1:,0] = Q[0,0] # assume initial inflow equals outflow all reaches\n",
    "    S[:,0] = K*Q[1,0] # assume initial storage equals outflow because no wedge storage\n",
    "    \n",
    "    # Muskingum coefficients\n",
    "    C1 = (delt - 2*K*X)/(2*K*(1-X)+delt)\n",
    "    C2 = (delt + 2*K*X)/(2*K*(1-X)+delt)\n",
    "    C3 = (2*K*(1-X)-delt)/(2*K*(1-X)+delt)\n",
    "#     print('C1:', C1,'C2:', C2, 'C3:', C3)\n",
    "    \n",
    "    for j in range(0,T-1):\n",
    "        for i in np.arange(0, N):\n",
    "            Q[i+1,j+1] = np.clip(C1*Q[i,j+1] + C2*Q[i,j] + C3*Q[i+1,j], 0, 1E15)\n",
    "            \n",
    "    return(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muskingum Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance and then time calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adj_Muskingum(I, N, K, X, k, gwe, elev):\n",
    "    \"\"\" \n",
    "    Given an upstream inflow route flow downstream with Muskingum and adjust for recharge losses to groundwater\n",
    "    assuming losing system\n",
    "    Input:\n",
    "    I = Inflow at uppermost reach\n",
    "    N = number of segments\n",
    "    K = Muskingum travel time\n",
    "    X = Muskingum storage weighting (0 = none, 0.5 = reservoir)\n",
    "    k = streambed hydraulic conductivity\n",
    "    gwe = groundwater elevation\n",
    "    elev = elevation of stream top for seepage calculation\n",
    "    \"\"\"\n",
    "    T = len(I)\n",
    "    # N rows and T columns\n",
    "    dim = [N+1, T]\n",
    "    dim2 = [N, T]\n",
    "    Q = np.zeros(dim)\n",
    "    S = np.zeros(dim2)\n",
    "    mb = np.zeros(dim2)\n",
    "    e = np.zeros(dim2)\n",
    "    swe = np.zeros(dim2)\n",
    "    dh = np.zeros(dim2)\n",
    "    qA = np.zeros(dim2)\n",
    "    \n",
    "    Q[0,:] = I # set first row as historic inflow\n",
    "    Q[1:,0] = Q[0,0] # assume initial inflow equals outflow all reaches\n",
    "    S[:,0] = K*Q[1,0] # assume initial storage equals outflow because no wedge storage\n",
    "    \n",
    "    # Muskingum coefficients\n",
    "    C1 = (delt - 2*K*X)/(2*K*(1-X)+delt)\n",
    "    C2 = (delt + 2*K*X)/(2*K*(1-X)+delt)\n",
    "    C3 = (2*K*(1-X)-delt)/(2*K*(1-X)+delt)\n",
    "#     print('C1:', C1,'C2:', C2, 'C3:', C3)\n",
    "    \n",
    "    for j in range(0,T-1):\n",
    "        # replace linear interpolation with Manning equation with XS data\n",
    "        swe[:, j] = np.linspace(TWC_stage(Q[-1,j]), MB_stage(Q[0,j]), 48)+elev\n",
    "        # update to allow for gw disconnection\n",
    "        dh[:, j] =  (swe[:,j] - gwe)/(elev - gwe)\n",
    "        for i in np.arange(0, N):\n",
    "            # groundwater seepage term\n",
    "            q = k[i]*dh[i,j] # darcian groundwater flow\n",
    "            qA[i,j] = q*perimeter_base*rchlen # volumetric groundwater seepage\n",
    "            Q[i+1,j+1] = np.clip(C1*Q[i,j+1] + C2*Q[i,j] + C3*Q[i+1,j] - qA[i,j], 0, 1E15)\n",
    "            \n",
    "            S[i,j+1] = S[i,j] + K*(X*(Q[i,j+1]-Q[i,j])+(1-X)*(Q[i+1,j+1]-Q[i+1,j]))\n",
    "            \n",
    "#         if current storage is greater than max\n",
    "#             if S[i,j] > Smax:\n",
    "#                 # calculate the excess storage\n",
    "#                 e[i,j] = S[i,j] - Smax\n",
    "#                 # remove the excess storage from the outflow because it\n",
    "#                 # is considered overbank flow\n",
    "#                 Q[i,j] = Q[i,j] - e[i,j]/(K*(1-X))\n",
    "#                 # reduce storage by amount that went overbank\n",
    "#                 S[i,j] = S[i,j] - e[i,j]\n",
    "                \n",
    "            # mass balance check\n",
    "            mb[i,j] = S[i,j] + K*(X*(Q[i,j+1]-Q[i,j])+(1-X)*(Q[i+1,j+1]-Q[i+1,j])) - S[i,j+1]\n",
    "#         swe[:, j+1] = np.linspace(TWC_stage(Q[i+1,j+1]), MB_stage(Q[i+1,j+1]), 48)\n",
    "#         dh[:, j+1] =  swe[:,j+1] - gwe[:,j+1]\n",
    "    return(Q, S, e, mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow statistics \n",
    "def stat(x):\n",
    "    print('Min:', np.min(x), 'Max:', np.max(x), 'Mean:', np.mean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 minute discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run of adjusted Muskingum routing which gives outflow for all reaches\n",
    "\n",
    "I = inflow_15_reg.Discharge_cfs.values\n",
    "# need to convert to cfm from cfs\n",
    "I0 = I*60\n",
    "\n",
    "t1 = datetime.now()\n",
    "tQ, tS, e, mb = Adj_Muskingum(I0, N, K, X, krch, gwe, elev)\n",
    "t2 =  datetime.now()\n",
    "print(t2-t1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 47 # between 0 and 47\n",
    "# between 0 and 200,000\n",
    "outflow = pd.DataFrame(index = inflow_15_reg.index, data = np.transpose(tQ))\n",
    "dt = np.arange(194000,199000)\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(outflow[1][dt])\n",
    "plt.plot(outflow[48][dt])\n",
    "plt.xlabel('Date-Time')\n",
    "plt.ylabel('Flow (cfm)')\n",
    "plt.legend(['Inflow Reach 0', 'Outflow Reach 48'])\n",
    "plt.savefig('Routed_inflow_outflow_peaks', dpi = 300, bbox = 8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

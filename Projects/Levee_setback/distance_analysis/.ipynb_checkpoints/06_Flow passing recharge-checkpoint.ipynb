{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Andrew Calderwood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename, dirname, join, exists\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from time import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as lines\n",
    "\n",
    "# from pandas.tseries import converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "    \n",
    "# dir of all gwfm data\n",
    "gwfm_dir = join(dirname(doc_dir),'Box/research_cosumnes/GWFlowModel')\n",
    "\n",
    "flopy_dir = doc_dir+'/GitHub/flopy'\n",
    "if flopy_dir not in sys.path:\n",
    "    sys.path.insert(0, flopy_dir)\n",
    "import flopy \n",
    "import flopy.utils.binaryfile as bf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set box directory for output figures and data\n",
    "box_dir = gwfm_dir+'/Levee_setback/levee_setback_distance_analysis/'\n",
    "\n",
    "# tprogs_id = '' # original tprogs with conditioning data in output tsim\n",
    "# tprogs_id = '_no_conditioning'\n",
    "tprogs_id = '_no_cond_c3d'\n",
    "\n",
    "\n",
    "data_dir = box_dir+ tprogs_id+'/data_output/'\n",
    "fig_dir = box_dir+tprogs_id+'/figures/'\n",
    "\n",
    "chan_dir = box_dir+'channel_data/'\n",
    "gis_dir = chan_dir+'GIS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_dir = join(doc_dir, 'GitHub','CosumnesRiverRecharge')\n",
    "fxn_dir = git_dir+'/python_utilities'\n",
    "if fxn_dir not in sys.path:\n",
    "    sys.path.append(fxn_dir)\n",
    "# sys.path\n",
    "# import muskingum_recharge as mr\n",
    "\n",
    "from importlib import reload\n",
    "# reload(mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 100\n",
    "ncol = 230\n",
    "rows = np.repeat(np.arange(0,nrow),ncol)\n",
    "cols = np.tile(np.arange(0,ncol),nrow)\n",
    "\n",
    "# dem data for cropping above land surface\n",
    "# dem_data = np.loadtxt(gwfm_dir+'/DIS_data/dem_52_9_200m_linear.tsv')\n",
    "dem_data = np.loadtxt(gwfm_dir+'/DIS_data/dem_52_9_200m_mean.tsv')\n",
    "\n",
    "zs = gpd.read_file(gwfm_dir+'/DIS_data/grid_elevation_m_statistics.shp')\n",
    "# columns with different quantiles 0 to 100% of elevation\n",
    "q_cols = zs.columns[zs.columns.str.contains('perc')]\n",
    "df_elevs = zs[q_cols]\n",
    "\n",
    "# convert quantile dataframe to a 3D array\n",
    "arr_elev = np.zeros((df_elevs.shape[1], zs.row.max(),zs.column.max()))\n",
    "for n in np.arange(0,df_elevs.shape[1]):\n",
    "    arr_elev[n, zs.row-1, zs.column-1] = df_elevs.iloc[:,n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(np.diff(arr_elev, axis=0), axis=0), vmax=1)\n",
    "plt.colorbar(shrink=0.5)\n",
    "np.mean(np.diff(arr_elev, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No flow routing, recharge loss only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_cfs = 22500 # 5 year\n",
    "# # Q_cfs = 2000 # 1ish year\n",
    "\n",
    "# Q_cms = Q_cfs*(0.3048**3) # convert to cubic meters per second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import muskingum_recharge\n",
    "reload(muskingum_recharge)\n",
    "\n",
    "from muskingum_recharge import min_Q, mannings, calc_depth_arr, xs_setback, gridded_interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(join(chan_dir, 'setback_locs.hdf5'), \"r\")\n",
    "local_str_setbacks = f['setbacks']['local'][:]\n",
    "str_setbacks = f['setbacks']['regional'][:]\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setbacks = np.arange(0, 3400,200)\n",
    "# smoothed XS data used for setback analysis\n",
    "xs_all_cln = pd.read_csv(chan_dir+'Elevation_by_XS_number_meters.csv', index_col='dist_from_center_m')\n",
    "# xs_all_cln = pd.read_csv(chan_dir+'xs_levee_smooth.csv', index_col='dist_from_center_m')\n",
    "num_segs = xs_all_cln.shape[1]\n",
    "\n",
    "# load array identifying row,col to XS id (1,28)\n",
    "xs_arr = np.loadtxt(chan_dir+'XS_num_grid_reference.tsv')\n",
    "\n",
    "# load flood typology characteristics (based on daily data 1908 - 2014) - median values \n",
    "#\"cms_pk\" for peak discharge, \"pk_loc\" for time to peak, and \"log_no_d\" for duration\n",
    "flood_type = pd.read_csv(join(box_dir, 'whipple_grp6_w97ftmedians.csv'),index_col='Group.1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_cms = flood_type.loc[1,'cms_pk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_thick=2\n",
    "# fn = chan_dir+'/tprogs_geomK_'+str(soil_thick)+'m_depth.tsv' # from linear dem but also seems off\n",
    "fn = chan_dir+'/tprogs_geomK_'+str(soil_thick)+'m_depth_dem_mean.tsv' # mean dem with newest cleaning function\n",
    "\n",
    "# units of m/day\n",
    "soil_K_out = np.loadtxt(fn, delimiter='\\t')\n",
    "soil_K = np.reshape(soil_K_out, (100, nrow, ncol))\n",
    "# convert soil conductivity from m/d to m/s and apply vertical anisotropy factor\n",
    "vani = 100\n",
    "soil_K = (soil_K/vani)/86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_percentile=87 # for permeameter (flow threshold)\n",
    "flow_percentile=6 # for connec3d (points of connectivity)\n",
    "\n",
    "hf_tot_in =  np.loadtxt(data_dir+'surface_highflow_by_realization_'+str(flow_percentile)+'.tsv',delimiter = '\\t')\n",
    "hf_tot = np.reshape(hf_tot_in, (100, nrow, ncol))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the minimum elevation for each subsegment applied outward across the transects\n",
    "xs_mins_arr = np.loadtxt(chan_dir+'subsegments_xs_mins.tsv', delimiter='\\t')\n",
    "# need to correct segment definition to where the xs_mins subsegment data is\n",
    "xs_arr[np.isnan(xs_mins_arr)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating curves for each segment and setback\n",
    "xs_flow_all = pd.read_csv(join(chan_dir,'all_xs_50pt_rating_curves.csv'))\n",
    "\n",
    "def depth_match(seg_flow, flow):\n",
    "    \"\"\" Given a XS (nseg, setback) return the expected depth (m) given a flow (cms)\"\"\"\n",
    "    # find flows above and below the input flow\n",
    "    flow_diff = (seg_flow.flow_cms-flow)\n",
    "    f_high = flow_diff[flow_diff>0].argsort().index[0]\n",
    "    f_low = flow_diff[flow_diff<0].argsort().index[-1]\n",
    "    match_d = seg_flow.loc[[f_low, f_high]].sort_values('flow_cms')\n",
    "    # linearly interpolate to calculate exact depth\n",
    "    flow_slope = (match_d.iloc[1].flow_cms-match_d.iloc[0].flow_cms)/(match_d.iloc[1].depth_m-match_d.iloc[0].depth_m)\n",
    "    out_depth = match_d.iloc[0].depth_m + (flow-match_d.iloc[0].flow_cms)/flow_slope\n",
    "    return(out_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nseg = 3\n",
    "setback=3200\n",
    "seg_flow = xs_flow_all[(xs_flow_all.nseg==nseg)&(xs_flow_all.setback==setback)]\n",
    "# seg_flow\n",
    "depth_match(seg_flow, flow=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in flood_type.index:\n",
    "# 1, 2, 3 are floods long enough to apply to analysis\n",
    "ft=2\n",
    "# typical winter baseflow, peak flow, peak location, total time (days)\n",
    "# flow of 23 m3/s listed by Whipple as floodplain cutoff\n",
    "q_base = 23 # 200*(0.3048**3)\n",
    "q_peak = flood_type.loc[ft,'cms_pk']\n",
    "# total duration in days \n",
    "T = int(10**flood_type.loc[ft,'log_no_d'])\n",
    "p_l = flood_type.loc[ft,'pk_loc']\n",
    "tp = int(p_l*T)\n",
    "\n",
    "q_rise = np.linspace(q_base, q_peak, tp)\n",
    "q_fall = np.linspace(q_peak, q_base, (T-tp+1))\n",
    "q_in = np.append(q_rise, q_fall[1:])\n",
    "plt.plot(q_in)\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Flow ($m^3/s$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow loss procedure\n",
    "1. Allocate arrays for:  \n",
    "    1. flow (n realizations, n setbacks, n segments +1)  \n",
    "    2. depth (n setbacks, nrow, ncol)  \n",
    "    3. water surface elevation (n setbacks, nrow, ncol)  \n",
    "    4. recharge (n realizations, n setbacks, nrow, ncol)  \n",
    "2. Primary iteration:  \n",
    "    1. Given a cross-section with a specified width for a given setback  \n",
    "    2. Calculate the depth in the channel from the flow with Manning Equation  \n",
    "    3. Add depth to cross-section minimum elevation to calculate water surface elevation for the given setback and segment  \n",
    "3. Secondary Iteration:  \n",
    "    1. Given a segment identify which cells have a water surface elevation above ground surface (i.e., inundated)  \n",
    "    2. Calculate recharge based on inundated area, hydraulic gradient due to flood depth and vertical conductivity  \n",
    "    3. Sum of recharge by segment  \n",
    "    4. Calculate flow leaving the segment by subtracting recharge from flow entering the segment  \n",
    "4. Optional Iteration:\n",
    "    1. Apply a sequence of flows that include the rising limb and falling limb in addition to the peak flow\n",
    "    2. Calculate total recharge from this continuous event\n",
    "5. Outermost Iteration:  \n",
    "    Complete these depth, recharge, flow calculations for each subsurface realization  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros((100, len(setbacks), xs_all_cln.shape[1]+1))\n",
    "Q[:,:,0] = Q_cms\n",
    "# save depth arrays for each setbacks\n",
    "d_arr = np.zeros((len(setbacks), nrow, ncol))\n",
    "wse_arr = np.zeros((len(setbacks), nrow, ncol))\n",
    "# save high recharge flows\n",
    "rch_hf_arr = np.zeros((100, len(setbacks), nrow, ncol))\n",
    "cell_frac = np.zeros((q_in.shape[0], len(setbacks), nrow, ncol))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than focusing on improving the solver iteration which isn't that bad (21 iterations isn't great but it could be worse), I should work on solution: updating roughness based on cross-section width, include levee wall roughness in wetted perimeter. Look at sensitivity of vertical conductivity. Summarize recharge by time period of flood (travel time is 13.2 hours/45 km per Whipple, about 0.3 hrs per 1 km) which is about 0.6 hrs per 2km to multiply by the recharge rate.   \n",
    "The current set up with a flow minus recharge makes sense if we assume a temporary steady state is reached (true for sub half hour), but if I want to start calculating volumes for transient events then I need to account for the duration.\n",
    "\n",
    "Whipple notes a floodplain inundation threshold of 23 m3/s at MHB where the lowest lying floodplain areas connect.\n",
    "\n",
    "* using rating curve method with linear interpolation is 15x faster than minimize scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_flow_all.nseg.unique().shape, xs_all_cln.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs a singular flow value\n",
    "from time import time\n",
    "# takes ~45 minutes\n",
    "t=0\n",
    "tic = time()\n",
    "n = 0.048 # assume constant roughness for now\n",
    "qn=0\n",
    "for t in np.arange(0,1):\n",
    "    # iterate across all cross-sections\n",
    "    for nseg in np.arange(0,xs_all_cln.shape[1]):\n",
    "        # iterate across all setbacks\n",
    "        for s,setback in enumerate(setbacks):\n",
    "            # for a given setback imagine there is an impenetrable levee blocking overbank flow\n",
    "            xs_elevs = xs_setback(xs_all_cln.iloc[:,nseg], setback)\n",
    "            # solve for depth that matches given flow, assume less than 1 cms is too small to calculate\n",
    "            if Q[qn, s,nseg] >1:\n",
    "                seg_flow = xs_flow_all[(xs_flow_all.nseg==nseg)&(xs_flow_all.setback==setback)]\n",
    "                depth = depth_match(seg_flow, flow=Q[qn, s, nseg])\n",
    "            else:\n",
    "                depth = 0\n",
    "            # join depth calculated at cross-section to corresponding model cells and corresponding setback\n",
    "#             wse_arr[s,(xs_arr==nseg)&(str_setbacks <= s+1)] = depth + xs_elevs.min()\n",
    "#             d_arr[s,(xs_arr==nseg)&(str_setbacks <= s+1)] = depth\n",
    "            wse_arr[s,(xs_arr==nseg)&(str_setbacks[s]==1)] = depth + xs_elevs.min()\n",
    "            d_arr[s,(xs_arr==nseg)&(str_setbacks[s]==1)] = depth \n",
    "        # identify wse above surface elevation \n",
    "        d_arr = d_arr* (wse_arr > dem_data)\n",
    "        # calculate vertical seepage with Darcy's equation assuming a saturated zone thickness similar to the lake bed in modflow\n",
    "        # hydraulic conductivity is in m/s, hydraulic gradient is unitless, area is 200x200 m^2\n",
    "        rch_hf_arr[t,:,:,:] += (xs_arr==nseg)*(soil_K[t,:,:])*(200*200)*((d_arr* + soil_thick)/soil_thick)\n",
    "        # rch_hf_arr[t,:,:,:] += (xs_arr==nseg)*(soil_K[t,:,:])*hf_tot[t,:,:] *(200*200)*((d_arr* + soil_thick)/soil_thick)\n",
    "        Q[t, :, nseg+1] = Q[t, :, nseg] - np.nansum(rch_hf_arr[t,:, xs_arr==nseg], axis=(0))\n",
    "        \n",
    "toc = time()\n",
    "print((toc-tic)/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find difference between water surface and cell elevations\n",
    "diff = wse_arr[tp-1,-1,:] - arr_elev\n",
    "diff[diff<0] = np.nan\n",
    "# find the highest elevation above which there is water\n",
    "bot_q = np.argmin(diff, axis=0)[rows,cols] - 1\n",
    "bot_q[bot_q<0] = 0\n",
    "top_q = np.argmin(diff, axis=0)[rows,cols] \n",
    "# find percentage of interim quantile\n",
    "perc_q = (dem_data[rows,cols] - arr_elev[bot_q, rows,cols])/(arr_elev[top_q, rows,cols] +1E-3 - arr_elev[bot_q, rows,cols])\n",
    "# percent of cell area covered by flood\n",
    "perc_A = np.reshape(bot_q + perc_q, (nrow,ncol))/10\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,3))\n",
    "n = 150\n",
    "ax.plot(arr_elev[0][:,n], label='min')\n",
    "ax.plot(dem_data[:,n], label='dem')\n",
    "ax.plot(arr_elev[10][:,n], label='max')\n",
    "ax.legend()\n",
    "fig,ax=plt.subplots()\n",
    "ax.imshow(perc_A)\n",
    "plt.colorbar(ax.images[0], shrink=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xs_mins_arr - arr_elev[0],vmin=-10, vmax=10)\n",
    "plt.colorbar(shrink=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wse_temp = np.zeros((nrow,ncol))\n",
    "nseg = 27\n",
    "s=0\n",
    "depth = 1\n",
    "qn = 0\n",
    "for s in np.arange(0,17):\n",
    "    for nseg in [27]:#np.arange(0,27):\n",
    "        fp_zon = (xs_arr==nseg)&(str_setbacks[s]==1)\n",
    "    \n",
    "        # join depth calculated at cross-section to corresponding model cells and corresponding setback\n",
    "        # add elevation to minimum to apply segment midpoint as elevation rather than lowest point\n",
    "        wse_arr[s, fp_zon] = depth + xs_mins_arr[fp_zon]\n",
    "        # calculate depth of water at different elevation percentiles for segment and setback\n",
    "        # to account for flood connectivity and avoid negligible, require a minimum of 0.1 m \n",
    "        diff = wse_arr[s,:]*fp_zon - 0.1 - arr_elev\n",
    "        # when depth is negative remove\n",
    "        diff[diff<0] = 0 #np.NaN\n",
    "        # only keep cells where water level is above lowest elevation\n",
    "        diffmax = np.nanmax(diff, axis=0)\n",
    "        # keep cells where diffmax >0 \n",
    "        x,y = np.where(diffmax>0)\n",
    "        # find the highest elevation above which there is water, subtract 1 uses lower percentile\n",
    "        # where the wse was below the minimum ignore\n",
    "        bot_q = np.argmin(diff, axis=0)[x,y] - 1\n",
    "        bot_q[bot_q<0] = 0\n",
    "        top_q = np.argmin(diff, axis=0)[x,y]\n",
    "        # find percentage of interim quantile\n",
    "        perc_q = (wse_arr[s, x,y] - arr_elev[bot_q, x,y])/(arr_elev[top_q, x,y] +1E-3 - arr_elev[bot_q, x,y])\n",
    "        # need to account for when top_q == bot_q\n",
    "        perc_q = np.where(arr_elev[bot_q, x,y]==arr_elev[top_q, x,y], 0, perc_q)\n",
    "        # adjust for when wse > top_q\n",
    "        perc_q = np.where(wse_arr[s, x,y]>arr_elev[top_q, x,y], 0, perc_q)\n",
    "        # percent of cell area covered by flood\n",
    "        cell_frac[qn, s,x,y] = (bot_q + perc_q)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_h5(Q, rch_hf_arr, d_arr, h5_fn):\n",
    "    # convert arrays of annual rates to hdf5 files individually\n",
    "    f = h5py.File(h5_fn, \"w\")\n",
    "    grp = f.require_group('array') # makes sure group exists\n",
    "    grp.attrs['units'] = 'cubic meters/second'\n",
    "    grp.attrs['description'] = 'Each layer of the array is a day in the event'\n",
    "    dset = grp.require_dataset('flow', Q.shape, dtype='f', compression=\"gzip\", compression_opts=4)\n",
    "    dset[:] = Q\n",
    "    dset = grp.require_dataset('rch_hf', rch_hf_arr.shape, dtype='f', compression=\"gzip\", compression_opts=4)\n",
    "    dset[:] = rch_hf_arr\n",
    "    dset = grp.require_dataset('depth', d_arr.shape, dtype='f', compression=\"gzip\", compression_opts=4)\n",
    "    dset[:] = d_arr\n",
    "    f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def realization_recharge(t, str_setbacks, region, save=True):\n",
    "    # allocate arrays - num flow steps, num setbacks, num segments\n",
    "    Q = np.zeros((q_in.shape[0], len(setbacks), xs_all_cln.shape[1]+1))\n",
    "    # set inflow for segment 1 across all setbacks and for all times\n",
    "    # rate of cubic meters per second\n",
    "    Q[:,:,0] = np.repeat(q_in.reshape(-1,1), len(setbacks), axis=1)\n",
    "    # save depth arrays for each setbacks\n",
    "    d_arr = np.zeros((q_in.shape[0], len(setbacks), nrow, ncol))\n",
    "    wse_arr = np.zeros((len(setbacks), nrow, ncol))\n",
    "    cell_frac = np.zeros((q_in.shape[0], len(setbacks), nrow, ncol))\n",
    "    # save high recharge flows\n",
    "    rch_hf_arr = np.zeros((q_in.shape[0], len(setbacks), nrow, ncol))\n",
    "\n",
    "    tic = time()\n",
    "    n = 0.048 # assume constant roughness for now\n",
    "\n",
    "    # iterate across streamflows\n",
    "    for qn in np.arange(0, q_in.shape[0]):\n",
    "        # iterate across all cross-sections\n",
    "        for nseg in np.arange(0,xs_all_cln.shape[1]):\n",
    "            # iterate across all setbacks\n",
    "            for s,setback in enumerate(setbacks):\n",
    "                # for a given setback imagine there is an impenetrable levee blocking overbank flow\n",
    "                xs_elevs = xs_setback(xs_all_cln.iloc[:,nseg], setback)\n",
    "                # boolean of row,col cells that fall within the segment and setback\n",
    "                fp_zon = (xs_arr==nseg)&(str_setbacks[s]==1)\n",
    "                # solve for depth that matches given flow, assume less than 1 cms is too small to calculate\n",
    "                if Q[qn, s,nseg] >1:\n",
    "                    seg_flow = xs_flow_all[(xs_flow_all.nseg==nseg)&(xs_flow_all.setback==setback)]\n",
    "                    depth = depth_match(seg_flow, flow=Q[qn, s, nseg])\n",
    "                else:\n",
    "                    depth = 0\n",
    "                # join depth calculated at cross-section to corresponding model cells and corresponding setback\n",
    "                # add elevation to minimum to apply segment midpoint as elevation rather than lowest point\n",
    "                wse_arr[s, fp_zon] = depth + xs_mins_arr[fp_zon]\n",
    "#                 if any(np.isnan(xs_mins_arr[fp_zon])):\n",
    "#                     print('Seg',str(nseg),'Setback',str(s), xs_mins_arr[fp_zon])\n",
    "                # calculate depth of water at different elevation percentiles for segment and setback\n",
    "                # to account for flood connectivity and avoid negligible, require a minimum of 0.1 m \n",
    "                diff = wse_arr[s,:]*fp_zon - 0.1 - arr_elev\n",
    "                # when depth is negative remove\n",
    "                diff[diff<0] = 0 #np.NaN\n",
    "                # only keep cells where water level is above lowest elevation\n",
    "                diffmax = np.nanmax(diff, axis=0)\n",
    "                # keep cells where diffmax >0 \n",
    "                x,y = np.where(diffmax>0)\n",
    "                # find the highest elevation above which there is water, subtract 1 uses lower percentile\n",
    "                # where the wse was below the minimum ignore\n",
    "                bot_q = np.argmin(diff, axis=0)[x,y] - 1\n",
    "                bot_q[bot_q<0] = 0\n",
    "                top_q = np.argmin(diff, axis=0)[x,y]\n",
    "                # find percentage of interim quantile\n",
    "                perc_q = (wse_arr[s, x,y] - arr_elev[bot_q, x,y])/(arr_elev[top_q, x,y] +1E-3 - arr_elev[bot_q, x,y])\n",
    "                # need to account for when top_q == bot_q\n",
    "                perc_q = np.where(arr_elev[bot_q, x,y]==arr_elev[top_q, x,y], 0, perc_q)\n",
    "                # adjust for when wse > top_q\n",
    "                perc_q = np.where(wse_arr[s, x,y]>arr_elev[top_q, x,y], 0, perc_q)\n",
    "                # percent of cell area covered by flood\n",
    "                cell_frac[qn, s,x,y] = (bot_q + perc_q)/10\n",
    "                # depth for each cell is difference between water surface and average flooded ground elevation\n",
    "                d_arr[qn, s,fp_zon] = np.nanmean(diff, axis=0)[fp_zon] #depth \n",
    "                # identify wse above surface elevation \n",
    "#                 d_arr[qn,:] = d_arr[qn,:] * cell_frac[qn] # caused overflow error\n",
    "            # calculate vertical seepage with Darcy's equation assuming a saturated zone thickness similar to the lake bed in modflow\n",
    "            # hydraulic conductivity is in m/s, hydraulic gradient is unitless, area is 200x200 m^2\n",
    "            # q_seep = (soil_K[t,:,:])*hf_tot[t,:,:]*(200*200)*((d_arr[qn,:] + soil_thick)/soil_thick) # recharge only in HCP\n",
    "            q_seep = (soil_K[t,:,:])*(200*200)*((d_arr[qn,:] + soil_thick)/soil_thick)\n",
    "            rch_hf_arr[qn,:,:,:] += (xs_arr==nseg) * q_seep * cell_frac[qn]\n",
    "            # identify when the flow is less than the recharge predicted and recharge > 0 \n",
    "            dry = (Q[qn, :, nseg] < np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=0)) & (np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=0)>0)\n",
    "            if any(dry):\n",
    "                # where the cells will end dry, reduce recharge so it sums to the flow into segment\n",
    "    #             scale = (Q[qn, :, nseg][dry]/np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=(0))[dry])\n",
    "                scale = (Q[qn, :, nseg]/(np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=(0)))) \n",
    "                scale = np.where(scale > 1, 1,scale) # only scale when flow is less than recharge\n",
    "#             if any(scale<1):\n",
    "#                 rch_hf_arr[qn, :,xs_arr==nseg][:,dry] *= scale\n",
    "                rch_hf_arr[qn, :,xs_arr==nseg] *= scale\n",
    "                print('scale', np.round(np.median(scale),2))\n",
    "            Q[qn, :, nseg+1] = Q[qn, :, nseg] - np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=(0))\n",
    "            if any(Q[qn,:,nseg+1]<0):\n",
    "                print(qn, nseg+1)\n",
    "                \n",
    "    # saving all of the flow at all steps, setbacks is needed to post-process\n",
    "    if save:\n",
    "        base_fn = join(data_dir, region, 'type'+str(ft), 'r'+str(t).zfill(3)+'_')\n",
    "        arr_to_h5(Q, rch_hf_arr, d_arr, base_fn+'output.hdf5')\n",
    "    toc = time()\n",
    "    print('Ran in %.2f' %((toc-tic)/3600), 'hours')\n",
    "    return(Q, rch_hf_arr, d_arr, cell_frac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check why the addition of dry segment check didn't fix negative flows\n",
    "qn = 0\n",
    "nseg = 24\n",
    "\n",
    "# identify when the flow is less than the recharge predicted and recharge > 0\n",
    "dry = (Q[qn, :, nseg] < np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=0)) & (np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=0)>0)\n",
    "# where the cells will end dry, reduce recharge so it sums to the flow into segment\n",
    "# scale = (Q[qn, :, nseg][dry]/np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=(0))[dry])\n",
    "if any(dry):\n",
    "    print('Recharge exceeds flow')\n",
    "print('Flow nseg -1   ',np.round(Q[qn, :, nseg-1],2))\n",
    "print('Recharge nseg-1',np.round(np.nansum(rch_hf_arr[qn,:, xs_arr==nseg-1], axis=0),2))\n",
    "# the flow into the next segment isn't equally the flow in the previous minus recharge with the dry adjustment\n",
    "print('Flow nseg     ',np.round(Q[qn, :, nseg],2))\n",
    "print('Recharge nseg  ',np.round(np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=0),2))\n",
    "\n",
    "# even though flow is negative there is somehow depth at these locations\n",
    "print('Depth nseg    ',np.round(np.nanmax(d_arr[qn,:,xs_arr==nseg], axis=0),2))\n",
    "# this may be an issue with how the minimum XS elevation is defined, bascially the min XS value should be consistent\n",
    "print('Flow nseg +1  ', np.round(Q[qn, :, nseg+1],2))\n",
    "# once flow hits negative then there is no longer depth so no more recharge at least\n",
    "# when flow is less than recharge and greater than 0 then scaling is appropriate\n",
    "# I'm get at least a couple of NAs in the scaling which will cause issues\n",
    "\n",
    "# if flow is already negative then this scaling function does not help, it would be adding flow from recharge which is wrong\n",
    "# scale = (Q[qn, :, nseg][dry]/np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=(0))[dry])\n",
    "scale = (Q[qn, :, nseg]/np.nansum(rch_hf_arr[qn,:, xs_arr==nseg], axis=(0)))\n",
    "scale = np.where(scale > 1, 1,scale)\n",
    "print('Scale nseg     ', scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a couple realizations failed to write output including 48\n",
    "t=5\n",
    "Q, rch_hf_arr, d_arr, cell_frac = realization_recharge(t, str_setbacks, 'regional', save=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2, figsize=(8,3))# time series\n",
    "# select segments all times\n",
    "for n in [0,5, 10,15,20,25]:\n",
    "    ax[0].plot(Q[:,-1,n], label=n)\n",
    "ax[0].legend(title='segment')\n",
    "# plt.show()\n",
    "# first time all segs\n",
    "# longitudinal losses\n",
    "for n in [0,5, 10,15,20,25]:\n",
    "    ax[1].plot(Q[n,-1, :],label=n)\n",
    "ax[1].legend(title='day')\n",
    "# rch_hf_arr.sum(axis=(2,3))[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate recharge for each flow and setback, daily average in m3/s\n",
    "rch_q_sum = pd.DataFrame(np.sum(rch_hf_arr, axis=(2,3)), columns= setbacks).transpose()\n",
    "# calculate sum for all flows (daily average)\n",
    "rch_sum = rch_q_sum.sum(axis=1)\n",
    "# convert to AF/day and will have the total AF recharged because already summed by day\n",
    "rch_sum_AF = rch_sum*86400/((0.3048**3)*43560)\n",
    "\n",
    "# if we divide by the setback area we will get the depth of recharge per setback area\n",
    "setback_area = [np.sum(str_setbacks[s]== s)*200*200 for s in np.arange(0,len(setbacks)) ]\n",
    "\n",
    "# (rch_sum_AF/setback_area).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp = 5\n",
    "# s = 5\n",
    "# fig,ax=plt.subplots(1,2,figsize=(8,4))\n",
    "# for s in [0,5,10,15]:\n",
    "#     temp = np.zeros(xs_all_cln.shape[1])\n",
    "#     for nseg in np.arange(0,xs_all_cln.shape[1]):\n",
    "# #         temp[nseg] = np.nanmean(wse_arr[tp,s][xs_arr==nseg])\n",
    "#         temp[nseg] = np.nanmean(d_arr[tp,s][xs_arr==nseg])\n",
    "# #     ax[1].plot(temp)\n",
    "#     ax[1].plot(xs_all_cln.min().values,label=s)\n",
    "#     ax[0].plot(temp,label=s)\n",
    "    \n",
    "    \n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp = 5\n",
    "# s = 5\n",
    "# temp = np.zeros(xs_all_cln.shape[1])\n",
    "# for nseg in np.arange(0,xs_all_cln.shape[1]):\n",
    "#     temp[nseg] = np.nanmean(wse_arr[tp,s][xs_arr==nseg])\n",
    "# plt.plot(temp, label='WSE')\n",
    "# xs_all_cln.min().plot(label='Channel Bottom')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr = gpd.read_file(gwfm_dir+'/SFR_data/final_grid_sfr/grid_sfr.shp')\n",
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=6\n",
    "setback = s*200\n",
    "\n",
    "sfr_union = gpd.GeoDataFrame(pd.DataFrame([0]), geometry = [grid_sfr.unary_union], crs=grid_sfr.crs)\n",
    "sfr_union.geometry = sfr_union.buffer(setback).exterior\n",
    "\n",
    "setback_grid = gpd.sjoin(sfr_union, grid_p, how='left')\n",
    "setback_outer = np.zeros((nrow,ncol))\n",
    "setback_outer[setback_grid.row-1, setback_grid.column-1] = 1\n",
    "setback_outer = ma.masked_where(setback_outer==0,setback_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['lightgray', 'blue']\n",
    "scale = [0, 1]\n",
    "cmap=mpl.colors.ListedColormap(colors)\n",
    "norm=mpl.colors.BoundaryNorm(scale, len(colors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot for the methods to show overlay of HCP, flood depth to recharge\n",
    "\n",
    "fig, ax = plt.subplots(3,1, dpi=600,figsize=(8,6), sharex=True)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "## plot HCPs\n",
    "ax_n = ax[0]\n",
    "im = ax_n.imshow(hf_tot[t],cmap=cmap)\n",
    "# color bar on all rows, with two discrete labels\n",
    "cbar=plt.colorbar(mappable = im, ax=ax_n,  ticks = [0.25,.75], shrink= 0.6)\n",
    "cbar.ax.set_yticklabels(['Background', 'HCP'])\n",
    "## plot flood depth\n",
    "ax_n = ax[1]\n",
    "nf = 2 \n",
    "d_plt = np.ma.masked_invalid(d_arr.mean(axis=0)[s])\n",
    "d_plt = np.ma.masked_where(d_plt==0,d_plt)\n",
    "\n",
    "im = ax_n.imshow(d_plt, \n",
    "                 norm = mpl.colors.LogNorm(vmin = 1E-2, vmax = np.nanmax(d_arr)),\n",
    "                 zorder=1\n",
    "                )\n",
    "plt.colorbar(im, ax=ax_n, orientation='vertical', label='Depth (m)', shrink=0.6,location='right')\n",
    "## plot recharge\n",
    "ax_n = ax[2]\n",
    "temp = rch_hf_arr.sum(axis=0)[s]*86400*1E-6\n",
    "im = ax_n.imshow(np.ma.masked_where(temp==0, temp))\n",
    "plt.colorbar(im, ax=ax_n, orientation='vertical', label='Total Recharge (MCM)', shrink=0.6,location='right')\n",
    "\n",
    "title = ['High Conductivity Pathways', 'Floodplain Inundation','Flood-activated Pathways']\n",
    "for n in np.arange(0,3):\n",
    "    ax_n = ax[n]\n",
    "    ax_n.imshow(setback_outer, cmap='gray') # works when dpi=600\n",
    "    ax_n.plot(grid_sfr.column-1, grid_sfr.row-1, color='black', linewidth=0.5, linestyle='-.')\n",
    "    ax_n.annotate(text = title[n], xy=(0.1,0.8), xycoords='axes fraction',\n",
    "                  bbox={'facecolor': 'lightgray', 'alpha': 0.9, 'pad': 2})\n",
    "\n",
    "\n",
    "fig.tight_layout(h_pad=-.3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.nansum(rch_hf_arr,axis=(0,2,3))*86400*1E-6)\n",
    "np.nansum(rch_hf_arr[s])*86400*1E-6 # MCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_plt.max(), d_plt.mean(), d_plt.min()\n",
    "# typical flow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified HCP with flood depth to recharge (Archived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# show change in activated pathways by either setback distance impact on flooded area or\n",
    "# flood flow impact\n",
    "fig,ax=plt.subplots(3,3, figsize=(6.5, 6.5), sharex=True, sharey=True, dpi=300)\n",
    "# fig.tight_layout(hspsace=0.2, wspace=0.2)\n",
    "plt.subplots_adjust(hspace=-0.75, wspace=0.05)\n",
    "\n",
    "s=6\n",
    "# initial, peak, half way receded\n",
    "for i,qn in enumerate([0, tp, int(tp+(T-tp)/2)]):\n",
    "#     ax[i,0].imshow(hf_tot[t])\n",
    "    im = ax[i,0].imshow(hf_tot[t],cmap=cmap)\n",
    "\n",
    "    ax[i,1].imshow(d_arr[qn,s,:]>0, cmap=cmap)\n",
    "#     ax[i,1].imshow(d_mask[qn,s,:])\n",
    "\n",
    "    ax[i,2].imshow(rch_hf_arr[qn,s,:]>0, cmap=cmap)\n",
    "    for n in np.arange(0,3):\n",
    "        ax[i,n].scatter(setback_grid.column-1, setback_grid.row-1, color='black', s=0.1)\n",
    "    \n",
    "# axis labels\n",
    "ax[0,0].set_ylabel('Initial\\nFlow')\n",
    "ax[1,0].set_ylabel('Peak\\nFlow')\n",
    "ax[2,0].set_ylabel('Receding\\nFlow')\n",
    "\n",
    "# color bar on all rows, with two discrete labels\n",
    "# cbar=plt.colorbar(mappable = im, ax=ax[2,0],  ticks = [0.25,.75], shrink= 0.7, orientation='horizontal')\n",
    "# cbar.ax.set_yticklabels(['Low flow facies', 'High flow facies'])\n",
    "\n",
    "# titles\n",
    "ax[0,0].set_title('High Conductivity\\nPathways')\n",
    "ax[0,1].set_title('Inundated\\nFloodplain')\n",
    "ax[0,2].set_title('Activated\\nPathways')\n",
    "\n",
    "plt.setp(ax, xticks=[], yticks=[])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

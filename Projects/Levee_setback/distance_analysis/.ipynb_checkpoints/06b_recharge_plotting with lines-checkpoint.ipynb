{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename, dirname, join, exists\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# 1d so the smoothing is specific to each realization\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as lines\n",
    "\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a91fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "    \n",
    "# dir of all gwfm data\n",
    "gwfm_dir = join(dirname(doc_dir),'Box/research_cosumnes/GWFlowModel')\n",
    "\n",
    "flopy_dir = doc_dir+'/GitHub/flopy'\n",
    "if flopy_dir not in sys.path:\n",
    "    sys.path.insert(0, flopy_dir)\n",
    "import flopy \n",
    "import flopy.utils.binaryfile as bf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c1785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set box directory for output figures and data\n",
    "box_dir = gwfm_dir+'/Levee_setback/levee_setback_distance_analysis/'\n",
    "\n",
    "# tprogs_id = '' # original tprogs with conditioning data in output tsim\n",
    "# tprogs_id = '_no_conditioning'\n",
    "tprogs_id = '_no_cond_c3d'\n",
    "\n",
    "\n",
    "data_dir = box_dir+ tprogs_id+'/data_output/'\n",
    "fig_dir = box_dir+tprogs_id+'/figures/'\n",
    "\n",
    "chan_dir = box_dir+'channel_data/'\n",
    "gis_dir = chan_dir+'GIS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b74547",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 100\n",
    "ncol = 230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "setbacks = np.arange(0, 3400,200)\n",
    "# smoothed XS data used for setback analysis\n",
    "xs_levee_smooth = pd.read_csv(chan_dir+'xs_levee_smooth.csv', index_col='dist_from_right_m')\n",
    "num_segs = xs_levee_smooth.shape[1]\n",
    "\n",
    "# load array identifying row,col to XS id (1,28)\n",
    "xs_arr = np.loadtxt(chan_dir+'XS_num_grid_reference.tsv')\n",
    "\n",
    "# load flood typology characteristics (based on daily data 1908 - 2014) - median values \n",
    "#\"cms_pk\" for peak discharge, \"pk_loc\" for time to peak, and \"log_no_d\" for duration\n",
    "flood_type = pd.read_csv(join(box_dir, 'whipple_grp6_w97ftmedians.csv'),index_col='Group.1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d83fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(join(chan_dir, 'setback_locs.hdf5'), \"r\")\n",
    "local_str_setbacks = f['setbacks']['local'][:]\n",
    "str_setbacks = f['setbacks']['regional'][:]\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c98eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_output(ft_in, region):\n",
    "    tic = time.time()\n",
    "    T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "    p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "    tp_in = int(p_l_in*T_in)\n",
    "    rch_hf_all = np.zeros((100, len(setbacks),nrow,ncol))\n",
    "    Q_all = np.zeros((100, T_in, len(setbacks),xs_levee_smooth.shape[1]+1))\n",
    "\n",
    "    # filter out for only those realizations that successfully ran\n",
    "    base_fn = join(data_dir, region, 'type'+str(ft_in))\n",
    "    r_out = pd.Series(os.listdir(base_fn)).str.extract(r'(\\d{3})')[0].unique().astype(int)\n",
    "    # takes a \n",
    "    for t in r_out: # np.arange(0,100): #[0]:\n",
    "        r_fn = join(base_fn,'r'+str(t).zfill(3)+'_')\n",
    "        # saving all of the flow at all steps, setbacks is needed to post-process\n",
    "        Q_in = np.loadtxt(r_fn+'flow.tsv')\n",
    "        Q = np.reshape(Q_in, ((T_in, len(setbacks), xs_levee_smooth.shape[1]+1)))\n",
    "        Q_all[t,:] = np.copy(Q)\n",
    "\n",
    "        # for recharge we want to aggregate across time steps but look at differences across setbacks\n",
    "        rch_in = np.loadtxt(r_fn+'recharge.tsv')\n",
    "        rch_sum = np.reshape(rch_in, (len(setbacks), nrow, ncol))\n",
    "        rch_hf_all[t] = np.copy(rch_sum)\n",
    "    # convert to m3/day and will have the total recharged after summing individual days\n",
    "    rch_hf_all = rch_hf_all*86400\n",
    "\n",
    "    # convert to total AF from total m3\n",
    "    # rch_hf_all = rch_hf_all/((0.3048**3)*43560)\n",
    "\n",
    "    toc = time.time()\n",
    "    print('Loading',region,'for flow type',str(ft_in), 'took %.2f minutes' %((toc-tic)/60))\n",
    "    return(Q_all, rch_hf_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_hdf5_output(ft_in, region):\n",
    "    tic = time.time()\n",
    "    T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "    p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "    tp_in = int(p_l_in*T_in)\n",
    "    rch_hf_all = np.zeros((100, len(setbacks),nrow,ncol))\n",
    "    Q_all = np.zeros((100, T_in, len(setbacks),xs_levee_smooth.shape[1]+1))\n",
    "    d_all = np.zeros((100, T_in, len(setbacks),xs_levee_smooth.shape[1]))\n",
    "\n",
    "    # filter out for only those realizations that successfully ran\n",
    "    base_fn = join(data_dir, region, 'type'+str(ft_in))\n",
    "    r_out = pd.Series(os.listdir(base_fn)).str.extract(r'(\\d{3})')[0].unique().astype(int)\n",
    "    # takes a \n",
    "    for t in r_out: # np.arange(0,100): #[0]:\n",
    "        # load hdf5 files for each realization\n",
    "        r_fn = join(base_fn,'r'+str(t).zfill(3)+'_')\n",
    "        f = h5py.File(r_fn+'output.hdf5', \"r\")\n",
    "        Q = f['array']['flow'][:]        \n",
    "        rch_hf = f['array']['rch_hf'][:]\n",
    "        # depth is a little complicated to summarize, not so bad to back it out from\n",
    "        d_arr = f['array']['depth'][:]\n",
    "        f.close()\n",
    "        # saving all of the flow at all steps, setbacks is needed to post-process\n",
    "        Q_all[t] = np.copy(Q)\n",
    "        # sum recharge across time to save storage space (breaks python at 25GB)\n",
    "        rch_hf = np.nansum(rch_hf, axis=0)\n",
    "        rch_hf_all[t] = np.copy(rch_hf)\n",
    "        # depth needs to be averaged across each segment\n",
    "        for s in np.arange(0,len(setbacks)):\n",
    "            for nseg in np.arange(0, num_segs):\n",
    "                # mask zeros to not estimate depth based on zero values\n",
    "                # could present as average positive depth or maximum\n",
    "                d_out = d_arr[:,s, (xs_arr==nseg)&(str_setbacks[s].astype(bool))]\n",
    "                d_all[t,:,s, nseg] =  ma.masked_where(d_out==0, d_out).mean()\n",
    "\n",
    "\n",
    "    # convert to m3/day and will have the total recharged after summing individual days\n",
    "    rch_hf_all = rch_hf_all*86400\n",
    "\n",
    "    toc = time.time()\n",
    "    print('Loading',region,'for flow type',str(ft_in), 'took %.2f minutes' %((toc-tic)/60))\n",
    "    return(Q_all, rch_hf_all, d_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_in=1\n",
    "region='regional'\n",
    "Q_all, rch_hf_all, d_all = load_hdf5_output(ft_in, region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "    p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "    tp_in = int(p_l_in*T_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb012888",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_seg = np.zeros((100, T_in, len(setbacks),xs_levee_smooth.shape[1]))\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "# takes .045 sec to extract nseg, should take about 5 sec\n",
    "for t in np.arange(0,100):\n",
    "    for s in np.arange(0,len(setbacks)):\n",
    "        for nseg in np.arange(0, num_segs):\n",
    "            # mask zeros to not estimate depth based on zero values\n",
    "            d_out = d_all[t,:,s, (xs_arr==nseg)&(str_setbacks[s].astype(bool))]\n",
    "            d_seg[t,:,s, nseg] =  ma.masked_where(d_out==0, d_out).mean()\n",
    "toc = time.time()\n",
    "toc-tic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e665ec1e",
   "metadata": {},
   "source": [
    "## Save files as hdf5 to save time with reloading\n",
    "For each region and flow type save an hdf5 file that will include all realizations, so when reloading it takes 1 second instead of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ends up as about 500 MB, may want individual files\n",
    "\n",
    "def arr_to_h5(arr, h5_fn):\n",
    "    # convert arrays of annual etc to hdf5 files individually\n",
    "    f = h5py.File(h5_fn, \"w\")\n",
    "    grp = f.require_group('array') # makes sure group exists\n",
    "    grp.attrs['units'] = 'cubic meters per day'\n",
    "    grp.attrs['description'] = 'Each layer of the array is a day in the triangular hydrograph'\n",
    "    dset = grp.require_dataset('all', arr.shape, dtype='f', compression=\"gzip\", compression_opts=4)\n",
    "    dset[:] = arr\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55562c5",
   "metadata": {},
   "source": [
    "This code only needs to be re-run when the models are rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate_hdf5 = True\n",
    "recreate_hdf5 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d952ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if recreate_hdf5:\n",
    "    for region in ['regional']: #['local_1','local_2','local_3']: # 'regional'\n",
    "        for ft_in in [1,2,3]:\n",
    "#             Q_all, rch_hf_all = load_output(ft_in, region)\n",
    "            Q_all, rch_hf_all, d_all = load_hdf5_output(ft_in, region)\n",
    "\n",
    "            arr_to_h5(Q_all, join(data_dir,'hdf5', 'all_flow_'+region+'_type'+str(ft_in)+'.hdf5'))\n",
    "            arr_to_h5(rch_hf_all, join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'))\n",
    "            arr_to_h5(d_all, join(data_dir,'hdf5', 'all_depth_'+region+'_type'+str(ft_in)+'.hdf5'))\n",
    "\n",
    "else:\n",
    "    print('Reusing existing recharge and flow hdf5 files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bbe1f2",
   "metadata": {},
   "source": [
    "## Calculate depth\n",
    "Depth is not directly saved as an output file, but can be calculated using the rating curve tables. This can be saved as an hdf file as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f209949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating curves for each segment and setback\n",
    "xs_flow_all = pd.read_csv(join(chan_dir,'all_xs_50pt_rating_curves.csv'))\n",
    "\n",
    "def depth_match(seg_flow, flow):\n",
    "    \"\"\" Given a XS (nseg, setback) return the expected depth (m) given a flow (cms)\"\"\"\n",
    "    # find flows above and below the input flow\n",
    "    flow_diff = (seg_flow.flow_cms-flow)\n",
    "    f_high = flow_diff[flow_diff>0].argsort().index[0]\n",
    "    f_low = flow_diff[flow_diff<0].argsort().index[-1]\n",
    "    match_d = seg_flow.loc[[f_low, f_high]].sort_values('flow_cms')\n",
    "    # linearly interpolate to calculate exact depth\n",
    "    flow_slope = (match_d.iloc[1].flow_cms-match_d.iloc[0].flow_cms)/(match_d.iloc[1].depth_m-match_d.iloc[0].depth_m)\n",
    "    out_depth = match_d.iloc[0].depth_m + (flow-match_d.iloc[0].flow_cms)/flow_slope\n",
    "    return(out_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_arr = np.zeros(Q_all.shape)\n",
    "\n",
    "# for s, setback in enumerate(setbacks):\n",
    "r=0\n",
    "s=5\n",
    "setback=1000\n",
    "t = tp_in\n",
    "for nseg in np.arange(0,num_segs):\n",
    "    seg_flow = xs_flow_all[(xs_flow_all.nseg==nseg)&(xs_flow_all.setback==setback)]\n",
    "    if Q_all[r,t, s, nseg] >=seg_flow.flow_cms.min():\n",
    "        d_arr[r,t, s, nseg] = depth_match(seg_flow, flow=Q_all[r,t, s, nseg])\n",
    "    else:\n",
    "        d_arr[r,t, s, nseg] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c53aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this method is slightly different than the depth from the output because here\n",
    "# the depth from the XS is given vs the depth above the raster\n",
    "# this method which back calculates the depth given the flow\n",
    "# returns the maximum depth for each segment which is what fish would likely have access to??\n",
    "if recreate_hdf5:\n",
    "    t0 = time.time()\n",
    "    region = 'regional'\n",
    "    for ft_in in [1,2,3]:\n",
    "        f = h5py.File(join(data_dir,'hdf5', 'all_flow_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "        Q_all = f['array']['all'][:]\n",
    "        f.close()\n",
    "        d_arr = np.zeros(Q_all.shape)\n",
    "        # iterate over realizations\n",
    "        for r in np.arange(Q_all.shape[0]):\n",
    "            # days of flow\n",
    "            for t in np.arange(0, Q_all.shape[1]):\n",
    "                # setbacks\n",
    "                for s, setback in enumerate(setbacks):\n",
    "                    # segments\n",
    "                    for nseg in np.arange(0,num_segs):\n",
    "                        seg_flow = xs_flow_all[(xs_flow_all.nseg==nseg)&(xs_flow_all.setback==setback)]\n",
    "                        if Q_all[r,t, s, nseg] >=seg_flow.flow_cms.min():\n",
    "                            d_arr[r,t, s, nseg] = depth_match(seg_flow, flow=Q_all[r,t, s, nseg])\n",
    "                        else:\n",
    "                            d_arr[r,t, s, nseg] = 0\n",
    "        # save to hdf5 file for each flow type\n",
    "        arr_to_h5(d_arr, join(data_dir,'hdf5', 'peak_flow_xs_depth_'+region+'_type'+str(ft_in)+'.hdf5'))\n",
    "\n",
    "    # output will be all depths\n",
    "    t1 = time.time()\n",
    "    # 6.7 seconds for 1 realization, ~10 min for 100 x 3 flood types is ~30 min\n",
    "    # the shortest flow type probably only took 10 min, the others are like 5-10x longer\n",
    "    # seems to take longer than 30 min because it took 2 hrs in total\n",
    "    print((t1-t0)/60)\n",
    "else:\n",
    "    print('Reusing existing recharge and flow hdf5 files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774de766",
   "metadata": {},
   "source": [
    "# Load joint array data back in\n",
    "Now each file can be reloading easily by specifying region and flow type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc492298",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_plt = [1,2,3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2dde0f",
   "metadata": {},
   "source": [
    "## Check fo setback distances/realizations that violate the minimum in-stream flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e1fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "region='regional'\n",
    "ft_in=2\n",
    "f = h5py.File(join(data_dir,'hdf5', 'all_flow_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "Q_all = f['array']['all'][:]\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum in-stream flow is 180 cfs generally, it is slightly higher as one goes up stream as it is dependent\n",
    "# on depth (1 foot for adults, 6 inches for juveniles)\n",
    "min_flw = 180*(0.3048**3)\n",
    "# find if the output discharge violates the minimum flow at any day in a flow event\n",
    "# for segments if any segment is violated then there is an issue\n",
    "# might need to consider the number of segments and days that are an issue\n",
    "# report by realization and setback distance\n",
    "min_flw_df = pd.DataFrame(np.transpose(np.where(Q_all < min_flw)), columns=['r','day','setback','seg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7785e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find realizations and setbacks that have any days or segments below the threshold\n",
    "any_min_flw = min_flw_df[['r','setback']].drop_duplicates()\n",
    "# find range of setbacks that generally cause excess flow loss\n",
    "# any_min_flw.hist('r', bins=range(100))\n",
    "any_min_flw.hist('setback', bins=range(17))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416de423",
   "metadata": {},
   "source": [
    "The histogram of realizations that break the minimum flow threshold per setback is helpful to visualize because it shows that by the 8th setback (1600 m) that 30-40% of the time the minimum flow threshold is broken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f9f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to get particular we could count the number of days a segment fails and allow for 1 or 2 perhaps?\n",
    "# but there wouldn't be validation for it except perhaps that research like Kenny's show salmon can survive\n",
    "# in disconnected pulls for a certain period\n",
    "# min_flw_df.groupby(['r','setback','seg']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecac225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax=plt.subplots(4,3, sharex=True, sharey=True, figsize=(8,8))\n",
    "# for nf, ft_in in enumerate(ft_plt):\n",
    "#     for nr, region in enumerate(['local_1','local_2','local_3','regional']):\n",
    "#         ax_n = ax[nr, nf]\n",
    "#         f = h5py.File(join(data_dir,'hdf5', 'all_flow_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "#         Q_all = f['array']['all'][:]\n",
    "#         plt_downstream_loss(Q_all, ft_in, ax=ax_n,setback=5)\n",
    "#         f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4801c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# was using regional and ft_in=2 (large and long) for example plots\n",
    "region = 'regional'\n",
    "ft_in = 2\n",
    "\n",
    "f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "rch_hf_all = f['array']['all'][:]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83bbcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rch_hf_all.shape\n",
    "# if the in-stream flow becomes zero then remove any recharge from that realization to represent it as a null case\n",
    "# as it would not be implemented\n",
    "rch_hf_all_adj = np.copy(rch_hf_all)\n",
    "rch_hf_all_adj[min_flw_df.r, min_flw_df.setback] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a81dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find realization closest to the mean\n",
    "# diff = rch_hf_all.sum(axis=(2,3)) -np.repeat(np.reshape(rch_hf_all.sum(axis=(2,3)).mean(axis=1),(100,1)), 17, axis=1)\n",
    "# diff.mean(axis=1).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c5e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_scale = hf_all.loc['Regional'].multiply(1/hf_all.loc['Regional',0].values, axis=0)\n",
    "# hf_scale.transpose().plot(legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735f81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "stats_elements = [\n",
    "    Line2D([0], [0],color='grey',label='Individual\\nRealization'),\n",
    "#     Line2D([0], [0],color='black',label='5th/95th', linestyle='--'),\n",
    "    Line2D([0], [0],color='black',label='1.5x Quartile\\nRange'),\n",
    "    Line2D([0], [0],color='tab:blue',label='25th/75th'),\n",
    "    Line2D([0], [0],color='tab:green',label='Median'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a0715",
   "metadata": {},
   "source": [
    "The box extends from the first quartile (Q1) to the third quartile (Q3) of the data, with a line at the median. \n",
    "The whiskers extend from the box by 1.5x the inter-quartile range (IQR)  \n",
    "whis = 1.5\n",
    "IQR = Q3-Q1\n",
    "upper whisker =  Q3 + whis\\*IQR\n",
    "lower whisker = Q1 - whis\\*IQR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_lines(df, ax):\n",
    "    \"\"\" Dataframe with realization as columns and setbacks as index\"\"\"\n",
    "    # plot quantiles on the line plot\n",
    "    quart = df.quantile([.25,.75], axis=1)\n",
    "    quart.transpose().plot(color='tab:blue', ax=ax, legend=False)\n",
    "    median = df.quantile([.5], axis=1)\n",
    "    median.transpose().plot(color='tab:green', ax=ax, legend=False)\n",
    "    # calculate whiskers\n",
    "    iqr = quart.loc[0.75]-quart.loc[0.25]\n",
    "    # 1.5 x the whole interquartile range\n",
    "    whisker = pd.DataFrame(quart.loc[0.75] + iqr*1.5)\n",
    "    whisker[1] = quart.loc[0.25] - iqr*1.5\n",
    "    # where whisker is greater than max or min set as max or min\n",
    "    whisker.loc[whisker[0]>df.max(axis=1), 0] = df.max(axis=1)[whisker[0]>df.max(axis=1)]\n",
    "    whisker.loc[whisker[1]<df.min(axis=1), 1] = df.min(axis=1)[whisker[1]<df.min(axis=1)]\n",
    "    whisker.plot(color='black', ax=ax, legend=False)\n",
    "#     quant = df.quantile([.05,.95], axis=1)\n",
    "#     quant.transpose().plot(color='black', ax=ax, legend=False, linestyle='--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rch_xs_sum = pd.DataFrame(np.sum(rch_hf_all, axis=(2,3)), columns= setbacks).transpose()/1E6\n",
    "# rch_xs_sum.multiply(1/rch_xs_sum.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a9a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rch_hf_all resembles the recharge rate for each flow at each setback (including all cells to the stream) for the grid\n",
    "# so the plot here is the recharge total recharge between the setbacks\n",
    "# total area within each setback\n",
    "setback_area = str_setbacks.sum(axis=(1,2))*200*200\n",
    "\n",
    "def plt_setback_recharge(rch_hf_all, ax):\n",
    "    # convert from \n",
    "    rch_xs_sum = pd.DataFrame(np.sum(rch_hf_all, axis=(2,3)), columns= setbacks).transpose()/1E6\n",
    "    # scale recharge by the area within the setback to create a benefit-cost ratio\n",
    "#     rch_xs_sum = rch_xs_sum.multiply(1/setback_area, axis=0)\n",
    "\n",
    "    rch_xs_sum.plot(legend=False, color='lightgray', ax =ax)\n",
    "    \n",
    "    rch_xs_sum_mean = pd.DataFrame(rch_xs_sum.mean(axis=1),columns=['mean'])\n",
    "#     rch_xs_sum_mean.plot(color='black', ax=ax, legend=False)\n",
    "\n",
    "    ax.set_xticks(rch_xs_sum.index[::4])\n",
    "    stats_lines(rch_xs_sum, ax)\n",
    "    return(rch_xs_sum_mean)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,2), dpi=300)\n",
    "rch_xs_sum_mean = plt_setback_recharge(rch_hf_all, ax=ax)\n",
    "# rch_xs_sum_mean = plt_setback_recharge(rch_hf_all_adj, ax=ax)\n",
    "ax.set_xlabel('Setback Distance (m)')\n",
    "ax.set_ylabel('Total Recharge ($10^6$ $m^3$)')\n",
    "fig.legend(handles=stats_elements, loc= 'outside upper left', ncol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "region='regional'\n",
    "rch_mean_all = pd.DataFrame()\n",
    "fig,ax=plt.subplots(3,1, sharex='col', sharey=False, figsize=(6.5,4), dpi=300)\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "        ax_n = ax[nf]\n",
    "        f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "        rch_hf_all = f['array']['all'][:]\n",
    "        f.close()\n",
    "        rch_xs_sum_mean = plt_setback_recharge(rch_hf_all, ax=ax_n)\n",
    "        # second plot for boxplot\n",
    "#         ax_n = ax[nf, 1]\n",
    "#         rch_xs_sum = pd.DataFrame(np.sum(rch_hf_all, axis=(2,3)), columns= setbacks).transpose()/1E6\n",
    "#         rch_xs_sum.transpose().boxplot(ax=ax_n)\n",
    "\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    ax_n = ax[nf]\n",
    "#     ax_n.set_xlabel('Setback Distance (m)')\n",
    "    ax_n.annotate('Type '+str(ft_in),xy=(0.1,0.8),xycoords='axes fraction')\n",
    "    ax_n.set_xticks(rch_xs_sum_mean.index)\n",
    "    ax_n.set_xticks([], minor=True)\n",
    "    rot_ticks =  plt.setp(ax_n.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# set x labels for boxplots \n",
    "# ax_n = ax[-1,1]\n",
    "# rot_ticks =  plt.setp(ax_n.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "fig.supylabel('Total Recharge (MCM)')#, x=-0.01)\n",
    "# plt.ylabel('Total Recharge ($10^6$ $m^3$)')\n",
    "fig.supxlabel('Setback Distance (m)')#,y=-0.04)\n",
    "# ax[0].set\n",
    "\n",
    "lgd = fig.legend(handles=stats_elements,  loc='center left', bbox_to_anchor=(0.13, 1.02),ncol=4)#loc= 'outside upper center',\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.legend(handles=stats_elements,  loc='upper center', ncol=4)#loc= 'outside upper center',\n",
    "\n",
    "fig.savefig(join(fig_dir, 'all_recharge_no_boxplot.png'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db44bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "region='regional'\n",
    "rch_mean_all = pd.DataFrame()\n",
    "fig,ax=plt.subplots(3,2, sharex='col', sharey=True, figsize=(6.5,4), dpi=300)\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "        ax_n = ax[nf,0]\n",
    "        f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "        rch_hf_all = f['array']['all'][:]\n",
    "        f.close()\n",
    "        rch_xs_sum_mean = plt_setback_recharge(rch_hf_all, ax=ax_n)\n",
    "        # second plot for boxplot\n",
    "        ax_n = ax[nf, 1]\n",
    "        rch_xs_sum = pd.DataFrame(np.sum(rch_hf_all, axis=(2,3)), columns= setbacks).transpose()/1E6\n",
    "        rch_xs_sum.transpose().boxplot(ax=ax_n)\n",
    "\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    ax_n = ax[nf,0]\n",
    "#     ax_n.set_xlabel('Setback Distance (m)')\n",
    "    ax_n.annotate('Type '+str(ft_in),xy=(0.1,0.8),xycoords='axes fraction')\n",
    "    ax_n.set_xticks(rch_xs_sum_mean.index)\n",
    "    ax_n.set_xticks([], minor=True)\n",
    "    rot_ticks =  plt.setp(ax_n.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# set x labels for boxplots \n",
    "ax_n = ax[-1,1]\n",
    "rot_ticks =  plt.setp(ax_n.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "fig.supylabel('Total Recharge (MCM)')#, x=-0.01)\n",
    "# plt.ylabel('Total Recharge ($10^6$ $m^3$)')\n",
    "fig.supxlabel('Setback Distance (m)')#,y=-0.04)\n",
    "# ax[0].set\n",
    "\n",
    "\n",
    "# fig.legend(handles=stats_elements,  loc='upper center', ncol=4)#loc= 'outside upper center',\n",
    "# lgd = fig.legend(handles=stats_elements,  loc=(0.15, .925), ncol=4, mode='horizontal')\n",
    "# solution was bbox_to_anchor\n",
    "lgd = fig.legend(handles=stats_elements,  loc='center left', bbox_to_anchor=(0.13, 1.02),ncol=4)\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.legend(handles=stats_elements,  loc='upper center', ncol=4)#loc= 'outside upper center',\n",
    "\n",
    "fig.savefig(join(fig_dir, 'all_recharge.png'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe046a02",
   "metadata": {},
   "source": [
    "When plotting the recharge as just the number of cells there are less situations where there is a negative slope. I'm not certain, but I must imagine that negative slopes must occur when additional setback opens up upstream recharge that lowers the depth for downstream recharge. Or what might be happening is that when the cross-section is expanded there can be side channel that develop which become the new thalweg so the cells being activated might be confined to a stream cell away from the original main channel and then as you open up the cross-section further there might be additional spots that are accessed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1932af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to resolve why there is a peak between the 1200 - 2000 m range\n",
    "# is it because those setbacks are ideal for inundating certain area or because flood depth varies\n",
    "# is there potentially an issue with the calculation somewhere?\n",
    "# nrow, ncol=(2,2)\n",
    "\n",
    "# fig,ax = plt.subplots(nrow, ncol, figsize=(8,8), sharex=True, sharey=True)\n",
    "\n",
    "# for n, s in enumerate(np.arange(1,17,4)):\n",
    "#     ax_n = ax[int(n/nrow), n%ncol]\n",
    "#     ax_n.imshow(rch_hf_all[30,n], norm = mpl.colors.LogNorm())\n",
    "#     ax_n.set_xlim(50,150)\n",
    "#     ax_n.set_ylim(20,60)\n",
    "#     ax_n.set_title(setbacks[s])\n",
    "# # fig.subplots_adjust(hspace=0)                                                                                  \n",
    "# fig.tight_layout(pad=0.1, w_pad=0.1, h_pad=-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ef619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rch_mean_all = pd.DataFrame()\n",
    "# ft_plt = [1,2,3] #[2,3]\n",
    "# # fig,ax=plt.subplots(4,3, sharex=True, sharey=True, figsize=(8,8)) \n",
    "# fig,ax=plt.subplots(1,3, sharex=True, sharey=True, figsize=(6.5,2), dpi=300)\n",
    "# for nf, ft_in in enumerate(ft_plt):\n",
    "# #     for nr, region in enumerate(['local_1','local_2','local_3','regional']):\n",
    "#     for nr, region in enumerate(['regional']):\n",
    "# #         ax_n = ax[nr, nf]\n",
    "#         ax_n = ax[nf]\n",
    "#         f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "#         rch_hf_all = f['array']['all'][:]\n",
    "#         f.close()\n",
    "#         rch_xs_sum_mean = plt_setback_recharge(rch_hf_all, ax=ax_n)\n",
    "#         rch_xs_sum_mean['region']=region\n",
    "#         rch_xs_sum_mean['ft'] = ft_in\n",
    "#         rch_mean_all = pd.concat((rch_mean_all,rch_xs_sum_mean))\n",
    "# region_names=['Lower','Middle','Upper','Regional']        \n",
    "# # for nr, region in enumerate(['local_1','local_2','local_3','regional']):\n",
    "# #     ax[nr,0].set_ylabel(region_names[nr])\n",
    "# for nf, ft_in in enumerate(ft_plt):\n",
    "# #     ax_n = ax[nr, nf]\n",
    "#     ax_n = ax[nf]\n",
    "#     ax_n.set_xlabel('Setback Distance (m)')\n",
    "#     ax_n.set_title('Type '+str(ft_in))\n",
    "#     rot_ticks =  plt.setp(ax_n.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# fig.supylabel('Total Recharge ($10^6$ $m^3$)')\n",
    "# # fig.supxlabel('Setback Distance (m)')\n",
    "# # ax[0].set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaae815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad1_df = pd.DataFrame(np.gradient(smooth)[1], columns = np.arange(0,3400,200))\n",
    "\n",
    "# # grad1_df.iloc[:,1:].multiply(1/setbacks[1:], axis=1).transpose().plot(legend=False,color='lightgray')\n",
    "# # grad1_df.iloc[:,1:].multiply(1/setbacks[1:], axis=1).transpose().mean(axis=1).plot(color='black')\n",
    "# smooth.diff(axis=1).iloc[:,1:].multiply(1/setbacks[1:], axis=1).transpose().plot(legend=False,color='lightgray')\n",
    "# smooth.diff(axis=1).iloc[:,1:].multiply(1/setbacks[1:], axis=1).transpose().mean(axis=1).plot(color='black')\n",
    "\n",
    "# plt.xticks(setbacks[1::2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a650d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # np.sign gives + or -, np diff gives out[i] = a[i+1] - a[i]. \n",
    "# # + to - means max of 1st derivative. So diff ==-2 means max, but to account for difference go up one indice\n",
    "# def plt_max_gradient(rch_hf_all, ax):\n",
    "#     rch_xs_sum = pd.DataFrame(np.sum(rch_hf_all, axis=(2,3)), columns= setbacks).transpose()/1E6\n",
    "#     # smooth across setback distances so the changes in high flow area are less abrupt, makes it easier to find gradients\n",
    "#     smooth = gaussian_filter1d(rch_xs_sum,2, axis=0)\n",
    "#     smooth = pd.DataFrame(smooth, index= setbacks)\n",
    "#     # tranpose to fit format for gradient analysis used previously\n",
    "#     smooth = smooth.transpose()\n",
    "#     r_out = np.arange(0,100)\n",
    "#     # can look at maximum of first derivative, or look where second derivative goes from + to -\n",
    "#     grad1_df = pd.DataFrame(np.gradient(smooth)[1],  columns = setbacks)\n",
    "#     grad2_df = pd.DataFrame(np.gradient(grad1_df)[1],  columns = setbacks)\n",
    "#     # plot difference\n",
    "#     max_df = pd.DataFrame(np.diff(np.sign(grad2_df)), columns = setbacks[1:])\n",
    "#     max_df = 1*(max_df==-2)\n",
    "#     # calculate the number of peak gradients per setback\n",
    "#     max_df = pd.DataFrame(max_df.loc[r_out].transpose().sum(axis=1), columns=['count'])\n",
    "#     max_df.plot(kind='bar', legend=False, ax=ax, color='lightgray') #.loc[n]\n",
    "# #     ax.set_xticks(max_df.loc[r_out].transpose().index[::2].astype(str))\n",
    "#     return(max_df)\n",
    "\n",
    "# fig,ax = plt.subplots(figsize=(6,3), dpi=300)\n",
    "# f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+'regional'+'_type'+str(2)+'.hdf5'), \"r\")\n",
    "# rch_hf_all = f['array']['all'][:]\n",
    "# f.close()\n",
    "# max_df = plt_max_gradient(rch_hf_all, ax=ax)    \n",
    "# plt.ylabel('Maximum gradient count\\n by realization')\n",
    "# plt.xlabel('Setback distance (m)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c22c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "region='regional'\n",
    "ft_in=2\n",
    "f = h5py.File(join(data_dir,'hdf5', 'all_flow_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "Q_all = f['array']['all'][:]\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dac14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t=0\n",
    "\n",
    "def plt_downstream_loss(Q_all, ft_in, ax, setback = -1):\n",
    "    T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "    p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "    tp_in = int(p_l_in*T_in)\n",
    "    # plot segments in reverse order to align with idea that upstream is east and downstream is west\n",
    "    Q_plt = pd.DataFrame(Q_all[:,tp_in,setback,:], columns = np.arange(28*2, -2, -2)).transpose()\n",
    "    Q_plt.plot(color='lightgray', legend=False, ax=ax)\n",
    "    # plot min, max\n",
    "#     Q_plt.loc[:,Q_plt.mean(axis=0).isin(Q_plt.mean(axis=0).quantile([0, 1]).values)].plot(legend=False, color='red', ax=ax)\n",
    "\n",
    "#     Q_plt.mean(axis=1).plot(color='black', label='Averaged Realizations', ax=ax)\n",
    "\n",
    "    # plot quantiles on the line plot\n",
    "#     quart = Q_plt.quantile([.25,.75], axis=1)\n",
    "#     quart.transpose().plot(color='tab:blue', ax=ax, legend=False)\n",
    "#     median = Q_plt.quantile([.5], axis=1)\n",
    "#     median.transpose().plot(color='tab:green', ax=ax, legend=False)\n",
    "#     whisker = (quart-median.values)*1.5 + median.values\n",
    "#     whisker.transpose().plot(color='black', ax=ax, legend=False)\n",
    "#     quant = Q_plt.quantile([.05,.95], axis=1)\n",
    "#     quant.transpose().plot(color='black', ax=ax, legend=False, linestyle='--')\n",
    "    stats_lines(Q_plt, ax=ax)\n",
    "    return(Q_plt)\n",
    "fig,ax = plt.subplots(figsize=(6,3), dpi=300)\n",
    "Q_plt = plt_downstream_loss(Q_all, ft_in, ax=ax, setback=5)\n",
    "plt.xlabel('Distance upstream (km)')\n",
    "plt.ylabel('Discharge ($m^3/s$)')\n",
    "\n",
    "ax.legend(handles=stats_elements,  loc='center right', ncol=1)#loc= 'outside upper center',\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dcfd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax_n = plt.subplots()\n",
    "# Q_all[0 ,:,-1,0]\n",
    "# # calculate XS recharge \n",
    "# Q_diff = np.diff(Q_all, axis=-1)\n",
    "# # add zero recharge for upstream first XS\n",
    "# Q_diff = np.append(np.zeros(np.append(Q_all.shape[:3],1)), Q_diff, axis=3)\n",
    "# Q_diff_plt = plt_downstream_loss(Q_diff, ft_in, ax=ax_n,setback=5)\n",
    "arr = rch_hf_all[:,5].mean(axis=0)\n",
    "arr = ma.masked_where(arr==0, arr)\n",
    "im = ax_n.imshow(arr)\n",
    "# cbar=plt.colorbar(mappable = im, ax=ax_n,   shrink= 0.7, orientation='horizontal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326be14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_plt = [1,2,3]\n",
    "# downside of spatial plots is I can't share the x-axis\n",
    "fig,ax=plt.subplots(3,3, sharex=False, sharey='row', figsize=(6.5,6.5),dpi=300)\n",
    "region='regional'\n",
    "s = 5\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'all_flow_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    Q_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    ax_d = ax[0, nf]\n",
    "    plt_downstream_loss(Q_all, ft_in, ax=ax_d,setback=5)\n",
    "    plt.setp(ax_d, xticklabels=[])\n",
    "    ax_n = ax[1, nf]\n",
    "    # calculate XS recharge \n",
    "    Q_diff = np.diff(Q_all, axis=-1)\n",
    "    # add zero recharge for upstream first XS\n",
    "    Q_diff = np.append(np.zeros(np.append(Q_all.shape[:3],1)), Q_diff, axis=3)\n",
    "    Q_diff_plt = plt_downstream_loss(Q_diff, ft_in, ax=ax_n,setback=s)\n",
    "    ax_n = ax[2, nf]\n",
    "    # spatial view\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    rch_hf_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    arr = rch_hf_all[:,s].mean(axis=0)\n",
    "    arr = ma.masked_where(arr==0, arr)\n",
    "    im = ax_n.imshow(arr)\n",
    "    \n",
    "    ## calculate the percentage reduction in flow by the downstream ##\n",
    "    # calculate reduction at peak flow for the 1000 m setback\n",
    "    Q_red = Q_all[:,tp_in,s,-1]/Q_all[:,tp_in,s,0]\n",
    "    print('Flow reduction mean %.2f' %((1-Q_red).mean()*100), 'and std dev %.2f'%((1-Q_red).std()*100) )\n",
    "## formatting ##\n",
    "ax[0,0].set_ylabel('Discharge ($m^3/s$)')\n",
    "ax[1,0].set_ylabel('Recharge ($m^3/s$)')\n",
    "ax[2,0].set_ylabel('Spatial Extent\\nof Recharge')\n",
    "# fig.supylabel('Discharge ($m^3/s$)')\n",
    "# fig.supxlabel('River kilometer')\n",
    "ax[1,1].set_xlabel('Distance upstream (m)')\n",
    "\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    ax_n = ax[0, nf]\n",
    "    ax_n.annotate('Type '+str(ft_in),xy=(0.7,0.8),xycoords='axes fraction')\n",
    "\n",
    "# ax[1,2].legend(handles=stats_elements,  loc='lower right', ncol=1)#loc= 'outside upper center',\n",
    "lgd = fig.legend(handles=stats_elements,  loc='center left', bbox_to_anchor=(0.13, 1.02),ncol=4)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(join(fig_dir, 'all_flow.png'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_plt = [1,2,3]\n",
    "# downside of spatial plots is I can't share the x-axis\n",
    "fig,ax=plt.subplots(3,2, sharex=True, sharey=False, figsize=(6.5,6.5),dpi=300)\n",
    "region='regional'\n",
    "s = 5\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'all_flow_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    Q_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    ax_d = ax[nf, 0]\n",
    "    plt_downstream_loss(Q_all, ft_in, ax=ax_d,setback=5)\n",
    "    ax_n = ax[nf, 1]\n",
    "    # calculate XS recharge \n",
    "    Q_diff = np.diff(Q_all, axis=-1)\n",
    "    # add zero recharge for upstream first XS\n",
    "    Q_diff = np.append(np.zeros(np.append(Q_all.shape[:3],1)), Q_diff, axis=3)\n",
    "    Q_diff_plt = plt_downstream_loss(Q_diff, ft_in, ax=ax_n,setback=s)\n",
    "#     ax_n = ax[2, nf]\n",
    "#     # spatial view\n",
    "#     f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "#     rch_hf_all = f['array']['all'][:]\n",
    "#     f.close()\n",
    "#     arr = rch_hf_all[:,s].mean(axis=0)\n",
    "#     arr = ma.masked_where(arr==0, arr)\n",
    "#     im = ax_n.imshow(arr)\n",
    "    \n",
    "    ## calculate the percentage reduction in flow by the downstream ##\n",
    "    # calculate reduction at peak flow for the 1000 m setback\n",
    "    Q_red = Q_all[:,tp_in,s,-1]/Q_all[:,tp_in,s,0]\n",
    "    print('Flow reduction mean %.2f' %((1-Q_red).mean()*100), 'and std dev %.2f'%((1-Q_red).std()*100) )\n",
    "## formatting ##\n",
    "# ax[0,0].set_ylabel('Discharge ($m^3/s$)')\n",
    "# ax[1,0].set_ylabel('Recharge ($m^3/s$)')\n",
    "# ax[2,0].set_ylabel('Spatial Extent\\nof Recharge')\n",
    "# fig.supylabel('Discharge ($m^3/s$)')\n",
    "# fig.supxlabel('River kilometer')\n",
    "ax[-1,0].set_xlabel('Distance upstream (m)')\n",
    "ax[-1,1].set_xlabel('Distance upstream (m)')\n",
    "#     plt.setp(ax_d, xticklabels=[])\n",
    "\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    ax_n = ax[nf,0 ]\n",
    "    ax_n.annotate('Type '+str(ft_in),xy=(0.7,0.8),xycoords='axes fraction')\n",
    "\n",
    "# ax[1,2].legend(handles=stats_elements,  loc='lower right', ncol=1)#loc= 'outside upper center',\n",
    "lgd = fig.legend(handles=stats_elements,  loc='center left', bbox_to_anchor=(0.13, 1.02),ncol=4)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# fig.savefig(join(fig_dir, 'all_flow.png'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5fc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(3,1, sharex=True, sharey=False, figsize=(6.5,6.5),dpi=300)\n",
    "region='regional'\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    ax_n = ax[nf]\n",
    "    # spatial view\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    rch_hf_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    arr = rch_hf_all[:,s].mean(axis=0)\n",
    "    arr = ma.masked_where(arr==0, arr)\n",
    "    im = ax_n.imshow(arr)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f50ebcf",
   "metadata": {},
   "source": [
    "# Summary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43051fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_in = 2\n",
    "\n",
    "T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "tp_in = int(p_l_in*T_in)\n",
    "# for each setback distance and flood type\n",
    "# prsent discharge at the downstream end (avg over realizations and use peak flow)\n",
    "q_avg = Q_all[:,tp_in,s,-1].mean().round(1)\n",
    "q_std = Q_all[:,tp_in,s,-1].std().round(1)\n",
    "q_out = str(q_avg)+'±'+ str(q_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ae460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_mean(df):\n",
    "    df_avg = df.mean().round(1)\n",
    "    df_std = df.std().round(1)\n",
    "#     df_out = str(df_avg)+'±'+ str(df_std)\n",
    "    df_out = str(df_avg)+'\\u00B1'+ str(df_std)\n",
    "    return(df_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e50e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_in=1\n",
    "f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "rch_hf_all = f['array']['all'][:]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa721b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s=2\n",
    "# present mean total recharge and std dev\n",
    "rch_sum = rch_hf_all[:,s].sum(axis=(1,2))/1E6\n",
    "format_mean(rch_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf8c7a",
   "metadata": {},
   "source": [
    "With the +- symbol saving to csv file causes an issue with utf-8 encoding of the csv and adds a symbol. Saving it as a text file doesn't cause an issue and the data can then be pasted into an xlsx to format for the paper. The txt file also writes the fastest.  \n",
    "The flow differencing has same standard deviation as discharge because it comes from the same data, and it only shows the inverse.  \n",
    "Flow depth can be back calculated with the discharge saved. Depth might not be a good parameter to plot because there is a big range in cross-section type, although the key reason for depth is to suggest if flow is to shallow rather than too deep so perhaps presenting mean and minimum depth is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a345b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_mean(d_all[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75966b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_csv = open(join(fig_dir, 'summary_table.txt'), 'w', encoding=\"utf-8\")\n",
    "region='regional'\n",
    "\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "#     for nr, region in enumerate(['local_1','local_2','local_3','regional']):\n",
    "#     max_df = max_df_all.loc[(max_df_all.region==region)&(max_df_all.ft==ft_in),'count']\n",
    "#     max_s = max_df.argmax()\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'all_flow_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    Q_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    # recharge\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    rch_hf_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'peak_flow_xs_depth_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    d_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "    p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "    tp_in = int(p_l_in*T_in)\n",
    "#     Q_s = Q_all[:,tp_in, max_s,:].mean(axis=0)\n",
    "#     d_Q_s = Q_s[0]-Q_s[-1]\n",
    "    ## output cleaning ##\n",
    "    for s in np.arange(0,len(setbacks)):\n",
    "    #     rch_mean =  rch_mean_all.loc[(rch_mean_all.region==region)&(rch_mean_all.ft==ft_in),'mean']\n",
    "        q_out = format_mean(Q_all[:,tp_in,s,-1])\n",
    "        rch_out = format_mean(rch_hf_all[:,s].sum(axis=(1,2))/1E6)\n",
    "#         d = d_all[:,tp_in, s, :-1]\n",
    "#         d_out = str(d.mean().round(2))+' ('+ str(d.min().round(2))+'-'+ str(d.max().round(2))+')'\n",
    "        # the min, max, and mean should be taken across the segments then averaged across realizations\n",
    "        d_mean = d_all[:,tp_in, s, :-1].mean(axis=1).mean()\n",
    "        d_min = d_all[:,tp_in, s, :-1].min(axis=1).mean()\n",
    "        d_max = d_all[:,tp_in, s, :-1].max(axis=1).mean()\n",
    "        d_out = str(d_mean.round(2))+' ('+ str(d_min.round(2))+'-'+ str(d_max.round(2))+')'\n",
    "        # summarize optimal setback distance with mean recharge and mean flow reduction\n",
    "        out = ','.join([flood_type.loc[ft_in,'Typology'],\n",
    "              str(setbacks[s]),  rch_out,\n",
    "          q_out, d_out, '\\n'])\n",
    "        f_csv.write(out)\n",
    "#         print( flood_type.loc[ft_in,'Typology'], region_names[nr],\n",
    "#               setbacks[max_s], '%.0f' %rch_mean.iloc[max_s],'%.0f' %d_Q_s)\n",
    "\n",
    "f_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de7971",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd796101",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in np.arange(0,len(setbacks)):\n",
    "\n",
    "    d_mean = d_all[:,tp_in, s, :-1].mean(axis=1).mean()\n",
    "    d_min = d_all[:,tp_in, s, :-1].min(axis=1).mean()\n",
    "    d_max = d_all[:,tp_in, s, :-1].max(axis=1).mean()\n",
    "    print('Mean %.2f'%d_mean,'min %.2f'%d_min,'max %.2f'%d_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbb2d93",
   "metadata": {},
   "source": [
    "First iteration of vertical recharge from floodplain inundation. Read in output from manning's equation depths estimated previously and use to calculate vertical hydraulic gradient. Assume recharge causes negligible flow losses such that no iterative calculation of flow to depth for the downstream segment is needed. Vertical conductivity is estimated with the 2m of TPROGs data below ground surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b08589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "from os.path import basename, dirname, exists, join\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import time\n",
    "\n",
    "# standard python plotting utilities\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import pyproj # for converting proj4string\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# mapping utilities\n",
    "import contextily as ctx\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eef4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "    \n",
    "git_dir = join(doc_dir,'GitHub','CosumnesRiverRecharge')\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = join(dirname(doc_dir),'Box/research_cosumnes/GWFlowModel')\n",
    "\n",
    "def add_path(fxn_dir):\n",
    "    if fxn_dir not in sys.path:\n",
    "        sys.path.append(fxn_dir)\n",
    "        \n",
    "flopy_dir = doc_dir+'/GitHub/flopy'\n",
    "if flopy_dir not in sys.path:\n",
    "    sys.path.insert(0, flopy_dir)\n",
    "\n",
    "import flopy \n",
    "import flopy.utils.binaryfile as bf\n",
    "\n",
    "add_path(doc_dir+'/GitHub/CosumnesRiverRecharge/tprogs_utilities')\n",
    "add_path(doc_dir+'/GitHub/CosumnesRiverRecharge/python_utilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f477452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set box directory for output figures and data\n",
    "box_dir = gwfm_dir+'/Levee_setback/levee_setback_distance_analysis/'\n",
    "\n",
    "# tprogs_id = '' # original tprogs with conditioning data in output tsim\n",
    "tprogs_id = '_no_conditioning'\n",
    "\n",
    "data_dir = box_dir+ tprogs_id+'/data_output/'\n",
    "fig_dir = box_dir+tprogs_id+'/figures/'\n",
    "\n",
    "chan_dir = box_dir+'channel_data/'\n",
    "gis_dir = chan_dir+'GIS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14abec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dir = 'F:/WRDAPP'\n",
    "c_dir = 'C:/WRDAPP'\n",
    "\n",
    "if os.path.exists(ext_dir):\n",
    "    loadpth = ext_dir \n",
    "elif os.path.exists(c_dir):\n",
    "    loadpth = c_dir \n",
    "\n",
    "loadpth = loadpth +'/GWFlowModel/Cosumnes/levee_setback/setback_distance_analysis/'\n",
    "model_ws = loadpth+'Permeameter_for_velocity' + tprogs_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a800c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'MF.nam'\n",
    "# name = 'MF_child.nam'\n",
    "# m = flopy.modflow.Modflow.load(name, model_ws=model_ws, \n",
    "#                                 exe_name='mf2005', version='mf2005')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec671fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nrow = m.dis.nrow\n",
    "# nlay = m.dis.nlay\n",
    "# ncol = m.dis.ncol\n",
    "delr, delc =  200, 200\n",
    "\n",
    "nlay, nrow,ncol = 320, 100,230"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6937338-9b5f-4a53-8c9e-d93e1e211b3b",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adbe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_sfr = gpd.read_file(gwfm_dir+'/SFR_data/final_grid_sfr/grid_sfr.shp')\n",
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n",
    "\n",
    "m_domain = gpd.read_file(gwfm_dir+'/DIS_data/NewModelDomain/GWModelDomain_52_9deg_UTM10N_WGS84.shp')\n",
    "grid_sfr = gpd.read_file(gwfm_dir+'/SFR_data/final_grid_sfr/grid_sfr.shp')\n",
    "# load sacramento river, creeks\n",
    "rivers = gpd.read_file(gwfm_dir+'/SFR_data/Sac_valley_rivers/Sac_valley_rivers.shp')\n",
    "cr = gpd.overlay(rivers.loc[rivers.GNIS_Name=='Cosumnes River'].to_crs('epsg:32610'), m_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae9aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(join(chan_dir, 'setback_locs.hdf5'), \"r\")\n",
    "local_str_setbacks = f['setbacks']['local'][:]\n",
    "str_setbacks = f['setbacks']['regional'][:]\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64552fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of XS\n",
    "xs_all = pd.read_csv(chan_dir+'/XS_point_elevations.csv',index_col=0)\n",
    "# cross-sections smoothed in the center at 2km distance\n",
    "xs_levee_smooth = pd.read_csv(chan_dir+'xs_levee_smooth.csv', index_col='dist_from_right_m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f592ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothed cross-section at every 200 m\n",
    "xs_levee_smooth200 = pd.read_csv(chan_dir+'xs_levee_smooth_subsegments.csv', index_col='dist_from_right_m')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e87dcef-5901-40a9-a914-32950be0fa62",
   "metadata": {},
   "source": [
    "# Identify XS to grid cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf46d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_gdf = gpd.GeoDataFrame(xs_all, geometry = gpd.points_from_xy(xs_all.Easting, xs_all.Northing), crs='epsg:32610')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "transg = gpd.read_file(gis_dir+'/transect_lines.shp')\n",
    "def transect2arr(transg, grid_p):\n",
    "    \"\"\"\n",
    "    Given transects (transg : geodataframe of polylines) identify the corresponding\n",
    "    model grid cells (grid_p:geodataframe of polygons) to create an array mapping XS number\n",
    "    \"\"\"\n",
    "    transg_box = transg.copy()\n",
    "    # upstream buffer only, seepage connects upstream to downstream cross-section\n",
    "    transg_box['geometry'] = transg_box.buffer(-3000, single_sided=True)\n",
    "\n",
    "    # overlay transect with grid to identify XS number for each row, col\n",
    "    grid_xs = gpd.sjoin(grid_p, transg_box)\n",
    "    # dissolve and find minimum assuming upstream reach is already covered by previous XS\n",
    "    grid_xs = grid_xs.dissolve('node','min')\n",
    "    # map XS number to an array for identifying which recharge goes to which XS number\n",
    "    xs_arr = np.full((nrow, ncol), np.NaN)\n",
    "    xs_arr[grid_xs.row-1, grid_xs.column-1] = grid_xs.line\n",
    "    return(xs_arr)\n",
    "\n",
    "xs_arr = transect2arr(transg, grid_p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6ffed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xs_arr)\n",
    "# np.savetxt(chan_dir+'XS_num_grid_reference.tsv', xs_arr, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e0d645-02e8-4303-a4c2-037d66cda065",
   "metadata": {},
   "source": [
    "# Calculate the XS minimum elevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transg200 = gpd.read_file(gis_dir+'/transect_lines_subsegments.shp')\n",
    "\n",
    "xs_arr200 = transect2arr(transg200, grid_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = gpd.read_file(gwfm_dir+'/DIS_data/grid_elevation_m_statistics.shp')\n",
    "# columns with different quantiles 0 to 100% of elevation\n",
    "q_cols = zs.columns[zs.columns.str.contains('perc')]\n",
    "df_elevs = zs[q_cols]\n",
    "\n",
    "# convert quantile dataframe to a 3D array\n",
    "arr_elev = np.zeros((df_elevs.shape[1], zs.row.max(),zs.column.max()))\n",
    "for n in np.arange(0,df_elevs.shape[1]):\n",
    "    arr_elev[n, zs.row-1, zs.column-1] = df_elevs.iloc[:,n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_min = arr_elev[-1,grid_sfr.row.values.astype(int)-1, grid_sfr.column.values.astype(int)-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ecf21",
   "metadata": {},
   "source": [
    "There needs to be a choice between having a linear, continuous water surface or having true ground elevations. Having a linear continuous elevation is a requirement with the kinematic wave when assuming continually downsloping channel and thus the slope being continually sloping. However in reality the cosumnes has an irregular flood elevation due to choke points, velocity changes, etc so it might be acceptable to assume a singular depth applies over irregular elevations with some discontinuities. \n",
    "An intermediate option would be a mostly linear downsloping channel but the bottom elevations after cleaning align closely.\n",
    "\n",
    "An issue with creating a linearly sloping water surface is that when mapping out inundation there are cells that will be consistently inundated if any interpolated stream bed (xs_mins_arr) is above the original minimum (arr_elev 0th percentile).\n",
    "I updated the subsegments minimum to follow this rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ee15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the corresponding minimum segment elevations from the raster sampled minimums\n",
    "arr_elev_mins = np.zeros(len(np.unique(xs_arr200)[:-1]))\n",
    "for n in np.unique(xs_arr200)[:-1].astype(int):\n",
    "    arr_elev_mins[n] = np.min(arr_elev[0,xs_arr200==n])\n",
    "#     print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c2397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearize_xs_min(xs_mins, dline, window=2):\n",
    "    \"\"\" \n",
    "    Clean up the XS minimums (xs_mins:dataframe) so they are always decreasing linearly,\n",
    "    this ensures that the constant depth applied will lead to an approximately linear water surface elevation\n",
    "    dline : distance between XS, used for slope \n",
    "    window : number of upstream or downstream points to use in rolling mean\n",
    "    \"\"\"\n",
    "    # find minimum value in XS related to thalweg\n",
    "    xs = pd.DataFrame(xs_mins, columns=['z_min'])\n",
    "    #roling mean of 2 window centered removes any negative slope (manually tested)\n",
    "    xs['z_min_cln'] = xs.rolling(window, center=False).mean()\n",
    "    # if rolling mean set values greater than 5% above previous value, reset\n",
    "    xs.loc[xs.z_min_cln > xs.z_min*1.01, 'z_min_cln'] =  xs.loc[xs.z_min_cln > xs.z_min*1.01, 'z_min']\n",
    "    xs['z_min_cln'] = xs['z_min_cln'].rolling(window, center=False).mean()\n",
    "\n",
    "    # calculate slope and fill NAs, fill slope with nearby\n",
    "    z_cln_diff = xs.z_min_cln.diff().bfill()\n",
    "    xs['slope'] = z_cln_diff.abs()/dline\n",
    "    # # correct slope less than 1E-4\n",
    "    xs.loc[xs.slope<1E-4,'slope'] = 1E-4\n",
    "    # average out slope\n",
    "    xs.loc[:,'slope'] = xs.loc[:,'slope'].rolling(window*4, center=False).min()\n",
    "    xs.loc[:,'slope'] = xs.loc[:,'slope'].bfill().ffill()\n",
    "\n",
    "    # fill NAs with original values\n",
    "#     xs.loc[xs.z_min_cln.isna(),'z_min_cln'] = xs.loc[xs.z_min_cln.isna(),'z_min']\n",
    "    \n",
    "    for i in xs.index[-2::-1]:\n",
    "    # fill NAs due to rolling mean, with backward filling\n",
    "        if np.isnan(xs.loc[i,'z_min_cln']):\n",
    "            xs.loc[i,'z_min_cln'] = xs.loc[i+1,'z_min_cln'] + xs.loc[i+1,'slope']*dline\n",
    "        \n",
    "#     fix str bot so all is downward sloping\n",
    "    for i in xs.index[:-1]:\n",
    "        if xs.loc[i+1,'z_min_cln'] >= xs.loc[i,'z_min_cln']:\n",
    "            xs.loc[i+1,'z_min_cln'] = xs.loc[i,'z_min_cln'] - xs.loc[i,'slope']*dline\n",
    "\n",
    "    return(xs)\n",
    "xs_mins = np.nanmin(xs_levee_smooth.loc[3100:3300], axis=0)\n",
    "xs = linearize_xs_min(xs_mins, dline=2000, window=2)\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "xs_plt = xs.set_index(np.arange(0,2000*xs.shape[0],2000))\n",
    "# xs_plt.plot(y='z_min',label='Min',ax=ax)\n",
    "# xs_plt.plot(y='z_min_cln',label='Clean',ax=ax)\n",
    "\n",
    "xs_mins = np.nanmin(xs_levee_smooth200.loc[3100:3300], axis=0)\n",
    "xs = linearize_xs_min(xs_mins, dline=200, window=5)\n",
    "\n",
    "xs_plt = xs.set_index(np.arange(0,200*xs.shape[0],200))\n",
    "xs_plt.plot(y='z_min',label='Subseg Min',ax=ax)\n",
    "xs_plt.plot(y='z_min_cln',label='Subseg Clean',ax=ax)\n",
    "\n",
    "# version based on raster minimum samples by grid cell\n",
    "r = linearize_xs_min(arr_elev_mins, dline=200, window=5)\n",
    "r_plt = r.set_index(np.arange(0,200*r.shape[0],200))\n",
    "r_plt.plot(y='z_min',label='Raster Min',ax=ax)\n",
    "r_plt['z_min_adj'] = np.where(r_plt.z_min_cln>r_plt.z_min, r_plt.z_min, r_plt.z_min_cln)\n",
    "r_plt.plot(y='z_min_adj',label='Raster Clean',ax=ax)\n",
    "\n",
    "# ax.plot(np.arange(0,200*sfr_min.shape[0],200), sfr_min, label='Quantile min')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of minimum eleations tied to the cleaning mins above spread out to each subsegment\n",
    "xs_mins_arr200 = np.full((nrow,ncol),np.nan)\n",
    "for n in np.arange(0, len(xs)):\n",
    "#     xs_mins_arr200[xs_arr200==n] = xs.z_min_cln[n] # sampled XS minimum\n",
    "    xs_mins_arr200[xs_arr200==n] = r_plt.z_min_adj.values[n] # sampled grid cell minimum\n",
    "    \n",
    "# np.savetxt(chan_dir+'subsegments_xs_mins.tsv', xs_mins_arr200, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0303fd-f6a6-4a7d-8355-57536a97516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r_plt.z_min_adj.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e9508",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(1,2)\n",
    "ax=axes[0]\n",
    "# transg_box.plot('line', ax=ax)\n",
    "transg.plot(ax=ax,color=\"black\")\n",
    "ax=axes[1]\n",
    "ax.imshow(xs_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f501cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1, sharex=True)\n",
    "fig.tight_layout()\n",
    "for i, Q_cfs in enumerate([22500, 39400, 93000]):\n",
    "    fn = glob.glob(chan_dir+'*depth*'+str(Q_cfs)+'*')[0]\n",
    "    d_arr_in = np.loadtxt(fn, delimiter='\\t')\n",
    "    d_arr = np.reshape(d_arr_in, (len(setbacks), m.dis.nrow, m.dis.ncol))\n",
    "    ax[i].set_title(str(int(Q_cfs*0.3048**3))+' (cms)')\n",
    "    for n in [0, 0.01,0.05, 0.1, 0.2]:\n",
    "        num_cells = (d_arr>n).sum(axis=(1,2))*200*200\n",
    "        ax[i].plot(setbacks, num_cells/1E4, color='gray')\n",
    "    \n",
    "        \n",
    "# plt.legend(title='Flow (cms)')\n",
    "plt.ylabel('Area of inundated \\ncells (hectares)') #$m^2$\n",
    "plt.xlabel('Setback distance (m)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dddfc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(3,1, figsize=(10,6), sharex=True)\n",
    "\n",
    "for n,Q_cfs in enumerate([22500, 39400, 93000]):\n",
    "    ax = axes[n]\n",
    "    fn = glob.glob(chan_dir+'*depth*'+str(Q_cfs)+'*')[0]\n",
    "    d_arr_in = np.loadtxt(fn, delimiter='\\t')\n",
    "    d_arr = np.reshape(d_arr_in, (len(setbacks), m.dis.nrow, m.dis.ncol))\n",
    "    cellsbysetback = (d_arr>0).cumsum(axis=0)\n",
    "    ax.set_title(str(int(Q_cfs*0.3048**3))+' (cms)')\n",
    "\n",
    "    im = ax.imshow(cellsbysetback[-1,:,:])\n",
    "    plt.colorbar(im, shrink=0.9, ax=ax, label='Depth ()')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bffb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_cfs = 22500\n",
    "# Q_cfs = 39400\n",
    "# Q_cfs = 93000\n",
    "\n",
    "fn = glob.glob(box_dir+'depth_arrays/*depth*'+str(Q_cfs)+'*')[0]\n",
    "d_arr_in = np.loadtxt(fn, delimiter='\\t')\n",
    "d_arr = np.reshape(d_arr_in, (len(setbacks), m.dis.nrow, m.dis.ncol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d24db50-71c5-4896-a389-1c846b32fda0",
   "metadata": {},
   "source": [
    "# TPROGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1021d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc_dir,\n",
    "tprogs_fxn_dir = git_dir+'/tprogs_utilities'\n",
    "if tprogs_fxn_dir not in sys.path:\n",
    "    sys.path.append(tprogs_fxn_dir)\n",
    "# sys.path\n",
    "import tprogs_cleaning as tc\n",
    "from tprogs_cleaning import  int_to_param, get_tprogs_for_elev\n",
    "# from importlib import reload\n",
    "# # importlib.reload\n",
    "# reload(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd14bb-a9c6-4691-ad4a-25fa10fba604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ma\n",
    "def tprogs_cut_elev(tprogs_line, dem_data, tprogs_info, **kwargs):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    tprogs_line : output from TPROGs of line data formatted to be converted by setting z then x then y\n",
    "    dem_data : 2D array of elevation data of ground surface above which TPROGs should not be real\n",
    "    rows : number of rows in the TPROGs model\n",
    "    cols : number of columns in the TPROGs model\n",
    "    \"\"\"\n",
    "    rows = kwargs.get('rows', np.where(np.ones(dem_data.shape)==1)[0])\n",
    "    cols = kwargs.get('cols', np.where(np.ones(dem_data.shape)==1)[1])\n",
    "    tprogs_elev = np.copy(np.reshape(tprogs_line,\n",
    "                             (tprogs_info[-1], dem_data.shape[0], dem_data.shape[1])))\n",
    "    # removed since analysis of HCP was not done with flipping of array\n",
    "    # flip tprogs model along z axis to match modflow definition of 0 as top (TPROGS says 0 is bottom)\n",
    "    # tprogs = np.flip(tprogs_elev,axis=0)\n",
    "    # flip along x-axis as tprogs has bottom row as 0 and modflow has top row as 0\n",
    "    # tprogs = np.flip(tprogs_elev,axis=1)\n",
    "    # the bottom layer of the tprogs model is at -80 m amsl and the top layer is 80 m amsl\n",
    "    delz = (tprogs_info[0] - tprogs_info[1])/tprogs_info[2]\n",
    "    for t, k in enumerate(np.arange(tprogs_info[0],tprogs_info[1],-delz)):\n",
    "        tprogs_elev[t,dem_data<k]= np.NaN\n",
    "\n",
    "    masked_tprogs = ma.masked_invalid(tprogs_elev)\n",
    "    return(masked_tprogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b8f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf_tprogs_dir = gwfm_dir+'/UPW_data/tprogs_final/'\n",
    "mf_tprogs_dir = gwfm_dir+'/UPW_data/tprogs_final_no_conditioning/'\n",
    "\n",
    "tprogs_files = glob.glob(mf_tprogs_dir+'*')\n",
    "\n",
    "gel_dir = gwfm_dir+'/UPW_data'\n",
    "# if 'ZonePropertiesInitial.csv' in os.listdir(model_ws):\n",
    "#     print('exists')\n",
    "#     params = pd.read_csv(model_ws+'/ZonePropertiesInitial.csv',index_col='Zone')\n",
    "# else:\n",
    "#     params = pd.read_csv(gel_dir+'/ZonePropertiesInitial.csv',index_col='Zone')\n",
    "#     params.to_csv(model_ws+'/ZonePropertiesInitial.csv')\n",
    "params = pd.read_csv(gel_dir+'/ZonePropertiesInitial.csv',index_col='Zone')\n",
    "\n",
    "# convert from m/s to m/d\n",
    "params['K_m_d'] = params.K_m_s * 86400   \n",
    "soil_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5531897d-1f02-40bd-9a87-d48b63a37c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maples had slightly different params that might be worth testing\n",
    "# lower sand/gravel (360/120 to 60/40 m/day) and much smaller mud (0.5 to 0.006 m/day)\n",
    "params = pd.read_csv(gel_dir+'/ZonePropertiesInitial_Maples.csv',index_col='Zone')\n",
    "soil_name = 'new'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f3c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dem data for cropping above land surface\n",
    "dem_data = np.loadtxt(gwfm_dir+'/DIS_data/dem_52_9_200m_linear.tsv') # original file\n",
    "dem_data_mean = np.loadtxt(gwfm_dir+'/DIS_data/dem_52_9_200m_mean.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d37ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = gpd.read_file(gwfm_dir+'/DIS_data/grid_elevation_m_statistics.shp')\n",
    "# columns with different quantiles 0 to 100% of elevation\n",
    "q_cols = zs.columns[zs.columns.str.contains('perc')]\n",
    "df_elevs = zs[q_cols]\n",
    "\n",
    "# convert quantile dataframe to a 3D array\n",
    "arr_elev = np.zeros((df_elevs.shape[1], zs.row.max(),zs.column.max()))\n",
    "for n in np.arange(0,df_elevs.shape[1]):\n",
    "    arr_elev[n, zs.row-1, zs.column-1] = df_elevs.iloc[:,n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea80b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "\n",
    "tprogs_info = [80, -80, 320]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7629c7f5",
   "metadata": {},
   "source": [
    "The recharge estimates need to be an overlay of the flood depth arrays and teh high flow cell arrays so that we are activating cells known to connect to the deeper aquifer through the permeameter test. This method allows me to avoid running flood recharge scenarios in modflow and tracking recharge volumes to the aquifer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164d517d-c417-48d0-9289-c49f793692d1",
   "metadata": {},
   "source": [
    "**The original work with permeameters used the linear sampling DEM while the new work with Connec3D used the new DEM with mean sampling.**\n",
    "- Most of the differences appear to be in locations where there are hills/more elevation variability. Maybe this didn't have a huge impact?\n",
    "\n",
    "Also if the assumption of the analysis is that flow will route dominantly through the HCP then the soil zone thickness shouldn't matter necessarily.\n",
    "\n",
    "**The mean length in the vertical direction for sand/gravel is ~4 m, we should use this as the top layer thickness because if there is a HCP then likely there are multiple layers so it shouldn't effect the geom_K but the non-HCP coarse cells should see a reduction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d7b2f-d735-4646-b80b-d3ffa756c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(dem_data-dem_data_mean,vmin=-2, vmax=2)\n",
    "# plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafa6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_thick = 4\n",
    "# def prep_soil_K(soil_thick, params, soil_name):\n",
    "soil_K = np.zeros((100,nrow,ncol))\n",
    "# a thicker soil layer reduces recharge\n",
    "# from 1 to 2 to 3 m showed about 30-50% reduction each time\n",
    "# using 2 meters would be more conservative than 1 m\n",
    "m_top = np.full((nrow,ncol), 80)\n",
    "# m_top = m.dis.top\n",
    "# top = dem_data\n",
    "# bot_arr = dem_data - soil_thick\n",
    "# fn = chan_dir+'/tprogs_geomK_'+str(soil_thick)+'m_depth.tsv'\n",
    "\n",
    "top = dem_data_mean\n",
    "bot_arr = dem_data_mean - soil_thick\n",
    "fn = chan_dir+'/tprogs_geomK_'+str(soil_thick)+'m_depth_dem_mean_'+soil_name+'.tsv'\n",
    "\n",
    "# takes about 30 minutes to run through all 100 realizations\n",
    "# since loading tprogs data is the slowest, it would be efficient to pre-process it into hydraulic conductivity arrays\n",
    "if not os.path.exists(fn):\n",
    "    tic_all = time.time()\n",
    "    for t in np.arange(0,100):\n",
    "        tic = time.time()\n",
    "        tprogs_line = np.loadtxt(tprogs_files[t])\n",
    "        masked_tprogs= tprogs_cut_elev(tprogs_line, m_top, tprogs_info)\n",
    "        # these are rates in m/d\n",
    "        K, Sy, Ss= int_to_param(masked_tprogs, params)\n",
    "\n",
    "        soil_tprogs = get_tprogs_for_elev(K, top, bot_arr, tprogs_info)\n",
    "        soil_K[t,:,:] = gmean(soil_tprogs,axis=0) \n",
    "        toc = time.time()\n",
    "        print(t, end=' ')\n",
    "    #     print('Realization', t,'done in %.2f sec' %(toc-tic), end=' ')\n",
    "    toc_all = time.time()\n",
    "    print('\\nTotal time is %.2f minutes' %((toc_all-tic_all)/60))\n",
    "\n",
    "    soil_K_out = np.reshape(soil_K, (100*nrow, ncol))\n",
    "    np.savetxt(fn, soil_K_out, delimiter='\\t')\n",
    "else:\n",
    "    soil_K_out = np.loadtxt(fn, delimiter='\\t')\n",
    "    soil_K = np.reshape(soil_K_out, (100, nrow, ncol))\n",
    "    # return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5b9d8-fa46-446b-8ea1-e31d9a5d8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "# prep_soil_K(4, params, '')\n",
    "# parameters from Maples et al. 2019\n",
    "# prep_soil_K(4, params_new, 'new')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c36b1d0-13a5-4f6c-95fe-fe279560ddc7",
   "metadata": {},
   "source": [
    "# Calculate example recharge\n",
    "Start with pre-calculated depth array so no flow routing downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac744d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elev_to_tprogs_layers(elev, tprogs_top_elev, tprogs_bot_elev, num_lays):\n",
    "    \"\"\"\n",
    "    function to get the tprogs layers based on the given elevation\n",
    "    Example\n",
    "    layer 0 is 80 meters, layer 1 is 79.5 meters, layer -1 is -80 meters\n",
    "    \"\"\"\n",
    "    lay_thick = (tprogs_top_elev - tprogs_bot_elev)/num_lays\n",
    "    elev_round = np.round((elev) * (1/lay_thick)) / (1/lay_thick) # dem rounded to the layer thickness\n",
    "    elev_round[elev_round >= tprogs_top_elev] = tprogs_top_elev# any elevation above the top is set to the top\n",
    "    # subtract the calculated row from top elev divided by layer thickness to get to index 0 at top and index 320 and bottom\n",
    "    elev_indices = tprogs_top_elev/lay_thick - elev_round*(1/lay_thick) \n",
    "    return(elev_indices.astype(int))\n",
    "\n",
    "# tprogs_cleaning.get_tprogs_for_elev(dem_data)\n",
    "tprogs_lay = elev_to_tprogs_layers(elev=dem_data,tprogs_top_elev=80, tprogs_bot_elev=-80, num_lays=320)\n",
    "# elev_to_tprogs_layers?\n",
    "rows = np.where(np.ones(tprogs_lay.shape)==1)[0]\n",
    "cols = np.where(np.ones(tprogs_lay.shape)==1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac01ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highflow_at_groundsurface(run_ws, flow_percentile):\n",
    "    ''' take Cell by Cell budget file and finds high flow cells by percentile\n",
    "    then finds those that outcrop at ground surface'''\n",
    "    cbb = flopy.utils.CellBudgetFile(run_ws+'/MF.cbc')\n",
    "    # load velocity in z direction\n",
    "    extcbb = flopy.utils.postprocessing.get_extended_budget(cbb)\n",
    "    (qx, qy, qz) = flopy.utils.postprocessing.get_specific_discharge(vectors = extcbb, model=m)\n",
    "    # convert flow to positive as it is all moving in the downward, -z direction\n",
    "    # q = qz * -1 # not a good indicator at all\n",
    "    # much better to use magntiude of velocity vector\n",
    "    q = np.sqrt(qx**2 + qy**2 + qz**2)\n",
    "    # split cells into low and high conductivity, based on chosen flow percentile\n",
    "    q_lay = np.zeros(q.shape)\n",
    "    q_lay[q >= np.percentile(q,flow_percentile)] = 1\n",
    "\n",
    "    # get high conductivity at ground surface\n",
    "    q_plt = np.zeros((100,230))\n",
    "    q_plt[rows,cols] = q_lay[tprogs_lay[rows,cols],rows,cols] \n",
    "\n",
    "    return(q_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def high_flow_arr(flow_percentile, str_setbacks):\n",
    "    tic = time.time()\n",
    "    # map the high flow cells for all 100 realizations\n",
    "    hf_tot = np.zeros((100,nrow,ncol))\n",
    "\n",
    "    for r in np.arange(0,100):\n",
    "        print('Realization', r, ' time since start ',(time.time()-tic)/60)\n",
    "        folder = '/realization'+ str(r).zfill(3)+'/'\n",
    "        run_ws = model_ws+folder\n",
    "        \n",
    "        q_lay = highflow_at_groundsurface(run_ws, flow_percentile)\n",
    "        # calculate total cells in each setback\n",
    "        hf_tot[r,:,:] = q_lay\n",
    "\n",
    "    # save counted high flow cells to a tsv\n",
    "    hf_tot_out = np.reshape(hf_tot, (100*nrow,ncol))\n",
    "    np.savetxt(data_dir+'surface_highflow_by_realization_'+str(flow_percentile)+'.tsv', hf_tot_out,delimiter = '\\t')\n",
    "\n",
    "    toc = time.time()\n",
    "    print('Total time was', (toc-tic)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba202c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_flow_arr(87, str_setbacks)\n",
    "# data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_percentile=95\n",
    "hf_tot_in =  np.loadtxt(data_dir+'surface_highflow_by_realization_'+str(flow_percentile)+'.tsv',delimiter = '\\t')\n",
    "hf_tot = np.reshape(hf_tot_in, (100, nrow, ncol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ea71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rch_hf_sum = np.zeros((100,len(setbacks)))\n",
    "rch_all_sum = np.zeros((100,len(setbacks)))\n",
    "\n",
    "\n",
    "# since loading tprogs data is the slowest, it would be efficient to pre-process it into hydraulic conductivity arrays\n",
    "for t in np.arange(0,100):\n",
    "\n",
    "    # calculate vertical seepage with Darcy's equation assuming a saturated zone thickness similar to the lake bed in modflow\n",
    "    # hydraulic conductivity is in m/day, hydraulic gradient is unitless, area is 200x200 m^2\n",
    "    rch_hf_arr = -soil_K[t,:,:]*hf_tot[t,:,:] *(200*200)* ((d_arr + soil_thick)/soil_thick)\n",
    "    # don't subset for high flow\n",
    "    rch_all_arr = -soil_K[t,:,:]*(200*200)* ((d_arr + soil_thick)/soil_thick)\n",
    "\n",
    "    # total recharge expected\n",
    "    rch_hf_sum[t, :] = np.nansum(rch_hf_arr, axis=(1,2)).data\n",
    "    rch_all_sum[t, :] = np.nansum(rch_all_arr, axis=(1,2)).data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50af0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rch_hf_sum = np.zeros((100,len(setbacks)))\n",
    "\n",
    "# since loading tprogs data is the slowest, it would be efficient to pre-process it into hydraulic conductivity arrays\n",
    "for t in np.arange(0,1):\n",
    "    # calculate vertical seepage with Darcy's equation assuming a saturated zone thickness similar to the lake bed in modflow\n",
    "    # hydraulic conductivity is in m/day, hydraulic gradient is unitless, area is 200x200 m^2\n",
    "    rch_hf_arr = -soil_K[t,:,:]*hf_tot[t,:,:] *(200*200)* ((d_arr + soil_thick)/soil_thick)\n",
    "    # total recharge expected\n",
    "    rch_hf_sum[t, :] = np.nansum(rch_hf_arr, axis=(1,2)).data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6df199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group recharge into upstream segments of each XS\n",
    "xs_rch_sum = np.zeros((len(grid_xs.line.unique()),len(setbacks)))\n",
    "for xs_n in grid_xs.line.unique():\n",
    "    row = grid_xs[grid_xs.line==xs_n].row-1\n",
    "    col = grid_xs[grid_xs.line==xs_n].column-1\n",
    "    xs_rch_sum[xs_n,:] = np.nansum(rch_hf_arr[:,row,col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ba0084",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "xs_rch_df = pd.DataFrame(xs_rch_sum*-1,columns = setbacks)\n",
    "# xs_rch_df.plot(cmap='gray',  kind='bar', legend=True)\n",
    "xs_rch_df.plot(cmap='gray',  legend=False, ax=ax)\n",
    "plt.ylabel('Recharge flux ($m^3/day$')\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "xs_rch_df.multiply((1/(86400 * 0.3048**3))).plot(cmap='gray', legend=False, ax=ax2)\n",
    "\n",
    "plt.ylabel('Recharge flux (cfs)')\n",
    "plt.legend(ncol=3, loc=(1.2,0.2))\n",
    "plt.xlabel('Cross section')\n",
    "plt.title('Filtered to high flow cells')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45e3b18",
   "metadata": {},
   "source": [
    "The combined flood depth-high flow cell recharge rates are ideal for optimizing compared to the TPROGs data alone. Additionally it is good to demonstrate that even with only using high flow cells the recharge rate is nearly equal what it would be with non-connected sands/gravels and fines.\n",
    "\n",
    "Helen suggested including a loss factor to the flood as I route it downstream based on the expected amount recharged through high connectivity cells. I can use the muskingum routing set up from ECI273 and change the loss factor to be estimated with the recharge estimates. In this way it will become a sort of simple 1D model where upstream recharge will impact the downstream.\n",
    "\n",
    "This analysis can be applied to local setbacks two ways:\n",
    "1. (simple) apply the high flow cells included in the local setbacks to the flood depth maps\n",
    "2. (complex) same as 1. but adjust flood depth maps to be impacted by local setback only.\n",
    "\n",
    "Plotting the cumulative recharge vs streamflow will help identify if this amount is negligible loss compared to the flow and whether it is necessary to  adjust streamflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d212df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rch_sum_df = pd.DataFrame(rch_hf_sum*-1,columns = setbacks).transpose()\n",
    "rch_sum_df.plot(cmap='gray', legend=False)\n",
    "plt.ylabel('Recharge flux ($m^3/day$')\n",
    "plt.xlabel('Setback distance (m)')\n",
    "plt.title('Filtered to high flow cells')\n",
    "\n",
    "rch_sum_df = pd.DataFrame(rch_all_sum*-1,columns = setbacks).transpose()\n",
    "rch_sum_df.plot(cmap='gray', legend=False)\n",
    "plt.title('Includes coarse and fine cells')\n",
    "plt.ylabel('Recharge flux ($m^3/day$')\n",
    "plt.xlabel('Setback distance (m)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e280448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

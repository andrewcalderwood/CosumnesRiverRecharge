{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename, dirname, join, exists\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# 1d so the smoothing is specific to each realization\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib import cm\n",
    "\n",
    "import h5py\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a91fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "    \n",
    "# dir of all gwfm data\n",
    "gwfm_dir = join(dirname(doc_dir),'Box/research_cosumnes/GWFlowModel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c272af-5002-48c2-9ff9-6b66735d4ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions.setback_stats\n",
    "reload(functions.setback_stats)\n",
    "\n",
    "from functions.setback_stats import stats_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c1785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set box directory for output figures and data\n",
    "box_dir = gwfm_dir+'/Levee_setback/levee_setback_distance_analysis/'\n",
    "\n",
    "# tprogs_id = '' # original tprogs with conditioning data in output tsim\n",
    "# tprogs_id = '_no_conditioning'\n",
    "tprogs_id = '_no_cond_c3d'\n",
    "\n",
    "\n",
    "data_dir = box_dir+ tprogs_id+'/data_output/'\n",
    "fig_dir = box_dir+tprogs_id+'/figures/'\n",
    "\n",
    "chan_dir = box_dir+'channel_data/'\n",
    "gis_dir = chan_dir+'GIS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b74547",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 100\n",
    "ncol = 230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388e95b-f95d-4d28-bf82-b461f3a1c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_percentile=6\n",
    "hf_tot_in =  np.loadtxt(data_dir+'surface_highflow_by_realization_'+str(flow_percentile)+'.tsv',delimiter = '\\t')\n",
    "hf_tot = np.reshape(hf_tot_in, (100, nrow, ncol))\n",
    "# hf_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "setbacks = np.arange(0, 3400,200)\n",
    "# original XS data\n",
    "xs_all_cln = pd.read_csv(chan_dir+'Elevation_by_XS_number_meters.csv', index_col='dist_from_center_m')\n",
    "# smoothed XS data used for setback analysis\n",
    "# xs_all_cln = pd.read_csv(chan_dir+'xs_levee_smooth.csv', index_col='dist_from_center_m')\n",
    "num_segs = xs_all_cln.shape[1]\n",
    "# load array identifying row,col to XS id (1,28)\n",
    "xs_arr = np.loadtxt(chan_dir+'XS_num_grid_reference.tsv')\n",
    "\n",
    "# load flood typology characteristics (based on daily data 1908 - 2014) - median values \n",
    "#\"cms_pk\" for peak discharge, \"pk_loc\" for time to peak, and \"log_no_d\" for duration\n",
    "flood_type = pd.read_csv(join(box_dir, 'whipple_grp6_w97ftmedians.csv'),index_col='Group.1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1deff-e7e6-4410-9427-98310e2642c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flood_type[['Typology','cms_pk']]\n",
    "# 10**flood_type['log_no_d'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d83fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(join(chan_dir, 'setback_locs.hdf5'), \"r\")\n",
    "local_str_setbacks = f['setbacks']['local'][:]\n",
    "str_setbacks = f['setbacks']['regional'][:]\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_hdf5_output(ft_in, region):\n",
    "    tic = time.time()\n",
    "    T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "    p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "    tp_in = int(p_l_in*T_in)\n",
    "    rch_hf_all = np.zeros((100, len(setbacks),nrow,ncol))\n",
    "    Q_all = np.zeros((100, T_in, len(setbacks),xs_all_cln.shape[1]+1))\n",
    "    d_xs_all = np.zeros((100, T_in, len(setbacks),xs_all_cln.shape[1]+1))\n",
    "    d_all = np.zeros((100, T_in, len(setbacks),xs_all_cln.shape[1]))\n",
    "    d_arr_all = np.zeros((100, len(setbacks),nrow,ncol))\n",
    "    cell_frac_all = np.zeros((100, len(setbacks),nrow,ncol))\n",
    "\n",
    "    # filter out for only those realizations that successfully ran\n",
    "    base_fn = join(data_dir, region, 'type'+str(ft_in))\n",
    "    r_out = pd.Series(os.listdir(base_fn)).str.extract(r'(\\d{3})')[0].unique().astype(int)\n",
    "    # takes a \n",
    "    for t in r_out: # np.arange(0,100): #[0]:\n",
    "        # load hdf5 files for each realization\n",
    "        r_fn = join(base_fn,'r'+str(t).zfill(3)+'_')\n",
    "        f = h5py.File(r_fn+'output.hdf5', \"r\")\n",
    "        Q = f['array']['flow'][:]        \n",
    "        rch_hf = f['array']['rch_hf'][:]\n",
    "        # depth is a little complicated to summarize, not so bad to back it out from\n",
    "        d_arr = f['array']['depth'][:]\n",
    "        d_xs = f['array']['XS_depth'][:]\n",
    "        cell_frac = f['array']['cell_frac'][:]\n",
    "        f.close()\n",
    "        # saving all of the flow at all steps, setbacks is needed to post-process\n",
    "        Q_all[t] = np.copy(Q)\n",
    "        # saving XS depth at all steps, setbacks needed to post-process\n",
    "        d_xs_all[t] = np.copy(d_xs)\n",
    "        # sum recharge across time to save storage space (breaks python at 25GB)\n",
    "        rch_hf = np.nansum(rch_hf, axis=0)\n",
    "        rch_hf_all[t] = np.copy(rch_hf)\n",
    "        # cell_frac - frational cell inundated should follow same pattern as depth array\n",
    "        cell_frac_all[t] = np.nanmean(ma.masked_where(cell_frac==0, cell_frac), axis=0)        \n",
    "        # average depth across time to save storage space (breaks python at 25GB)\n",
    "        d_arr_all[t] = np.nanmean(ma.masked_where(d_arr==0, d_arr), axis=0)\n",
    "        # depth needs to be averaged across each segment to keep for all times\n",
    "        for s in np.arange(0,len(setbacks)):\n",
    "            for nseg in np.arange(0, num_segs):\n",
    "                # mask zeros to not estimate depth based on zero values\n",
    "                # could present as average positive depth or maximum\n",
    "                d_out = d_arr[:,s, (xs_arr==nseg)&(str_setbacks[s].astype(bool))]\n",
    "                d_all[t,:,s, nseg] =  ma.masked_where(d_out==0, d_out).mean()\n",
    "\n",
    "\n",
    "    # convert to m3/day and will have the total recharged after summing individual days\n",
    "    rch_hf_all = rch_hf_all*86400\n",
    "\n",
    "    toc = time.time()\n",
    "    print('Loading',region,'for flow type',str(ft_in), 'took %.2f minutes' %((toc-tic)/60))\n",
    "    return(Q_all, rch_hf_all, d_all, d_arr_all, cell_frac_all, d_xs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_in=1\n",
    "# region='regional'\n",
    "# Q_all, rch_hf_all, d_all, d_arr_all = load_hdf5_output(ft_in, region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_in=1\n",
    "\n",
    "T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "tp_in = int(p_l_in*T_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb012888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_seg = np.zeros((100, T_in, len(setbacks),xs_all_cln.shape[1]))\n",
    "\n",
    "# tic = time.time()\n",
    "\n",
    "# # takes .045 sec to extract nseg, should take about 5 sec\n",
    "# for t in np.arange(0,100):\n",
    "#     for s in np.arange(0,len(setbacks)):\n",
    "#         for nseg in np.arange(0, num_segs):\n",
    "#             # mask zeros to not estimate depth based on zero values\n",
    "#             d_out = d_all[t,:,s, (xs_arr==nseg)&(str_setbacks[s].astype(bool))]\n",
    "#             d_seg[t,:,s, nseg] =  ma.masked_where(d_out==0, d_out).mean()\n",
    "# toc = time.time()\n",
    "# toc-tic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e665ec1e",
   "metadata": {},
   "source": [
    "## Save files as hdf5 to save time with reloading\n",
    "For each region and flow type save an hdf5 file that will include all realizations, so when reloading it takes 1 second instead of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ends up as about 500 MB, may want individual files\n",
    "\n",
    "def arr_to_h5(arr, h5_fn):\n",
    "    # convert arrays of annual etc to hdf5 files individually\n",
    "    f = h5py.File(h5_fn, \"w\")\n",
    "    grp = f.require_group('array') # makes sure group exists\n",
    "    grp.attrs['units'] = 'cubic meters per day'\n",
    "    grp.attrs['description'] = 'Each layer of the array is a day in the triangular hydrograph'\n",
    "    dset = grp.require_dataset('all', arr.shape, dtype='f', compression=\"gzip\", compression_opts=4)\n",
    "    dset[:] = arr\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55562c5",
   "metadata": {},
   "source": [
    "This code only needs to be re-run when the models are rerun. Takes about 49 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate_hdf5 = True\n",
    "recreate_hdf5 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d952ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "if recreate_hdf5:\n",
    "    for region in ['regional']: #['local_1','local_2','local_3']: # 'regional' #'regional_new'\n",
    "        for ft_in in [1,2,3]:\n",
    "            print(ft_in)\n",
    "#             Q_all, rch_hf_all = load_output(ft_in, region)\n",
    "            Q_all, rch_hf_all, d_all, d_arr_all, cell_frac, d_xs_all = load_hdf5_output(ft_in, region)\n",
    "\n",
    "            arr_to_h5(Q_all, join(data_dir,'hdf5', 'all_flow_'+region+'_type'+str(ft_in)+'.hdf5'))\n",
    "            arr_to_h5(rch_hf_all, join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'))\n",
    "            arr_to_h5(d_all, join(data_dir,'hdf5', 'all_depth_'+region+'_type'+str(ft_in)+'.hdf5'))\n",
    "            arr_to_h5(d_arr_all, join(data_dir,'hdf5', 'depth_avg_arr'+region+'_type'+str(ft_in)+'.hdf5'))\n",
    "            arr_to_h5(cell_frac, join(data_dir,'hdf5', 'cell_frac_arr'+region+'_type'+str(ft_in)+'.hdf5'))\n",
    "            arr_to_h5(d_xs_all, join(data_dir,'hdf5', 'peak_flow_xs_depth_'+region+'_type'+str(ft_in)+'.hdf5'))\n",
    "\n",
    "else:\n",
    "    print('Reusing existing recharge and flow hdf5 files')\n",
    "\n",
    "t1= time.time()\n",
    "print('Time to write %.2f min' %((t1-t0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc492298",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_plt = [1,2,3]\n",
    "region = 'regional'\n",
    "# region = 'regional_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5f65f-66aa-41af-85f3-8eac530d46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_type_plot = flood_type.loc[flood_type.index.isin(ft_plt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735f81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "stats_elements = [\n",
    "    Line2D([0], [0],color='grey',label='Individual\\nRealization'),\n",
    "#     Line2D([0], [0],color='black',label='5th/95th', linestyle='--'),\n",
    "    Line2D([0], [0],color='black',label='1.5x Quartile\\nRange'),\n",
    "    Line2D([0], [0],color='tab:blue',label='25th/75th'),\n",
    "    Line2D([0], [0],color='tab:green',label='Median'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a0715",
   "metadata": {},
   "source": [
    "The box extends from the first quartile (Q1) to the third quartile (Q3) of the data, with a line at the median. \n",
    "The whiskers extend from the box by 1.5x the inter-quartile range (IQR)  \n",
    "whis = 1.5\n",
    "IQR = Q3-Q1\n",
    "upper whisker =  Q3 + whis\\*IQR\n",
    "lower whisker = Q1 - whis\\*IQR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d51f10-3b0d-4e80-abeb-8c81a8c27ba2",
   "metadata": {},
   "source": [
    "# Recharge by setback distance\n",
    "\n",
    "If we know that the geology has a consistent relationship with recharge then we can trust an example realization like the median because we know that the recharge will shift in a certain way given a change in geology (e.g., HCP area).  \n",
    "\n",
    "Originally subset the recharge to the lower third of the domain by column but it is more accurate to use locations where the xs_arr applies because that is where depth will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fd9b0-8a78-4722-a478-c847f834373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rch_col = int(230/3) # lower third\n",
    "# while there is slightly more flooding in the lower 2/3 the setback distance still suggests 200 m more than 600/1200\n",
    "# rch_col = int(230*2/3) # lower 2/3\n",
    "\n",
    "np.unique(xs_arr[:, :rch_col]),np.unique(xs_arr[:, :rch_col]).shape\n",
    "# there are 9 xs in the lower third which is 1/3 of XS as well, so it makes it easy to compare both ways "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c000b-b579-420f-900d-87123f07cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify XS for plotting\n",
    "xs_nums = np.unique(xs_arr)[~np.isnan(np.unique(xs_arr))]\n",
    "rch_xs = int(len(xs_nums)/3)\n",
    "xs_arr_lower = np.copy(xs_arr)\n",
    "xs_arr_lower[(xs_arr < xs_nums[-rch_xs])] = np.nan\n",
    "# plt.imshow(xs_arr_lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db44bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region='regional'\n",
    "rch_xs_all = pd.DataFrame()\n",
    "rch_chan_all = pd.DataFrame()\n",
    "# subset results to lower region with most recharge activity and shallowest water tables\n",
    "rch_lower = pd.DataFrame()\n",
    "rch_xs_hf = pd.DataFrame()\n",
    "\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    with h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\") as f:\n",
    "        rch_hf_all = f['array']['all'][:]\n",
    "    # aggregate to XS level\n",
    "    rch_xs_sum = pd.DataFrame(np.sum(rch_hf_all, axis=(2,3)), columns= setbacks).transpose()/1E6\n",
    "    rch_xs_all = pd.concat((rch_xs_all, rch_xs_sum.assign(ft = ft_in)))\n",
    "    # calculate the recharge specific to the channel for each setback\n",
    "    rch_chan_sum = pd.DataFrame(rch_hf_all[:,:, str_setbacks[0]==1].sum(axis=2), columns= setbacks).transpose()/1E6\n",
    "    rch_chan_all = pd.concat((rch_chan_all, rch_chan_sum.assign(ft = ft_in)))\n",
    "    # pull recharge results for the domain bottom 1/3\n",
    "    # rch_lower_sum = pd.DataFrame(np.sum(rch_hf_all[:,:,:, :rch_col], axis=(2,3)), columns= setbacks).transpose()/1E6\n",
    "    rch_lower_sum = pd.DataFrame(np.sum(rch_hf_all[:,:, ~np.isnan(xs_arr_lower)], axis=(2)), columns= setbacks).transpose()/1E6\n",
    "    rch_lower = pd.concat((rch_lower, rch_lower_sum.assign(ft = ft_in)))\n",
    "    # recharge from HF separated out\n",
    "    rch_hf = pd.DataFrame()\n",
    "    for ns, s in enumerate(setbacks):\n",
    "        rch_hf[s] = np.sum(np.multiply(rch_hf_all[:,ns], hf_tot), axis=(1,2))/1E6\n",
    "    rch_xs_hf = pd.concat((rch_xs_hf, rch_hf.transpose().assign(ft = ft_in)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f3c254-5ab9-4010-9931-307a44e5485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "setback_area = str_setbacks[:,:,:rch_col].sum(axis=(1,2))*200*200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2758f3-7cbd-49cf-a65e-d4e0397dff39",
   "metadata": {},
   "source": [
    "## Total recharge\n",
    "- the recharge total or coarse alone is nearly identical\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104bb9dc-8212-4146-b7ee-39876fe852c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import functions.setback_plotting\n",
    "reload(functions.setback_plotting)\n",
    "\n",
    "from functions.setback_plotting import plt_rech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c4d34-1172-4116-8b02-b0930e78ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b064a-c792-4eb9-8670-e9a2cae0c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the cumulative recharge to the area it covers\n",
    "setback_area = str_setbacks.sum(axis=(1,2))*200*200\n",
    "rch_sum = plt_rech(\n",
    "    rch_xs_all.loc[setbacks[:]], \n",
    "    # rch_lower.loc[setbacks[:]],\n",
    "    # rch_xs_hf,\n",
    "    flood_type_plot,\n",
    "                    # setback_area[:]\n",
    "                  )\n",
    "# plt.savefig(join(fig_dir, 'all_recharge_by_setback.tif'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff8923-9cfd-4c38-92c5-3b1a65e1003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data for Helen to use\n",
    "rch_xs_out =rch_sum.copy()\n",
    "rch_xs_out.index.name='setback_dist_m'\n",
    "rch_xs_out.to_csv(join(box_dir,'figures','to_Helen','Fig08_total_recharge_MCM_by_realization.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b3e841-3749-4a6e-a42e-c4b0a1ff30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value to insert to paper for median recharge at 800 m\n",
    "med_800 = rch_sum[rch_sum.ft==2].loc[800].drop(columns='ft').median()\n",
    "print('Median total recharge at 800 m is %.1f MCM' %med_800)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69b8ec3-b1e2-4110-86e2-8d94b2c3f57e",
   "metadata": {},
   "source": [
    "### recharge from HCP only\n",
    "Shows the same pattern as the total recharge with a slight reduction. Not greatly worth presenting since the map plots show the higher rates in spots where there is higher conductivity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6032462c-847f-4aec-83c7-9e2461a6a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions.setback_stats\n",
    "reload(functions.setback_stats)\n",
    "\n",
    "from functions.setback_stats import compare_hf_to_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff5880-ca2e-4893-948c-cde5f958ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "compare_hf_to_all(600, rch_xs_all, rch_xs_hf)\n",
    "compare_hf_to_all(1200, rch_xs_all, rch_xs_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0082d-cf9d-4c76-ab4c-c38eb17066f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only consider area of HCP within floodplain\n",
    "# setback_area = pd.DataFrame()\n",
    "# for n in np.arange(0,100):\n",
    "#     setback_area[n] = (str_setbacks*hf_tot[n]).sum(axis=(1,2))*200*200\n",
    "# setback_area.index=setbacks\n",
    "\n",
    "# rch_sum = plt_rech(\n",
    "#     rch_xs_hf.loc[setbacks[:]],\n",
    "#     # rch_xs_hf.loc[setbacks[1:]],\n",
    "#     #                 setback_area[1:]\n",
    "#                   )\n",
    "# plt.savefig(join(fig_dir, 'HCP_recharge_by_setback.tif'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb8a2a5-061d-43de-84bd-2512739e555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that HCP area is less than total area\n",
    "# setback_area.plot(legend=False)\n",
    "# plt.plot(setbacks,str_setbacks.sum(axis=(1,2))*200*200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dcd408-35ac-4331-9d6e-88d0415beef1",
   "metadata": {},
   "source": [
    "## Channel vs floodplain\n",
    "plot recharge in the channel separate from floodplain\n",
    "\n",
    "- the recharge in the channel generally declines with larger setbacks\n",
    "- looking at floodplain recharge alone shows a bit clearer the upward trend from 0 m to 1400 m where it then levels off\n",
    "    - **worthwhile to plot floodplain recharge solo because of how clear the value is**\n",
    "- the ratio of floodplain recharge to total recharge is interesting because it shows that the biggest shifts in recharge proportion happen early on. From 0 to 200 m there is a 40% median change then almost 20% then only about 15%.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff646c-f5a2-47a3-8d58-b7d7b827199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# floodplain recharge\n",
    "rch_fp = rch_xs_all.copy()\n",
    "rch_fp.iloc[:,:-1] = rch_xs_all.iloc[:,:-1]- rch_chan_all.iloc[:,:-1]\n",
    "# ratio of floodplain to channel recharge or floodplain as fraction of flow\n",
    "chan_fp = rch_xs_all.copy()\n",
    "# chan_fp.iloc[:,:-1] = rch_chan_all.iloc[:,:-1]/ rch_xs_all.iloc[:,:-1]\n",
    "chan_fp.iloc[:,:-1] = rch_fp.iloc[:,:-1]/ rch_xs_all.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da12265-c4b7-42eb-adad-54f636354b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the cumulative recharge to the area it covers\n",
    "setback_area = str_setbacks.sum(axis=(1,2))*200*200\n",
    "rch_fp_sum = plt_rech(\n",
    "    # rch_chan_all,\n",
    "    # rch_fp,\n",
    "    chan_fp,\n",
    "    flood_type_plot,\n",
    "    # setback_area#[1:]\n",
    "    alt_ylab='Fraction of recharge in the floodplain'\n",
    "                  )\n",
    "\n",
    "plt.savefig(join(fig_dir, 'floodplain_recharge_fraction.tif'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e1ed9-2657-458b-a3cf-d1a5ebac8e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26dd5658-062e-437b-8e4d-374c68050fdc",
   "metadata": {},
   "source": [
    "## Effective recharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e367df-82bc-41cf-a12e-9fedb5301325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compare the cumulative recharge to the area it covers\n",
    "setback_area = str_setbacks.sum(axis=(1,2))*200*200\n",
    "eff_rch_sum = plt_rech(rch_xs_all.loc[setbacks[:]], \n",
    "                       flood_type_plot,\n",
    "                       setback_area[:],\n",
    "                   log=True\n",
    "                  )\n",
    "\n",
    "# plt.savefig(join(fig_dir, 'all_effective_recharge_by_setback.tif'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bb953-6d3f-4a8f-a318-46d9424490b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data for Helen to use\n",
    "rch_xs_out = eff_rch_sum.copy()\n",
    "rch_xs_out.index.name='setback_dist_m'\n",
    "rch_xs_out.to_csv(join(box_dir,'figures','to_Helen','Fig10_effective_recharge_m_day_by_realization.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214249e3-a483-4734-b5ff-69eb498fa981",
   "metadata": {},
   "source": [
    "## lower floodplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dbc39c-acb4-46ab-8958-747e1af98ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only consider area of lower floodplain\n",
    "# setback_area = pd.DataFrame()\n",
    "# for n in np.arange(0,100):\n",
    "#     # setback_area[n] = (str_setbacks[:,:,:rch_col]).sum(axis=(1,2))*200*200\n",
    "#     setback_area[n] = (str_setbacks[:, ~np.isnan(xs_arr_lower)]).sum(axis=(1))*200*200\n",
    "# setback_area.index=setbacks\n",
    "\n",
    "# rch_sum_lower = plt_rech(\n",
    "#     rch_lower.loc[setbacks[:]],\n",
    "    # flood_type_plot,\n",
    "#                          # ,setback_area[1:]\n",
    "#                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56d11a-b0d4-4726-9ae5-0dd2e57209fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rch_xs_all.drop(columns=['ft']).loc[600].median(axis=1).values/rch_xs_all.drop(columns=['ft']).loc[1200].median(axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ec93d-2fe4-4ed2-9a8e-0ed2136094ce",
   "metadata": {},
   "source": [
    "## Maximum effective recharge\n",
    "Now that we have a recharge scaled by setback area if we remove the rates at a 0 m setback then the 1200 m setback tends to be more valuable, we could remove the 0 m and compare the maximum and secondmost effective recharge for each realization.\n",
    "- When 0 m setback is included there are a few realizations (10 that identify 1200 m) which shows that with most geology it tends to be cheaper to not setback\n",
    "- When 0 m is removed, then there are ~45 for 200 m and ~25 for 1200 m which still strongly indicates that no setback is cheaper\n",
    "- When both 0 m and 200 m are removed then 1200 m is dominant with 35, followed by 400and 600 with ~17 each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c84ebd-8828-429d-a381-df8476f394db",
   "metadata": {},
   "source": [
    "The plots of effective recharge would really start to show some difference if we performed the analysis by region because the lower region would simply have more value.\n",
    "- When we subset to the lower region we see slightly lower effective recharge rates but a shift away from maximums at 0 m because there is more benefit per setback area in the lower region since more inundation is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d67ed-41c8-475f-b52b-57f7b9c1dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_eff_plt(eff_rch):\n",
    "    fig,ax = plt.subplots(3,1, sharex=True)\n",
    "    for n, i in enumerate([0,1,2]):\n",
    "\n",
    "        eff_rch.iloc[i:].idxmax(axis=0).hist(bins=setbacks, ax=ax[n])\n",
    "        ax[n].set_xticks(setbacks+100, setbacks, rotation=90);\n",
    "    fig.supxlabel('Setback Distance (m)')\n",
    "\n",
    "    ax[0].set_ylabel('All setbacks')\n",
    "    ax[1].set_ylabel('No 0 m \\nsetback')\n",
    "    ax[2].set_ylabel('No 0 m and \\n200 m setback')\n",
    "\n",
    "    ax[0].set_title('Histogram - Max Effective Recharge')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "# max_eff_plt(eff_rch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61572756-617a-4ff2-a1a3-7b2a0b85a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the lower third we can also plot the recharge and find that max isn't always ta 3200m\n",
    "ft_in=1\n",
    "fig,ax=plt.subplots(3,1, figsize=(6.5,6.5), sharex=True)\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    # rch_sum_lower[rch_sum_lower.ft==ft_in].loc[400:].drop(columns=['ft']).idxmax(axis=0).hist(bins=setbacks, ax=ax[nf])\n",
    "    # rch_lower[rch_lower.ft==ft_in].loc[0:].drop(columns=['ft']).idxmax(axis=0).hist(bins=setbacks, ax=ax[nf])\n",
    "    rch_xs_all[rch_xs_all.ft==ft_in].loc[0:].drop(columns=['ft']).idxmax(axis=0).hist(bins=setbacks, ax=ax[nf])\n",
    "    ax[nf].set_xticks(setbacks+100, setbacks, rotation=90);\n",
    "fig.supylabel('Count')\n",
    "fig.supxlabel('Setback distance (m)')\n",
    "fig.tight_layout(h_pad=0.1)\n",
    "plt.savefig(join(fig_dir, 'histogram_max_recharge_all.tif'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f35e31-13e3-4a87-9884-df5df0672c78",
   "metadata": {},
   "source": [
    "# Discharge loss downstream\n",
    "\n",
    "Goal: present the discharge loss and depths by segment for the median of realizations. Then present the results just for the 600 m and 1200 m as example choices with the full spread of realizations to help discuss the range of benefits one might expect depending on local conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c22c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region='regional'\n",
    "ft_in=2\n",
    "f = h5py.File(join(data_dir,'hdf5', 'all_flow_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "Q_all = f['array']['all'][:]\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea3b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "tp_in = int(p_l_in*T_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dac14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t=0\n",
    "\n",
    "def plt_downstream_loss(Q_all, ft_in, ax, setback = -1, sec=False):\n",
    "    T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "    p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "    tp_in = int(p_l_in*T_in)\n",
    "    # plot segments in reverse order to align with idea that upstream is east and downstream is west\n",
    "    Q_plt = pd.DataFrame(Q_all[:,tp_in,setback,:], columns = np.arange((num_segs)*2, -2, -2)).transpose()\n",
    "    Q_plt.plot(color='lightgray', legend=False, ax=ax)\n",
    "    stats_lines(Q_plt, ax=ax)\n",
    "    if sec:\n",
    "        def scale_Q(x):\n",
    "            return ((x / Q_plt.values[0,0])-1)*-1\n",
    "        def unscale_Q(x):\n",
    "            return ((x*-1+1) * Q_plt.values[0,0])\n",
    "        ax.secondary_yaxis('right', functions=(scale_Q, unscale_Q))\n",
    "\n",
    "    return(Q_plt)\n",
    "\n",
    "# fig,ax = plt.subplots(figsize=(6,3), dpi=300)\n",
    "# Q_plt = plt_downstream_loss(Q_all, ft_in, ax=ax, setback=5, sec=True)\n",
    "# plt.xlabel('Upstream distance (km)')\n",
    "# plt.ylabel('Discharge ($m^3/s$)')\n",
    "# ax.legend(handles=stats_elements,  loc='center right', ncol=1)#loc= 'outside upper center',\n",
    "\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0664cd0d-9278-4771-8a7a-446214347337",
   "metadata": {},
   "source": [
    "The recharge going up and downstream is not as helpful because it is so variable and merely shows that most recharge occurs in lower reaaches which can be parsed from the discharge plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_plt = [1,2,3]\n",
    "# downside of spatial plots is I can't share the x-axis\n",
    "# xticks based on number of stream segments\n",
    "xtick = np.sort(np.arange((num_segs-1)*2, -2, -2))[::2]\n",
    "\n",
    "fig,ax=plt.subplots(3,2, sharex=True, sharey=False, figsize=(6.5,6.5),dpi=300)\n",
    "\n",
    "s = 4 # 800 m is interesting for lower range\n",
    "s=7 # paper uses 1400 m as final selection\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'all_flow_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    Q_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    ax_d = ax[nf, 0]\n",
    "    Q_plt = plt_downstream_loss(Q_all, ft_in, ax=ax_d,setback=s, sec=True)\n",
    "    \n",
    "    ax_n = ax[nf, 1]\n",
    "    # calculate XS recharge \n",
    "    Q_diff = np.diff(Q_all, axis=-1)*-1\n",
    "    # add zero recharge for upstream first XS\n",
    "    Q_diff = np.append(np.zeros(np.append(Q_all.shape[:3],1)), Q_diff, axis=3)\n",
    "    Q_diff_plt = plt_downstream_loss(Q_diff, ft_in, ax=ax_n,setback=s)\n",
    "\n",
    "    ## calculate the percentage reduction in flow by the downstream ##\n",
    "    # calculate reduction at peak flow for the 1000 m setback\n",
    "    T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "    p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "    tp_in = int(p_l_in*T_in)\n",
    "    Q_red = Q_all[:,tp_in,s,-1]/Q_all[:,tp_in,s,0]\n",
    "    print('Flow reduction mean %.2f' %((1-Q_red).mean()*100), 'and std dev %.2f'%((1-Q_red).std()*100) )\n",
    "\n",
    "## formatting ##\n",
    "ax[-1,0].set_xlabel('Upstream distance (km)')\n",
    "ax[-1,1].set_xlabel('Upstream distance (km)')\n",
    "# ax[0,0].set_title('Peak Flow ($m^3/s$) - left\\n Fractional Reduction - right')\n",
    "# ax[0,1].set_title('Recharge at Peak Flow ($m^3/s$)')\n",
    "ax[-1,0].set_xticks(ticks=xtick[::2],labels=xtick[::2])\n",
    "ax[-1,0].set_xticks(ticks=xtick, minor=True)\n",
    "\n",
    "\n",
    "ax[1,0].set_ylabel('Peak Flow ($m^3/s$)', labelpad=5)\n",
    "ax2 = ax[1,0].twinx()\n",
    "ax2.set_yticks([])\n",
    "ax2.set_ylabel('Fractional Reduction', labelpad=25)\n",
    "ax[1,1].set_ylabel('Floodplain recharge ($m^3/s$)',labelpad=5)\n",
    "\n",
    "#     plt.setp(ax_d, xticklabels=[])\n",
    "# secax.set_ylabel('Fractional Reduction in Peak Discharge')\n",
    "\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    ax_n = ax[nf,0 ]\n",
    "    ax_n.annotate('Type '+str(ft_in),xy=(0.7,0.6),xycoords='axes fraction')\n",
    "# ax[1,2].legend(handles=stats_elements,  loc='lower right', ncol=1)#loc= 'outside upper center',\n",
    "lgd = fig.legend(handles=stats_elements,  loc='center left', bbox_to_anchor=(0.13, 1.02),ncol=4)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(join(fig_dir, 'cross_section_flow_and_recharge_all_'+str(s*200)+'.tif'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3197882d-46f6-4041-898b-cf99855219d1",
   "metadata": {},
   "source": [
    "## Plot of flow losses by setback for median of realizations\n",
    "It seems like it may be helpful to show the medians for each flood type then show the spread for the chosen realization at the end.\n",
    "\n",
    "Also rather than showing recharge it's better to present the depth as an indicator of floodplain benefit for ecosystems and depth indicates hydraulic gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f311b-64ca-4daa-92b2-609f1e652bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xs_dpth(d_all, rch_hf_all):\n",
    "    dim = (100,len(setbacks), num_segs)\n",
    "    xs_fld_dpth = np.zeros(dim)\n",
    "    xs_rch = np.zeros(dim)\n",
    "    # look at simplifying depth from the floodplain perspective\n",
    "    for ns, seg in enumerate(np.arange(0,num_segs)):\n",
    "    # for ns, seg in enumerate(np.unique(xs_arr)[~np.isnan(np.unique(xs_arr))]):\n",
    "        # take mean across the XS array group and median across realizations\n",
    "        xs_fld_dpth[:, :,ns] =  np.nanmean(d_all[:,:,xs_arr ==seg], axis=2)\n",
    "        xs_rch[:, :,ns] =  np.nanmean(rch_hf_all[:,:,xs_arr ==seg], axis=2)\n",
    "\n",
    "    # the XS flood depth for the flooplain will be small because it is a time averaged depth which brings down the depth\n",
    "    # similar results with median or mean across realziations\n",
    "    # start at 27 instead of 28 since depth isn't calculated for the inflow which is constant\n",
    "    xs_fld_df = pd.DataFrame(np.nanmedian(xs_fld_dpth, axis=0), columns = np.arange((num_segs-1)*2, -2, -2)).transpose()\n",
    "    xs_rch_df = pd.DataFrame(np.nanmedian(xs_rch, axis=0), columns = np.arange((num_segs-1)*2, -2, -2)).transpose()\n",
    "\n",
    "    return(xs_fld_df, xs_rch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223f9b55-a7bd-48f0-a964-4168cd626603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(xs_arr)[~np.isnan(np.unique(xs_arr))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892e915-9a10-4b37-9adc-ee02c20cce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_arr = np.zeros((3,nrow,ncol))\n",
    "xs_fld_df_all = pd.DataFrame()\n",
    "xs_rch_df_all = pd.DataFrame()\n",
    "\n",
    "# setback\n",
    "s = 6\n",
    "\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'depth_avg_arr'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    d_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    # spatial view\n",
    "    d_arr[nf] = np.nanmean(d_all[:,s], axis=0)\n",
    "\n",
    "    # XS view\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    rch_hf_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    # scale depth and recharge to XS level with mean\n",
    "    xs_fld_df, xs_rch_df = get_xs_dpth(d_all, rch_hf_all)\n",
    "    xs_fld_df_all = pd.concat((xs_fld_df_all, xs_fld_df.assign(ft=ft_in)))\n",
    "    xs_rch_df_all = pd.concat((xs_rch_df_all, xs_rch_df.assign(ft=ft_in)))\n",
    "    \n",
    "# mask where depth is 0\n",
    "d_arr = ma.masked_where(d_arr==0, d_arr)\n",
    "d_arr = ma.masked_invalid(d_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e2916e-aa11-47c7-aae8-410b523fdb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "#normalize item number values to colormap\n",
    "cmap = cm.viridis\n",
    "# norm = mpl.colors.Normalize(vmin=0, vmax=len(setbacks)) # continuous\n",
    "bounds = np.arange(0, len(setbacks)+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N) # discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80335548-e5c7-4090-b5fe-3c1d26c3d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plt_downstream_median(Q_all, ft_in, ax,  sec=False):\n",
    "    T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "    p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "    tp_in = int(p_l_in*T_in)\n",
    "    # plot segments in reverse order to align with idea that upstream is east and downstream is west\n",
    "    Q_plt = pd.DataFrame(np.median(Q_all[:,tp_in,:], axis=0), columns = np.arange(num_segs*2, -2, -2)).transpose()\n",
    "    # for t in np.arange(0,len(setbacks)):\n",
    "    #     Q_plt.iloc[:,t].plot(legend=False, ax=ax, color=cm.gray(norm(t)),alpha=0.7,)\n",
    "    Q_plt.plot(legend=False, ax=ax, color=cm.viridis(norm(np.arange(0,len(setbacks)))), alpha=0.7,)\n",
    "    if sec:\n",
    "        def scale_Q(x):\n",
    "            return ((x / Q_plt.values[0,0])-1)*-1\n",
    "        def unscale_Q(x):\n",
    "            return ((x*-1+1) * Q_plt.values[0,0])\n",
    "        ax.secondary_yaxis('right', functions=(scale_Q, unscale_Q))\n",
    "\n",
    "    return(Q_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb86c4-dcd5-4168-ba9e-5d51b4f5c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we want to show the depths in the channel to explain fish passage capabilities\n",
    "## but also depth on the floodplain for supporting fish juvenile rearing and other floodplain processes\n",
    "ft_in=2\n",
    "f = h5py.File(join(data_dir,'hdf5', 'peak_flow_xs_depth_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "d_xs_all = f['array']['all'][:]\n",
    "f.close()\n",
    "# for s in np.arange(0,16):\n",
    "# the min, max, and mean should be taken across the segments then averaged across realizations\n",
    "    # d_mean = d_xs_all[:,tp_in, s, :-1].mean(axis=1).median()\n",
    "    # d_min = d_xs_all[:,tp_in, s, :-1].min(axis=1).median()\n",
    "    # d_max = d_xs_all[:,tp_in, s, :-1].max(axis=1).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8a1dd-e62f-437e-8d02-07a13cc1c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "smid = 8\n",
    "setbacks_lgd = [\n",
    "    Line2D([0], [0],color='black',label='Seback 800 m', linestyle='--'),\n",
    "    Line2D([0], [0],color='black',label='Seback 1400 m', linestyle='-.'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4fd06b-95a3-4ee8-961b-4f6982785034",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(3,2, sharex=True, sharey=False, figsize=(6.5, 6.5), dpi=300)\n",
    "\n",
    "region='regional'\n",
    "s = [4, 7]\n",
    "ls = ['--','-.']\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'all_flow_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    Q_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    ax_d = ax[nf, 0]\n",
    "    Q_plt = plt_downstream_median(Q_all, ft_in, ax=ax_d, sec=True)\n",
    "    Q_plt[s].plot(ax=ax_d, legend=False, color='black', style=ls,linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    ax_n = ax[nf,1]\n",
    "    ax_n.yaxis.set_label_position(\"right\")\n",
    "    ax_n.yaxis.tick_right()\n",
    "    xs_fld_df = xs_fld_df_all[xs_fld_df_all.ft==ft_in].drop(columns=['ft'])\n",
    "    xs_fld_df.plot(ax=ax_n, legend=False, color=cm.viridis(norm(np.arange(0,len(setbacks)))), alpha=0.7)\n",
    "    xs_fld_df[s].plot(ax=ax_n, legend=False, color='black', style=ls, linewidth=0.5, alpha=0.7)\n",
    "\n",
    "lgd = fig.legend(handles=setbacks_lgd,  loc='center left', bbox_to_anchor=(0.2, 1.02),ncol=3)\n",
    "ax[-1,0].set_xlabel('Upstream distance (km)')\n",
    "ax[-1,1].set_xlabel('Upstream distance (km)')\n",
    "xtick = np.sort(xs_fld_df.index.values)[::2]\n",
    "ax[-1,0].set_xticks(ticks=xtick[::2],labels=xtick[::2])\n",
    "ax[-1,0].set_xticks(ticks=xtick, minor=True)\n",
    "# ax[-1,1].set_xticks(ticks=xtick,labels=xtick, rotation=45)\n",
    "\n",
    "ax[1,0].set_ylabel('Peak Flow ($m^3/s$)', labelpad=5)\n",
    "ax2 = ax[1,0].twinx()\n",
    "ax2.set_yticks([])\n",
    "ax2.set_ylabel('Fractional Reduction', labelpad=25)\n",
    "ax[1,1].set_ylabel('Floodplain depth (m)',labelpad=5)\n",
    "\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    ax_n = ax[nf,0 ]\n",
    "    ax_n.annotate('Type '+str(ft_in),xy=(0.7,0.2),xycoords='axes fraction')\n",
    "\n",
    "fig.tight_layout(h_pad=0 ) #pad=0.4, w_pad=0.5,\n",
    "\n",
    "cbar_ax=ax.ravel().tolist()\n",
    "\n",
    "cbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), ax=cbar_ax, \n",
    "                    # ticks=bounds[:-1]+0.5, \n",
    "                    label='Seback distance (m)',\n",
    "                    orientation='horizontal', ticks=bounds[:-1:2]+0.5, \n",
    "                   )\n",
    "cbar.set_ticklabels(setbacks[::2]);\n",
    "\n",
    "plt.savefig(join(fig_dir, 'cross_section_flow_and_depth_median.tif'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496256b9-cf2b-4106-a3b0-042b32346238",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.arange(0, 17)\n",
    "# for nf, ft_in in enumerate(ft_plt):\n",
    "Q_red = Q_all[:,tp_in,s,-1]/Q_all[:,tp_in,s,0]\n",
    "# print('Flow reduction mean %.2f' %((1-Q_red).mean()*100), 'and std dev %.2f'%((1-Q_red).std()*100) )\n",
    "(1-Q_red).mean(axis=0), (1-Q_red).std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed404976-0712-4718-b903-3dd642ba9a65",
   "metadata": {},
   "source": [
    "# Depth maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e8ce1d-faec-4a1f-9fa6-e9c44f8c5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr = gpd.read_file(gwfm_dir+'/SFR_data/final_grid_sfr/grid_sfr.shp')\n",
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13590d-26e0-442c-86e7-5844ba08215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setback\n",
    "s = 7\n",
    "def load_darr(s):\n",
    "    d_arr = np.zeros((3,nrow,ncol))\n",
    "\n",
    "    for nf, ft_in in enumerate(ft_plt):\n",
    "        f = h5py.File(join(data_dir,'hdf5', 'depth_avg_arr'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "        d_all = f['array']['all'][:]\n",
    "        f.close()\n",
    "        # spatial view\n",
    "        d_arr[nf] = np.nanmean(d_all[:,s], axis=0)\n",
    "    \n",
    "    # mask where depth is 0\n",
    "    d_arr = ma.masked_where(d_arr==0, d_arr)\n",
    "    d_arr = ma.masked_invalid(d_arr)\n",
    "    return d_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09b174-c5df-4137-8dd2-a7009fd044ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions.setback_plotting\n",
    "reload(functions.setback_plotting)\n",
    "from functions.setback_plotting import sfr_setback, floodplain_annotate, arr_plt_label_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5fc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_depth(fig,ax, d_arr):\n",
    "    vmin, vmax = (10,0 )\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "    region='regional'\n",
    "    for nf, ft_in in enumerate(ft_plt):\n",
    "        ax_n = ax[nf]\n",
    "        im = ax_n.imshow(d_arr[nf], \n",
    "                         vmin = np.nanmin(d_arr), vmax = np.nanmax(d_arr), \n",
    "                         # cool might be better\n",
    "                         cmap='cool', #'viridis_r', # options, cool, Blues, GnBu, winter, gist_earth_r\n",
    "                         zorder=1\n",
    "                        )\n",
    "        # ax[nf].imshow(setback_outer, cmap='gray') # works when dpi=600\n",
    "        ax[nf].plot(grid_sfr.column-1, grid_sfr.row-1, color='black', linewidth=0.5, linestyle='-.')\n",
    "        # ax[nf].imshow(xs_arr)\n",
    "    return im\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4dd89-0bb6-42c9-9bb4-6ef67c0020b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a26e0-a4a6-4984-869a-beefd36f8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(3,2, sharex=True, sharey=True, figsize=(6.5,3.5),dpi=600)\n",
    "\n",
    "d_arr = load_darr(3)\n",
    "ax_n = ax[:,0]\n",
    "ex_depth(fig,ax_n,d_arr)\n",
    "setback_outer = sfr_setback(grid_sfr, grid_p, 3)\n",
    "floodplain_annotate(ax_n, setback_outer, grid_sfr,  title=['(A)', '(C)','(E)'])\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    np.savetxt(join(box_dir,'figures','to_Helen','Figure06', 'flood_depth_m_array_Type'+str(ft_in)+'_'+str(3*200)+'m.txt') ,d_arr[nf])\n",
    "\n",
    "ax_n = ax[:,1]\n",
    "d_arr = load_darr(6)\n",
    "im = ex_depth(fig,ax_n,d_arr)\n",
    "setback_outer = sfr_setback(grid_sfr, grid_p, 6)\n",
    "floodplain_annotate(ax_n, setback_outer, grid_sfr,  title=['(B)', '(D)','(F)'])\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    np.savetxt(join(box_dir,'figures','to_Helen','Figure06', 'flood_depth_m_array_Type'+str(ft_in)+'_'+str(6*200)+'m.txt') ,d_arr[nf])\n",
    "\n",
    "arr_plt_label_stream(ax=ax[2,0])\n",
    "arr_plt_label_stream(ax=ax[2,1])\n",
    "\n",
    "fig.tight_layout(h_pad=0, w_pad=2) #pad=0.4, w_pad=0.5,\n",
    "cbar_ax=ax.ravel().tolist()\n",
    "fig.colorbar(im, ax=cbar_ax, orientation='vertical', label='Depth (m)', shrink=0.4,location='right')\n",
    "# fig.colorbar(im, ax=cbar_ax, orientation='horizontal', label='Depth (m)', shrink=0.4)\n",
    "\n",
    "# plt.savefig(join(fig_dir, 'flood_depth_map_setback_side_by_side.tif'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6d793-f447-4890-bef0-55255b4c8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Flood depth')\n",
    "xs_fld_df_lower = xs_fld_df_all[xs_fld_df_all.index.isin(np.arange(0,18))]\n",
    "# mean depth for each floodplain reach and median depth across realizations\n",
    "s_chk = [3,6,9]\n",
    "s_chk = [4,7]\n",
    "xs_fld_df_all.groupby('ft').mean()[s_chk]\n",
    "# xs_fld_df_lower.groupby('ft').mean()[s_chk]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee4de3a-2787-4289-9a56-20417fd07891",
   "metadata": {},
   "source": [
    "## Inundation area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9555ed-73d7-4cba-98f7-37fcf7d7843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_frac = np.zeros((3,len(setbacks), nrow,ncol))\n",
    "cell_frac_r = np.zeros((3, 100, len(setbacks)))\n",
    "\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'cell_frac_arr'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    cell_frac_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    # spatial view\n",
    "    cell_frac_all = ma.masked_invalid(cell_frac_all)\n",
    "    # median across realizations\n",
    "    cell_frac[nf] = np.median(cell_frac_all, axis=0)\n",
    "    cell_frac_r[nf] = np.sum(cell_frac_all, axis=(2,3))\n",
    "\n",
    "# mask where depth is 0\n",
    "cell_frac = ma.masked_where(cell_frac==0, cell_frac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1e59e-2c37-4822-b51d-b9d8c73e9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the cumulative recharge to the area it covers\n",
    "setback_area = str_setbacks.sum(axis=(1,2))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.5,2),dpi=300, sharex='col')\n",
    "\n",
    "wet_frac_all = pd.DataFrame()\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "\n",
    "    wet_frac = pd.DataFrame(np.nansum(cell_frac[nf], axis=(1,2))/setback_area)\n",
    "    wet_frac.columns = ['inundated_fraction']\n",
    "    wet_frac.index = setbacks[::]\n",
    "    # plot flooded area divided by setback area with setback distance for x-axis\n",
    "    ax.plot(np.nansum(cell_frac[nf], axis=(1,2))/setback_area, label='Type '+str(ft_in))\n",
    "    wet_frac_all = pd.concat((wet_frac_all, wet_frac.assign(ft=ft_in)))\n",
    "\n",
    "# set x labels for boxplots \n",
    "ax_n = ax\n",
    "plt.xticks(np.arange(0,len(setbacks)), setbacks[::], \n",
    "                      rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "plt.xlabel('Setback Distance (m)')#,y=-0.04)\n",
    "plt.ylabel('Inundated Fraction')#, x=-0.01)\n",
    "plt.legend()\n",
    "# plt.savefig(join(fig_dir, 'inundated_fraction_by_setback.tif'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c30b16-08c3-4fb0-ad56-cc295c0ae7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wet_frac_all.index.name='setback_dist_m'\n",
    "\n",
    "wet_frac_all.to_csv(join(box_dir,'figures','to_Helen','Fig07_inundated_fraction_by_setback.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d98f8d-8f41-424d-a358-63976fbaed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fractional area')\n",
    "for s in [0, 3,6, 9]:\n",
    "    # calculate fraction of inundated floodplain for median case\n",
    "    frac_sum = np.nansum(cell_frac[:, s], axis=(1,2))/str_setbacks[s].sum()\n",
    "    # subset to lower third\n",
    "    # frac_sum = np.nansum(cell_frac[:, s, :, :rch_col], axis=(1,2))/str_setbacks[s][:,:rch_col].sum()\n",
    "    print(s, frac_sum.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7bf93-e311-415c-b433-b277f7baa0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "639fbc96-24b1-4d4c-a5a9-f538b6387407",
   "metadata": {},
   "source": [
    "### Inundation fraction by reach\n",
    "The reviewer requested a plot showing inundated fraction by reach to illustrate my point that we see more inundation and recharge downstream due to loewr floodplain elevations.\n",
    "\n",
    "The reviewer also requested a plot showing the fraction of inundated HCPs by setback distance which is similar to the plot above but they requested for the entire dataset, perhaps these could be coplotted. This plotting was completed under the method figures script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788e485-e41f-440d-a725-3976e463c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "reach_frac = np.zeros((len(ft_plt),str_setbacks.shape[0], num_segs))\n",
    "# use xs_arr to translate from grid cells to reaches of the river\n",
    "for seg in np.arange(0,num_segs):\n",
    "    # compare the cumulative recharge to the area it covers\n",
    "    setback_area = str_setbacks[:, xs_arr==seg].sum(axis=1)\n",
    "    # seg=0\n",
    "    # sum the inundation fraction across cells and divide the area under each reach\n",
    "    reach_frac[:,:,seg] = np.nansum(cell_frac[:,:, xs_arr==seg],axis=2)/setback_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ebd25-a4e9-4ceb-8aa5-09393247d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(len(ft_plt),1, sharex=True, figsize=(8,6), dpi=300)\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    ax_n = ax[nf]\n",
    "    df_plt = pd.DataFrame(reach_frac[nf].transpose())\n",
    "    df_plt.index = columns = np.arange((num_segs-1)*2, -2, -2)\n",
    "    df_plt.plot(ax=ax_n, cmap='viridis', legend=False, alpha=0.7)\n",
    "\n",
    "# fig.supylabel('Inundated fraction')\n",
    "ax[-2].set_ylabel('Inundated fraction')\n",
    "ax_n.set_xlabel('Upstream distance (km)')\n",
    "xtick = np.sort(df_plt.index.values)[::2]\n",
    "ax_n.set_xticks(ticks=xtick[::2],labels=xtick[::2])\n",
    "ax_n.set_xticks(ticks=xtick, minor=True);\n",
    "\n",
    "\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "    ax_n = ax[nf]\n",
    "    ax_n.annotate('Type '+str(ft_in),xy=(0.7,0.8),xycoords='axes fraction')\n",
    "    \n",
    "fig.tight_layout(h_pad=0.5 ) #pad=0.4, w_pad=0.5,\n",
    "\n",
    "cbar_ax=ax.ravel().tolist()\n",
    "# cbar_ax = ax_n\n",
    "cbar = fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), ax=cbar_ax, \n",
    "                    # ticks=bounds[:-1]+0.5, \n",
    "                    label='Seback distance (m)',\n",
    "                    orientation='horizontal', ticks=bounds[:-1:2]+0.5, \n",
    "                   )\n",
    "cbar.set_ticklabels(setbacks[::2]);\n",
    "plt.savefig(join(fig_dir, 'supplementary - inundated_fraction_by_reach.tif'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85dcc9-2801-4081-a002-20f7fd6e87a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be1ab5bc-a404-4840-8226-f65154138d53",
   "metadata": {},
   "source": [
    "# Weighting for optimal setback\n",
    "To identify the optimal setback we can identify the location of the maximum for the parameters of interest. We want to maximize total recharge, effective recharge, inundated area and depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a5a98-4034-4e26-85dc-e78fc73b91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider a weighting scheme to balance maximum recharge with effective recharge\n",
    "# assign a weight to each setback based on the maximum recharge (0-1)\n",
    "# same procedure but for maximum effective recharge (0-1)\n",
    "# then sum the weights together and identify which setback has the maximum value\n",
    "ft_in = 2\n",
    "\n",
    "temp = eff_rch_sum[eff_rch_sum.ft==ft_in].drop(columns='ft')\n",
    "eff_temp = temp.multiply(1/temp.max(axis=0).values,axis=1)\n",
    "\n",
    "temp = rch_sum[rch_sum.ft==ft_in].drop(columns='ft')\n",
    "rch_temp = temp.multiply(1/temp.max(axis=0).values,axis=1)\n",
    "# rch_temp.transpose().boxplot()\n",
    "\n",
    "# max_temp = (eff_temp*0.5+rch_temp*0.5)\n",
    "# max_temp.transpose().boxplot()\n",
    "# plt.show()\n",
    "# max_temp.loc[200:].idxmax(axis=0).hist(bins=setbacks)\n",
    "# plt.xticks(setbacks+100, setbacks, rotation=90);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f1a77-8b83-4761-8076-f7e8965d45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation the maximum cell fraction area\n",
    "temp_c = cell_frac_r[ft_in-1] / np.reshape(cell_frac_r.max(axis=2)[ft_in-1],(-1,1))\n",
    "temp_c = pd.DataFrame(temp_c,columns=setbacks).transpose()\n",
    "\n",
    "f = h5py.File(join(data_dir,'hdf5', 'depth_avg_arr'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "d_all = f['array']['all'][:]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a14343-bfca-4e44-87c4-79ebc36fedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_arr_r = np.nanmean(d_all,axis=(2,3))\n",
    "temp_d = d_arr_r / np.reshape(d_arr_r.max(axis=1)[ft_in-1],(-1,1))\n",
    "temp_d = pd.DataFrame(temp_d, columns=setbacks).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e012c68-2ab0-4faa-a8dd-1e78067c9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wt = 0.25\n",
    "max_temp = eff_temp*wt + rch_temp*wt + temp_c*wt + temp_d*wt\n",
    "\n",
    "max_temp.transpose().boxplot()\n",
    "plt.show()\n",
    "max_temp.loc[200:].idxmax(axis=0).hist(bins=setbacks)\n",
    "plt.xticks(setbacks+100, setbacks, rotation=90);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a21c1d-5d7a-4e9e-99db-d6b7601dc620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c93d4-b68d-429d-9aa9-c7ae46996564",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nansum(cell_frac[:,s], axis=(1,2))/str_setbacks[s].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3b028-3abf-4156-a018-9074748f1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at depth by cell there is a slight overestimate of inundated area\n",
    "# (d_arr>0.1).sum(axis=(1,2))/str_setbacks[s].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a9fac-c1c4-45af-8e21-29708ea8453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.nanmean(cell_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba01bfd2-4918-4f3d-bbe7-f9aa926de0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(dpi=600)\n",
    "# im=ax.imshow(cell_frac[0])\n",
    "# plt.colorbar(im, shrink=0.5)\n",
    "# # cell_frac[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c06951-7af9-4dd7-89c2-cfce70907df8",
   "metadata": {},
   "source": [
    "# Summary statistics/relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c92a069-d3cd-4066-909b-a6449debbfe0",
   "metadata": {},
   "source": [
    "The geology is interesting because it enables us to show that across a variety of aquifer compositions there is consistency in the value of recharge with setback distance because it is driven by the mean lengths, but we aren't quantifying that because we have constant mean lengths.  \n",
    "\n",
    "One item that would be helpful is if we could make an equation to relate the expected recharge to the number of facies given a discharge? We should compare the correlation or R2 value on recharge from geology vs the flood flow to identify under which conditions the geology or flow is more limited as these relationships can be specific to a setback.\n",
    "\n",
    "- for a given setback calculate the correlation coefficient between the geologic area and the recharge. A relationship of mean flow or flow area and recharge won't work because we can only use the inflow since downstream flows are impact by the geology and we only have 3 flood types.\n",
    "\n",
    "\\* *We need to use mean flow rather than depth because flow is conservative while depth is segment dependent. The depth is more important when considering ecological thresholds*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad50196c-7448-46b3-b601-6b5131f158fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics functions\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn import datasets, linear_model\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2f67c7-4c63-46e2-9be7-2166dbf983ef",
   "metadata": {},
   "source": [
    "While the summary stats are a way to mark when the system is geology vs flow limited this doesn't directly help policy makers beyond suggesting limits based on flow limitation. For policy makers we want to suggest solutions that they can make based on the status of their system of geology/flow. How does setback distance change in a system with low to moderate to high outcroppings of coarse facie?\n",
    "- If a system has more coarse deposits then is a smaller setback more attainable? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd19280-ec41-4c16-b902-c61a0724ff51",
   "metadata": {},
   "source": [
    "- Pearson's r absolute value: .5 to 1 is strong, .3 to .5 is moderate, 0 to .3 is weak\n",
    "    - italicize r, no leading zero as maximum is 1, two significant digits is common, if reporting significance of the test then also report degrees of freedom (sample size - 2)   \n",
    "- Spearman's coefficient is defined as the Pearson coefficient between the rank variables. X, Y are converted to ranks R(X), R(Y) then pearson's r is calculated.\n",
    "- Kendall's tau is a test on whether the order of the variables aligns with the values, that is xi > xj and yi > yj to be considered concordant. The statistics then is based on the number of concordant and discordant pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf0b41f-d64e-47b1-a68d-d0007cd19a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = 6\n",
    "label='regional'\n",
    "hf_tot_df = pd.read_csv(data_dir+'surface_highflow_by_distance_'+label+'_'+str(percentile)+'.csv')\n",
    "# hf_tot_df = hf_tot_df.transpose()\n",
    "hf_tot_df.columns = hf_tot_df.columns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad078dcc-85fd-492e-9346-048cf1ea7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_in=3\n",
    "rch_corr = rch_xs_all[rch_xs_all.ft==ft_in].drop(columns=['ft']).transpose().copy()\n",
    "# rch_corr = rch_lower[rch_lower.ft==ft_in].drop(columns=['ft']).transpose().copy()\n",
    "# rch_corr = rch_scale_sum.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a7eb1-3a31-4cf3-899b-4e7b3b0062a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8dc2ef-68ed-491f-8e05-b7310f445696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_plt(x, y, ax):\n",
    "    ax.scatter(x,y)\n",
    "    # linear, regression\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x, y)\n",
    "    x_range = np.array([[x.min()], [x.max()]])\n",
    "    ax.plot(x_range, regr.predict(x_range), color='black', linewidth=3)\n",
    "    r2_val = r2_score(y, regr.predict(x))\n",
    "    ax.annotate('$r^2$: '+ str(np.round(r2_val,3)), (0.4,0.1), xycoords='axes fraction')\n",
    "    \n",
    "# fig,ax = plt.subplots()\n",
    "# s = 200\n",
    "# reg_plt(hf_tot_df[[s]].values, rch_corr[[s]].values, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ccf3a6-48fc-4883-bae8-8583be756a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis is across the realizations\n",
    "\n",
    "fig, ax = plt.subplots(4,4, figsize=(6.5,6.5), sharex='row', sharey='row')\n",
    "for n, s in enumerate(setbacks[:-1]):\n",
    "    ax_n = ax[int(n/4), n%4]\n",
    "    x = hf_tot_df[[s]].values\n",
    "    y = rch_corr[[s]].values\n",
    "    reg_plt(x, y, ax=ax_n)\n",
    "fig.supylabel('Recharge (MCM)')\n",
    "fig.supxlabel('Number of HCP cells')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37caecaa-d123-49e2-a350-a0a18c23e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ft_in=1 \n",
    "xs_fld_df = xs_fld_df_all[xs_fld_df_all.ft==ft_in].drop(columns=['ft'])\n",
    "xs_rch_df = xs_rch_df_all[xs_rch_df_all.ft==ft_in].drop(columns=['ft'])\n",
    "\n",
    "fig, ax = plt.subplots(4,4, figsize=(10,10), sharex=False, sharey=False)\n",
    "for ns, s in enumerate(setbacks[:-1]):\n",
    "    ax_n = ax[int(ns/4), ns%4]\n",
    "    # compare across segments for relationship\n",
    "    x = xs_fld_df[[ns]].values\n",
    "    y = xs_rch_df[[ns]].values\n",
    "    reg_plt(x, y, ax=ax_n)\n",
    "fig.supylabel('Recharge (MCM)')\n",
    "fig.supxlabel('Flood Depth')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398d2f5b-6740-4a9e-8c9b-f1ca2159e364",
   "metadata": {},
   "source": [
    "The linear regression helps demonstrate that the geology has a decreasing impact at higher setback distances because there is more control from the discharge loss rather than the geology. Since the linear fit is so weak it might actually be interesting to see if there is a non-signficant correlation between recharge and number of HCP cells after a certain setback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81861b88-da42-420e-b671-ab0b0fd89708",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = ['Pearson', 'Spearman','Kendall']\n",
    "def calc_corr_stats(corr_all, coarse_ref):\n",
    "    # take pearson's r\n",
    "    pr = corr_all.apply(lambda x : pearsonr(coarse_ref, x), axis=0)\n",
    "    pr.index=['r','p']\n",
    "    pr['type'] = 'Pearson'\n",
    "    sr = corr_all.apply(lambda x : spearmanr(coarse_ref, x), axis=0)\n",
    "    sr.index=['r','p']\n",
    "    sr['type'] = 'Spearman'\n",
    "    kt = corr_all.apply(lambda x : kendalltau(coarse_ref, x), axis=0)\n",
    "    kt.index=['r','p']\n",
    "    kt['type'] = 'Kendall'\n",
    "    # join data together\n",
    "    corr_out = pd.concat((pr, sr, kt))\n",
    "    return(corr_out)\n",
    "# corr_out = calc_corr_stats(corr_all, coarse_ref.num_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52654c6-f224-4187-9303-85d0c63c37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_tot_df[[s]].values\n",
    "setbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce162b-3564-4381-b34d-9a71ab582389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_corr_stats(hf_tot_df[[s]], setbacks).assign(setback=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a4851-4ae8-4e2b-aaa2-541af1af781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_out = pd.DataFrame()\n",
    "for s in setbacks:\n",
    "    corr = calc_corr_stats(rch_corr[[s]], hf_tot_df[s]).assign(setback=s)\n",
    "    corr = corr.rename(columns={s:'val'})\n",
    "                  \n",
    "    corr_out = pd.concat((corr_out, corr), axis=0)\n",
    "\n",
    "# fig, ax = plt.subplots(4,4, figsize=(6.5,6.5), sharex='row', sharey='row')\n",
    "# for n, s in enumerate(setbacks[:-1]):\n",
    "#     ax_n = ax[int(n/4), n%4]\n",
    "    # corr_plt = corr_out[corr_out.setback==s].loc['r'].set_index('type').transpose()\n",
    "corr_plt = corr_out.loc['r'].pivot_table(index='setback', values='val',  columns='type', dropna=False)\n",
    "corr_plt[tests].plot(kind='bar', rot=25)\n",
    "    # corr_plt.plot(kind='bar', ax=ax_n, rot=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4091ab2-ecdd-459a-a469-a75b9dd06073",
   "metadata": {},
   "source": [
    "The correlation plots present the same information as the linear regression that we see a lower strength of relationship between geology and recharge with greater setback distances. These low correlation coefficients are likely driven by the large areas of the domain that are above floodplain access which means the HCP area is meaningless, so it might be necessary to check this result on a localized level (variability of HCP area by XS group)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d6d72-799b-4c2f-948b-fb2b37fea3fd",
   "metadata": {},
   "source": [
    "Beyond the impact of geology, Helen was interested in the general relationship between depth/inundated area and recharge which also requires plotting by XS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f50ebcf",
   "metadata": {},
   "source": [
    "# Summary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43051fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_in = 2\n",
    "\n",
    "T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "tp_in = int(p_l_in*T_in)\n",
    "# for each setback distance and flood type\n",
    "# prsent discharge at the downstream end (avg over realizations and use peak flow)\n",
    "q_avg = Q_all[:,tp_in,s,-1].mean().round(1)\n",
    "q_std = Q_all[:,tp_in,s,-1].std().round(1)\n",
    "q_out = str(q_avg)+'±'+ str(q_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ae460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_mean(df):\n",
    "    df_avg = df.mean().round(1)\n",
    "    df_std = df.std().round(1)\n",
    "#     df_out = str(df_avg)+'±'+ str(df_std)\n",
    "    df_out = str(df_avg)+'\\u00B1'+ str(df_std)\n",
    "    return(df_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e50e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_in=1\n",
    "# f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "# rch_hf_all = f['array']['all'][:]\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa721b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# s=2\n",
    "# # present mean total recharge and std dev\n",
    "# rch_sum = rch_hf_all[:,s].sum(axis=(1,2))/1E6\n",
    "# format_mean(rch_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf8c7a",
   "metadata": {},
   "source": [
    "With the +- symbol saving to csv file causes an issue with utf-8 encoding of the csv and adds a symbol. Saving it as a text file doesn't cause an issue and the data can then be pasted into an xlsx to format for the paper. The txt file also writes the fastest.  \n",
    "The flow differencing has same standard deviation as discharge because it comes from the same data, and it only shows the inverse.  \n",
    "Flow depth can be back calculated with the discharge saved. Depth might not be a good parameter to plot because there is a big range in cross-section type, although the key reason for depth is to suggest if flow is to shallow rather than too deep so perhaps presenting mean and minimum depth is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a345b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format_mean(d_all[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75966b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_csv = open(join(fig_dir, 'summary_table.txt'), 'w', encoding=\"utf-8\")\n",
    "region='regional'\n",
    "\n",
    "for nf, ft_in in enumerate(ft_plt):\n",
    "#     for nr, region in enumerate(['local_1','local_2','local_3','regional']):\n",
    "#     max_df = max_df_all.loc[(max_df_all.region==region)&(max_df_all.ft==ft_in),'count']\n",
    "#     max_s = max_df.argmax()\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'all_flow_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    Q_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    # recharge\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'all_recharge_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    rch_hf_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    f = h5py.File(join(data_dir,'hdf5', 'peak_flow_xs_depth_'+region+'_type'+str(ft_in)+'.hdf5'), \"r\")\n",
    "    d_xs_all = f['array']['all'][:]\n",
    "    f.close()\n",
    "    T_in = int(10**flood_type.loc[ft_in,'log_no_d'])\n",
    "    p_l_in = flood_type.loc[ft_in,'pk_loc']\n",
    "    tp_in = int(p_l_in*T_in)\n",
    "#     Q_s = Q_all[:,tp_in, max_s,:].mean(axis=0)\n",
    "#     d_Q_s = Q_s[0]-Q_s[-1]\n",
    "    ## output cleaning ##\n",
    "    for s in np.arange(0,len(setbacks)):\n",
    "    #     rch_mean =  rch_mean_all.loc[(rch_mean_all.region==region)&(rch_mean_all.ft==ft_in),'mean']\n",
    "        q_out = format_mean(Q_all[:,tp_in,s,-1])\n",
    "        rch_out = format_mean(rch_hf_all[:,s].sum(axis=(1,2))/1E6)\n",
    "#         d = d_all[:,tp_in, s, :-1]\n",
    "#         d_out = str(d.mean().round(2))+' ('+ str(d.min().round(2))+'-'+ str(d.max().round(2))+')'\n",
    "        # the min, max, and mean should be taken across the segments then averaged across realizations\n",
    "        d_mean = d_xs_all[:,tp_in, s, :-1].mean(axis=1).mean()\n",
    "        d_min = d_xs_all[:,tp_in, s, :-1].min(axis=1).mean()\n",
    "        d_max = d_xs_all[:,tp_in, s, :-1].max(axis=1).mean()\n",
    "        d_out = str(d_mean.round(2))+' ('+ str(d_min.round(2))+'-'+ str(d_max.round(2))+')'\n",
    "        # summarize optimal setback distance with mean recharge and mean flow reduction\n",
    "        out = ','.join([flood_type.loc[ft_in,'Typology'],\n",
    "              str(setbacks[s]),  rch_out,\n",
    "          q_out, d_out, '\\n'])\n",
    "        f_csv.write(out)\n",
    "#         print( flood_type.loc[ft_in,'Typology'], region_names[nr],\n",
    "#               setbacks[max_s], '%.0f' %rch_mean.iloc[max_s],'%.0f' %d_Q_s)\n",
    "\n",
    "f_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd796101",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in np.arange(0,len(setbacks)):\n",
    "\n",
    "    d_mean = d_xs_all[:,tp_in, s, :-1].mean(axis=1).mean()\n",
    "    d_min = d_xs_all[:,tp_in, s, :-1].min(axis=1).mean()\n",
    "    d_max = d_xs_all[:,tp_in, s, :-1].max(axis=1).mean()\n",
    "    print('Mean %.2f'%d_mean,'min %.2f'%d_min,'max %.2f'%d_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31882bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename, dirname, join, exists\n",
    "import sys\n",
    "import glob \n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import geopandas as gpd \n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from time import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as lines\n",
    "\n",
    "# from pandas.tseries import converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca55467",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "\n",
    "# git dir\n",
    "git_dir = join(doc_dir,'GitHub')\n",
    "\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = join(dirname(doc_dir),'Box/research_cosumnes/GWFlowModel')\n",
    "\n",
    "flopy_dir = doc_dir+'/GitHub/flopy'\n",
    "if flopy_dir not in sys.path:\n",
    "    sys.path.insert(0, flopy_dir)\n",
    "import flopy \n",
    "\n",
    "import flopy.utils.binaryfile as bf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb23f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set box directory for output figures and data\n",
    "box_dir = gwfm_dir+'/Levee_setback/levee_setback_distance_analysis/'\n",
    "\n",
    "# tprogs_id = '' # original tprogs with conditioning data in output tsim\n",
    "tprogs_id = '_no_conditioning'\n",
    "\n",
    "data_dir = box_dir+ tprogs_id+'/data_output/'\n",
    "fig_dir = box_dir+tprogs_id+'/figures/'\n",
    "\n",
    "chan_dir = box_dir+'channel_data/'\n",
    "gis_dir = chan_dir+'GIS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c998042",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_dir = join(doc_dir,'GitHub')\n",
    "fxn_dir = git_dir+'/python_utilities'\n",
    "if fxn_dir not in sys.path:\n",
    "    sys.path.append(fxn_dir)\n",
    "# sys.path\n",
    "# import muskingum_recharge as mr\n",
    "\n",
    "from importlib import reload\n",
    "# reload(mr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceef794e",
   "metadata": {},
   "source": [
    "# Regional Model Connec3D input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c3094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.reshape fortran- F = first index is fastest, last is slowest, C = last is fastest, first is slowest\n",
    "# CONNEC3D assumes Z is fastest then Y then X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tprogs_id = '_no_conditioning'\n",
    "mf_tprogs_dir = gwfm_dir+'/UPW_data/tprogs_final' + tprogs_id+'/'\n",
    "tprogs_files = glob.glob(mf_tprogs_dir+'*')\n",
    "# tprogs_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cee006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z, y, x\n",
    "nlay, nrow, ncol = (320, 100,230)\n",
    "arr_dim = (nlay,nrow,ncol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dir = 'F:/WRDAPP'\n",
    "c_dir = 'C:/WRDAPP'\n",
    "\n",
    "if os.path.exists(ext_dir):\n",
    "    loadpth = ext_dir \n",
    "elif os.path.exists(c_dir):\n",
    "    loadpth = c_dir \n",
    "\n",
    "loadpth = loadpth +'/GWFlowModel/Cosumnes/levee_setback/setback_distance_analysis/'\n",
    "model_ws = loadpth+'Connec3d' + tprogs_id\n",
    "os.makedirs(model_ws, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f53c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path(fxn_dir):\n",
    "    if fxn_dir not in sys.path:\n",
    "        sys.path.append(fxn_dir)\n",
    "        \n",
    "add_path(doc_dir+'/GitHub/CosumnesRiverRecharge/tprogs_utilities')\n",
    "add_path(doc_dir+'/GitHub/CosumnesRiverRecharge/python_utilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adfecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tprogs_cleaning as tc\n",
    "import tprogs_permeameter as tp\n",
    "\n",
    "from importlib import reload\n",
    "# importlib.reload\n",
    "reload(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a basic connectivity run takes about 1 hour (7610 components), good enough in parallel with python\n",
    "# might be worth trying to compile with ifortran to speed things up\n",
    "# adding a compiler option seemed to speed things up\n",
    "# reviewing CCO output showed a bad result (didn't line up with input) reshape order='F' is not needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e7bd2",
   "metadata": {},
   "source": [
    "the runtime is incredibly long so I\"m going to remove unnecessary cells from the calculation \n",
    "drop cells above land surface and cells outside of floodplain (3,000m limit) with a buffer for lateral connectivity\n",
    "only 36 percent of coarse are within the floodplain  \n",
    "-> decided not to do this so that in the future if someone wants it then it's available on the full scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_data = np.loadtxt(gwfm_dir+'/DIS_data/dem_52_9_200m_mean.tsv')\n",
    "\n",
    "grid_sfr = gpd.read_file(gwfm_dir+'/SFR_data/final_grid_sfr/grid_sfr.shp')\n",
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n",
    "\n",
    "str_setbacks = np.zeros((nrow,ncol))\n",
    "buf_sfr = grid_sfr.copy()\n",
    "# give lateral buffer of 600 to account for mean length\n",
    "buf_sfr.geometry = grid_sfr.buffer(3800)\n",
    "grid_sfr_buf = gpd.sjoin(grid_p,buf_sfr, how='right', lsuffix = 'grid', rsuffix = 'sfr',predicate='within')\n",
    "grid_sfr_buf = grid_sfr_buf.drop_duplicates('node_grid')    \n",
    "str_setbacks[grid_sfr_buf.row_grid.values-1,grid_sfr_buf.column_grid.values-1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ce72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprogs_info = [80, -80, 320]\n",
    "\n",
    "# masked_tprogs = tc.tprogs_cut_elev(tprogs_line, dem_data, tprogs_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3364c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(join(chan_dir, 'setback_locs.hdf5'), \"r\")\n",
    "local_str_setbacks = f['setbacks']['local'][:]\n",
    "str_setbacks = f['setbacks']['regional'][:]\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771d297e",
   "metadata": {},
   "source": [
    "## Iterate and write .dat files\n",
    "On 2023-5-25 I tested the impact if we cropped data above the DEM before running connectivity as there might be lateral connecting components above ground that don't actually exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f72be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert any data above ground to the background (0)\n",
    "# bottom elevations array of tprogs\n",
    "bot_elev = np.reshape(np.flip(np.arange(-80,80,0.5)), (320, 1,1))\n",
    "bot_elev = np.repeat(np.repeat(bot_elev, 100, axis=1), 230, axis=2)\n",
    "\n",
    "# make any data above the DEM a -1 and crop out\n",
    "# conn_arr[bot_elev>dem_data] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275d61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ws, dat_nam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42731cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dat files are slow to write and are better run with multiprocess\n",
    "# write dat file input\n",
    "# for t in np.arange(0,100):\n",
    "for t in [0,9]:\n",
    "    tprogs_line = np.loadtxt(tprogs_files[t])\n",
    "    # convert any negatives representing input data to same value\n",
    "    tprogs_arr = np.abs(np.reshape(tprogs_line, (320, 100,230)))\n",
    "    conn_arr = np.zeros((320, 100,230))\n",
    "    # new array where sand, gravel (1,2) are 1-coarse and sandy mud, mud are 0-fine\n",
    "    conn_arr[(tprogs_arr == 1)|(tprogs_arr == 2)] = 1\n",
    "    # AJC 2023-5-25, make any data above the DEM (plus 1 m buffer) a 0 and crop out\n",
    "    conn_arr[bot_elev>dem_data+1] = 0\n",
    "    # AJC new 2023-4-21, because CCO don't align with distinct units\n",
    "    # change shape to be X, Y, Z for Connec3D\n",
    "    conn_arr_t = np.transpose(conn_arr)\n",
    "    # convert to z,y, x order\n",
    "    conn_line = np.reshape(conn_arr_t, (320*100*230) ) #, order='F')\n",
    "\n",
    "    dat_nam = 'r'+str(t).zfill(3)+'.DAT'\n",
    "    np.savetxt(join(model_ws,  dat_nam), conn_line.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error checking\n",
    "# tprogs_arr.shape, conn_arr_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bdc01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relatively small files so okay to run from notebook\n",
    "# write par file input\n",
    "# for t in np.arange(0,1):\n",
    "# for t in [0,9]:\n",
    "    dat_nam = 'r'+str(t).zfill(3)+'.DAT'\n",
    "    connec_id = 1\n",
    "    connec_pts = 6 # 6, 18, 26 point connectivity (faces, edge, corners)\n",
    "    # dat file name\n",
    "    # number of cells in x,y,z\n",
    "    # x,y,z cell lengths\n",
    "    # lags, Alisha recommended 30\n",
    "    out_par = [str(connec_id),str(connec_pts), dat_nam, '230 100 320', '200 200 0.5', '30']\n",
    "    out_par = '\\n'.join(out_par) +'\\n'\n",
    "\n",
    "    with open(model_ws+ '/r'+str(t).zfill(3)+'.PAR', 'w') as f:\n",
    "        f.write(out_par)\n",
    "        # output file names\n",
    "        f.write('r'+str(t).zfill(3)+'.STA\\n')\n",
    "        f.write('r'+str(t).zfill(3)+'.CCO\\n')\n",
    "        f.write('r'+str(t).zfill(3)+'.COF\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used since multiprocess works\n",
    "# write batch file input\n",
    "# with open(model_ws+ '/00_run_all_series.bat', 'w') as f:\n",
    "#     for t in np.arange(0,100):\n",
    "#         file = 'r'+str(t).zfill(3)+'.PAR'\n",
    "#         runline = 'echo '+ file +' | Connec3DLarge.exe\\n'\n",
    "#         f.write(runline) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06138329",
   "metadata": {},
   "source": [
    "## Check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "tprogs_line = np.loadtxt(tprogs_files[t])\n",
    "# convert any negatives representing input data to same value\n",
    "tprogs_arr = np.abs(np.reshape(tprogs_line, (320, 100,230)))\n",
    "conn_arr = np.zeros((320, 100,230))\n",
    "# new array where sand, gravel (1,2) are 1-coarse and sandy mud, mud are 0-fine\n",
    "conn_arr[(tprogs_arr == 1)|(tprogs_arr == 2)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tprogs_hist = np.histogram(tprogs_arr, bins=[0,1.1,2.1,3.1,4.1])\n",
    "# tprogs_hist[0]/(320*100*230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c4c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connec3D Connected Components Output file\n",
    "# cco_in = np.loadtxt(join(model_ws, 'r000.CCO'))\n",
    "cco_in = np.loadtxt(join(model_ws, 'r000.CCO'))\n",
    "# reshape to array format\n",
    "# cco = np.reshape(cco_in, arr_dim)\n",
    "# account for transposing before input\n",
    "cco = np.reshape(cco_in, np.flip(arr_dim))\n",
    "cco = np.transpose(cco)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575dbf90",
   "metadata": {},
   "source": [
    "# Process output\n",
    "I didn't do this originally but technically the output should be flipped along the y and z. Since the data for connec3d didn't use conditioning data then there isn't really a need to flip since the output should essentially be all random.\n",
    "- I did not re-run the C3D processing to remaing consistent for the setback distance analysis that there is not flipping which must be consistent when sampling for the conductivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544f0728",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_dir = gwfm_dir+'/Levee_setback/levee_setback_distance_analysis/'\n",
    "\n",
    "# tprogs_id = '' # original tprogs with conditioning data in output tsim\n",
    "# tprogs_id = '_no_conditioning'\n",
    "tprogs_id = '_no_cond_c3d'\n",
    "\n",
    "data_dir = box_dir+ tprogs_id+'/data_output/'\n",
    "fig_dir = box_dir+tprogs_id+'/figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab25339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cco_vert(cco, dem_data):\n",
    "    # identify the connected components, each has a unique number\n",
    "    z,y,x = np.where(cco>0)\n",
    "    val = cco[z,y,x]\n",
    "    # np.transpose((z,y,x,val))\n",
    "    # create a dataframe of the locations of connected components\n",
    "    df = pd.DataFrame(np.transpose((z,y,x,val)),columns=['z','y','x','cc'])\n",
    "    # find ground elevation at each connected point\n",
    "    df['dem'] = dem_data[df.y.astype(int),df.x.astype(int)]\n",
    "    # calculate elevation from tprogs layer\n",
    "    df['elev'] = 80-z*0.5\n",
    "    # check whether each layer is above land surface\n",
    "    df['above_gse'] = (df.elev > df.dem) \n",
    "    # check wehether each layer is 30 m below land surface (100 ft)\n",
    "#     df['below_30'] = (df.elev <= df.dem - 60)\n",
    "    df['below_30'] = (df.elev <= - 79)\n",
    "    df_sum = df.groupby('cc').sum()\n",
    "    # find connected components that are above ground and connect deeper than 30m below\n",
    "    df_conn = df_sum[(df_sum.above_gse>0).values & (df_sum.below_30 >0).values].index\n",
    "    # check if top and bottom connected is in cco array\n",
    "    cco_vert = np.isin(cco, df_conn)\n",
    "    return(cco_vert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cco_vert = get_cco_vert(cco, dem_data)\n",
    "# tprogs_cleaning.get_tprogs_for_elev(dem_data)\n",
    "tprogs_lay = tc.elev_to_tprogs_layers(elev=dem_data, tprogs_info=tprogs_info)\n",
    "# elev_to_tprogs_layers?\n",
    "rows = np.where(np.ones(tprogs_lay.shape)==1)[0]\n",
    "cols = np.where(np.ones(tprogs_lay.shape)==1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if comparing against cco with above land cropped\n",
    "conn_arr[dem_data<bot_elev]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0999fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this 1% doesn't change between setting bottom 30 m below to the model bottom\n",
    "# 1% of CCOs are not vertically connected\n",
    "(cco_vert>0).sum()/(320*100*230), conn_arr.sum()/(320*100*230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d929726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropped above land surface\n",
    "(cco_vert>0).sum()/(bot_elev<dem_data).sum(), conn_arr.sum()/(bot_elev<dem_data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cco_plt = np.copy(cco_vert).astype(int)\n",
    "cco_plt[cco_vert != conn_arr] = 2\n",
    "\n",
    "# plt.imshow(q_plt)\n",
    "plt.imshow(cco_plt[150])\n",
    "plt.colorbar(shrink=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90017910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conn_count(cpts, str_setbacks):\n",
    "    tic = time.time()\n",
    "#     setbacks = np.unique(str_setbacks)\n",
    "    setbacks = np.arange(0, str_setbacks.shape[0])\n",
    "    setbacks = setbacks[~np.isnan(setbacks)]*200\n",
    "    # will count total number of cells for each setback distance and for all 100 realizations\n",
    "    hf_tot = np.zeros((100,len(setbacks)))\n",
    "    # layer for each local setback\n",
    "    num_sites = len(np.unique(local_str_setbacks))-1\n",
    "    hf_tot_local = np.zeros((num_sites, 100,len(setbacks)))\n",
    "    hf_all = np.zeros((100, 100, 230)) # map high flow for each realization\n",
    "    \n",
    "    # dataframe for grouping and area analysis\n",
    "    stat_cols = ['Num_Grps','Mean','Median','Min','Max','Variance','Realization', 'Setback']\n",
    "    cell_stats_all = pd.DataFrame(np.zeros((100*len(str_setbacks),len(stat_cols))), columns=stat_cols)\n",
    "    local_cols = stat_cols+['Location']\n",
    "    cell_stats_all_local = pd.DataFrame(np.zeros((num_sites*100*len(str_setbacks),len(local_cols))), columns=local_cols)\n",
    "    \n",
    "    k=0 # counter \n",
    "    kl = 0 # local counter\n",
    "    for r in np.arange(0,100):\n",
    "        print('Realization', r, ' time since start %.2f min' %((time.time()-tic)/60), end='. ')\n",
    "        cco_in = np.loadtxt(join(model_ws, 'r'+str(r).zfill(3)+'.CCO'))\n",
    "        # reshape to array format\n",
    "#         cco = np.reshape(cco_in, arr_dim)\n",
    "        cco = np.reshape(cco_in, np.flip(arr_dim))\n",
    "        cco = np.transpose(cco)\n",
    "        cco_vert = get_cco_vert(cco, dem_data)\n",
    "        print('Percent connected %.2f '%((cco_vert>0).sum()*100/(320*100*230)))\n",
    "        # get high conductivity at ground surface\n",
    "        q_lay = np.zeros((100,230))\n",
    "        q_lay[rows,cols] = cco_vert[tprogs_lay[rows,cols],rows,cols] \n",
    "        \n",
    "        hf_all[r,:] = np.copy(q_lay)\n",
    "        # complete analysis for regional and local setbacks\n",
    "        for n in np.arange(0,len(setbacks)):\n",
    "            # overlay high flow cells with setback distance\n",
    "#             q_lay_setback = tp.overlay_hf_setback(q_lay, str_setbacks < n+1)\n",
    "            q_lay_setback = tp.overlay_hf_setback(q_lay, str_setbacks[n,:,:])\n",
    "            # calculate total cells in each setback\n",
    "            hf_tot[r,n] = q_lay_setback.sum()\n",
    "            # calculate high flow groups and summary statistics\n",
    "            cell_stats_all.iloc[k] = tp.calc_area_stats(r,n, 0, q_lay_setback, stat_cols)\n",
    "            k +=1\n",
    "            # iterate over local setbacks\n",
    "            for l in np.unique(local_str_setbacks)[1:].astype(int):\n",
    "                arr = np.zeros(local_str_setbacks[n,:,:].shape)\n",
    "                arr[local_str_setbacks[n,::]==l] = 1\n",
    "                q_lay_setback_local = tp.overlay_hf_setback(q_lay, arr)\n",
    "#                 q_lay_setback_local = overlay_hf_setback(q_lay, arr)\n",
    "                hf_tot_local[l-1,r,n] = q_lay_setback_local.sum()\n",
    "                cell_stats_all_local.iloc[kl] = tp.calc_area_stats(r,n,l, q_lay_setback_local, local_cols)\n",
    "                kl+=1\n",
    "    hf_tot_df = pd.DataFrame(hf_tot, columns = setbacks)\n",
    "    hf_tot_local = np.reshape(hf_tot_local, (num_sites*100,len(setbacks)))\n",
    "    hf_tot_local_df = pd.DataFrame(hf_tot_local, columns = setbacks)\n",
    "    hf_all_out = np.reshape(hf_all, (100*100, 230))\n",
    "    np.savetxt(data_dir+'surface_highflow_by_realization_'+str(cpts)+'.tsv', hf_all_out, delimiter = '\\t')\n",
    "    \n",
    "    # save counted high flow cells to a csv\n",
    "    hf_tot_df.to_csv(data_dir+'surface_highflow_by_distance_regional_'+str(cpts)+'.csv', index=False)\n",
    "    hf_tot_local_df.to_csv(data_dir+'surface_highflow_by_distance_local_'+str(cpts)+'.csv', index=False)\n",
    "    # save grouping analysis and area statistics\n",
    "    cell_stats_all.to_csv(data_dir+'surface_highflow_cells_statistics_regional'+str(cpts)+'.csv', index=False)\n",
    "    cell_stats_all_local.to_csv(data_dir+'surface_highflow_cells_statistics_local'+str(cpts)+'.csv', index=False)\n",
    "\n",
    "    toc = time.time()\n",
    "    print('Total time was', (toc-tic)/60, 'minutes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df7b6ac",
   "metadata": {},
   "source": [
    "The range of connected facies meeting vertical criteria is 16.5-17.5 out of 17.8 so not huge variability but not enough to be interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd12aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the two models that ran independently with new dat files was r000 and r009 which show a coarse of 16%, issue with input?\n",
    "# it's because those realizations cropped the data above land surface so they have a different default\n",
    "conn_count(6, str_setbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c73e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosumnes Model \n",
    "@author: Andrew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import time\n",
    "from scipy.stats import gmean\n",
    "\n",
    "# standard python plotting utilities\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import pyproj # for converting proj4string\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# mapping utilities\n",
    "import contextily as ctx\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run installed version of flopy or add local path\n",
    "try:\n",
    "    import flopy\n",
    "    from flopy.discretization.structuredgrid import StructuredGrid\n",
    "    from flopy.utils.reference import SpatialReference\n",
    "    from flopy.utils import Raster\n",
    "except:\n",
    "    import flopy\n",
    "    fpth = os.path.abspath(os.path.join('..', '..'))\n",
    "    sys.path.append(fpth)\n",
    "    from flopy.discretization.structuredgrid import StructuredGrid\n",
    "    from flopy.utils.reference import SpatialReference\n",
    "    from flopy.utils import Raster\n",
    "from flopy.utils.gridgen import Gridgen\n",
    "from flopy.utils import OptionBlock\n",
    "import flopy.utils.binaryfile as bf\n",
    "\n",
    "\n",
    "print(sys.version)\n",
    "print('numpy version: {}'.format(np.__version__))\n",
    "print('matplotlib version: {}'.format(mpl.__version__))\n",
    "print('flopy version: {}'.format(flopy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transient -> might want to think about making SP1 steady\n",
    "end_date = '2018-01-2'\n",
    "# end_date = '2018-01-02'\n",
    "strt_date = '2018-01-01'\n",
    "\n",
    "dates = pd.date_range(strt_date, end_date)\n",
    "\n",
    "# The number of periods is the number of dates \n",
    "nper = len(dates)+1\n",
    "\n",
    "# Each period has a length of one because the timestep is one day, have the 1st stress period be out of the date range\n",
    "# need to have the transient packages start on the second stress period\n",
    "perlen = np.ones(nper)\n",
    "# Steady or transient periods\n",
    "steady = np.zeros(nper)\n",
    "steady[0] = 1 # first period is steady state, rest are transient\n",
    "steady = steady.astype('bool').tolist()\n",
    "# Reduce the number of timesteps to decrease run time\n",
    "nstp = np.ones(nper)*np.append(np.ones(1),6*np.ones(nper-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maribeth's model parameters, had to switch nrow and ncol due to her issue in xul, yul\n",
    "nrow=100\n",
    "ncol=230\n",
    "delr=200\n",
    "delc=200\n",
    "rotation=52.9\n",
    "\n",
    "# The number of layers should be 1 for the Mehrten formation, 1 for the laguna plus the number of TPROGS layers,\n",
    "# where the Laguna formation will be clipped by the TPROGS layers\n",
    "nlay = 320\n",
    "\n",
    "\n",
    "# There is essentially no difference bewtween WGS84 and NAD83 for UTM Zone 10N\n",
    "# proj4_str='EPSG:26910'\n",
    "proj4_str='+proj=utm +zone=10 +ellps=WGS84 +datum=WGS84 +units=m +no_defs '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up directory referencing\n",
    "# Package data\n",
    "git_dir = os.getcwd()\n",
    "while os.path.basename(git_dir) != 'GitHub':\n",
    "    git_dir = os.path.dirname(git_dir)\n",
    "usr_dir = os.getcwd()\n",
    "while os.path.basename(usr_dir) != 'Users':\n",
    "    temp = os.path.basename(usr_dir)\n",
    "    usr_dir = os.path.dirname(usr_dir)\n",
    "usr_dir = usr_dir+'/'+temp\n",
    "\n",
    "# gwfm_dir = '\\\\'.join(str.split(git_dir,'\\\\')[0:3])+ '/Box/research_cosumnes/GWFlowModel'\n",
    "gwfm_dir = usr_dir + '/Box/research_cosumnes/GWFlowModel'\n",
    "print(git_dir, gwfm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flopy.utils.geometry import Polygon, LineString, Point\n",
    "# Original model domain, 44.7 deg angle\n",
    "# m_domain = gpd.read_file(gwfm_dir+'\\\\GWModelDomain_UTM10N\\\\GWModelDomain_Rec_UTM10N.shp')\n",
    "# New model domain 52.9 deg\n",
    "m_domain = gpd.read_file(gwfm_dir+'/DIS_data/NewModelDomain\\\\GWModelDomain_52_9deg_UTM10N_WGS84.shp')\n",
    "\n",
    "# Need to check this when changing model domains\n",
    "xul, yul = list(m_domain.geometry.values[0].exterior.coords)[1]\n",
    "list(m_domain.geometry.values[0].exterior.coords)\n",
    "# m_domain.geometry.values[0].exterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Flopy GitHub \"Technically you need to create both a SpatialReference object and a ModelGrid object, but in practice the code looks very similar and can easily be implemented in one line.\"\n",
    "WGS84 Zone 10N has EPSG: 32610  \n",
    "Lower left corner of model is   \n",
    "Zone 10 N  \n",
    "Easting: 661211.18 m E  \n",
    "Northing: 4249696.50 m N  \n",
    "angle is approximate 53 degrees  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Users may change loadpath \n",
    "The default loadpath is set to an existing external hard drive for Andrew as F://\n",
    "If the script doesn't find an external harddrive F:// then it will default to the C:// Drive in WRDAPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dir = 'F:/WRDAPP'\n",
    "c_dir = 'C:/WRDAPP'\n",
    "\n",
    "if os.path.exists(ext_dir):\n",
    "    loadpth = ext_dir \n",
    "elif os.path.exists(c_dir):\n",
    "    loadpth = c_dir \n",
    "\n",
    "loadpth = loadpth +'/GWFlowModel/Cosumnes/levee_setback/setback_distance_analysis/'\n",
    "\n",
    "model_ws = loadpth+'Permeameter_for_velocity'\n",
    "tprogs_id= '' # tprogs data with conditioning data in the model\n",
    "tprogs_id = '_no_conditioning' # tprogs without conditioining data in the model\n",
    "\n",
    "model_ws = model_ws+tprogs_id + '_VHG_0.01'\n",
    "\n",
    "print(model_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple model to speed up loading but still be able to apply functions\n",
    "nlay, nrow, ncol = (320, 100,230)\n",
    "delc, delr= (200, 200)\n",
    "rotation=52.9\n",
    "\n",
    "m = flopy.modflow.Modflow(modelname = 'MF', exe_name = 'mf2005', \n",
    "                          version = 'mf2005', model_ws=model_ws)\n",
    "#lenuni = 1 is in ft, lenuni = 2 is in meters\n",
    "# itmuni is time unit 5 = years, 4=days, 3 =hours, 2=minutes, 1=seconds\n",
    "dis = flopy.modflow.ModflowDis(nrow=nrow, ncol=ncol, nlay=nlay, delr=delr, delc=delc,\n",
    "                               model=m, lenuni = 2, itmuni = 4,\n",
    "#                               nper = nper, perlen=perlen, nstp=nstp, steady = steady,\n",
    "                              )\n",
    "xll, yll = 645500.0, 4227700.0\n",
    "m.modelgrid.set_coord_info(xoff=xll, yoff=yll, proj4='EPSG:32610', angrot=rotation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = flopy.modflow.Modflow(modelname = 'MF', exe_name = 'MODFLOW-NWT.exe', \n",
    "#                           version = 'mfnwt', model_ws=model_ws)\n",
    "m = flopy.modflow.Modflow(modelname = 'MF', exe_name = 'mf2005', \n",
    "                          version = 'mf2005', model_ws=model_ws)\n",
    "#lenuni = 1 is in ft, lenuni = 2 is in meters\n",
    "# itmuni is time unit 5 = years, 4=days, 3 =hours, 2=minutes, 1=seconds\n",
    "dis = flopy.modflow.ModflowDis(nrow=nrow, ncol=ncol, \n",
    "                               nlay=nlay, delr=delr, delc=delc,\n",
    "                               model=m, lenuni = 2, itmuni = 4,\n",
    "                               xul = xul, yul = yul,rotation=rotation, proj4_str=proj4_str,\n",
    "                              nper = nper, perlen=perlen, nstp=nstp, steady = steady,\n",
    "                              start_datetime = strt_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.modelgrid.set_coord_info(xoff=xoff, yoff=yoff, proj4='EPSG:32610', angrot=angrot)\n",
    "mg = m.modelgrid\n",
    "# Write model grid to shapefile for later use\n",
    "# mg.write_shapefile(gwfm_dir+'/DIS_data/grid/grid.shp', epsg = '32610')\n",
    "# mg.write_shapefile(gwfm_dir+'/DIS_data/44_7_grid/44_7_grid.shp', epsg = '32610')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model grid as geopandas object\n",
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n",
    "# grid_p = gpd.read_file(gwfm_dir+'/DIS_data/44_7_grid/44_7_grid.shp')\n",
    "# print(gwfm_dir)\n",
    "\n",
    "# Find Michigan Bar location\n",
    "# mb_gpd = sensors[sensors.Sensor_id == \"MI_Bar\"]\n",
    "# mb_grid = gpd.sjoin(mb_gpd, grid_p, how = 'left', op = 'intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vertexes of model domain\n",
    "# ll = mg.get_coords(0, 0) #lower left\n",
    "# lr = mg.get_coords(nrow*delr, 0) #lower right\n",
    "# ur = mg.get_coords(nrow*delr, ncol*delc) #upper right\n",
    "# ul = mg.get_coords(0, ncol*delc) #upper left\n",
    "ll = mg.get_coords(0, 0) #lower left\n",
    "lr = mg.get_coords(0, nrow*delr) #lower right\n",
    "ur = mg.get_coords(ncol*delc, nrow*delr) #upper right\n",
    "ul = mg.get_coords(ncol*delc, 0) #upper left\n",
    "print(ll, lr, ur, ul)\n",
    "\n",
    "# Shapefile of model bounds\n",
    "from shapely.geometry import Polygon\n",
    "vertices = np.stack(np.asarray((ll,lr, ur, ul)))\n",
    "vertices\n",
    "geoms = Polygon(vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(gwfm_dir+'\\DIS_data\\dem_44_7_200m_nearest.tsv', dem_data, delimiter = '\\t')\n",
    "\n",
    "# Based on Maribeth's grid aligned with Alisha's TPROGS model\n",
    "# dem_data = np.loadtxt(gwfm_dir+'\\DIS_data\\dem_52_9_200m_nearest.tsv', delimiter = '\\t')\n",
    "dem_data = np.loadtxt(gwfm_dir+'\\DIS_data\\dem_52_9_200m_linear.tsv', delimiter = '\\t')\n",
    "# dem_data = np.loadtxt(gwfm_dir+'\\DIS_data\\dem_44_7_200m_linear_missing_right_corner.tsv', delimiter = '\\t')\n",
    "\n",
    "# dem_data = np.loadtxt(gwfm_dir+'\\DIS_data\\dem_44_7_200m_nearest.tsv', delimiter = '\\t')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.heatmap(dem_data, cmap = 'viridis', vmin = 0,square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alter existing botm for just TPROGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rectangular set up of botm from -80 to 80\n",
    "botm = np.zeros((nlay, nrow, ncol))\n",
    "for n, elev in enumerate(np.arange(-80,80,0.5)):\n",
    "    botm[len(botm)-1-n,:,:] = elev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the elevation of the top layer based on the DEM\n",
    "m.dis.top = 80\n",
    "# Bottom of model based on geology\n",
    "m.dis.botm = botm\n",
    "chk = dis.check()\n",
    "chk.summary_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ibound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified ibound, only no flow cell if it is below the bottom of the Mehrten Formation\n",
    "# Specify no flow boundary based on rough approx of geology (upper basin volcanics)\n",
    "ibound = np.ones([nlay, nrow,ncol])\n",
    "strt = np.ones((nlay, nrow, ncol), dtype = np.float32)\n",
    "# The model should start in hydraulic connection\n",
    "strt[:,:,:] = m.dis.top[:,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic package, BAS\n",
    "\n",
    "# ibound < 0 is constant head\n",
    "# ibound = 0 is inactive cell\n",
    "# ibound > 0 is active cell\n",
    "# strt is array of starting heads\n",
    "bas = flopy.modflow.ModflowBas(model = m, ibound=ibound, strt = strt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas.check()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in TPROGS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"C:\\Users\\ajcalder\\Box\\research_cosumnes\\Large_TPROGS_run\\TPROGS_realizations\\tsim_Cosumnes_Full_Model.asc1\"\n",
    "# create tprogs directory reference to 100 large tprogs runs ascii files\n",
    "# tprogs_dir = os.path.dirname(gwfm_dir)+'/Large_TPROGS_run/Archive/TPROGS_realizations/'\n",
    "# tprogs_dir = os.path.dirname(gwfm_dir)+'/Large_TPROGS_run/TPROGS_realizations/'\n",
    "# tprogs_dir = os.path.dirname(gwfm_dir)+'/Large_TPROGS_run/New_realizations/'\n",
    "\n",
    "# # get all file names\n",
    "# tprogs_files = glob.glob(tprogs_dir+'*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_tprogs_dir = gwfm_dir+'/UPW_data/tprogs_final' + tprogs_id+'/'\n",
    "tprogs_files = glob.glob(mf_tprogs_dir+'*')\n",
    "# tprogs_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gel_dir = gwfm_dir+'/UPW_data'\n",
    "if 'ZonePropertiesInitial.csv' in os.listdir(model_ws):\n",
    "    params = pd.read_csv(model_ws+'/ZonePropertiesInitial.csv',index_col='Zone')\n",
    "else:\n",
    "    params = pd.read_csv(gel_dir+'/ZonePropertiesInitial.csv',index_col='Zone')\n",
    "    params.to_csv(model_ws+'/ZonePropertiesInitial.csv')\n",
    "# convert from m/s to m/d\n",
    "params['K_m_d'] = params.K_m_s * 86400    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tprogs_cut_elev(tprogs_line, dem_data, **kwargs):\n",
    "    rows = kwargs.get('rows', np.where(np.ones(dem_data.shape)==1)[0])\n",
    "    cols = kwargs.get('cols', np.where(np.ones(dem_data.shape)==1)[1])\n",
    "    tprogs_arr = np.reshape(tprogs_line, (320, 100,230))\n",
    "    tprogs_c = np.reshape(tprogs_arr[:, rows,cols],\n",
    "                             (tprogs_arr.shape[0],dem_data.shape[0],dem_data.shape[1]))\n",
    "    tprogs_elev = np.copy(tprogs_c)\n",
    "    # the bottom layer of the tprogs model is at -50 m amsl and the top layer is 50 m amsl\n",
    "    t = 0\n",
    "    for k in np.arange(-80,80,0.5):\n",
    "        tprogs_elev[t,dem_data<k]= np.NaN\n",
    "        t+=1\n",
    "    masked_tprogs = ma.masked_invalid(tprogs_elev)\n",
    "    return(masked_tprogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.ma as ma\n",
    "def tprogs_cut_saturated(tprogs,kriged):\n",
    "    tprogs_unsat = np.copy(tprogs)\n",
    "    # the bottom layer of the tprogs model is at -80 m amsl and the top layer is 80 m amsl\n",
    "    # set any tprogs cells below the average fall water table depth as np.nan\n",
    "    t = 0\n",
    "    for k in np.arange(-80,80,0.5):\n",
    "        tprogs_unsat[t,kriged>k]= np.NaN\n",
    "        t+=1\n",
    "    masked_tprogs = ma.masked_invalid(tprogs_unsat)\n",
    "    return(masked_tprogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_param(tprogs):\n",
    "    tprogs[tprogs<0] *= -1\n",
    "    tprogs = tprogs.astype(float)\n",
    "    # flip tprogs model along z axis to match modflow definition of 0 as top (TPROGS says 0 is bottom)\n",
    "    tprogs = np.flip(tprogs,axis=0)\n",
    "    tprogs_K = np.copy(tprogs)\n",
    "    tprogs_Sy = np.copy(tprogs)\n",
    "    tprogs_Ss = np.copy(tprogs)\n",
    "    # hydraulic parameters from fleckenstein 2006\n",
    "    # I-IV gravel, sand, muddy sand, mud\n",
    "    # K in m/s, Sy, Ss\n",
    "    for n in np.arange(1,5):\n",
    "        tprogs_K[tprogs==n]= params.loc[n,'K_m_d']\n",
    "    for n in np.arange(1,5):\n",
    "        tprogs_Sy[tprogs==n]= params.loc[n,'Sy']\n",
    "    for n in np.arange(1,5):\n",
    "        tprogs_Ss[tprogs==n]= params.loc[n,'Ss']\n",
    "            \n",
    "    return(tprogs_K,tprogs_Sy,tprogs_Ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0\n",
    "tprogs_line = np.loadtxt(tprogs_files[t])\n",
    "tprogs_arr = np.reshape(tprogs_line, (320, 100,230))\n",
    "\n",
    "K, Sy, Ss= int_to_param(tprogs_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first layer starts at -10 m which corresponds to 20 layers below 0\n",
    "# 0m AMSL is 160 layers above the bottom of tprogs which ends up giving 160-20 is layer 140 or 139 for 0 based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LPF/UPW package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elev_to_tprogs_layers(elev):\n",
    "    # function to get the tprogs layers based on the given elevation\n",
    "    # layer 0 is 80 meters, layer 1 is 79.5 meters, layer -1 is -80 meters\n",
    "    elev_05 = np.round((elev) * 2) / 2 # dem rounded to the nearest 0.5\n",
    "    elev_05[elev_05 >= 80] = 80# any elevation above 80 m is set to 80\n",
    "    elev_indices = 160 - elev_05*2 # subtract the calculated row from 160 to get to 0 at 160 and 320 and -160\n",
    "    return(elev_indices.astype(int))\n",
    "    \n",
    "def get_tprogs_for_elev(tprogs_arr, top_elev, bot_elev, **kwargs):\n",
    "    rows = kwargs.get('rows', np.where(np.ones(top_elev.shape)==1)[0])\n",
    "    cols = kwargs.get('cols', np.where(np.ones(top_elev.shape)==1)[1])\n",
    "    top_indices = elev_to_tprogs_layers(top_elev)\n",
    "    bot_indices = elev_to_tprogs_layers(bot_elev)\n",
    "    # find tprogs layer for desired rows and columns\n",
    "    top_indices = top_indices[rows, cols].astype(int)\n",
    "    bot_indices = bot_indices[rows, cols].astype(int)\n",
    "    # the first row of the array will be the top layer and will progress downward until the max bottom is reached\n",
    "    # with NaNs for rows,cols where there are less layers indexed than the max\n",
    "    tprogs_subset = np.full(shape = (np.max(bot_indices - top_indices).astype(int), len(rows)),\n",
    "                       fill_value = np.nan, dtype = float)\n",
    "    max_layers = np.max(bot_indices - top_indices)\n",
    "    for k in np.arange(0,max_layers):\n",
    "        layexist = (bot_indices-top_indices) > k # pick where data should be referenced\n",
    "        tprogs_subset[k, layexist] = tprogs_arr[top_indices[layexist]+k, rows[layexist], cols[layexist]]\n",
    "    # return grabbed data in array format if entire domain was used\n",
    "    if len(rows) == top_elev.shape[0]*top_elev.shape[1]:\n",
    "        tprogs_subset = np.reshape(tprogs_subset, (max_layers, top_elev.shape[0], top_elev.shape[1]))\n",
    "    # mask na values so they don't cause issues with gmean or hmean\n",
    "    tprogs_subset = ma.masked_array(tprogs_subset, mask = np.isnan(tprogs_subset))\n",
    "    return(tprogs_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk = np.zeros(botm.shape)\n",
    "vka = np.zeros(botm.shape)\n",
    "sy = np.zeros(botm.shape)\n",
    "ss = np.zeros(botm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # take of 2 for the bottom layers and 1 for the unsat zone layer up top\n",
    "# # for tprogs arrays 0 is the bottom of the model, so flipping on z will fix\n",
    "hk = np.flip(K,axis=0)\n",
    "#need to set anisotropy for TPROGs, may not matter for this\n",
    "vka = np.flip(K,axis=0)\n",
    "sy = np.flip(Sy,axis=0)\n",
    "ss = np.flip(Ss,axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuff breccia is very dense, hard and low water yielding. It is supposedly responsible for the many \"haystack\" hills in the eastern part of the county\n",
    "\n",
    "DWR report has a few final well pumping rates, drawdowns and specific capacities but limited.\n",
    "\n",
    "Fleckenstein et al. 2006 found the Mehrten had\n",
    "Kh = 1 to 1.8 x10^-5 m/s\n",
    "Kv = 1 to 1.8 x10^-7 m/s\n",
    "Sy = 0.15 to 0.2\n",
    "Ss = 1e-4 to 1e-3 m^-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layvka 0 means vka is vert K, non zero means its the anisotropy ratio between horiz and vert\n",
    "layvka = 0\n",
    "\n",
    "# LAYTYP MUST BE GREATER THAN ZERO WHEN IUZFOPT IS 2\n",
    "# 0 is confined, >0 convertible, <0 convertible unless the THICKSTRT option is in effect\n",
    "# laytyp = np.ones(nlay)  \n",
    "laytyp = np.zeros(nlay)\n",
    "# Laywet must be 0 if laytyp is confined laywet = [1,1,1,1,1]\n",
    "laywet = np.zeros(len(laytyp))\n",
    "laywet[laytyp==1] = 1\n",
    "#ipakcb = 55 means cell-by-cell budget is saved because it is non zero (default is 53)\n",
    "\n",
    "# until upscaling is begun then vertical and horiz K are the same for TPROGS\n",
    "# upw = flopy.modflow.ModflowUpw(model = m, hk =hk, layvka = layvka, vka = hk, sy=sy, ss=ss,\n",
    "#             laytyp=laytyp, ipakcb=55)\n",
    "\n",
    "lpf = flopy.modflow.ModflowLpf(model = m, hk =hk, layvka = layvka, vka = hk, sy=sy, ss=ss,\n",
    "                               laytyp=laytyp, laywet = laywet, ipakcb=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHD Package Time variant head\n",
    "May need to remove Mehrten formation and leave Laguna as bottom to avoid having very low conductivity layer causing water mounding, but still need Laguna formation to balance out the layer in the bottom layer with TPROGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chd = flopy.modflow.ModflowChd(model=m,ipakcb=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model top constant head boundary\n",
    "chd_df = grid_p.copy()\n",
    "chd_df = chd_df.drop(['geometry','node'],axis=1)\n",
    "chd_df.row -= 1\n",
    "chd_df.column -=1\n",
    "chd_df['layer'] = 0\n",
    "chd_df['head'] = m.dis.top.array[chd_df.row, chd_df.column]\n",
    "# model bottom constant head boundary\n",
    "\n",
    "chd_bot = chd_df.copy()\n",
    "chd_bot.layer = m.dis.nlay-1\n",
    "# if head at bottom = -80 m then there is a head gradient of 1\n",
    "chd_bot['head'] = m.dis.botm.array[chd_bot.layer[0], chd_bot.row, chd_bot.column]\n",
    "# for a head gradient of 0.1 the head at the bottom must be 64m\n",
    "# h = 80 - 0.1*160\n",
    "h = 80 - 0.01*160 # check to see impact of lower gradient\n",
    "chd_bot['head'] = h\n",
    "\n",
    "chd_df = chd_df.append(chd_bot)\n",
    "\n",
    "# prep format for MF input: layer, row, column, shead, ehead\n",
    "chd_arr = chd_df.loc[:,['layer','row','column','head','head']].values\n",
    "chd.stress_period_data =  {0: chd_arr}\n",
    "chd.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output control\n",
    "# default unit number for heads is 51, cell by cell is 53 and drawdown is 52\n",
    "# (0,0) is (stress period, time step)\n",
    "\n",
    "# For later model runs when all the data is needed to be saved\n",
    "spd = { (j,0): ['save head', 'save budget'] for j in np.arange(0,nper,1)}\n",
    "\n",
    "# get the first of each month to print the budget\n",
    "month_intervals = (pd.date_range(strt_date,end_date, freq=\"MS\")-pd.to_datetime(strt_date)).days\n",
    "\n",
    "for j in month_intervals:\n",
    "    spd[j,0] = ['save head', 'save budget','print budget']\n",
    "    \n",
    "oc = flopy.modflow.ModflowOc(model = m, stress_period_data = spd, compact = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.version = 'mfnwt'\n",
    "# m.exe_name = 'mf-nwt.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcg = flopy.modflow.ModflowPcg(model = m)\n",
    "# nwt = flopy.modflow.ModflowNwt(model= m)\n",
    "# thickfact: portion of cell thickness used for smoothly adjusting storage and conductance coefficients to zero (default is 1e-5)\n",
    "# linmeth (linear method): 1 for GMRES and 2 for XMD (1 is default)\n",
    "# iprnwt: flag whether additional info about solver convergence will be printed to the main listing file (default is 0)\n",
    "# ibotav: flag whether corretion will be made to gw head relative to cell-bottom if surrounded by dry cells.\n",
    "# 1 = corrections and  0 = no correction (default is 0)\n",
    "# options: specify comlexity of solver. SIMPLE : default solver for linear models, MODERATE for moderately nonlinear models,\n",
    "# COMPLEX for highly nonlinear models (default is COMPLEX)\n",
    "# Continue: if model fails to converge during a time step it will continue to solve the next time step (default is False) \n",
    "# epsrn (XMD) is the drop tolerance for preconditioning (default is 1E-4)\n",
    "# hclosexmd (XMD) head closure criteria for inner (linear) iterations (default 1e-4)\n",
    "\n",
    "# solver = flopy.modflow.ModflowNwt(model = m, headtol=0.01, fluxtol=500, maxiterout=200, thickfact=1e-05, \n",
    "#                                linmeth=1, iprnwt=1, ibotav=0, options='MODERATE', Continue=False,\n",
    "#                                maxbackiter=50, backtol=1.1, maxitinner=50, ilumethod=2, \n",
    "#                                levfill=5, stoptol=1e-10, msdr=15, iacl=2, norder=1, level=5, north=7, \n",
    "#                                iredsys=0, rrctols=0.0, idroptol=1, epsrn=0.0001, hclosexmd=0.0001, \n",
    "#                                mxiterxmd=50, extension='nwt', unitnumber=27)\n",
    "\n",
    "# solver = flopy.modflow.ModflowNwt(model = m,options='MODERATE', Continue=False,\n",
    "#                                extension='nwt', unitnumber=28, filenames='MF.nwt.out')\n",
    "\n",
    "# GMG is more successful than pcg which is fine for steady state model\n",
    "# mxiter, max outer, iiter = max inner, hclose = head change criterion for convergence, \n",
    "# rclose = residual criterion for convergence\n",
    "\n",
    "# solver = flopy.modflow.ModflowGmg(model = m, mxiter=50, iiter=30, hclose = 1e-5, rclose = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nwt.write_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_outer = 200\n",
    "max_inner = 100\n",
    "# iter_mo max outer iters, ter_mi = max inner iters, close_r residual criterion for stopping iteration\n",
    "# close_h is alternate criterion for nonlinear problem, and is head closure which should be smaller than residual closer\n",
    "# ipunit =0 means no info on solver, ipunit=1 means output about solver issues is written\n",
    "# if iter_mo >1 then closer_r is used not close_h and closer_r is compared to \n",
    "# the square root of the inner product of the residuals (the residual norm)\n",
    "# adamp =0 is std damping, adamp=1 is adaptive damping that further decreases or increases damping based on picard\n",
    "# iteration sucess\n",
    "#adamp is 0.7 to resolve issues with heads oscillating near solution +1 m\n",
    "# damp_lb = lower bound, rate_d is rate of increase of damping based picard iteration success\n",
    "\n",
    "solver = flopy.modflow.ModflowPcgn(m, iter_mo = max_outer, iter_mi=max_inner, close_r=1e-01, close_h=1e-02, ipunit=28) \n",
    "#                                 relax = 0.99, ifill=1)\n",
    "#                                adamp=1, damp=0.7, damp_lb=0.1, rate_d=0.01)\n",
    "\n",
    "\n",
    "# mxiter = max outer iterations, iter1 = max inner iterations\n",
    "# solver = flopy.modflow.ModflowPcg(m, mxiter = max_outer, iter1=max_inner, rclose=1e-01, hclose=1e-03)\n",
    "#                                adamp=1, damp=0.7, damp_lb=0.1, rate_d=0.01)\n",
    "\n",
    "\n",
    "# solver = flopy.modflow.ModflowDe4(m, itermx = max_inner, hclose=1E-2)\n",
    "# solver = flopy.modflow.ModflowSip(m, mxiter = max_inner, hclose=1e-02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver.write_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.exe_name = 'mf2005.exe' #MODFLOW-NWT.exe\n",
    "# m.version = 'mf2005' #mfnwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_package_list()\n",
    "# m.remove_package('DATA')\n",
    "# m.remove_package('LAK')\n",
    "# m.remove_package('WEL')\n",
    "# m.remove_package('RCH')\n",
    "# m.remove_package('NWT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m.check()\n",
    "# lak.check()\n",
    "# upw.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadpth = 'C:/WRDAPP/GWFlowModel/Cosumnes_Blodgett_10yr/'\n",
    "# model_ws = loadpth+'WEL_SFR_RCH_layercake'\n",
    "# m = flopy.modflow.Modflow.load('MF.nam',model_ws = model_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.model_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the MODFLOW data files\n",
    "m.write_input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33fc88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "from os.path import join, exists, dirname, basename\n",
    "import sys\n",
    "import glob\n",
    "from importlib import reload\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import hmean, gmean\n",
    "\n",
    "# import calendar\n",
    "import time\n",
    "\n",
    "# standard python plotting utilities\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import pyproj # for converting proj4string\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# mapping utilities\n",
    "import contextily as ctx\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b65f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ajcalder/Box/research_cosumnes/GWFlowModel'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel'\n",
    "gwfm_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c97c05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path(fxn_dir):\n",
    "    \"\"\" Insert fxn directory into first position on path so local functions supercede the global\"\"\"\n",
    "    if fxn_dir not in sys.path:\n",
    "        sys.path.insert(0, fxn_dir)\n",
    "# flopy github path - edited\n",
    "add_path(doc_dir+'/GitHub/flopy')\n",
    "import flopy \n",
    "\n",
    "# other functions\n",
    "py_dir = join(doc_dir,'GitHub/CosumnesRiverRecharge/python_utilities')\n",
    "add_path(py_dir)\n",
    "\n",
    "from mf_utility import get_layer_from_elev\n",
    "from map_cln import gdf_bnds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a97d8417",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = join(dirname(doc_dir),'Box','SESYNC_paper1')\n",
    "data_dir = join(proj_dir, 'model_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "636f9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_dir = 'C://WRDAPP/GWFlowModel'\n",
    "run_dir = 'F://WRDAPP/GWFlowModel'\n",
    "\n",
    "# loadpth = run_dir +'/Cosumnes/levee_setback/streamflow/'\n",
    "# # model_nam = 'setback_streamflow'\n",
    "# model_nam = 'historical_streamflow'\n",
    "\n",
    "loadpth = run_dir +'/Cosumnes/Regional/'\n",
    "# model_nam = 'setback_streamflow'\n",
    "model_nam = 'historical_simple_geology'\n",
    "\n",
    "base_model_ws = loadpth+model_nam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d9cf212",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = flopy.modflow.Modflow.load('MF.nam', model_ws= base_model_ws, \n",
    "                                exe_name='mf-owhm', version='mfnwt')\n",
    "\n",
    "nrow,ncol,nlay,delr,delc = (m.dis.nrow, m.dis.ncol, m.dis.nlay, m.dis.delr, m.dis.delc)\n",
    "m.model_ws = loadpth + 'crop_modflow'\n",
    "\n",
    "if 'LPF' in m.get_package_list():\n",
    "    gel_nam = 'LPF'\n",
    "else:\n",
    "    gel_nam = 'UPW'\n",
    "gel = m.__getattr__(gel_nam)\n",
    "\n",
    "# doesn't change between realizations\n",
    "gel.write_file()\n",
    "# test to see if model will run with longer itemp, owhm might auto correct\n",
    "m.chd.write_file()\n",
    "m.ghb.write_file()\n",
    "\n",
    "m.nwt.write_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2a570dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model grid as geopandas object\n",
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4f54186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_data = np.copy(m.dis.top.array)\n",
    "botm = np.copy(m.dis.botm.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "37177af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "uzf_dir = join(gwfm_dir, 'UZF_data')\n",
    "nrow_p, ncol_p = 100,230\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "767f05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wel_dir = join(gwfm_dir, 'WEL_data')\n",
    "uzf_dir = join(gwfm_dir, 'UZF_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf14122",
   "metadata": {},
   "source": [
    "Write static modflow files into the main directory including LPF, GHB, CHD. LPF (21 MB) will not need to be written as there is no dependence on stress periods. GHB, CHD and SFR (20 MB) will need to be overwritten or saved multiple times as they have a change due to stress periods with ITMP. Pre-processing and writing output for each of these will save runtime later, but take up about 1.5 GB of storage.\n",
    "\n",
    "\n",
    "The RCH package is 492 MB and well package is 1.59 GB but these file sizes will be subdivided for each period so won't take up much more storage than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee3fdc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-10-01 00:00:00 2020-09-30T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "all_strt_date = pd.to_datetime(m.dis.start_datetime)\n",
    "all_dates = all_strt_date + (m.dis.perlen.array.cumsum()-1).astype('timedelta64[D]')\n",
    "all_end_date = all_dates[-1]\n",
    "print(all_strt_date, all_end_date)\n",
    "months = pd.date_range(all_strt_date, all_end_date, freq='MS')\n",
    "years = pd.date_range(all_strt_date, all_end_date, freq='YS').year.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de961263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ymd2dt(year, month, day):\n",
    "    date = pd.to_datetime(str(year)+'-'+ month.astype(str)+'-'+day.astype(str))\n",
    "    return(date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "485fd590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose crops on first day of year\n",
    "month_crop = pd.Series(1)\n",
    "day_crop = pd.Series(1)\n",
    "\n",
    "# load summary excel sheet on irrigation optimization\n",
    "# this will specify the date ranges to run and pause\n",
    "fn = join(data_dir,'static_model_inputs.xlsx')\n",
    "season = pd.read_excel(fn, sheet_name='Seasons', comment='#')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2d964940",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify dates where modflow will start \n",
    "all_run_dates = pd.DataFrame()\n",
    "# yn = 0\n",
    "# y = years[yn]\n",
    "for y in years:\n",
    "    run_dates = ymd2dt(y, season.month_run, season.day_run)\n",
    "    run_dates = run_dates.drop_duplicates().sort_values()\n",
    "    run_dates = pd.DataFrame(run_dates).assign(use='irrigation')\n",
    "    crop_date = ymd2dt(y, month_crop, day_crop)\n",
    "    crop_date = pd.DataFrame(crop_date).assign(use='crop')\n",
    "    all_run_dates = pd.concat((all_run_dates, crop_date, run_dates))\n",
    "    \n",
    "all_run_dates = pd.concat((pd.DataFrame([all_strt_date]).assign(use='start'), all_run_dates))\n",
    "all_run_dates = pd.concat((pd.DataFrame([all_end_date]).assign(use='end'), all_run_dates))\n",
    "all_run_dates=all_run_dates.sort_values(0).reset_index(drop=True).rename(columns={0:'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "007600f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load the existing deep percolation and ETc (i.e., AW) datasets (hdf5)\n",
    "\n",
    "# Load the optimized irrigation rates and corresponding deep percolation values\n",
    "# translate from fields to grid cells (may be already done in other script)\n",
    "\n",
    "# where the irrigation optimizer ran overwrite the default DP and AW data\n",
    "\n",
    "# write the recharge and WEL packages\n",
    "\n",
    "\n",
    "# using the existing full model rewrite the GHB/CHD package for the given dates\n",
    "\n",
    "# rewrite BAS6 with start heads from previous output\n",
    "\n",
    "# rewrite geology\n",
    "\n",
    "# rewrite OC, NWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5332e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Potential ETo spatial interpolation from CIMIS\n",
    "fn = glob.glob(join(uzf_dir,'Cosumnes_dailyET_precip*.csv'))\n",
    "daily_data = pd.DataFrame()\n",
    "for file in fn:\n",
    "    new_data = pd.read_csv(file, index_col = ['Date'], parse_dates = True)\n",
    "    daily_data = pd.concat((daily_data, new_data))\n",
    "# units of mm\n",
    "data_in = daily_data[daily_data['Stn Name']=='Fair Oaks']\n",
    "# clean up data so columns are by location, units of Precip are in mm\n",
    "rain_in = data_in.pivot_table(index = 'Date', columns = 'Stn Name', values = 'Precip (mm)')\n",
    "rain_m = rain_in/1000\n",
    "# clean up data so columns are by location, units of Precip are in mm\n",
    "ETo_in = data_in.pivot_table(index = 'Date', columns = 'Stn Name', values = 'ETo (mm)')\n",
    "ETo_m = ETo_in/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c4799c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwr_etc(strt_date, end_date):\n",
    "    nper_tr = (end_date-strt_date).days+1\n",
    "    natETc = np.zeros((nper_tr,nrow_p,ncol_p))\n",
    "    agETc = np.zeros((nper_tr,nrow_p,ncol_p))\n",
    "\n",
    "    per_n = 0 \n",
    "    for y in np.arange(strt_date.year, end_date.year+1):\n",
    "        # set start and end date for range for the year to be iterated over\n",
    "        yr_strt = pd.to_datetime(str(y)+'-01-01')\n",
    "        yr_end = pd.to_datetime(str(y)+'-12-31')\n",
    "        # get the length of the date range needed for that year\n",
    "        yearlen = len(pd.date_range(yr_strt, yr_end))\n",
    "        if yr_strt < strt_date:\n",
    "            yr_strt = strt_date\n",
    "        if yr_end > end_date:\n",
    "            yr_end = end_date\n",
    "        yr_len = len(pd.date_range(yr_strt, yr_end))\n",
    "        # load hdf5 files\n",
    "        f_irr = h5py.File(join(uzf_dir, \"dwr_ETc/irrigated_\"+str(y)+\".hdf5\"), \"r\")\n",
    "        agETc[per_n:per_n+yr_len,:,:] = f_irr['array'][str(y)][:][yr_strt.dayofyear-1:yr_end.dayofyear,:,:]\n",
    "        f_irr.close()\n",
    "        f_nat = h5py.File(join(uzf_dir, \"dwr_ETc/native_\"+str(y)+\".hdf5\"), \"r\")\n",
    "        natETc[per_n:per_n+yr_len,:,:] = f_nat['array'][str(y)][:][yr_strt.dayofyear-1:yr_end.dayofyear,:,:]\n",
    "        f_nat.close()\n",
    "        per_n += yr_len\n",
    "    # make sure the return value is separate from the loop\n",
    "    return(agETc, natETc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bf07cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_perc(strt_date, end_date):\n",
    "    nper_tr = (end_date-strt_date).days+1\n",
    "    # years and array index \n",
    "    years = pd.date_range(strt_date,end_date,freq='AS-Oct')\n",
    "    yr_ind = (years-strt_date).days\n",
    "    perc = np.zeros((nper_tr, nrow_p,ncol_p))\n",
    "    # need separte hdf5 for each year because total is 300MB\n",
    "    for n in np.arange(0,len(yr_ind)-1):\n",
    "    #     arr = pc[yr_ind[n]:yr_ind[n+1]]\n",
    "        fn = join(uzf_dir, 'basic_soil_budget',\"percolation_WY\"+str(years[n].year+1)+\".hdf5\")\n",
    "        f = h5py.File(fn, \"r\")\n",
    "        arr = f['array']['WY'][:]\n",
    "        perc[yr_ind[n]:yr_ind[n+1]] = arr\n",
    "    #     arr_to_h5(arr, fn)\n",
    "        f.close()\n",
    "    return(perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03adc6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agETc, natETc = dwr_etc(m_strt, m_end)\n",
    "# net ETc should be ETc from ag and native plants joined\n",
    "ETc = agETc + natETc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "60b0c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_well_depth_arr = np.loadtxt(wel_dir+'/ag_well_depth_arr.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304fdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified ag well layer with just one layer per well\n",
    "ag_row, ag_col = np.where(ET_ag.sum(axis=0)>0)\n",
    "ag_well_lay = get_layer_from_elev((dem_data-ag_well_depth_arr*0.9)[ag_row, ag_col], \n",
    "                                  botm[:, ag_row, ag_col], m.dis.nlay)\n",
    "ag_well_lay.shape, ag_row.shape\n",
    "ag_well_lay = pd.DataFrame(np.transpose((ag_row,ag_col, ag_well_lay)), columns=['row','column','layer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e134e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prepared daily domestic use data\n",
    "dom_use = pd.read_csv(join(wel_dir, 'domestic_water_use.csv'), index_col=0, parse_dates=True)\n",
    "dom_use = dom_use[all_strt_date:all_end_date]\n",
    "\n",
    "# load data of locations of domestic wells\n",
    "dom_loc = pd.read_csv(join(wel_dir, 'ag_res_parcel_domestic_wells.csv'), index_col=0)\n",
    "# make row,column 0 based\n",
    "dom_loc.row = (dom_loc.row-1).astype(int)\n",
    "dom_loc.column = (dom_loc.column -1).astype(int)\n",
    "# aggregate to the cell level, summing area will keep water usage scaling correct\n",
    "dom_loc = dom_loc.groupby(['node','row','column', 'CITY']).sum(numeric_only=True).reset_index()\n",
    "# get domestic well layers\n",
    "dom_wel_bot = (dem_data[dom_loc.row, dom_loc.column]- dom_loc.fill_depth_m).values\n",
    "dom_loc['layer'] = get_layer_from_elev(dom_wel_bot, botm[:,dom_loc.row, dom_loc.column], m.dis.nlay)\n",
    "\n",
    "# use either the total area or expected fraction of irrigated area\n",
    "# dom_loc['pump_scale'] = dom_loc.used_area_acres\n",
    "dom_loc['pump_scale'] = dom_loc.area_acres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8be665c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the coefficient for open water is 1.2 at all times\n",
    "ET_water = ETo_m[all_strt_date:all_end_date]*1.2\n",
    "\n",
    "water_surf = gpd.read_file(join(uzf_dir,'county_landuse','ag_lu_locally_defined.shp'))\n",
    "water_surf = gpd.overlay(water_surf, grid_p)\n",
    "water_surf['area_m2'] = water_surf.geometry.area\n",
    "# make row,column 0 based\n",
    "water_surf.row = (water_surf.row-1).astype(int)\n",
    "water_surf.column = (water_surf.column -1).astype(int)\n",
    "# determine layer\n",
    "water_surf['depth_m'] = ag_well_depth_arr[water_surf.row, water_surf.column]\n",
    "wel_bot_elev = dem_data[water_surf.row, water_surf.column] - water_surf.depth_m\n",
    "water_surf['layer'] = get_layer_from_elev(wel_bot_elev, botm[:,water_surf.row, water_surf.column], m.dis.nlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dictionary to fill with stress period data\n",
    "wel_ETc_dict = {}\n",
    "# end date is not included as a stress period, starting at 1st TR spd (2)\n",
    "for t in np.arange(0,nper):\n",
    "    wel_i, wel_j = np.where(ET_ag[t, :, :]>0)\n",
    "    new_xyz = ag_well_lay.loc[list(zip(wel_i,wel_j))] \n",
    "#     wel_ETc = -ET_ag[t-1,wel_i,wel_j]*delr*delr\n",
    "# use new row,cols because there are more layers to use\n",
    "#     wel_ETc = -ET_ag_layered[t, new_xyz.rowi, new_xyz.colj]*delr*delr\n",
    "    wel_ETc = -ET_ag[t, new_xyz.rowi, new_xyz.colj]*delr*delr\n",
    "    # ['layer','row','column', 'flux'] are necessary for WEL package\n",
    "    spd_ag = np.stack((new_xyz.layer, new_xyz.rowi, new_xyz.colj,wel_ETc),axis=1)\n",
    "    # correct by dropping any rows or cols without pumping as some may be added\n",
    "    spd_ag = spd_ag[spd_ag[:,-1]!=0,:]\n",
    "    spd_all = np.copy(spd_ag)\n",
    "    wel_ETc_dict[t] = spd_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e402dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wel_dict = {}\n",
    "for t in np.arange(0, nper):\n",
    "    # for each stress period specify the flux of parcels from the expected domestic well flux time series\n",
    "    dom_loc['flux'] = - dom_use.loc[dates[t-time_tr0],'flux_m3d']*dom_loc.pump_scale\n",
    "    wells_dom = dom_loc[['layer','row','column','flux']].values\n",
    "    # for each stress period specify the flux of water surfaces \n",
    "    water_surf['flux'] = -ET_water.loc[dates[t-time_tr0],'Fair Oaks']*water_surf.area_m2\n",
    "    wells_ws = water_surf[['layer','row','column','flux']].values\n",
    "    spd_noag = np.vstack((wells_dom, wells_ws))\n",
    "    spd_all = np.vstack((wel_ETc_dict[t],spd_noag)) \n",
    "    wel_dict[t] = spd_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61299b",
   "metadata": {},
   "source": [
    "Write out modflow files that are not impacted by irrigation optimization (GHB, CHD, UPW, OC, NWT, DIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9dd51340",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "## write out the irrigation independent inputs (GHB, CHD, UPW, OC, NWT, DIS)\n",
    "\n",
    "# m_per = 1\n",
    "for m_per in np.arange(1,5): # runs first year to next crop choice\n",
    "# for m_per in np.arange(0, all_run_dates.shape[0]-1):\n",
    "    m_strt = all_run_dates.iloc[m_per].date\n",
    "    m_end = all_run_dates.iloc[m_per+1].date\n",
    "\n",
    "    dates = pd.date_range(m_strt, m_end)\n",
    "\n",
    "    # The number of periods is the number of dates \n",
    "    nper = len(dates) \n",
    "    # Each period has a length of one because the timestep is one day, have the 1st stress period be out of the date range\n",
    "    # need to have the transient packages start on the second stress period\n",
    "    perlen = np.ones(nper)\n",
    "    # Steady or transient periods\n",
    "    steady = np.zeros(nper).astype('bool').tolist()\n",
    "    # Reduce the number of timesteps to decrease run time\n",
    "    nstp = np.ones(nper)\n",
    "    # Identify periods to pull data from\n",
    "    all_dates[(all_dates>=m_strt)&(all_dates<m_end)]\n",
    "    spd = np.where((all_dates>=m_strt)&(all_dates<m_end))[0]\n",
    "\n",
    "    ##############################################################################################\n",
    "    model_ws = loadpth + 'crop_modflow/'+str(m_strt.date())\n",
    "\n",
    "    # switch to modflow nwt to enable option bloack for use in owhm\n",
    "    m_month = flopy.modflow.Modflow(modelname = 'MF', exe_name = 'mf-owhm.exe', \n",
    "                              version = 'mfnwt', model_ws= model_ws)\n",
    "\n",
    "    #lenuni = 1 is in ft, lenuni = 2 is in meters\n",
    "    # itmuni is time unit 5 = years, 4=days, 3 =hours, 2=minutes, 1=seconds\n",
    "    dis = flopy.modflow.ModflowDis(nrow=nrow, ncol=ncol, \n",
    "                                   nlay=nlay, delr=delr, delc=delc,\n",
    "                                   model=m_month, lenuni = 2, itmuni = 4,\n",
    "    #                                xul = xul, yul = yul,rotation=rotation, proj4_str=proj4_str,\n",
    "                                  nper = nper, perlen=perlen, nstp=nstp, steady = steady,\n",
    "                                  start_datetime = m_strt)\n",
    "    #\n",
    "    m_month.dis.botm = np.copy(m.dis.botm.array)\n",
    "    m_month.dis.top = np.copy(m.dis.top.array)\n",
    "\n",
    "    # overwrite files that change\n",
    "    ghb_spd = dict()\n",
    "    chd_spd = dict()\n",
    "    for n, t in enumerate(spd):\n",
    "        ghb_spd[n] = m.ghb.stress_period_data[t]\n",
    "        chd_spd[n] = m.chd.stress_period_data[t]\n",
    "\n",
    "    ghb_month = flopy.modflow.ModflowGhb(model=m_month, stress_period_data = ghb_spd, ipakcb=55)\n",
    "    chd_month = flopy.modflow.ModflowChd(model=m_month,stress_period_data =  chd_spd)\n",
    "\n",
    "    # For later model runs when all the data is needed to be saved\n",
    "    oc_spd = {}\n",
    "    oc_spd = { (j,0): ['save head', 'save budget'] for j in np.arange(0,nper,1)}\n",
    "    oc_spd[0,0] = ['save head', 'save budget','print budget']\n",
    "    oc = flopy.modflow.ModflowOc(model = m_month, stress_period_data = oc_spd, compact = True)\n",
    "\n",
    "    # add LPF connection and re-write name file\n",
    "    upw_month = flopy.modflow.ModflowUpw.load(loadpth + 'crop_modflow/MF.upw', model=m_month)\n",
    "\n",
    "    # load NWT file\n",
    "    nwt_month = flopy.modflow.ModflowNwt.load(loadpth + 'crop_modflow/MF.nwt', model=m_month)\n",
    "\n",
    "    # m_month.write_name_file()\n",
    "#     m_month.write_input()\n",
    "    dis.write_input()\n",
    "    ghb_month.write_input()\n",
    "    chd_month.write_input()\n",
    "    upw_month.write_input()\n",
    "    oc.write_input()\n",
    "    nwt_month.write_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c415de",
   "metadata": {},
   "source": [
    "Write out files that receive input from the irrigation input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dc3d5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "\n",
    "for m_per in np.arange(1,5): # runs first year to next crop choice\n",
    "# for m_per in np.arange(0, all_run_dates.shape[0]-1):\n",
    "    m_strt = all_run_dates.iloc[m_per].date\n",
    "    m_end = all_run_dates.iloc[m_per+1].date\n",
    "\n",
    "    dates = pd.date_range(m_strt, m_end)\n",
    "    # The number of periods is the number of dates \n",
    "    nper = len(dates) \n",
    "    # Identify periods to pull data from\n",
    "    all_dates[(all_dates>=m_strt)&(all_dates<m_end)]\n",
    "#     spd = np.where((all_dates>=m_strt)&(all_dates<m_end))[0]\n",
    "\n",
    "    ##############################################################################################\n",
    "    model_ws = loadpth + 'crop_modflow/'+str(m_strt.date())\n",
    "\n",
    "    # switch to modflow nwt to enable option bloack for use in owhm\n",
    "    load_only=['UPW','DIS','OC','NWT']\n",
    "    m_month = flopy.modflow.Modflow.load('MF.nam',  model_ws= model_ws,\n",
    "                                        load_only=load_only,\n",
    "                                        )  \n",
    "    # vka needed for other packages\n",
    "    vka = np.copy(m.upw.vka.array)\n",
    "    ## update deep percolation \n",
    "    perc = load_perc(m_strt, m_end)\n",
    "    # percolation can't exceed vertical conductivity (secondary runoff)\n",
    "    perc = np.where(perc >vka[0,:,:], vka[0,:,:], perc)\n",
    "\n",
    "    # have transient recharge start after the 1st spd\n",
    "    rech_spd = {}\n",
    "    for j in np.arange(0,nper):\n",
    "        rech_spd[j] = perc[j,:,:] \n",
    "\n",
    "    # nrchop = 3, to highest active cell\n",
    "    rch = flopy.modflow.ModflowRch(model = m_month, nrchop=3, rech = rech_spd, ipakcb=55)\n",
    "    \n",
    "    ## update pumping\n",
    "    agETc, natETc = dwr_etc(m_strt, m_end)\n",
    "    # net ETc should be ETc from ag and native plants joined\n",
    "#     ETc = agETc + natETc\n",
    "    # already filtering by land type above\n",
    "    ET_ag = np.copy(agETc)\n",
    "\n",
    "    wel_spd = dict()\n",
    "    for n, t in enumerate(spd):\n",
    "        wel_spd[n] = m.wel.stress_period_data[t]\n",
    "    # Create well flopy object\n",
    "    wel_month = flopy.modflow.ModflowWel(m_month, stress_period_data=wel_spd,ipakcb=55)\n",
    "\n",
    "    strt = np.ones((nlay, nrow, ncol), dtype = np.float32)\n",
    "    # The model should start in hydraulic connection\n",
    "    if spd[0]==0:\n",
    "        strt[:,:,:] = m.dis.top[:,:] #maybe the mean of starting heads i causing issues?\n",
    "    else:\n",
    "        model_ws_last = loadpth + 'crop_modflow/'+str(all_run_dates.loc[m_per-1].date.date())\n",
    "        hdobj = flopy.utils.HeadFile(model_ws_last + '/MF.hds')\n",
    "        sp_last = hdobj.get_kstpkper()[-1]\n",
    "        strt[:,:,:] = hdobj.get_data(sp_last)\n",
    "    ibound = np.ones([nlay, nrow,ncol])\n",
    "\n",
    "    # for the first period we use dem as starting point\n",
    "    # if solver criteria are not met, the model will continue if model percent error is less than stoperror\n",
    "    bas_month = flopy.modflow.ModflowBas(model = m_month, ibound=ibound, strt = strt)\n",
    "\n",
    "    # m_month.write_name_file()\n",
    "#     m_month.write_input()\n",
    "    bas_month.write_input()\n",
    "    rch_month.write_input()\n",
    "    wel_month.write_input()\n",
    "\n",
    "#     success, buff = m_month.run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410eab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

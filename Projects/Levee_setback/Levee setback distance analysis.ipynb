{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inclusive-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "import calendar\n",
    "import time\n",
    "from scipy.stats import gmean\n",
    "\n",
    "# standard python plotting utilities\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import pyproj # for converting proj4string\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# mapping utilities\n",
    "import contextily as ctx\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-rogers",
   "metadata": {},
   "source": [
    "Graham suggested running permeameter tests to look at the rate of flow velocity in the high hydraulic conductivity facies to determine which pathways are indeed connected from the ground to bottom.\n",
    "1. Load a geostatistical model\n",
    "2. Apply basic cleaning scripts to remove data above ground surface\n",
    "3. Set boundary conditions using a CHD along an axis (look at what head gradient jan fleckenstein used)\n",
    "4. Create loop to copy boundary conditions and basic model set up to all files.\n",
    "5. Look into using zone package with LPF or UPW to ease set up\n",
    "6. Create loop to create geology or zone package for each realization\n",
    "7. Run all 100 realizations and create a cbc and head output file\n",
    "8. Plot flow lines\n",
    "9. Filter flow lines by the magnitude, cells with more than 50% of the average flow must be highly conductive\n",
    "10. Find a way to plot all the cells that have high flow and locate start and end (min and max of row, columns)\n",
    "\n",
    "Graham also mentioned Jan Fleckenstein used the permeameter tests to calculate the vertical anisotropy ratios which were on the order of 1:1000 or 1:10,000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "equivalent-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up directory referencing\n",
    "# Package data\n",
    "gwfm_dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "user_dir = '\\\\'.join(str.split(gwfm_dir,'\\\\')[:3])\n",
    "git_dir = user_dir+'/Documents/GitHub/GWFlowModel'\n",
    "fxn_dir = git_dir+'/01_python_scripts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "automatic-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location for working with/creating output from tprogs analysis as it may make large datafiles\n",
    "model_ws = 'F:/WRDAPP/GWFlowModel/Cosumnes/levee_setback/setback_distance_analysis'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "parental-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "gel_dir = gwfm_dir+'/UPW_data'\n",
    "if 'ZonePropertiesInitial.csv' in os.listdir(model_ws):\n",
    "    params = pd.read_csv(model_ws+'/ZonePropertiesInitial.csv',index_col='Zone')\n",
    "else:\n",
    "    params = pd.read_csv(gel_dir+'/ZonePropertiesInitial.csv',index_col='Zone')\n",
    "    params.to_csv(model_ws+'/ZonePropertiesInitial.csv')\n",
    "# convert from m/s to m/d\n",
    "params['K_m_d'] = params.K_m_s * 86400    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "hearing-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_data = np.loadtxt(gwfm_dir+'/DIS_data/dem_52_9_200m_linear.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "constitutional-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add python script directory to sys path for easy referencing\n",
    "sys.path.insert(0, fxn_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "desperate-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tprogs_cleaning as tc\n",
    "# import tprogs_elev_referencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "disabled-marketplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'elev_to_tprogs_layers',\n",
       " 'get_tprogs_for_elev',\n",
       " 'int_to_param',\n",
       " 'np',\n",
       " 'sys',\n",
       " 'tprogs_cut_elev']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "owned-argentina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "tprogs_cleaning module. \n",
      "Different functions for preparing data for use in MODFLOW and other groundwater modeling software.\n",
      "First iteration as a Module Oct 2021\n",
      "Author: Andrew Calderwood\n",
      "\"\"\"\n",
      "\n",
      "import sys\n",
      "import numpy as np\n",
      "\n",
      "def tprogs_cut_elev(tprogs_line, dem_data, **kwargs):\n",
      "    \"\"\"\n",
      "    Parameters\n",
      "    ----------\n",
      "    tprogs_line : output from TPROGs of line data formatted to be converted by setting z then x then y\n",
      "    dem_data : 2D array of elevation data of ground surface above which TPROGs should not be real\n",
      "    rows : number of rows in the TPROGs model\n",
      "    cols : number of columns in the TPROGs model\n",
      "    \"\"\"\n",
      "    rows = kwargs.get('rows', np.where(np.ones(dem_data.shape)==1)[0])\n",
      "    cols = kwargs.get('cols', np.where(np.ones(dem_data.shape)==1)[1])\n",
      "    tprogs_arr = np.reshape(tprogs_line, (320, 100,230))\n",
      "    tprogs_c = np.reshape(tprogs_arr[:, rows,cols],\n",
      "                             (tprogs_arr.shape[0],dem_data.shape[0],dem_data.shape[1]))\n",
      "    tprogs_elev = np.copy(tprogs_c)\n",
      "    # the bottom layer of the tprogs model is at -50 m amsl and the top layer is 50 m amsl\n",
      "    t = 0\n",
      "    for k in np.arange(-80,80,0.5):\n",
      "        tprogs_elev[t,dem_data<k]= np.NaN\n",
      "        t+=1\n",
      "    masked_tprogs = ma.masked_invalid(tprogs_elev)\n",
      "    return(masked_tprogs)\n",
      "\n",
      "\n",
      "def int_to_param(tprogs, params):\n",
      "    \"\"\"\n",
      "    Parameters\n",
      "    ----------\n",
      "    tprogs: 3D masked array of TPROGs realization\n",
      "    params: Reference table connecting TPROGs facie to a hydraulic value\n",
      "    \"\"\"\n",
      "    tprogs[tprogs<0] *= -1\n",
      "    tprogs = tprogs.astype(float)\n",
      "    # flip tprogs model along z axis to match modflow definition of 0 as top (TPROGS says 0 is bottom)\n",
      "    tprogs = np.flip(tprogs,axis=0)\n",
      "    tprogs_K = np.copy(tprogs)\n",
      "    tprogs_Sy = np.copy(tprogs)\n",
      "    tprogs_Ss = np.copy(tprogs)\n",
      "    # hydraulic parameters from fleckenstein 2006\n",
      "    # I-IV gravel, sand, muddy sand, mud\n",
      "    # K in m/s, Sy, Ss\n",
      "    for n in np.arange(1,5):\n",
      "        tprogs_K[tprogs==n]= params.loc[n,'K_m_d']\n",
      "    for n in np.arange(1,5):\n",
      "        tprogs_Sy[tprogs==n]= params.loc[n,'Sy']\n",
      "    for n in np.arange(1,5):\n",
      "        tprogs_Ss[tprogs==n]= params.loc[n,'Ss']\n",
      "            \n",
      "    return(tprogs_K,tprogs_Sy,tprogs_Ss)\n",
      "\n",
      "\n",
      "def elev_to_tprogs_layers(elev, tprogs_top_elev, tprogs_bot_elev, num_lays):\n",
      "    \"\"\"\n",
      "    function to get the tprogs layers based on the given elevation\n",
      "    Example\n",
      "    layer 0 is 80 meters, layer 1 is 79.5 meters, layer -1 is -80 meters\n",
      "    \"\"\"\n",
      "    lay_thick = (tprogs_top_elev - tprogs_bot_elev)/num_lays\n",
      "    elev_round = np.round((elev) * (1/lay_thick)) / (1/lay_thick) # dem rounded to the layer thickness\n",
      "    elev_round[elev_round >= tprogs_top_elev] = tprogs_top_elev# any elevation above the top is set to the top\n",
      "    # subtract the calculated row from top elev divided by layer thickness to get to index 0 at top and index 320 and bottom\n",
      "    elev_indices = top/lay_thick - elev_round*(1/lay_thick) \n",
      "    return(elev_indices.astype(int))\n",
      "\n",
      "\n",
      "def get_tprogs_for_elev(tprogs_arr, top_elev, bot_elev, **kwargs):\n",
      "    \"\"\"\n",
      "    Function to grab the TPROGs layers by elevation filters and returns\n",
      "    a 3D array with uneven numbers of filled values in the vertical direction.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    tprogs_arr : 3D masked array of TPROGs_realziation\n",
      "    top_elev : 2D array of elevation setting top reference point\n",
      "    bot_elev: 2D array of elevation setting bottom reference poing\n",
      "    \"\"\"\n",
      "    rows = kwargs.get('rows', np.where(np.ones(top_elev.shape)==1)[0])\n",
      "    cols = kwargs.get('cols', np.where(np.ones(top_elev.shape)==1)[1])\n",
      "    top_indices = elev_to_tprogs_layers(top_elev)\n",
      "    bot_indices = elev_to_tprogs_layers(bot_elev)\n",
      "    # find tprogs layer for desired rows and columns\n",
      "    top_indices = top_indices[rows, cols].astype(int)\n",
      "    bot_indices = bot_indices[rows, cols].astype(int)\n",
      "    # the first row of the array will be the top layer and will progress downward until the max bottom is reached\n",
      "    # with NaNs for rows,cols where there are less layers indexed than the max\n",
      "    tprogs_subset = np.full(shape = (np.max(bot_indices - top_indices).astype(int), len(rows)),\n",
      "                       fill_value = np.nan, dtype = float)\n",
      "    max_layers = np.max(bot_indices - top_indices)\n",
      "    for k in np.arange(0,max_layers):\n",
      "        layexist = (bot_indices-top_indices) > k # pick where data should be referenced\n",
      "        tprogs_subset[k, layexist] = K[top_indices[layexist]+k, rows[layexist], cols[layexist]]\n",
      "    # return grabbed data in array format if entire domain was used\n",
      "    if len(rows) == top_elev.shape[0]*top_elev.shape[1]:\n",
      "        tprogs_subset = np.reshape(tprogs_subset, (max_layers, top_elev.shape[0], top_elev.shape[1]))\n",
      "    return(tprogs_subset)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from inspect import getsource\n",
    "\n",
    "print(getsource(tc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "immediate-proportion",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "elev_to_tprogs_layers() got an unexpected keyword argument 'num_lays'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28280/1031999966.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melev_to_tprogs_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdem_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtprogs_top_elev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtprogs_bot_elev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_lays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m320\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: elev_to_tprogs_layers() got an unexpected keyword argument 'num_lays'"
     ]
    }
   ],
   "source": [
    "tc.elev_to_tprogs_layers(dem_data, tprogs_top_elev = 80, tprogs_bot_elev = -80, num_lays = 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "integral-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.elev_to_tprogs_layers?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

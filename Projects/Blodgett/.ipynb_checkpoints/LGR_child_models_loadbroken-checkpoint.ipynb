{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "import calendar\n",
    "import time\n",
    "from scipy.stats import gmean\n",
    "\n",
    "# standard python plotting utilities\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import pyproj # for converting proj4string\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# mapping utilities\n",
    "import contextily as ctx\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comparable-arrival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.10 (default, Feb 26 2021, 13:06:18) [MSC v.1916 64 bit (AMD64)]\n",
      "numpy version: 1.19.2\n",
      "matplotlib version: 3.3.4\n",
      "flopy version: 3.3.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# run installed version of flopy or add local path\n",
    "try:\n",
    "    import flopy\n",
    "    from flopy.discretization.structuredgrid import StructuredGrid\n",
    "    from flopy.utils.reference import SpatialReference\n",
    "    from flopy.utils import Raster\n",
    "except:\n",
    "    import flopy\n",
    "    fpth = os.path.abspath(os.path.join('..', '..'))\n",
    "    sys.path.append(fpth)\n",
    "    from flopy.discretization.structuredgrid import StructuredGrid\n",
    "    from flopy.utils.reference import SpatialReference\n",
    "    from flopy.utils import Raster\n",
    "from flopy.utils.gridgen import Gridgen\n",
    "from flopy.utils import OptionBlock\n",
    "import flopy.utils.binaryfile as bf\n",
    "\n",
    "\n",
    "print(sys.version)\n",
    "print('numpy version: {}'.format(np.__version__))\n",
    "print('matplotlib version: {}'.format(mpl.__version__))\n",
    "print('flopy version: {}'.format(flopy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "identical-association",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ajcalder\\\\Box\\\\research_cosumnes\\\\GWFlowModel'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set up directory referencing\n",
    "# Package data\n",
    "gwfm_dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "gwfm_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "catholic-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_grid = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "false-scientist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mf2005'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_p.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "active-chase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# SFR package for  MODFLOW-2005, generated by Flopy.\\n',\n",
       " 'REACHINPUT TRANSROUTE TABFILES 1 731\\n',\n",
       " '-256 27 0 0 86400.00000000 0.00010000 55 54 1 1 4 0.75000000 3.00000000 \\n',\n",
       " '1 94 219 1 1 130.0 51.79605 0.002 0.6089 0.0005616\\n',\n",
       " '1 94 218 1 2 240.0 51.426052 0.002 0.6089 0.0005616\\n',\n",
       " '1 93 217 1 3 200.0 50.90605 0.002 0.6089 0.0043213437\\n',\n",
       " '1 93 216 1 4 210.0 50.49605 0.002 0.6089 0.0008862483\\n',\n",
       " '1 93 215 1 5 110.0 50.176052 0.002 0.6089 0.0008862483\\n',\n",
       " '1 92 215 1 6 240.0 49.773018 0.002 0.6089 0.0068760286\\n',\n",
       " '1 91 215 1 7 280.0 49.017548 0.002 0.6089 0.0005616\\n',\n",
       " '1 90 216 1 8 250.0 48.270927 0.002 0.6089 0.0005616\\n',\n",
       " '1 89 216 1 9 170.0 47.36128 0.002 0.6089 0.0005616\\n',\n",
       " '1 88 216 1 10 250.0 46.64794 0.002 0.6089 0.0005616\\n',\n",
       " '1 88 215 1 11 240.0 46.15794 0.002 0.6089 0.0005616\\n',\n",
       " '1 88 214 1 12 210.0 45.70794 0.002 0.6089 0.033251446\\n',\n",
       " '1 88 213 1 13 210.0 45.28794 0.002 0.6089 0.016842762\\n',\n",
       " '1 88 212 1 14 200.0 44.87794 0.002 0.6089 0.0005616\\n',\n",
       " '1 88 211 1 15 230.0 44.44794 0.002 0.6089 0.0005616\\n',\n",
       " '1 87 210 1 16 250.0 43.20564 0.002 0.6089 0.0005616\\n',\n",
       " '1 87 209 1 17 180.0 41.03065 0.002 0.6089 0.0011087263\\n',\n",
       " '1 87 208 1 18 160.0 40.429245 0.002 0.6089 0.0005616\\n',\n",
       " '1 86 207 1 19 270.0 39.899246 0.002 0.8677 0.0005616\\n',\n",
       " '1 85 206 1 20 160.0 39.181747 0.002 0.8677 0.0008862483\\n',\n",
       " '1 84 206 1 21 200.0 38.809246 0.002 0.8677 0.0216\\n',\n",
       " '1 83 205 1 22 250.0 38.259247 0.002 0.8677 0.008531316\\n',\n",
       " '1 82 204 1 23 180.0 37.73158 0.0009611111 1.1265 0.0011087263\\n',\n",
       " '1 81 203 1 24 220.0 37.220615 0.0005318182 1.1265 0.0043213437\\n',\n",
       " '1 81 202 1 25 230.0 36.29651 0.00074347825 1.1265 0.0011087263\\n',\n",
       " '1 80 201 1 26 230.0 36.04019 0.0003 1.1265 0.0021888781\\n',\n",
       " '1 80 200 1 27 210.0 35.97419 0.0003 1.3534 0.0005616\\n',\n",
       " '1 80 199 1 28 200.0 35.91269 0.0003 1.5803 0.0005616\\n',\n",
       " '1 80 198 2 1 210.0 35.80484 0.00038095238 1.5803 0.0005616\\n',\n",
       " '1 80 197 2 2 230.0 34.15809 0.0006695652 1.5803 0.0005616\\n',\n",
       " '1 80 196 2 3 220.0 33.450535 0.0008409091 1.5803 0.0043213437\\n',\n",
       " '1 80 195 2 4 210.0 33.274155 0.00054285716 1.5803 0.0021888781\\n',\n",
       " '1 79 194 3 1 200.0 33.195423 0.0003 1.5803 0.0043213437\\n',\n",
       " '1 79 193 3 2 210.0 33.10778 0.00038095238 1.5803 0.0005616\\n',\n",
       " '1 78 192 4 1 210.0 32.41906 0.00054285716 1.5803 0.065645926\\n',\n",
       " '1 77 191 4 2 240.0 32.241795 0.00037083332 1.5803 0.0043213437\\n',\n",
       " '1 76 190 4 3 140.0 32.162487 0.0003 1.0776 0.0005616\\n',\n",
       " '1 75 190 5 1 230.0 32.106987 0.0003 1.5803 0.008531316\\n',\n",
       " '1 74 190 6 1 220.0 32.039486 0.0003 1.5803 0.0005616\\n',\n",
       " '1 73 190 6 2 110.0 31.976622 0.0003 1.5803 0.0005616\\n',\n",
       " '1 72 189 6 3 230.0 31.735106 0.00089130434 1.5803 0.002797137\\n',\n",
       " '1 71 189 6 4 110.0 31.19654 0.0007636364 1.5803 0.0005616\\n',\n",
       " '1 71 188 7 1 160.0 30.720541 0.0005125 1.5803 0.0005616\\n',\n",
       " '1 70 188 7 2 160.0 30.627995 0.00040625 1.5803 0.0005616\\n',\n",
       " '1 70 187 7 3 210.0 30.572495 0.0003 1.5803 0.002797137\\n',\n",
       " '1 70 186 7 4 170.0 30.507069 0.0005 1.0776 0.002797137\\n',\n",
       " '1 69 185 7 5 240.0 30.130882 0.00086666667 1.5803 0.0005616\\n',\n",
       " '1 69 184 7 6 210.0 29.684853 0.0003 1.5803 0.0005616\\n',\n",
       " '1 68 183 7 7 210.0 29.616028 0.00038095238 1.5803 0.008531316\\n',\n",
       " '1 68 182 8 1 220.0 29.510519 0.0008409091 1.5803 0.008531316\\n',\n",
       " '1 67 181 8 2 180.0 29.38745 0.0005833333 1.5803 0.0005616\\n',\n",
       " '1 66 181 8 3 200.0 29.196632 0.00098 1.5803 0.0005616\\n',\n",
       " '1 65 181 8 4 200.0 28.566843 0.00081 1.5803 0.0005616\\n',\n",
       " '1 65 182 9 1 220.0 28.319473 0.0006090909 1.5803 0.0027610927\\n',\n",
       " '1 64 183 9 2 230.0 28.080791 0.0006695652 1.5803 0.027504114\\n',\n",
       " '1 63 184 10 1 210.0 27.66088 0.00038095238 1.0776 0.005496279\\n',\n",
       " '1 62 183 10 2 180.0 27.430878 0.00077222224 1.5803 0.122188054\\n',\n",
       " '1 61 183 10 3 160.0 27.288721 0.00104375 1.5803 0.004885004\\n',\n",
       " '1 60 184 10 4 210.0 27.00991 0.00094761903 1.0776 0.03758864\\n',\n",
       " '1 59 183 10 5 150.0 26.91136 0.0003 1.5803 0.013931582\\n',\n",
       " '1 58 183 10 6 220.0 26.826813 0.00045454546 1.5803 0.0005616\\n',\n",
       " '1 58 182 10 7 160.0 26.68154 0.00040625 1.5803 0.008531316\\n',\n",
       " '1 57 182 11 1 220.0 26.482803 0.0005318182 1.5803 0.0043213437\\n',\n",
       " '1 56 182 11 2 150.0 26.18835 0.0007533333 1.5803 0.065645926\\n',\n",
       " '1 55 181 11 3 220.0 26.071226 0.00045454546 1.5803 0.0216\\n',\n",
       " '1 55 180 11 4 210.0 25.98549 0.00038095238 1.5803 0.01712357\\n',\n",
       " '1 54 179 11 5 220.0 25.896322 0.0003 1.5803 0.0005616\\n',\n",
       " '1 53 179 11 6 210.0 25.813822 0.0003 1.5803 0.0005616\\n',\n",
       " '1 52 178 11 7 210.0 25.729822 0.0003 1.5803 0.0005616\\n',\n",
       " '1 52 177 12 1 160.0 25.666822 0.0003 1.5803 0.0005616\\n',\n",
       " '1 52 176 12 2 260.0 25.596321 0.0003 1.5803 0.0005616\\n',\n",
       " '1 51 175 12 3 130.0 25.51382 0.0003 1.5803 0.0005616\\n',\n",
       " '1 51 174 12 4 240.0 25.45832 0.0003 1.5803 0.0005616\\n',\n",
       " '1 50 173 12 5 130.0 25.375822 0.0003 1.5803 0.033251446\\n',\n",
       " '1 50 172 12 6 250.0 25.31882 0.0003 1.5803 0.0005616\\n',\n",
       " '1 49 172 12 7 230.0 25.246822 0.0003 1.5803 0.0021888781\\n',\n",
       " '1 48 172 13 1 150.0 24.902666 0.00052666664 1.5803 0.0011087263\\n',\n",
       " '1 48 171 13 2 150.0 24.646763 0.00052666664 1.5803 0.016842762\\n',\n",
       " '1 47 170 13 3 210.0 23.518263 0.00054285716 1.5803 0.010850905\\n',\n",
       " '1 47 169 13 4 210.0 23.403269 0.00046190477 1.5803 0.0008862483\\n',\n",
       " '1 48 168 14 1 220.0 23.225616 0.0006863636 1.5803 0.008531316\\n',\n",
       " '1 49 167 14 2 150.0 23.150936 0.0003 1.5803 0.0005616\\n',\n",
       " '1 49 166 14 3 210.0 23.096937 0.0003 1.5529 0.0005616\\n',\n",
       " '1 48 165 14 4 110.0 23.030937 0.0003 1.5803 0.0005616\\n',\n",
       " '1 49 164 14 5 230.0 22.967936 0.0003 1.5529 0.0005616\\n',\n",
       " '1 49 163 14 6 210.0 22.901936 0.0003 1.5529 0.0005616\\n',\n",
       " '1 50 162 14 7 210.0 22.835936 0.0003 1.5255 0.0005616\\n',\n",
       " '1 50 161 14 8 220.0 22.771437 0.0003 1.5255 0.0005616\\n',\n",
       " '1 51 160 14 9 140.0 22.690435 0.0003 1.5255 0.0005616\\n',\n",
       " '1 51 159 14 10 200.0 22.639437 0.0003 1.5255 0.0005616\\n',\n",
       " '1 52 158 14 11 200.0 22.564436 0.0003 1.5255 0.0005616\\n',\n",
       " '1 52 157 14 12 180.0 22.507437 0.0003 1.5255 0.0005616\\n',\n",
       " '1 51 156 14 13 200.0 22.441437 0.0003 1.5255 0.0005616\\n',\n",
       " '1 51 155 14 14 200.0 22.381435 0.0003 1.5255 0.0005616\\n',\n",
       " '1 52 154 14 15 140.0 22.306437 0.0003 1.5255 0.0043572183\\n',\n",
       " '1 52 153 14 16 210.0 22.253937 0.0003 1.5255 0.0034828954\\n',\n",
       " '1 52 152 14 17 220.0 22.189436 0.0003 1.5255 0.0005616\\n',\n",
       " '1 53 151 14 18 260.0 22.111437 0.0003 1.5255 0.0005616\\n',\n",
       " '1 53 150 15 1 210.0 22.040936 0.0003 1.5255 0.0005616\\n',\n",
       " '1 53 149 15 2 190.0 21.980936 0.0003 1.5255 0.0005616\\n',\n",
       " '1 54 148 15 3 150.0 21.926937 0.0003 1.5255 0.033251446\\n',\n",
       " '1 53 148 15 4 170.0 21.878937 0.0003 1.5255 0.0005616\\n',\n",
       " '1 52 147 15 5 250.0 21.800936 0.0003 1.5255 0.0005616\\n',\n",
       " '1 51 146 16 1 210.0 21.719936 0.0003 1.5255 0.0005616\\n',\n",
       " '1 51 145 16 2 240.0 21.652437 0.0003 1.5255 0.0011087263\\n',\n",
       " '1 51 144 16 3 210.0 21.584936 0.0003 1.5255 0.0005616\\n',\n",
       " '1 51 143 16 4 200.0 21.523436 0.0003 1.5255 0.0005616\\n',\n",
       " '1 51 142 16 5 210.0 21.460936 0.00036666667 1.5255 0.0005616\\n',\n",
       " '1 50 141 17 1 280.0 21.262936 0.001 1.5255 0.0005616\\n',\n",
       " '1 49 140 17 2 250.0 20.967936 0.001 1.5255 0.03380583\\n',\n",
       " '1 48 139 17 3 210.0 20.707935 0.001 1.5255 0.0216\\n',\n",
       " '1 49 138 17 4 240.0 20.452936 0.001 1.5255 0.0005616\\n',\n",
       " '1 50 137 17 5 180.0 20.162937 0.001 1.5255 0.0005616\\n',\n",
       " '1 50 136 17 6 250.0 19.947937 0.001 1.5255 0.0005616\\n',\n",
       " '1 51 135 18 1 230.0 19.707935 0.001 1.5255 0.013687541\\n',\n",
       " '1 51 134 18 2 210.0 19.487936 0.001 1.5255 0.0216\\n',\n",
       " '1 51 133 18 3 110.0 19.327936 0.001 1.5255 0.0013985685\\n',\n",
       " '1 50 132 18 4 200.0 19.072937 0.001 1.5255 0.0008862483\\n',\n",
       " '1 50 131 18 5 210.0 18.867937 0.001 1.5255 0.0005616\\n',\n",
       " '1 50 130 18 6 220.0 18.652937 0.001 1.5255 0.0013985685\\n',\n",
       " '1 49 129 18 7 160.0 18.362936 0.001 1.5255 0.013931582\\n',\n",
       " '1 48 129 18 8 220.0 18.172935 0.001 1.5255 0.3456\\n',\n",
       " '1 47 128 18 9 220.0 17.942936 0.001 1.5255 0.0021888781\\n',\n",
       " '1 47 127 18 10 210.0 17.727936 0.001 1.5255 0.14650454\\n',\n",
       " '1 47 126 18 11 210.0 17.517937 0.001 1.5255 0.1296\\n',\n",
       " '1 47 125 19 1 220.0 17.302937 0.001 1.5255 0.23924091\\n',\n",
       " '1 46 124 19 2 180.0 17.062937 0.001 1.5255 0.0011087263\\n',\n",
       " '1 46 123 19 3 210.0 16.867937 0.001 1.5255 0.0011087263\\n',\n",
       " '1 46 122 19 4 230.0 16.647936 0.001 1.5255 0.0005616\\n',\n",
       " '1 46 121 20 1 240.0 16.443562 0.00059166667 1.5255 0.0005616\\n',\n",
       " '1 45 120 20 2 260.0 16.340437 0.0003 1.5255 0.0005616\\n',\n",
       " '1 44 119 20 3 270.0 16.257936 0.0003 1.6154 0.0005616\\n',\n",
       " '1 43 119 21 1 210.0 16.185936 0.0003 1.5255 0.0005616\\n',\n",
       " '1 42 118 21 2 270.0 15.843068 0.0004888889 1.5255 0.0005616\\n',\n",
       " '1 41 117 21 3 160.0 15.6937065 0.0003 1.5255 0.1296\\n',\n",
       " '1 42 116 22 1 200.0 15.627707 0.0003 1.5255 0.0005616\\n',\n",
       " '1 42 115 22 2 250.0 15.495213 0.000368 1.5255 0.0005616\\n',\n",
       " '1 43 114 22 3 220.0 15.391927 0.0007636364 1.6154 0.0216\\n',\n",
       " '1 43 113 22 4 200.0 15.267445 0.0003 1.6154 0.0043213437\\n',\n",
       " '1 43 112 22 5 210.0 15.138693 0.00054285716 1.6154 0.0005616\\n',\n",
       " '1 43 111 22 6 220.0 14.92451 0.0006863636 1.6154 0.0005616\\n',\n",
       " '1 43 110 23 1 190.0 14.676844 0.00065789477 1.6154 0.0005616\\n',\n",
       " '1 42 110 23 2 190.0 14.497787 0.00056842103 1.5255 0.0005616\\n',\n",
       " '1 42 109 23 3 140.0 14.42922 0.0003 1.5255 0.0005616\\n',\n",
       " '1 42 108 23 4 230.0 14.364078 0.0003 1.5255 0.0005616\\n',\n",
       " '1 43 107 23 5 230.0 14.283077 0.0003 1.6154 0.0005616\\n',\n",
       " '1 42 106 23 6 200.0 13.5983515 0.000725 1.5255 0.0013985685\\n',\n",
       " '1 42 105 24 1 210.0 13.190256 0.0011904762 1.5255 0.0034828954\\n',\n",
       " '1 43 104 24 2 180.0 12.61877 0.00077222224 1.5255 0.0005616\\n',\n",
       " '1 43 103 24 3 190.0 12.268543 0.00074736844 1.5255 0.0005616\\n',\n",
       " '1 44 102 24 4 220.0 11.900678 0.0007636364 1.5255 0.0005616\\n',\n",
       " '1 44 101 25 1 210.0 11.78008 0.0003 1.5255 0.0005616\\n',\n",
       " '1 44 100 25 2 200.0 11.71858 0.0003 1.5255 0.0005616\\n',\n",
       " '1 45 99 25 3 170.0 11.63608 0.0003 1.6154 0.0005616\\n',\n",
       " '1 45 98 25 4 230.0 11.57608 0.0003 1.5255 0.0005616\\n',\n",
       " '1 45 97 25 5 220.0 11.50858 0.0003 1.5255 0.0005616\\n',\n",
       " '1 45 96 25 6 150.0 11.45308 0.0003 1.5255 0.0011087263\\n',\n",
       " '1 44 95 25 7 260.0 11.37358 0.0003 1.5255 0.0661909\\n',\n",
       " '1 43 94 25 8 230.0 11.27908 0.0003 1.5255 0.03380583\\n',\n",
       " '1 42 93 26 1 240.0 11.19958 0.0003 1.5255 0.008602141\\n',\n",
       " '1 42 92 26 2 170.0 11.13808 0.0003 1.5255 0.041944012\\n',\n",
       " '1 41 91 26 3 210.0 11.06608 0.0003 1.5255 0.0043572183\\n',\n",
       " '1 41 90 26 4 230.0 11.00008 0.0003 1.5255 0.010850905\\n',\n",
       " '1 41 89 26 5 220.0 10.93258 0.0003 1.5255 0.0077089146\\n',\n",
       " '1 41 88 26 6 200.0 10.86958 0.0003 1.5255 0.12118203\\n',\n",
       " '1 41 87 26 7 210.0 10.80808 0.0003 1.5255 0.13522331\\n',\n",
       " '1 41 86 26 8 230.0 10.74208 0.0003 1.5255 0.19123463\\n',\n",
       " '1 42 85 26 9 240.0 10.67158 0.0003 1.5255 0.013931582\\n',\n",
       " '1 43 84 27 1 210.0 10.57708 0.0003 1.5255 0.0005616\\n',\n",
       " '1 43 83 27 2 200.0 10.51558 0.0003 1.5255 0.0005616\\n',\n",
       " '1 43 82 27 3 240.0 10.391002 0.00079583336 1.5255 0.0005616\\n',\n",
       " '1 42 81 27 4 270.0 10.255723 0.0003 1.5255 0.0005616\\n',\n",
       " '1 41 80 27 5 270.0 10.168723 0.0003 1.5255 0.0077729123\\n',\n",
       " '1 40 79 27 6 180.0 10.086223 0.0003 1.5255 0.0022070496\\n',\n",
       " '1 40 78 27 7 200.0 9.783421 0.00047 1.5255 0.008673554\\n',\n",
       " '1 40 77 27 8 210.0 9.336648 0.0003 1.5255 0.0034828954\\n',\n",
       " '1 39 76 27 9 120.0 9.266148 0.0003 1.6154 0.0005616\\n',\n",
       " '1 40 75 27 10 210.0 8.997657 0.00046190477 1.5255 0.0034828954\\n',\n",
       " '1 40 74 27 11 200.0 8.907056 0.0003 1.5255 0.0011087263\\n',\n",
       " '1 40 73 27 12 200.0 8.847056 0.0003 1.5255 0.0005616\\n',\n",
       " '1 40 72 27 13 200.0 8.772334 0.00047 1.5255 0.0005616\\n',\n",
       " '1 40 71 27 14 220.0 8.603085 0.0006090909 1.5255 0.0034828954\\n',\n",
       " '1 40 70 27 15 190.0 8.511766 0.0003 1.5255 0.0005616\\n',\n",
       " '1 41 69 27 16 210.0 8.445766 0.0003 1.5255 0.0021888781\\n',\n",
       " '1 41 68 27 17 200.0 8.384266 0.0003 1.5255 0.033251446\\n',\n",
       " '1 41 67 27 18 240.0 8.318266 0.0003 1.5255 0.065645926\\n',\n",
       " '1 42 66 27 19 200.0 8.240266 0.0003 1.5255 0.065645926\\n',\n",
       " '1 42 65 27 20 210.0 8.178766 0.0003 1.5255 0.021245781\\n',\n",
       " '1 43 64 27 21 200.0 8.111266 0.0003 1.5255 0.0661909\\n',\n",
       " '1 43 63 27 22 210.0 7.9343524 0.00094761903 1.5255 0.013574846\\n',\n",
       " '1 43 62 27 23 210.0 7.52826 0.00054285716 1.5255 0.0034828954\\n',\n",
       " '1 42 61 27 24 180.0 7.3293757 0.0003 1.5255 0.0005616\\n',\n",
       " '1 42 60 27 25 200.0 7.2723756 0.0003 1.5255 0.0005616\\n',\n",
       " '1 42 59 27 26 200.0 7.2123756 0.0003 1.5255 0.0005616\\n',\n",
       " '1 42 58 27 27 220.0 7.145232 0.00037727272 1.5255 0.0005616\\n',\n",
       " '1 42 57 27 28 210.0 7.077864 0.0003 1.5255 0.0005616\\n',\n",
       " '1 42 56 27 29 200.0 7.016364 0.0003 1.5255 0.0005616\\n',\n",
       " '1 42 55 27 30 150.0 6.963864 0.0003 1.5255 0.0034828954\\n',\n",
       " '1 43 54 27 31 220.0 6.887364 0.0003 1.5255 0.005496279\\n',\n",
       " '1 43 53 27 32 200.0 6.8243637 0.0003 1.5255 0.0034828954\\n',\n",
       " '1 43 52 27 33 200.0 6.764364 0.0003 1.5255 0.0005616\\n',\n",
       " '1 43 51 27 34 210.0 6.702864 0.0003 1.5255 0.0005616\\n',\n",
       " '1 43 50 27 35 120.0 6.6533637 0.0003 1.5255 0.0005616\\n',\n",
       " '1 44 50 27 36 170.0 6.6098638 0.0003 1.5255 0.016842762\\n',\n",
       " '1 44 49 27 37 220.0 6.551364 0.0003 1.5255 0.1296\\n',\n",
       " '1 44 48 27 38 210.0 6.486864 0.0003 1.5255 0.1296\\n',\n",
       " '1 44 47 27 39 220.0 6.4223638 0.0003 1.5255 0.1296\\n',\n",
       " '1 45 46 27 40 170.0 6.0701113 0.0007 1.5255 0.02702232\\n',\n",
       " '1 45 45 27 41 200.0 5.9001284 0.0003 1.5255 0.008673554\\n',\n",
       " '1 45 44 27 42 210.0 5.8386283 0.0003 1.5255 0.013687541\\n',\n",
       " '1 45 43 27 43 220.0 5.7741284 0.0003 1.5255 0.0216\\n',\n",
       " '1 45 42 27 44 210.0 5.7096286 0.0003 1.5255 0.008673554\\n',\n",
       " '1 45 41 27 45 160.0 5.234546 0.00115 1.5255 0.0005616\\n',\n",
       " '1 46 40 27 46 210.0 4.3731837 0.0003 1.5255 0.0216\\n',\n",
       " '1 46 39 27 47 220.0 4.3109517 0.00045454546 1.5255 0.0022070496\\n',\n",
       " '1 47 38 27 48 220.0 4.222191 0.0003 1.5255 0.0005616\\n',\n",
       " '1 48 38 27 49 170.0 4.152466 0.0005 1.5255 0.0005616\\n',\n",
       " '1 49 37 27 50 250.0 3.96912 0.00064 1.5255 0.0021888781\\n',\n",
       " '1 50 36 27 51 270.0 3.713502 0.0008037037 1.5255 0.0005616\\n',\n",
       " '1 51 35 27 52 260.0 3.4293075 0.0006923077 1.5255 0.0005616\\n',\n",
       " '1 52 34 27 53 240.0 3.1913114 0.0005833333 1.5255 0.0005616\\n',\n",
       " '1 53 33 27 54 140.0 3.0918572 0.0003 1.5255 0.0005616\\n',\n",
       " '1 53 32 27 55 270.0 3.0303571 0.0003 1.5255 0.0011087263\\n',\n",
       " '1 54 31 27 56 170.0 2.9643571 0.0003 1.5255 0.0068194154\\n',\n",
       " '1 53 30 27 57 210.0 2.8249485 0.00054285716 1.5255 0.0043213437\\n',\n",
       " '1 53 29 27 58 210.0 2.7538328 0.0003 1.5255 0.0043213437\\n',\n",
       " '1 53 28 27 59 220.0 2.5049615 0.0005318182 1.5255 0.0021888781\\n',\n",
       " '1 53 27 27 60 210.0 2.2324612 0.0007047619 1.5255 0.016842762\\n',\n",
       " '1 52 26 27 61 150.0 2.1156218 0.00052666664 1.5255 0.0005616\\n',\n",
       " '1 53 25 27 62 230.0 1.9346391 0.00052173913 1.5255 0.0043213437\\n',\n",
       " '1 54 24 27 63 230.0 1.7595534 0.00037391303 1.5255 0.026579183\\n',\n",
       " '1 54 23 27 64 210.0 1.6302099 0.00046190477 1.5255 0.1296\\n',\n",
       " '1 54 22 27 65 200.0 1.5246305 0.00047 1.5255 0.0661909\\n',\n",
       " '1 54 21 27 66 210.0 1.2551998 0.00046190477 1.5255 0.08280703\\n',\n",
       " '1 54 20 27 67 210.0 1.038907 0.0006238095 1.5255 0.0043213437\\n',\n",
       " '1 54 19 27 68 210.0 0.8379543 0.0003 1.5255 0.0021888781\\n',\n",
       " '1 54 18 27 69 210.0 0.7498549 0.00038095238 1.5255 0.0005616\\n',\n",
       " '1 54 17 27 70 230.0 0.58712727 0.00037391303 1.5255 0.0005616\\n',\n",
       " '1 55 16 27 71 130.0 0.4856459 0.00043076923 1.5255 0.0005616\\n',\n",
       " '1 55 15 27 72 220.0 0.4331459 0.0003 1.5255 0.0005616\\n',\n",
       " '1 55 14 27 73 220.0 0.3671459 0.0003 1.5255 0.0005616\\n',\n",
       " '1 55 13 27 74 210.0 0.3026459 0.0003 1.5255 0.0005616\\n',\n",
       " '1 54 13 27 75 150.0 0.2486459 0.0003 1.5255 0.0005616\\n',\n",
       " '1 54 12 27 76 230.0 0.19164589 0.0003 1.5255 0.0005616\\n',\n",
       " '1 53 11 27 77 120.0 0.11214589 0.0003 1.5255 0.0005616\\n',\n",
       " '1 52 11 27 78 240.0 0.058145896 0.0003 1.5255 0.0005616\\n',\n",
       " '1 51 10 27 79 180.0 -0.025854103 0.0003 1.5255 0.0005616\\n',\n",
       " '1 50 10 27 80 150.0 -0.07535411 0.0003 1.5255 0.0005616\\n',\n",
       " '1 49 9 27 81 220.0 -0.1608541 0.0003 1.5255 0.0005616\\n',\n",
       " '1 48 8 27 82 230.0 -0.2403541 0.0003 1.5255 0.0012533445\\n',\n",
       " '1 47 8 27 83 220.0 -0.30785412 0.0003 1.5255 0.0012533445\\n',\n",
       " '1 46 8 27 84 230.0 -0.3753541 0.0003 1.5255 0.0034828954\\n',\n",
       " '1 45 8 27 85 180.0 -0.4368541 0.0003 1.5255 0.0022070496\\n',\n",
       " '1 44 7 27 86 240.0 -0.5148541 0.0003 1.5255 0.0005616\\n',\n",
       " '1 43 6 27 87 230.0 -0.6063541 0.0003 1.5255 0.0062424787\\n',\n",
       " '1 42 5 27 88 230.0 -0.6903541 0.0003 1.5255 0.0005616\\n',\n",
       " '27 0 0\\n',\n",
       " '1 4 2 0 36 244857.6 0 0 0 \\n',\n",
       " '11213.93 176276.55 279491.19 327493.16 595586.80 687403.88 769427.13 800277.67 847900.13 957835.78 1010844.84 1207333.40 1284092.48 1535916.12 1632385.27 1985085.28 2116689.76 2290897.37 2500485.16 2678732.72 2885382.36 3065833.53 3302966.44 3568379.01 4224075.39 4653534.48 5218025.89 5791454.17 6419850.26 7149490.00 7917080.79 9929711.19 11990086.48 15024947.04 18581328.62 24325405.17 \\n',\n",
       " '0.67 0.93 0.98 1.01 1.13 1.17 1.20 1.21 1.22 1.25 1.26 1.31 1.33 1.38 1.40 1.46 1.48 1.51 1.53 1.56 1.58 1.61 1.63 1.66 1.73 1.76 1.81 1.85 1.89 1.94 1.99 2.10 2.19 2.29 2.41 2.56 \\n',\n",
       " '11.89 23.27 25.11 26.78 31.57 32.44 33.83 35.96 38.08 42.41 44.56 50.56 52.67 59.16 61.31 67.41 69.47 71.33 73.64 75.34 75.52 75.56 75.59 75.32 75.41 76.17 76.30 76.52 76.95 77.04 77.33 78.45 79.36 80.49 81.49 82.79 \\n',\n",
       " '2 2 3 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 0.20 3.80 13.10 90.10 130.70 140.70 149.50 \\n',\n",
       " '4.40 2.52 0.59 0.00 2.98 2.03 3.08 2.16 \\n',\n",
       " '3 2 4 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 10.78 50.06 71.00 90.29 92.57 93.00 95.25 \\n',\n",
       " '1.19 0.00 1.97 2.17 1.86 0.77 1.96 2.81 \\n',\n",
       " '4 2 5 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 3.73 4.43 22.23 57.06 66.08 70.23 72.18 \\n',\n",
       " '8.26 4.03 0.52 0.00 0.71 2.71 4.36 6.12 \\n',\n",
       " '5 2 6 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 1.50 4.40 32.50 53.00 61.15 63.50 72.35 \\n',\n",
       " '4.16 2.31 0.99 0.95 0.00 0.83 2.51 5.12 \\n',\n",
       " '6 2 7 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 5.33 7.00 8.44 12.06 20.00 62.90 70.15 \\n',\n",
       " '3.57 3.65 2.54 2.82 1.43 0.00 0.32 2.36 \\n',\n",
       " '7 2 8 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 2.60 6.10 14.70 25.95 63.25 69.15 76.50 \\n',\n",
       " '5.75 4.71 4.18 3.79 2.20 0.00 0.36 4.55 \\n',\n",
       " '8 2 9 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 11.31 18.66 30.06 54.56 66.81 70.56 78.36 \\n',\n",
       " '5.74 2.13 0.59 0.21 0.50 0.00 0.05 4.48 \\n',\n",
       " '9 2 10 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 4.95 16.20 35.55 72.25 83.35 91.55 100.85 \\n',\n",
       " '3.80 2.31 3.12 2.62 0.00 0.21 2.71 2.96 \\n',\n",
       " '10 2 11 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 2.00 5.50 19.90 34.10 68.60 73.88 77.21 \\n',\n",
       " '6.47 1.36 0.00 0.91 0.26 2.88 5.12 7.26 \\n',\n",
       " '11 2 12 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 17.50 52.65 59.75 86.55 92.00 96.50 96.60 \\n',\n",
       " '3.09 4.68 2.96 0.71 0.00 1.58 8.18 8.18 \\n',\n",
       " '12 2 13 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 5.25 28.50 43.90 61.80 65.90 69.84 75.71 \\n',\n",
       " '4.38 1.87 0.90 1.06 0.00 0.86 3.32 4.26 \\n',\n",
       " '13 2 14 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 3.65 6.55 14.30 15.95 17.20 18.85 59.45 \\n',\n",
       " '9.07 6.75 5.42 2.64 1.74 0.39 0.00 0.31 \\n',\n",
       " '14 2 15 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 6.45 17.75 23.70 53.25 54.60 58.60 61.90 \\n',\n",
       " '3.30 0.45 0.00 0.45 0.96 1.50 1.62 2.11 \\n',\n",
       " '15 2 16 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 8.20 11.35 35.20 45.00 50.40 58.60 72.00 \\n',\n",
       " '1.56 1.02 0.00 2.80 2.89 5.48 5.27 8.96 \\n',\n",
       " '16 2 17 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 20.90 36.70 44.70 69.00 85.69 93.05 97.44 \\n',\n",
       " '6.02 3.38 3.13 1.03 0.00 0.03 1.11 8.41 \\n',\n",
       " '17 2 18 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 2.90 4.75 39.20 51.20 58.30 64.05 64.10 \\n',\n",
       " '4.44 0.65 0.00 0.49 0.05 1.87 5.90 5.90 \\n',\n",
       " '18 2 19 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 8.40 13.00 35.00 36.80 37.10 39.00 40.40 \\n',\n",
       " '5.70 1.19 0.00 0.92 1.38 2.00 2.55 4.23 \\n',\n",
       " '19 2 20 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 3.10 4.40 7.10 8.80 23.10 33.70 36.45 \\n',\n",
       " '6.38 4.43 2.80 1.85 0.77 0.00 0.29 1.78 \\n',\n",
       " '20 2 21 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 4.50 5.65 7.15 14.85 39.15 39.85 42.95 \\n',\n",
       " '5.73 4.73 2.83 1.73 0.73 0.00 0.16 3.68 \\n',\n",
       " '21 2 22 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 5.10 16.55 30.60 38.20 43.80 44.30 49.80 \\n',\n",
       " '3.33 0.91 1.09 0.00 0.25 2.73 3.78 6.94 \\n',\n",
       " '22 2 23 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 2.30 7.20 25.80 32.45 34.20 35.60 42.35 \\n',\n",
       " '7.24 5.21 2.29 1.69 0.00 0.92 1.04 6.98 \\n',\n",
       " '23 2 24 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 4.85 8.75 10.85 11.25 23.55 29.65 33.45 \\n',\n",
       " '5.60 4.38 2.26 1.83 1.23 0.00 0.86 3.17 \\n',\n",
       " '24 2 25 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 1.30 4.80 6.40 9.70 21.35 25.40 32.30 \\n',\n",
       " '7.56 4.62 2.87 1.37 0.56 0.53 0.00 0.57 \\n',\n",
       " '25 2 26 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 2.40 4.50 5.80 7.50 25.45 31.50 34.50 \\n',\n",
       " '6.78 3.57 3.30 1.55 0.73 0.00 1.39 4.36 \\n',\n",
       " '26 2 27 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 8.65 20.95 37.50 39.05 40.75 41.85 44.25 \\n',\n",
       " '0.67 0.00 1.35 0.66 1.85 1.84 3.72 4.51 \\n',\n",
       " '27 2 0 0 0 0 0 0 0.048 0.083 \\n',\n",
       " '0.00 0.05 4.40 15.70 22.10 26.40 30.75 33.55 \\n',\n",
       " '3.13 2.44 0.55 0.60 0.00 0.26 3.06 6.23 \\n',\n",
       " '1 731 56\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " '-27 0 0\\n',\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = os.path.join(model_ws+'/MF.sfr')\n",
    "stuff = open(f).readlines()\n",
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "expired-locator",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModflowSfr2' object has no attribute '_generate_heading'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7324/3787887929.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# reload sfr package to remove any changes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msfr_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModflowSfr2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_ws\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/MF.sfr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflow\\mfsfr2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, f, model, nper, gwt, nsol, ext_unit_dict)\u001b[0m\n\u001b[0;32m   1078\u001b[0m             \u001b[0mnparseg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnparseg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m             \u001b[0mconst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m             \u001b[0mdleak\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdleak\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1081\u001b[0m             \u001b[0mipakcb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mipakcb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m             \u001b[0mistcb2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mistcb2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflow\\mfsfr2.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, nstrm, nss, nsfrpar, nparseg, const, dleak, ipakcb, istcb2, isfropt, nstrail, isuzn, nsfrsets, irtflg, numtim, weight, flwtol, reach_data, segment_data, channel_geometry_data, channel_flow_data, dataset_5, irdflag, iptflag, reachinput, transroute, tabfiles, tabfiles_dict, extension, unit_number, filenames, options)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[0mextra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[1;31m# set package name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m         \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ModflowSfr2' object has no attribute '_generate_heading'"
     ]
    }
   ],
   "source": [
    "# blank model to allow loading\n",
    "m = flopy.modflow.Modflow()\n",
    "# reload sfr package to remove any changes\n",
    "sfr_p = flopy.modflow.ModflowSfr2.load(f = model_ws+'/MF.sfr', model = m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "collect-brooks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating new model with name: MF\n",
      "--------------------------------------------------\n",
      "\n",
      "Parsing the namefile --> F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.nam\n",
      "\n",
      "--------------------------------------------------\n",
      "External unit dictionary:\n",
      "{2: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.list, filetype:LIST, 11: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.dis, filetype:DIS, 13: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.bas, filetype:BAS6, 15: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.lpf, filetype:LPF, 17: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.sfr, filetype:SFR, 56: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.tab, filetype:DATA, 23: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.ghb, filetype:GHB, 24: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.chd, filetype:CHD, 19: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.rch, filetype:RCH, 20: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.wel, filetype:WEL, 39: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.hob, filetype:HOB, 14: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.oc, filetype:OC, 27: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.pcg, filetype:PCG, 55: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.cbc, filetype:DATA(BINARY), 54: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.sfr.out, filetype:DATA, 50: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.hob.out, filetype:DATA, 51: filename:F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/WEL_SFR_RCH_layercake\\MF.hds, filetype:DATA(BINARY)}\n",
      "--------------------------------------------------\n",
      "\n",
      "ModflowBas6 free format:True\n",
      "\n",
      "loading dis package file...\n",
      "   Loading dis package with:\n",
      "      3 layers, 100 rows, 230 columns, and 731 stress periods\n",
      "   loading laycbd...\n",
      "   loading delr...\n",
      "   loading delc...\n",
      "   loading top...\n",
      "   loading botm...\n",
      "      for 3 layers and 0 confining beds\n",
      "   loading stress period data...\n",
      "       for 731 stress periods\n",
      "adding Package:  DIS\n",
      "   DIS  package load...success\n",
      "   LIST package load...skipped\n",
      "loading bas6 package file...\n",
      "adding Package:  BAS6\n",
      "   BAS6 package load...success\n",
      "loading lpf package file...\n",
      "   loading IBCFCB, HDRY, NPLPF...\n",
      "   loading LAYTYP...\n",
      "   loading LAYAVG...\n",
      "   loading CHANI...\n",
      "   loading LAYVKA...\n",
      "   loading LAYWET...\n",
      "   loading hk layer   1...\n",
      "   loading vka layer   1...\n",
      "   loading ss layer   1...\n",
      "   loading hk layer   2...\n",
      "   loading vka layer   2...\n",
      "   loading ss layer   2...\n",
      "   loading hk layer   3...\n",
      "   loading vka layer   3...\n",
      "   loading ss layer   3...\n",
      "Adding MF.cbc (unit=55) to the output list.\n",
      "adding Package:  LPF\n",
      "   LPF  package load...success\n",
      "loading sfr2 package file...\n",
      "Adding MF.sfr.out (unit=54) to the output list.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ModflowSfr2' object has no attribute '_generate_heading'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7324/763571136.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel_ws\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mm_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MF.nam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_ws\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_ws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflow\\mf.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, f, version, exe_name, verbose, model_ws, load_only, forgive, check)\u001b[0m\n\u001b[0;32m    918\u001b[0m                                 \u001b[0mml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m                                 \u001b[0mext_unit_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mext_unit_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m                             )\n\u001b[0m\u001b[0;32m    921\u001b[0m                         \u001b[0mfiles_successfully_loaded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflow\\mfsfr2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, f, model, nper, gwt, nsol, ext_unit_dict)\u001b[0m\n\u001b[0;32m   1078\u001b[0m             \u001b[0mnparseg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnparseg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m             \u001b[0mconst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m             \u001b[0mdleak\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdleak\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1081\u001b[0m             \u001b[0mipakcb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mipakcb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m             \u001b[0mistcb2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mistcb2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflow\\mfsfr2.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, nstrm, nss, nsfrpar, nparseg, const, dleak, ipakcb, istcb2, isfropt, nstrail, isuzn, nsfrsets, irtflg, numtim, weight, flwtol, reach_data, segment_data, channel_geometry_data, channel_flow_data, dataset_5, irdflag, iptflag, reachinput, transroute, tabfiles, tabfiles_dict, extension, unit_number, filenames, options)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[0mextra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[1;31m# set package name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m         \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ModflowSfr2' object has no attribute '_generate_heading'"
     ]
    }
   ],
   "source": [
    "# loadpth = 'C:/WRDAPP/GWFlowModel/Cosumnes_Blodgett_10yr/'\n",
    "loadpth = 'F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/'\n",
    "model_ws = loadpth+'WEL_SFR_RCH_layercake'\n",
    "# packages = ['DIS','BAS6','LPF','GHB','CHD']\n",
    "\n",
    "# loadpth = 'F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_simple/'\n",
    "# model_ws = loadpth+'WEL_SFR_RCH_layercake'\n",
    "\n",
    "model_ws\n",
    "m_p = flopy.modflow.Modflow.load('MF.nam',model_ws = model_ws, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-knowing",
   "metadata": {},
   "source": [
    "# Set begin and end of grid refinement\n",
    "Start 5 rows above and 5 columns below Blodgett Dam and end 5 rows below and 5 columns above Blodgett Dam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "dam_row = 51\n",
    "dam_col = 151\n",
    "xy = gpd.GeoDataFrame(geometry=gpd.points_from_xy([m_p.modelgrid.xyzvertices[0][dam_row,dam_col]],\n",
    "                                                  [m_p.modelgrid.xyzvertices[1][dam_row,dam_col]]))\n",
    "\n",
    "xy = gpd.GeoDataFrame(geometry=gpd.points_from_xy([m_p.modelgrid.xyzcellcenters[0][dam_row,dam_col]],\n",
    "                                                  [m_p.modelgrid.xyzcellcenters[1][dam_row,dam_col]]))\n",
    "\n",
    "xy.crs='epsg:32610'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cells = 8\n",
    "beg_row= dam_row - num_cells + 1\n",
    "end_row= dam_row + num_cells + 1\n",
    "beg_col = dam_col - num_cells + 1\n",
    "end_col = dam_col + num_cells + 1 \n",
    "\n",
    "beg_lay = 0\n",
    "end_lay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_grid = parent_grid.loc[(parent_grid.row>=beg_row)&(parent_grid.row<end_row)]\n",
    "child_grid = child_grid.loc[(child_grid.column>=beg_col)&(child_grid.column<end_col)]\n",
    "\n",
    "child_grid = child_grid.rename({'node':'p_node','row':'p_row','column':'p_column'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "\n",
    "child_grid.plot(ax=ax,color='None', edgecolor='black')\n",
    "\n",
    "xy.plot(ax=ax)\n",
    "\n",
    "# xy.plot(ax=ax)\n",
    "# xmin,ymin, xmax, ymax = xy.buffer(2000).total_bounds\n",
    "# xmin, ymin = xy.buffer(400).total_bounds[0:2]\n",
    "\n",
    "# ax.set_xlim(xmin, xmax)\n",
    "# ax.set_ylim(ymin, ymax)\n",
    "\n",
    "ctx.add_basemap(ax, source = ctx.providers.Esri.WorldImagery,\n",
    "                crs='epsg:26910', alpha = 0.6)\n",
    "\n",
    "\n",
    "# parent_grid.plot(ax=ax,color='None', edgecolor='black')\n",
    "# child_grid.plot(ax=ax,color='None', edgecolor='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-avatar",
   "metadata": {},
   "source": [
    "# Create child model based on parent\n",
    "No side boundary conditions using GHB, CHD needed. These will be applied using the BFH package from LGR.  \n",
    "Packages to implement are BAS6 to identify connections with the parent grid, LPF to show refined geology, the LAK for Blodgett Dam and SFR for the Cosumnes River, and potentially the RCH and WEL package if the refined area is large enough but as the BFH should set the boundary heads and because the area is so small groundwater levels should be near uniform except for mounding under the river."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation = 52.9\n",
    "proj4_str='+proj=utm +zone=10 +ellps=WGS84 +datum=WGS84 +units=m +no_defs '\n",
    "\n",
    "ncpp = 4\n",
    "ncol = ncpp*(child_grid.p_column.max() - child_grid.p_column.min()+1)\n",
    "nrow = ncpp*(child_grid.p_row.max() - child_grid.p_row.min()+1)\n",
    "\n",
    "def make_delrc(n, ncpp, parent_delrc):\n",
    "    delrc = np.zeros(n)\n",
    "    for i in np.arange(0,ncpp):\n",
    "        delrc[i::ncpp] = parent_delrc/ncpp\n",
    "    return(delrc)\n",
    "delr = make_delrc(nrow, ncpp, m_p.dis.delr.array[beg_col:end_col])\n",
    "delc = make_delrc(ncol, ncpp, m_p.dis.delc.array[beg_row:end_row])\n",
    "\n",
    "# need to go to second layer to see total deep recharge\n",
    "ncppl = [4, 4]\n",
    "nlay = sum(ncppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_grid['id']=0\n",
    "m_domain = child_grid.dissolve(by='id')\n",
    "coords = list(m_domain.geometry.values[0].exterior.coords)\n",
    "xul = np.min(coords)\n",
    "yul = coords[np.where(coords==xul)[0][0]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "nper = m_p.dis.nper\n",
    "perlen = m_p.dis.perlen\n",
    "nstp = m_p.dis.nstp\n",
    "steady = m_p.dis.steady\n",
    "strt_date = m_p.dis.start_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-isaac",
   "metadata": {},
   "source": [
    "# Create Model and DIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = flopy.modflow.Modflow(modelname = 'MF', exe_name = 'MODFLOW-NWT.exe', \n",
    "#                           version = 'mfnwt', model_ws=model_ws)\n",
    "lgr_model_ws = loadpth+ 'LGR_SFR'\n",
    "m_c = flopy.modflow.Modflow(modelname = 'MF_child', exe_name = 'mf2005', \n",
    "                          version = 'mf2005', model_ws=lgr_model_ws)\n",
    "#lenuni = 1 is in ft, lenuni = 2 is in meters\n",
    "# itmuni is time unit 5 = years, 4=days, 3 =hours, 2=minutes, 1=seconds\n",
    "dis = flopy.modflow.ModflowDis(model=m_c,nrow=nrow, ncol=ncol, \n",
    "                               nlay=nlay, delr=delr, delc=delc,\n",
    "                                lenuni = 2, itmuni = 4,\n",
    "                               xul = xul, yul = yul,rotation=rotation, proj4_str=proj4_str,\n",
    "                              nper = nper, perlen=perlen, nstp=nstp, steady = steady,\n",
    "                              start_datetime = strt_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_c.modelgrid.write_shapefile(gwfm_dir+'/Blodgett_Dam/geospatial/blodgett_child_grid/blodgett_child_grid.shp')\n",
    "grid_c_nums = gpd.read_file(gwfm_dir+'/Blodgett_Dam/geospatial/blodgett_child_grid/blodgett_child_grid.shp')\n",
    "grid_c_nums.crs = 'epsg:32610'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer parents grid slightly to insure each cell covers the 4 child cells\n",
    "child_grid_buf = child_grid.copy()\n",
    "child_grid_buf.geometry = child_grid_buf.geometry.buffer(10) # works with 100, 50 meter cells\n",
    "child_connections = gpd.sjoin(child_grid_buf, grid_c_nums, how ='left',op='contains')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "# child_connections.to_csv(gwfm_dir+'/Blodgett_Dam/geospatial/child_connections/child_connection.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 0 based child_grid\n",
    "grid_c_py = child_connections.loc[:,child_connections.columns != 'geometry'].copy()\n",
    "grid_c_py.loc[:,grid_c_py.columns] = grid_c_py.loc[:,grid_c_py.columns].values - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get corresponding parent and child layers\n",
    "layers = pd.DataFrame(np.arange(0,sum(ncppl)), columns=['c_layers'])\n",
    "layers['p_layers']=0\n",
    "ncppl_cum = np.append(0,np.cumsum(np.asarray(ncppl)))\n",
    "tl = 0\n",
    "for n in ncppl_cum:\n",
    "    layers.loc[(layers['c_layers']>=n),'p_layers'] = tl\n",
    "    tl+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add layer connections to the grid indices correspondance between the parent and child grids\n",
    "grid_c_py['p_layer'] = 0\n",
    "grid_c_py['layer'] = 0\n",
    "df = grid_c_py.copy()\n",
    "\n",
    "for n in layers.index:\n",
    "    df.loc[:,'p_layer'] = layers.loc[n,'p_layers']\n",
    "    df.loc[:,'layer'] = layers.loc[n,'c_layers']\n",
    "    grid_c_py = grid_c_py.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_c_py.to_csv(gwfm_dir+'/Blodgett_Dam/geospatial/child_connections/child_connections_0based.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model top and bottom from previous model \n",
    "# if vertical grid refinement is desired\n",
    "top = np.zeros(m_c.dis.top.shape)\n",
    "top[grid_c_py.row,grid_c_py.column] = m_p.dis.top.array[grid_c_py.p_row,grid_c_py.p_column]\n",
    "m_c.dis.top = top\n",
    "\n",
    "topbotm = np.zeros((nlay+1, nrow, ncol))\n",
    "topbotm[0,:,:] = np.copy(top)\n",
    "topbotm_p = np.zeros((m_p.dis.nlay+1,m_p.dis.nrow,m_p.dis.ncol))\n",
    "topbotm_p[0,:,:] = m_p.dis.top.array\n",
    "topbotm_p[1:,:,:] = m_p.dis.botm.array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_num = 56\n",
    "# plt.plot(m_p.dis.top.array[row_num,:])\n",
    "# plt.plot(m_p.dis.botm.array[:,row_num,:][0])\n",
    "# plt.plot(m_p.dis.botm.array[:,row_num,:][1])\n",
    "# plt.plot(m_p.dis.botm.array[:,row_num,:][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(ncppl)\n",
    "# 2 or 8\n",
    "tl = 0\n",
    "for n in np.arange(0,len(ncppl)):\n",
    "    m_p.dis.botm.array[n, grid_c_py.p_row,grid_c_py.p_column]\n",
    "    thick_o = -np.diff(topbotm_p[n:n+2,grid_c_py.p_row,grid_c_py.p_column],axis=0)\n",
    "    thick = thick_o/ncppl[n]\n",
    "    for nl in np.arange(0,ncppl[n]):\n",
    "        topbotm[tl+1, grid_c_py.row,grid_c_py.column] = topbotm[tl, grid_c_py.row,grid_c_py.column] - thick\n",
    "        tl += 1\n",
    "\n",
    "m_c.dis.botm = topbotm[1:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(gwfm_dir+'/Blodgett_Dam/geospatial/DIS_data/topbotm_child.tsv',\n",
    "#            np.reshape(topbotm, (topbotm.shape[0]*topbotm.shape[1], topbotm.shape[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-philip",
   "metadata": {},
   "source": [
    "# BAS6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_array_data(m_p, m_c, package, param):\n",
    "    arr_p = getattr(getattr(m_p, package),param).array\n",
    "    arr_c = np.zeros(m_c.dis.botm.shape)\n",
    "    arr_c[grid_c_py.layer, grid_c_py.row,grid_c_py.column] = arr_p[grid_c_py.p_layer,grid_c_py.p_row,grid_c_py.p_column]\n",
    "    return(arr_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic package, BAS\n",
    "strt = np.zeros(m_c.dis.botm.shape)\n",
    "strt[:] = m_c.dis.top.array\n",
    "\n",
    "# mimic parent model ibound package\n",
    "ibound = refine_array_data(m_p, m_c, package='bas6',param='ibound')\n",
    "# add boundaries representing flow to and from the parent model\n",
    "ibound[:,0,:] = -59\n",
    "ibound[:,:,0] = -59\n",
    "ibound[:,-1,:] = -59\n",
    "ibound[:,:,-1] = -59\n",
    "ibound[-1,:,:] = -59\n",
    "\n",
    "# ibound < 0 is constant head\n",
    "# ibound = 0 is inactive cell\n",
    "# ibound > 0 is active cell\n",
    "# strt is array of starting heads\n",
    "bas = flopy.modflow.ModflowBas(model = m_c, ibound=ibound, strt = strt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-direction",
   "metadata": {},
   "source": [
    "# LPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_tprogs_dir = gwfm_dir+'/UPW_data/tprogs_final/'\n",
    "tprogs_files = glob.glob(mf_tprogs_dir+'*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.read_csv(m_c.model_ws+'/ZonePropertiesInitial.csv',index_col='Zone')\n",
    "# convert from m/s to m/d\n",
    "params['K_m_d'] = params.K_m_s * 86400    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tprogs_cut_elev(tprogs_line, dem_data, **kwargs):\n",
    "    rows = kwargs.get('rows', np.where(np.ones(dem_data.shape)==1)[0])\n",
    "    cols = kwargs.get('cols', np.where(np.ones(dem_data.shape)==1)[1])\n",
    "    tprogs_arr = np.reshape(tprogs_line, (320, 100,230))\n",
    "    tprogs_c = np.reshape(tprogs_arr[:, rows,cols],\n",
    "                             (tprogs_arr.shape[0],dem_data.shape[0],dem_data.shape[1]))\n",
    "    tprogs_elev = np.copy(tprogs_c)\n",
    "    # the bottom layer of the tprogs model is at -50 m amsl and the top layer is 50 m amsl\n",
    "    t = 0\n",
    "    for k in np.arange(-80,80,0.5):\n",
    "        tprogs_elev[t,dem_data<k]= np.NaN\n",
    "        t+=1\n",
    "    masked_tprogs = ma.masked_invalid(tprogs_elev)\n",
    "    return(masked_tprogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_param(tprogs):\n",
    "    tprogs[tprogs<0] *= -1\n",
    "    tprogs = tprogs.astype(float)\n",
    "    # flip tprogs mocdel along z axis to match modflow definition of 0 as top (TPROGS says 0 is bottom)\n",
    "    tprogs = np.flip(tprogs,axis=0)\n",
    "    tprogs_K = np.copy(tprogs)\n",
    "    tprogs_Sy = np.copy(tprogs)\n",
    "    tprogs_Ss = np.copy(tprogs)\n",
    "    # hydraulic parameters from fleckenstein 2006\n",
    "    # I-IV gravel, sand, muddy sand, mud\n",
    "    # K in m/s, Sy, Ss\n",
    "    for n in np.arange(1,5):\n",
    "        tprogs_K[tprogs==n]= params.loc[n,'K_m_d']\n",
    "    for n in np.arange(1,5):\n",
    "        tprogs_Sy[tprogs==n]= params.loc[n,'Sy']\n",
    "    for n in np.arange(1,5):\n",
    "        tprogs_Ss[tprogs==n]= params.loc[n,'Ss']\n",
    "            \n",
    "    return(tprogs_K,tprogs_Sy,tprogs_Ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0\n",
    "tprogs_line = np.loadtxt(tprogs_files[t])\n",
    "masked_tprogs=tprogs_cut_elev(tprogs_line, m_c.dis.top.array, rows = child_connections.p_row,cols = child_connections.p_column )\n",
    "K, Sy, Ss= int_to_param(masked_tprogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-condition",
   "metadata": {},
   "source": [
    "Accuracy may be better if hydraulic properties are the same for adjoining cells at the interface. Different flow Packages can be used for the parent and child grids. Don't refine exterior line defined by ibound = -59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically screen parent model for lpf or upw\n",
    "if getattr(m_p, 'lpf') != None:\n",
    "    print('lpf exists')\n",
    "    gel_pac = 'lpf'\n",
    "elif getattr(m_p, 'upw')  != None:\n",
    "    print('upw exists')\n",
    "    gel_pac = 'upw'\n",
    "\n",
    "hk = refine_array_data(m_p, m_c, gel_pac, 'hk')\n",
    "vka = refine_array_data(m_p, m_c, gel_pac, 'vka')\n",
    "sy = refine_array_data(m_p, m_c, gel_pac, 'sy')\n",
    "ss = refine_array_data(m_p, m_c, gel_pac, 'ss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layvka 0 means vka is vert K, non zero means its the anisotropy ratio between horiz and vert\n",
    "layvka = 0\n",
    "\n",
    "# LAYTYP MUST BE GREATER THAN ZERO WHEN IUZFOPT IS 2\n",
    "laytyp = 0 # 0 is confined, >0 convertible, <0 convertible unless the THICKSTRT option is in effect\n",
    "# Laywet must be 0 if laytyp is confined laywet = [1,1,1,1,1]\n",
    "#ipakcb = 55 means cell-by-cell budget is saved because it is non zero (default is 53)\n",
    "\n",
    "# until upscaling is begun then vertical and horiz K are the same for TPROGS\n",
    "# upw = flopy.modflow.ModflowUpw(model = m, hk =hk, layvka = layvka, vka = hk, sy=sy, ss=ss,\n",
    "#             laytyp=laytyp, ipakcb=53)\n",
    "\n",
    "lpf = flopy.modflow.ModflowLpf(model = m_c, hk =hk, layvka = layvka, vka = hk, sy=sy, ss=ss,\n",
    "                               laytyp=laytyp, ipakcb=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-connecticut",
   "metadata": {},
   "source": [
    "## Soils data for variable use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "uzf_path = gwfm_dir+'\\\\UZF_data'\n",
    "soil_path = uzf_path+'\\\\wss_gsmsoil_CA'\n",
    "# # Read in the soil map spatial data\n",
    "# soil_gpd = gpd.read_file(uzf_path+'\\\\wss_gsmsoil_CA\\\\spatial\\\\gsmsoilmu_a_ca.shp')\n",
    "# soil_gpd = soil_gpd.to_crs('EPSG:32610')\n",
    "# # soil_gpd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "soilKs_array = np.loadtxt(uzf_path+'/final_soilKs.tsv', delimiter = '\\t')\n",
    "soiln_array = np.loadtxt(uzf_path+'/final_soiln.tsv', delimiter = '\\t')\n",
    "soileps_array = np.loadtxt(uzf_path+'/final_soileps.tsv', delimiter = '\\t')\n",
    "soildepth_array = np.loadtxt(uzf_path+'/final_soildepth.tsv', delimiter = '\\t')\n",
    "\n",
    "# soilKs_array = fill_uzf(grid_uzf.Ksat_Rep, grid_uzf)\n",
    "# soiln_array = fill_uzf(grid_uzf.Porosity_R, grid_uzf)\n",
    "# soileps_array = fill_uzf(grid_uzf.EPS, grid_uzf)\n",
    "\n",
    "# np.savetxt(uzf_path+'/final_soilKs.tsv', soilKs_array, delimiter = '\\t')\n",
    "# np.savetxt(uzf_path+'/final_soiln.tsv', soiln_array, delimiter = '\\t')\n",
    "# np.savetxt(uzf_path+'/final_soileps.tsv', soileps_array, delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-croatia",
   "metadata": {},
   "source": [
    "# SFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_dir = gwfm_dir+'/SFR_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-contact",
   "metadata": {},
   "source": [
    "Shapefile and csv of stream points for Sacramento County developed by Jason Weiner using the best available elevation datasets (10m, 1m DEMs, available Thalweg data, 1 ft Sac County elevation contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_pts = pd.read_csv(sfr_dir+'/1_SASb/SASb_stream_pts_XYZ.csv')\n",
    "str_pts = gpd.GeoDataFrame(str_pts, geometry=gpd.points_from_xy(str_pts.X_coord_UTM ,str_pts.Y_coord_UTM ))\n",
    "str_pts.crs = 'epsg:32610'\n",
    "str_pts = gpd.clip(str_pts, m_domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rivers and creeks in the larger area encompassing Cosumnes River in both South American and Cosumnes Subbasins\n",
    "rivers = gpd.read_file(gwfm_dir+\"/SFR_data/Sac_valley_rivers/Sac_valley_rivers.shp\")\n",
    "rivers = rivers.to_crs('EPSG:32610')\n",
    "rivers_clip = gpd.clip(rivers, m_domain)\n",
    "\n",
    "# # Split into individual streams/creeks\n",
    "cr_ind = rivers_clip[rivers_clip.GNIS_Name == 'Cosumnes River']\n",
    "# dc_ind = rivers_clip[rivers_clip.GNIS_Name == 'Deer Creek']\n",
    "# # Pull out data for each river/creek\n",
    "cr = rivers_clip.loc[cr_ind.index,]\n",
    "# dc = rivers_clip.loc[dc_ind.index,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get str pts just for the Cosumnes\n",
    "cr_buf = cr.copy()\n",
    "cr_buf['geometry'] = cr_buf.buffer(200)\n",
    "cos_pts = gpd.sjoin(str_pts, cr_buf)\n",
    "# cos_pts.plot('Z_NAVD_88_m',legend=True)\n",
    "# cos_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from shapely.geometry import shape, mapping\n",
    "from shapely.ops import linemerge\n",
    "\n",
    "cr.geometry.values.crs = \"epsg:32610\"\n",
    "geom = linemerge(cr.geometry.values)\n",
    "# how often to interpolate a point\n",
    "dline = 10\n",
    "# # length of the LineString\n",
    "length = int(geom.length)\n",
    "point = np.zeros((int(length/dline)+1,3))\n",
    "for i, distance in enumerate(range(0, int(length), dline)):\n",
    "         point[i,:] = geom.interpolate(distance).coords[:][0]\n",
    "point = point[:,[0,1]]\n",
    "plt.plot(point[:,0],point[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_name = gwfm_dir+'/DEM_data/USGS_ten_meter_dem/regional_10m.tif'\n",
    "\n",
    "# dem10 = rasterio.open(raster_name)\n",
    "\n",
    "pnts = pd.DataFrame()\n",
    "with rasterio.open(raster_name) as src:\n",
    "    pnts['z'] = [sample[0] for sample in src.sample(point)]\n",
    "pnts\n",
    "pnts['easting'] = point[:,0]\n",
    "pnts['northing'] = point[:,1]\n",
    "pnts = pnts[pnts.z > -1E4]\n",
    "pnts['z_original'] = pnts.z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,3))\n",
    "pnts.z_original.plot()\n",
    "pnts['slope'] = 0.002\n",
    "for i in np.arange(1,len(pnts)):\n",
    "    if pnts.z.values[i] >= pnts.z.values[i-1]:\n",
    "        # if strtop is greater than previous strtop use previous elevation minus the average slope\n",
    "        slope = 0.0003\n",
    "        pnts.z.values[i] = pnts.z.values[i-1] - slope*dline\n",
    "        pnts.slope.values[i] = slope\n",
    "pnts.z.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnts['Point_order'] = pnts.index\n",
    "pnts_gpd = gpd.GeoDataFrame(pnts, geometry = gpd.points_from_xy(pnts.easting, pnts.northing))\n",
    "pnts_gpd.crs = 'epsg:32610'\n",
    "\n",
    "# # Samples the points every 10 meters to match with the 100 meter grid\n",
    "grid_sfr = gpd.sjoin(grid_c_nums, pnts_gpd, how = \"inner\", op= \"intersects\")\n",
    "\n",
    "# Set reach length for each reach based on the separation used to create the points from the line object, dline is 10 meters\n",
    "grid_sfr['length_m'] = dline\n",
    "\n",
    "# Dissolve the points again but using sum this time to get the total length of each reach\n",
    "length_m_sums = grid_sfr.dissolve(by = 'node', aggfunc = 'sum').length_m.values\n",
    "\n",
    "# Dissolves the points every 10 meters to the 200 meter spacing, using mean because the interested component is elevation\n",
    "grid_sfr = grid_sfr.dissolve(by = 'node', aggfunc = 'mean')\n",
    "grid_sfr.length_m = length_m_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_quant = 0.2\n",
    "print('mean stream length in cell is ', grid_sfr.length_m.mean(), ' meters')\n",
    "print('the',cutoff_quant*100 , '% quantile is', grid_sfr.length_m.quantile(cutoff_quant), ' meters')\n",
    "print('the 75% quantile is', grid_sfr.length_m.quantile(0.75), ' meters')\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(10,4))\n",
    "\n",
    "grid_sfr.length_m.hist(ax=ax[0])\n",
    "ax[0].set_xlabel('Reach length (m)')\n",
    "\n",
    "length_threshold = grid_sfr.length_m.quantile(cutoff_quant)\n",
    "grid_sfr.loc[grid_sfr.length_m >length_threshold].plot(ax=ax[1])\n",
    "print('even after setting cutoff at', length_threshold, 'm there is still stream connection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove reaches with a length less than 100m, short reaches with high conductance can lead to large errors\n",
    "# in the SFR package and unneccessarily increase computation time\n",
    "grid_sfr = grid_sfr.loc[grid_sfr.length_m >length_threshold]\n",
    "\n",
    "# reorder reaches, and relabel the reach numbering after removing very shroty reaches\n",
    "grid_sfr = grid_sfr.sort_values(by = 'Point_order')\n",
    "grid_sfr['reach'] = np.arange(1,len(grid_sfr)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_sfr.drop('index_right',axis=1).to_file(gwfm_dir+'/Blodgett_Dam/geospatial/child_grid_sfr/child_grid_sfr.shp')\n",
    "# grid_sfr = gpd.read_file(gwfm_dir+'/Blodgett_Dam/geospatial/child_grid_sfr/child_grid_sfr.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario = 'design'\n",
    "# scenario = 'actual'\n",
    "# scenario = 'new'\n",
    "scenario = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "XS8pt = pd.read_csv(sfr_dir+'8pointXS.csv')\n",
    "# XSlocs = gpd.read_file(sfr_dir+'8pointXS_locs/8pointXS_locs.shp')\n",
    "# new shapefile with an extra point for blodgett dam as site 16.5\n",
    "XSlocs = gpd.read_file(gwfm_dir+'/Blodgett_Dam/geospatial/8pointXS_locs/8pointXS_locs.shp')\n",
    "XSlocs.crs = 32610\n",
    "XSlocs.geometry = XSlocs.buffer(5) # buffer XS locs to insure they cross with grid_sfr\n",
    "XSg  = gpd.sjoin(grid_sfr, XSlocs, how = \"inner\", op= \"intersects\", lsuffix = 'sfr',rsuffix = 'xs')\n",
    "XSg = XSg.drop_duplicates('Site') # drop second 17 that was duplicated by buffering\n",
    "\n",
    "if scenario == 'none':\n",
    "    # if no blodgett dam scenario then remove the extra cross section\n",
    "    XSg = XSg.loc[(XSg.Site!=16.5)]\n",
    "    XSg = XSg.loc[(XSg.Site!=16.2)]\n",
    "#     XSg = XSg.loc[XSg.Site!=16.2]\n",
    "elif scenario == 'actual':\n",
    "    XSg_side = XSg.loc[XSg.Site==16.5]\n",
    "    XSg_side.loc[:,'Site'] = 16.4\n",
    "    XSg = XSg.append(XSg_side)\n",
    "elif scenario == 'design':\n",
    "    # may or may not want to remove the segment before\n",
    "    XSg = XSg.loc[(XSg.Site!=16.2)]\n",
    "\n",
    "# if the scneario is the restructured or designed dam then no change in the segments is necessary\n",
    "# sort by site to make sure any XS added are properly included\n",
    "XSg = XSg.sort_values('Site')\n",
    "# print(len(XSg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "if scenario =='actual':\n",
    "    pre_rch_num = XSg.loc[XSg.Site==16.2,'reach'].iloc[0]\n",
    "    add_rch = grid_sfr.loc[grid_sfr.reach== pre_rch_num].copy()\n",
    "    # for all reaches after added reach, need to add 1 to the reach number\n",
    "    grid_sfr.loc[grid_sfr.reach>pre_rch_num,'reach'] = grid_sfr.loc[grid_sfr.reach>pre_rch_num,'reach'] +1\n",
    "    # using the desired reach add 1 to just the duplicate\n",
    "    add_rch.reach +=1\n",
    "    # extra channel is 10m in length because it is there just to allow transfer of flow\n",
    "    grid_sfr.loc[grid_sfr.reach== pre_rch_num,'length_m'] = 10\n",
    "    add_rch.z = add_rch.z-10*add_rch.slope # adjust elevation of added reach to account for slope required\n",
    "    grid_sfr = grid_sfr.append(add_rch).sort_values('reach')\n",
    "    # adjust XSg to account for chnages to grid_sfr\n",
    "    XSg.loc[XSg.reach>pre_rch_num,'reach'] +=1\n",
    "    XSg.loc[XSg.Site==16.2,'reach']+=1 #add one to 16.2 because can't have two of the same reach\n",
    "    \n",
    "    # need to duplicate the reach for the segment\n",
    "    add_rch_num = XSg.loc[XSg.Site==16.4,'reach'].iloc[0]\n",
    "    add_rch = grid_sfr.loc[grid_sfr.reach== add_rch_num].copy()\n",
    "    # for all reaches after added reach, need to add 1 to the reach number\n",
    "    grid_sfr.loc[grid_sfr.reach>add_rch_num,'reach'] = grid_sfr.loc[grid_sfr.reach>add_rch_num,'reach'] +1\n",
    "    # using the desired reach add 1 to just the duplicate\n",
    "    add_rch.reach +=1\n",
    "\n",
    "    # side channel is 70m in length from satellite\n",
    "    # length of reach after dam can be kept the same but could be reduced slightly to account for addition of flooding/lake\n",
    "    grid_sfr.loc[grid_sfr.reach== add_rch_num,'length_m'] = 70\n",
    "    add_rch.z = add_rch.z-70*add_rch.slope # adjust elevation of added reach to account for slope required\n",
    "    grid_sfr = grid_sfr.append(add_rch).sort_values('reach')\n",
    "    \n",
    "    # adjust XSg to account for chnages to grid_sfr\n",
    "    XSg.loc[XSg.reach>add_rch_num,'reach'] +=1\n",
    "    XSg.loc[XSg.Site==16.5,'reach']+=1 #add one to 16.5 because can't have two of the same reach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "XSg['iseg'] = np.arange(1,len(XSg)+1) # add the segment that corresponds to each cross section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if scenario == 'dam':\n",
    "    # designed scenario flow through dam only\n",
    "    new_xs = pd.read_csv(gwfm_dir+'/Blodgett_Dam/geospatial/02_designed_XS.csv', skiprows=1)\n",
    "elif scenario =='actual':\n",
    "    # current situation, flow around dam and after dam\n",
    "    new_xs = pd.read_csv(gwfm_dir+'/Blodgett_Dam/geospatial/03_actual_XS.csv', skiprows=1)\n",
    "elif scenario =='new':\n",
    "    # depending scenario, use different input cross sections for 16.5\n",
    "    new_xs = pd.read_csv(gwfm_dir+'/Blodgett_Dam/geospatial/01_New_wide_XS.csv')\n",
    "\n",
    "# if there is a scneario then need to add the new XS\n",
    "if scenario != 'none':\n",
    "    XS8pt = pd.concat([XS8pt,new_xs],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is one reach for each cell that a river crosses\n",
    "NSTRM = -len(grid_sfr)\n",
    "# There should a be a stream segment if there are major changes\n",
    "# in variables in Item 4 or Item 6\n",
    "# no extra segments needed in child model\n",
    "NSS =  len(XSg) \n",
    "# NSS = 2\n",
    "# nparseg (int) number of stream-segment definition with all parameters, must be zero when nstrm is negative\n",
    "NPARSEG = 0\n",
    "CONST = 86400 # mannings constant for SI units, 1.0 for seconds, 86400 for days\n",
    "# real value equal to the tolerance of stream depth used in\n",
    "# computing leakage between each stream reach and active model cell\n",
    "DLEAK = 0.0001 # unit in lengths, 0.0001 is sufficient for units of meters\n",
    "IPAKCB = 55\n",
    "# writes out stream depth, width, conductance, gradient when cell by cell\n",
    "# budget is specified and istcb2 is the unit folder\n",
    "ISTCB2 = 54\n",
    "# isfropt = 1 is no unsat flow\n",
    "# specifies whether unsat flow beneath stream or not, isfropt 2 has properties read for each reach, isfropt 3 also has UHC\n",
    "# read for each reach, isfropt 4 has properties read for each segment (no UHC), 5 reads for each segment with UHC\n",
    "ISFROPT = 1\n",
    "# nstrail (int), number of trailing weave increments used to represent a trailing wave, used to represent a decrease \n",
    "# in the surface infiltration rate. Can be increased to improve mass balance, values between 10-20 work well with error \n",
    "# beneath streams ranging between 0.001 and 0.01 percent, default is 10 (only when isfropt >1)\n",
    "NSTRAIL = 20\n",
    "# isuzn (int) tells max number of vertical cells used to define the unsaturated zone beneath a stream reach (default is 1)\n",
    "ISUZN = 1\n",
    "#nsfrsets (int) is max number of different sets of trailing waves (used to allocate arrays), a value of 30 is sufficient for problems\n",
    "# where stream depth varies often, value doesn't effect run time (default is 30)\n",
    "NSFRSETS = 30\n",
    "# IRTFLG (int) indicates whether transient streamflow routing is active, must be specified if NSTRM <0. If IRTFLG >0 then\n",
    "# flow will be routed with the kinematic-wave equations, otherwise it should be 0 (only for MF2005), default is 1\n",
    "IRTFLG = 1\n",
    "# numtim (int) is number of sub time steps used to route streamflow. Streamflow time step = MF Time step / NUMTIM. \n",
    "# Default is 2, only when IRTFLG >0\n",
    "NUMTIM = 2\n",
    "# weight (float) is a weighting factor used to calculate change in channel storage 0.5 - 1 (default of 0.75) \n",
    "WEIGHT = 0.75\n",
    "# flwtol (float), flow tolerance, a value of 0.00003 m3/s has been used successfully (default of 0.0001)\n",
    "# 0.00003 m3/s = 2.592 m3/day\n",
    "# if my units are in m3/day then flwtol should be in m3/day\n",
    "FLWTOL = 3\n",
    "\n",
    "\n",
    "sfr = flopy.modflow.ModflowSfr2(model = m_c, nstrm = NSTRM, nss = NSS, nparseg = NPARSEG, \n",
    "                           const = CONST, dleak = DLEAK, ipakcb = IPAKCB, istcb2 = ISTCB2, \n",
    "                          isfropt = ISFROPT, nstrail = NSTRAIL, isuzn = ISUZN, irtflg = IRTFLG, \n",
    "                          numtim = NUMTIM, weight = WEIGHT, flwtol = FLWTOL,\n",
    "                                reachinput=True, transroute=True, tabfiles=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_sfr = grid_sfr.set_index('reach')\n",
    "# set all reaches to start as segment 1 which will be changed iteratively based on the number of cross-sections\n",
    "xs_sfr['iseg'] = 1\n",
    "# add a column reach_new that will be changed iteratively as the segment number is changed\n",
    "xs_sfr['reach_new'] = xs_sfr.index\n",
    "# xs_sfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Given the reach number of each XS, the 718 reaches will be broken down into each segment\n",
    "## create a new reach column based on XS reach number and \n",
    "for i in np.arange(0,len(XSg)):\n",
    "    xs_r = XSg.reach.values[i]\n",
    "    rchnum = xs_sfr.index[-1] - xs_r+1\n",
    "    xs_sfr.reach_new.loc[xs_r:] = np.linspace(1,rchnum, rchnum)\n",
    "    xs_sfr.iseg.loc[xs_r:] = XSg.iseg.values[i]\n",
    "    \n",
    "# for simple 1 XS model\n",
    "# temp_reach = XSg.reach\n",
    "# rchnum = xs_sfr.index[-1] - temp_reach+1\n",
    "# xs_sfr.reach_new.loc[temp_reach:] = np.linspace(1,rchnum, rchnum)\n",
    "# xs_sfr.iseg.loc[temp_reach:] = segcount\n",
    "# segcount +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_sfr.reach_new = xs_sfr.reach_new.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which layer the streamcell is in\n",
    "# since the if statement only checks whether the first layer is greater than the streambed elevation, \n",
    "# otherwise it would be less than and zero (most should be in layer 0)\n",
    "sfr_lay = np.zeros(len(grid_sfr))\n",
    "\n",
    "for i in np.arange(0,nlay-1):\n",
    "    # pull out elevation of layer bottom\n",
    "    lay_elev = m_c.dis.botm.array[i, (grid_sfr.row.values-1).astype(int), (grid_sfr.column.values-1).astype(int)]\n",
    "    for j in np.arange(0,len(grid_sfr)):\n",
    "        # want to compare if streambed is lower than the layer bottom\n",
    "        # 1 will be subtracted from each z value to make sure it is lower than the model top in the upper reaches\n",
    "        if lay_elev[j] < (grid_sfr.z.values-1)[j]:\n",
    "            sfr_lay[j] = i \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KRCH, IRCH, JRCH, ISEG, IREACH, RCHLEN, STRTOP, SLOPE, STRTHICK, STRHC1, THTS, THTI, EPS, UHC\n",
    "\n",
    "columns = ['KRCH', 'IRCH', 'JRCH', 'ISEG', 'IREACH', 'RCHLEN', 'STRTOP', \n",
    "               'SLOPE', 'STRTHICK', 'STRHC1', 'THTS', 'THTI', 'EPS', 'UHC']\n",
    "\n",
    "sfr_rows = (grid_sfr.row.values-1).astype(int)\n",
    "sfr_cols = (grid_sfr.column.values-1).astype(int)\n",
    "\n",
    "sfr.reach_data.node = grid_sfr.index\n",
    "sfr.reach_data.k = sfr_lay.astype(int)\n",
    "sfr.reach_data.i = sfr_rows\n",
    "sfr.reach_data.j = sfr_cols\n",
    "sfr.reach_data.iseg = xs_sfr.iseg\n",
    "sfr.reach_data.ireach = xs_sfr.reach_new\n",
    "sfr.reach_data.rchlen = xs_sfr.length_m.values\n",
    "sfr.reach_data.strtop = grid_sfr.z.values-1\n",
    "sfr.reach_data.slope = grid_sfr.slope.values\n",
    " # a guess of 2 meters thick streambed was appropriate\n",
    "sfr.reach_data.strthick = soildepth_array[sfr.reach_data.i, sfr.reach_data.j]\n",
    "sfr.reach_data.thts = soiln_array[sfr.reach_data.i, sfr.reach_data.j]\n",
    "sfr.reach_data.thti = sfr.reach_data.thts\n",
    "sfr.reach_data.eps = soileps_array[sfr.reach_data.i, sfr.reach_data.j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr['dist_m'] = grid_sfr.length_m.cumsum()\n",
    "grid_sfr.dist_m -= grid_sfr.dist_m.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-season",
   "metadata": {},
   "source": [
    "## Setting stream hydraulic conductivity\n",
    "Currently the streambed hydraulic conductivity is set based on the streambed mapping done by Constantine 2001. An alternative approach would be to use the top layer of the TPROGS mode for the first few meters at the ground surface as VKA values after upscaling and then cycling through all of these models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elev_to_tprogs_layers(elev):\n",
    "    # function to get the tprogs layers based on the given elevation\n",
    "    # layer 0 is 80 meters, layer 1 is 79.5 meters, layer -1 is -80 meters\n",
    "    elev_05 = np.round((elev) * 2) / 2 # dem rounded to the nearest 0.5\n",
    "    elev_05[elev_05 >= 80] = 80# any elevation above 80 m is set to 80\n",
    "    elev_indices = 160 - elev_05*2 # subtract the calculated row from 160 to get to 0 at 160 and 320 and -160\n",
    "    return(elev_indices.astype(int))\n",
    "    \n",
    "def get_tprogs_for_elev(tprogs_arr, top_elev, bot_elev, **kwargs):\n",
    "    rows = kwargs.get('rows', np.where(np.ones(m_c.dis.top.shape)==1)[0])\n",
    "    cols = kwargs.get('cols', np.where(np.ones(m_c.dis.top.shape)==1)[1])\n",
    "    top_indices = elev_to_tprogs_layers(top_elev)\n",
    "    bot_indices = elev_to_tprogs_layers(bot_elev)\n",
    "    # find tprogs layer for desired rows and columns\n",
    "    top_indices = top_indices[rows, cols].astype(int)\n",
    "    bot_indices = bot_indices[rows, cols].astype(int)\n",
    "    # the first row of the array will be the top layer and will progress downward until the max bottom is reached\n",
    "    # with NaNs for rows,cols where there are less layers indexed than the max\n",
    "    tprogs_subset = np.full(shape = (np.max(bot_indices - top_indices).astype(int), len(rows)),\n",
    "                       fill_value = np.nan, dtype = float)\n",
    "    max_layers = np.max(bot_indices - top_indices)\n",
    "    for k in np.arange(0,max_layers):\n",
    "        layexist = (bot_indices-top_indices) > k # pick where data should be referenced\n",
    "        tprogs_subset[k, layexist] = K[top_indices[layexist]+k, rows[layexist], cols[layexist]]\n",
    "    # return grabbed data in array format if entire domain was used\n",
    "    if len(rows) == m_c.dis.nrow*m_c.dis.ncol:\n",
    "        tprogs_subset = np.reshape(tprogs_subset, (max_layers, m_c.dis.nrow,m_c.dis.ncol))\n",
    "    return(tprogs_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "strbd_thick = 4\n",
    "# get_tprogs_for_elev(K, m_c.dis.top.array, m_c.dis.top.array- np.linspace(1,4,m_c.dis.ncol), rows = sfr_rows, cols = sfr_cols)\n",
    "strbd_tprogs = get_tprogs_for_elev(K, m_c.dis.top.array, m_c.dis.top.array- strbd_thick, rows = sfr_rows, cols = sfr_cols)\n",
    "sfr_K = gmean(strbd_tprogs,axis=0)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stream hydraulic conductivity based on soil maps\n",
    "# sfr.reach_data.strhc1 = soilKs_array[sfr.reach_data.i, sfr.reach_data.j]*scalingfactors.RIV\n",
    "# set hydraulic conductivity smaller than aquifer hydraulic conductivity to limit interaction\n",
    "# and ease the numerical stress\n",
    "sfr.reach_data.strhc1 = sfr_K\n",
    "\n",
    "# calibration of the whole river now by scaling conductivity\n",
    "m_c.sfr.reach_data.strhc1 = m_c.sfr.reach_data.strhc1 \n",
    "# next step is to break river up into reaches based on the grain size analysis or perhaps just by stream segment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-norwegian",
   "metadata": {},
   "source": [
    "## Segment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_seg = sfr.segment_data[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15.0=14, 16.2 = 15, 16.4 = 16, 16.5 = 17, 17.0=18\n",
    "# 14 outseg will be the side channel (16), 15 is the diversion before the Dam from 14 iupseg\n",
    "# outseg for 15 will be -1 for the lake representing BLodgett Dam\n",
    "# there is a diversion from 15 (segment to Dam) to 16 (side channel) to correct for the flood diversion\n",
    "# so that below 500 cfs flow only goes to the side channel and above 500 cfs flow is 80% to Dam and 20% to side channel\n",
    "# based on the idea that the side channel has a XS roughly 1/4 the size of the main channel and under high flows there\n",
    "# will be more depth and force that flow will most likely be dominantly straight and avoid the side channel more\n",
    "if scenario =='actual':\n",
    "    pre_seg = XSg.loc[XSg.Site==16.2,'iseg'].iloc[0]\n",
    "    side_seg = XSg.loc[XSg.Site==16.4,'iseg'].iloc[0]\n",
    "if (scenario =='actual') | (scenario=='design'):\n",
    "    post_seg = XSg.loc[XSg.Site==16.5,'iseg'].iloc[0]\n",
    "# print(pre_seg,side_seg,post_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate version of segment data loading using if statements when filtering data rather than in a loop\n",
    "sfr_seg.nseg = np.arange(1,NSS+1) \n",
    "\n",
    "sfr_seg.icalc = 2 # Mannings and 8 point channel XS is 2 with plain MF, 5 with SAFE\n",
    "sfr_seg.outseg = sfr_seg.nseg+1 # the outsegment will typically be the next segment in the sequence\n",
    "sfr_seg.iupseg = 0 # iupseg is zero for no diversion\n",
    "# correct outseg and iupseg to account for Blodgett Dam scenario\n",
    "if scenario =='design':\n",
    "    sfr_seg.outseg[sfr_seg.nseg==post_seg-1]=-1 # segment before dam flows to lake\n",
    "    sfr_seg.iupseg[sfr_seg.nseg==post_seg]=-1 # lake outflow is diverted to segment after dam\n",
    "elif scenario == 'actual':\n",
    "    sfr_seg.outseg[sfr_seg.nseg==pre_seg-1] = side_seg # the river should flow to the side segment first\n",
    "     # there will be a diversion from the river to the dam above 500 cfs, of which 20% will be returned to the side channel\n",
    "    sfr_seg.iupseg[sfr_seg.nseg==pre_seg] = pre_seg-1\n",
    "    sfr_seg.iprior[sfr_seg.nseg==pre_seg] = -3 # iprior=-3 any flows above the flow specified will be diverted\n",
    "    sfr_seg.flow[sfr_seg.nseg==pre_seg] = 500*0.3048*86400 # 500 cfs is the start of higher flow in the Cosumnes\n",
    "    sfr_seg.outseg[sfr_seg.nseg==pre_seg] = -1 #outflow from short segment before Dam is the LAK for the dam\n",
    "\n",
    "    # adjust for flow from pre dam segment back to side channel\n",
    "    sfr_seg.iupseg[sfr_seg.nseg==side_seg] = pre_seg\n",
    "    sfr_seg.iprior[sfr_seg.nseg==side_seg] = -2 # the flow diverted is a % of the total flow in the channel\n",
    "    sfr_seg.flow[sfr_seg.nseg==side_seg] = 0.2 # the side channel is about 1/4 the size so 20% of flow should run through\n",
    "    # divert flow from lake back into the segment after the dam\n",
    "    sfr_seg.iupseg[sfr_seg.nseg==post_seg] = -1 # no need to change iprior because diversion is based on lake stage\n",
    "    \n",
    "# set a flow into segment 1 for the steady state model run\n",
    "sfr_seg.flow[0] = 2.834*86400. # m3/day, originally 15 m3/s\n",
    "# set the values for ET, runoff and PPT to 0 as the inflow will be small relative to the flow in the river\n",
    "sfr_seg.runoff = 0.0\n",
    "sfr_seg.etsw = 0.0\n",
    "sfr_seg.pptsw = 0.0\n",
    "\n",
    "# Manning's n data comes from Barnes 1967 UGSS Paper 1849 and USGS 1989 report on selecting manning's n\n",
    "# RoughCH is only specified for icalc = 1 or 2\n",
    "sfr_seg.roughch[(sfr_seg.icalc==1) | (sfr_seg.icalc==2)] = 0.048\n",
    "# ROUGHBK is only specified for icalc = 2\n",
    "sfr_seg.roughbk[(sfr_seg.icalc==2) | (sfr_seg.icalc==5)] = 0.083# higher due to vegetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr.segment_data[0] = sfr_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out data for upstream and downstream reach of each segment\n",
    "up_data = xs_sfr.drop_duplicates('iseg')\n",
    "dn_data = xs_sfr.sort_values('reach_new',ascending = False).drop_duplicates('iseg').sort_values('iseg')\n",
    "\n",
    "\n",
    "# Need to return to later and remove hard coding\n",
    "# These are getting used for initial guesses\n",
    "# Read in first stress period when ICALC = 1 or 2 and ISFROPT is 5\n",
    "# Dataset 6b\n",
    "sfr.segment_data[0].hcond1 = sfr.reach_data.strhc1[0]\n",
    "sfr.segment_data[0].thickm1 = 2\n",
    "sfr.segment_data[0].elevup = up_data.z.values\n",
    "sfr.segment_data[0].width1 = 20\n",
    "sfr.segment_data[0].depth1 = 1\n",
    "sfr.segment_data[0].thts1 = 0.4\n",
    "sfr.segment_data[0].thti1 = 0.15\n",
    "sfr.segment_data[0].eps1 = 4\n",
    "sfr.segment_data[0].uhc1 = sfr.reach_data.strhc1[0]\n",
    "\n",
    "# Dataset 6c\n",
    "sfr.segment_data[0].hcond2 = sfr.reach_data.strhc1[-1]\n",
    "sfr.segment_data[0].thickm2 = 2\n",
    "sfr.segment_data[0].elevdn = dn_data.z.values\n",
    "sfr.segment_data[0].width2 = 20\n",
    "sfr.segment_data[0].depth2 = 1\n",
    "sfr.segment_data[0].thts2 = 0.4\n",
    "sfr.segment_data[0].thti2 = 0.15\n",
    "sfr.segment_data[0].eps2 = 4\n",
    "sfr.segment_data[0].uhc2 = sfr.reach_data.strhc1[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column name to float type for easier referencing in iteration\n",
    "XS8pt.columns = XS8pt.columns.astype('float')\n",
    "# Pre-create dictionary to be filled in loop\n",
    "sfr.channel_geometry_data = {0:{j:[] for j in np.arange(1,len(XSg)+1)}  }\n",
    "\n",
    "xsnum = 1\n",
    "for k in XSg.Site.values:\n",
    "        pos = int(XS8pt.columns.get_loc(k))\n",
    "        XCPT = XS8pt.iloc[:,pos].values\n",
    "        ZCPT = XS8pt.iloc[:,pos+1].values\n",
    "        ZCPT_min = np.min(ZCPT)\n",
    "        ZCPT-= ZCPT_min\n",
    "        sfr.channel_geometry_data[0][xsnum] = [XCPT, ZCPT]\n",
    "        xsnum += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-thomas",
   "metadata": {},
   "source": [
    "## Read in Parent SFR\n",
    "First find parent SFR reach cells that overlap child model.\n",
    "Then determine the corresponding segment for the first and last reach cell to be outside of the child grid.\n",
    "Then remove theto remove and correct routing to go from the parent model to the child model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caring-australia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_simple/WEL_SFR_RCH_layercake/MF.sfr'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ws+'/MF.sfr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "future-shoot",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModflowSfr2' object has no attribute '_generate_heading'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7324/2164303313.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# reload sfr package to remove any changes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msfr_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModflowSfr2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_ws\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/MF.sfr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mm_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflow\\mfsfr2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, f, model, nper, gwt, nsol, ext_unit_dict)\u001b[0m\n\u001b[0;32m   1078\u001b[0m             \u001b[0mnparseg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnparseg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m             \u001b[0mconst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m             \u001b[0mdleak\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdleak\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1081\u001b[0m             \u001b[0mipakcb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mipakcb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m             \u001b[0mistcb2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mistcb2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflow\\mfsfr2.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, nstrm, nss, nsfrpar, nparseg, const, dleak, ipakcb, istcb2, isfropt, nstrail, isuzn, nsfrsets, irtflg, numtim, weight, flwtol, reach_data, segment_data, channel_geometry_data, channel_flow_data, dataset_5, irdflag, iptflag, reachinput, transroute, tabfiles, tabfiles_dict, extension, unit_number, filenames, options)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[0mextra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[1;31m# set package name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m         \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ModflowSfr2' object has no attribute '_generate_heading'"
     ]
    }
   ],
   "source": [
    "# reload sfr package to remove any changes\n",
    "sfr_p = flopy.modflow.ModflowSfr2.load(f = model_ws+'/MF.sfr',model=m_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr_p = gpd.read_file(sfr_dir+'/final_grid_sfr/grid_sfr.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "rch_c = pd.DataFrame(sfr.reach_data)\n",
    "seg_c = pd.DataFrame(sfr.segment_data[0])\n",
    "\n",
    "# # get reach, segment and XS data\n",
    "rch_p = pd.DataFrame(sfr_p.reach_data)\n",
    "seg_p = pd.DataFrame(sfr_p.segment_data[0])\n",
    "xs_dict = sfr_p.channel_geometry_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_p['lgrgrid'] = 0 # default is no lgrgrid\n",
    "seg_p['lgrseg'] = 0 # default is no lgrseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('Segments',rch_p.iseg.unique().shape[0])\n",
    "# find overlaps between SFR grid for the parent and the child grid\n",
    "sfr_overlap = grid_c_py.rename({'p_row':'i','p_column':'j'},axis=1).\\\n",
    "join(rch_p.set_index(['i','j']),how='inner',on=['i','j'],rsuffix='sfrp')\n",
    "\n",
    "rch_overlap = sfr_overlap.reachID.unique() #reaches to drop\n",
    "rch_min = sfr_overlap.reachID.min()\n",
    "rch_max = sfr_overlap.reachID.max()\n",
    "seg_overlap = np.sort(sfr_overlap.iseg.unique()) # segments to drop\n",
    "seg_min = rch_p.set_index('reachID').loc[rch_min].iseg\n",
    "seg_max = rch_p.set_index('reachID').loc[rch_max].iseg\n",
    "\n",
    "# add one to the segment starting in the first reach that overlaps the child grid\n",
    "rch_p.loc[rch_p.reachID >= rch_min,'iseg'] +=1\n",
    "# add one to the segment starting in the first reach that is past the child grid\n",
    "rch_p.loc[rch_p.reachID > rch_max,'iseg'] +=1\n",
    "\n",
    "print('Segments',rch_p.iseg.unique().shape[0])\n",
    "\n",
    "## correct sub reach number for altered segments\n",
    "rch_fix = rch_p.set_index('iseg').loc[(rch_p.groupby('iseg').min().ireach >1),:]\n",
    "for n in rch_fix.index.unique().values:\n",
    "    rch_fix.loc[n, 'ireach'] = np.arange(1,len(rch_fix.loc[n])+1)\n",
    "rch_fix = rch_fix.reset_index().set_index('reachID')\n",
    "\n",
    "rch_p = rch_p.set_index('reachID')\n",
    "rch_p.loc[rch_fix.index] = rch_fix\n",
    "\n",
    "# update XS dict to account for new segments due to grid crossing\n",
    "new_dict = {}\n",
    "new_s = 0\n",
    "for key, value in xs_dict.items():\n",
    "    key += new_s\n",
    "    new_dict[key] = value\n",
    "    if key==seg_min:\n",
    "        new_s +=1\n",
    "        new_dict[key + 1] = value\n",
    "    elif key == seg_max:\n",
    "        new_s+=1\n",
    "        new_dict[key + 1] = value\n",
    "# segments on the edge of child grids\n",
    "edge_segs = rch_fix.iseg.unique()\n",
    "\n",
    "# add segments in to update grid\n",
    "for n in edge_segs:\n",
    "    seg_p.loc[seg_p.nseg > n, 'nseg'] +=1\n",
    "    seg_p.loc[seg_p.nseg > n, 'outseg'] +=1\n",
    "    seg_add = seg_p.loc[seg_p.nseg == n]\n",
    "    seg_add.nseg +=1\n",
    "    seg_add.outseg +=1\n",
    "    seg_p = seg_p.append(seg_add)\n",
    "# clean up segment data before setting in sfr package\n",
    "seg_p = seg_p.sort_values('nseg')\n",
    "# reset last outseg as 0\n",
    "seg_p.loc[seg_p.nseg==seg_p.nseg.max(), 'outseg'] = 0\n",
    "\n",
    "# set sfr segments covered by the child grids as -1, 0\n",
    "for n in np.arange(0,len(edge_segs)/2, dtype=int):\n",
    "    seg_p.loc[seg_p.nseg>=edge_segs[n],'lgrgrid'] = -1\n",
    "    seg_p.loc[seg_p.nseg>=edge_segs[n+1],'lgrgrid'] = 0\n",
    "    seg_p.loc[seg_p.nseg==edge_segs[n+1],'lgrgrid'] = n+1 # set\n",
    "    seg_p.loc[seg_p.nseg==edge_segs[n+1],'lgrseg'] = sfr.segment_data[0].nseg.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(figsize=(6,6))\n",
    "# # grid_sfr.plot(ax=ax)\n",
    "# child_grid.plot(ax=ax,color='None',edgecolor='black')\n",
    "# # grid_c_num\n",
    "\n",
    "# temp_plot = gpd.overlay(grid_sfr_p,child_grid)\n",
    "# temp_plot.plot('reach',ax=ax,legend=False)\n",
    "# # Create annotation\n",
    "# for j in np.arange(0,len(temp_plot)):\n",
    "#     ax.annotate(\n",
    "#         temp_plot.reach[j],                      # Use `label` as label\n",
    "#         (temp_plot.geometry.centroid.x[j], temp_plot.geometry.centroid.y[j]),         # Place label at end of the bar\n",
    "#         xytext=(0, 0),          # Vertically shift label by `space`\n",
    "#         textcoords=\"offset points\", # Interpret `xytext` as offset in points\n",
    "#         ha='center')                      # Vertically align label differently for\n",
    "#                                         # positive and negative values.\n",
    "# xmin,ymin, xmax, ymax = child_grid.buffer(200).total_bounds\n",
    "# ax.set_xlim(xmin, xmax)\n",
    "# ax.set_ylim(ymin, ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_p.reach_data = rch_p.reset_index().to_records(index=None)\n",
    "sfr_p.segment_data[0] = seg_p.to_records(index=None)\n",
    "sfr_p.channel_geometry_data[0] = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-jefferson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfr check didn't have any issues with new variables for lgr, but may need to update flopy as model.version\n",
    "# won't work for activating the read/write of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-shanghai",
   "metadata": {},
   "source": [
    "# LAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "lak_extent = gpd.read_file(gwfm_dir+'/Blodgett_Dam/geospatial/bathymetry_extent/bathymetry_extent.shp')\n",
    "lak_extent.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "lak_extent.plot(ax=ax)\n",
    "xmin,ymin, xmax, ymax = lak_extent.buffer(200).total_bounds\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "\n",
    "grid_c_nums.plot(ax=ax,color='None',edgecolor='black', linewidth=0.1)\n",
    "\n",
    "ctx.add_basemap(ax, source = ctx.providers.Esri.WorldImagery,\n",
    "                crs='epsg:26910', alpha = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (scenario == 'actual') | (scenario == 'design'):\n",
    "    lak_buf = lak_extent.copy()\n",
    "    lak_buf.geometry = lak_buf.buffer(100)\n",
    "    # grid_sfr.drop('index_right',axis=1)\n",
    "    # gpd.sjoin(grid_c_nums, lak_buf, how='left',op='contains').plot()\n",
    "    lak_grid = gpd.overlay(grid_c_nums, lak_extent, how='intersection')\n",
    "    # get cells with more than 1/3 of Blodgett Dam \"lake extent\"\n",
    "    lak_grid = lak_grid.loc[lak_grid.geometry.area > delr[lak_grid.row]*delr[lak_grid.column]/3]\n",
    "\n",
    "    # Set empty array of zeros for nonlake cells\n",
    "    lakarr = np.zeros((nlay, nrow,ncol))\n",
    "    # Each lake is given a different integer, and needs to be specified depending on the layer\n",
    "    lakarr[0,(lak_grid.row.values-1).astype(int),(lak_grid.column.values-1).astype(int)] = 1\n",
    "\n",
    "    bdlknc = np.zeros(( nrow,ncol))\n",
    "    # set blodgett dam Ksat same as stream Ksat at same location, leakance is K/lakebed thickness\n",
    "    lkbd_thick = sfr.reach_data.strthick[XSg.loc[XSg.Site==16.5].reach]\n",
    "    lkbd_K = sfr_K[XSg.loc[XSg.Site==16.5].reach]\n",
    "    bdlknc[(lak_grid.row.values-1).astype(int),(lak_grid.column.values-1).astype(int)] = lkbd_K/lkbd_thick\n",
    "\n",
    "    lakeRst = rasterio.open(gwfm_dir+'/Blodgett_Dam/geospatial/DEMs/hecras_1m_bathymetry.tif')\n",
    "    lakeBottom = lakeRst.read(1)\n",
    "    noDataValue = np.copy(lakeBottom[0,0])\n",
    "    #replace value for np.nan\n",
    "    lakeBottom[lakeBottom==noDataValue]= np.nan\n",
    "    # the stage for the stream section just after the dam is 23.04 m thus the bottom of the lake must be set 10 ft below that\n",
    "    lakeBottom = lakeBottom - 10\n",
    "    lakeBottom *= 0.3048\n",
    "\n",
    "    # get raster minimum and maximum \n",
    "    minElev = np.nanmin(lakeBottom)\n",
    "    maxElev = np.nanmax(lakeBottom)\n",
    "    print('Min bottom elevation %.2f m., max bottom elevation %.2f m.'%(minElev,maxElev))\n",
    "\n",
    "    # steps for calculation\n",
    "    nSteps = 151\n",
    "\n",
    "    # lake bottom elevation intervals\n",
    "    elevSteps = np.round(np.linspace(minElev,maxElev,nSteps),2)\n",
    "\n",
    "\n",
    "    # definition of volume function\n",
    "    def calculateVol_A(elevStep,elevDem,lakeRst):\n",
    "        tempDem = elevStep - elevDem[elevDem<elevStep]\n",
    "        tempArea = len(tempDem)*lakeRst.res[0]*0.3048*lakeRst.res[1]*0.3048\n",
    "        tempVol = tempDem.sum()*lakeRst.res[0]*0.3048*lakeRst.res[1]*0.3048\n",
    "        return(tempVol, tempArea)\n",
    "    # calculate volumes, areas for each elevation\n",
    "    volArray = [0]\n",
    "    saArray = [0]\n",
    "    for elev in elevSteps[1:]:\n",
    "        tempVol,tempArea = calculateVol_A(elev,lakeBottom,lakeRst)\n",
    "        volArray.append(tempVol)\n",
    "        saArray.append(tempArea)\n",
    "\n",
    "\n",
    "    # print(\"Lake bottom elevations %s\"%elevSteps)\n",
    "    # volArrayMCM = [round(i/1000000,2) for i in volArray]\n",
    "    # print(\"Lake volume in million of cubic meters %s\"%volArrayMCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (scenario == 'actual') | (scenario == 'design'):\n",
    "    # Exactly 151 lines must be included within each lake bathymetry input file and each line must contain 1 value \n",
    "    #  of lake stage (elevation), volume, and area (3 numbers per line) if the keyword TABLEINPUT is specified in item 1a.\n",
    "    # A separate file is required for each lake. \n",
    "\n",
    "    stages = minElev+0.1\n",
    "    # (ssmn, ssmx) max and min stage of each lake for steady state solution, there is a stage range for each lake\n",
    "    # so double array is necessary\n",
    "    stage_range = [[minElev, maxElev]]\n",
    "\n",
    "    # lake stage (elevation), volume, and area (3 numbers per line)\n",
    "    lak_depth = elevSteps - elevSteps[0]\n",
    "    bathtxt = np.column_stack((elevSteps, volArray, saArray))\n",
    "\n",
    "    np.savetxt(m_c.model_ws+'/MF_child.txt', bathtxt, delimiter = '\\t')\n",
    "\n",
    "\n",
    "    ## Need to specify flux data\n",
    "    # Dict of lists keyed by stress period. The list for each stress period is a list of lists,\n",
    "    # with each list containing the variables PRCPLK EVAPLK RNF WTHDRW [SSMN] [SSMX] from the documentation.\n",
    "    # flux_data = np.zeros((nrow,ncol))\n",
    "\n",
    "    flux_data = {0:{0:[0,0,0,0]}}\n",
    "    # filler value for bdlknc until soil map data is loaded by uzf\n",
    "    lak = flopy.modflow.ModflowLak(model = m_c, lakarr = lakarr, bdlknc = bdlknc,  stages=stages, \n",
    "                                   stage_range=stage_range, flux_data = flux_data,tabdata= True, \n",
    "                                   tab_files='MF.txt', tab_units=[57],ipakcb=55)\n",
    "\n",
    "    # the lak package doesn't specify the tab file unit number when the files are written\n",
    "    # example:      110.0     100.0     170.0   22   Item 3:  STAGES,SSMN,SSMX,IUNITLAKTAB\n",
    "\n",
    "    lak.options = ['TABLEINPUT']\n",
    "\n",
    "    # need to reset tabdata as True before writing output for LAK\n",
    "    lak.tabdata = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-imaging",
   "metadata": {},
   "source": [
    "## LAK Gage package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (scenario == 'actual') | (scenario == 'design'):\n",
    "    # numgage is total number of gages\n",
    "    # gage_data (list, or array), includes 2 to 3 entries (LAKE UNIT (OUTTYPE)) for each LAK entry\n",
    "    #  4 entries (GAGESEG< GAGERCH, UNIT, OUTTYPE) for each SFR package entry\n",
    "\n",
    "    lak_gage_data = [[-1, -37, 1]]\n",
    "    lak_file = 'MF_child.lak.gage'\n",
    "    lak_file_out = 'MF_child.lak.gage.out'\n",
    "    gag = flopy.modflow.ModflowGage(model=m_c,numgage= 1,gage_data=lak_gage_data,file =[lak_file_out], filenames =[lak_file])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-genius",
   "metadata": {},
   "source": [
    "# Output Control (OC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = pd.to_datetime(strt_date)+pd.DateOffset(days = nper-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output control\n",
    "# default unit number for heads is 51, cell by cell is 53 and drawdown is 52\n",
    "# (0,0) is (stress period, time step)\n",
    "\n",
    "# For later model runs when all the data is needed to be saved\n",
    "spd = { (j,0): ['save head', 'save budget'] for j in np.arange(0,nper,1)}\n",
    "\n",
    "# get the first of each month to print the budget\n",
    "month_intervals = (pd.date_range(strt_date,end_date, freq=\"MS\")-pd.to_datetime(strt_date)).days\n",
    "\n",
    "for j in month_intervals:\n",
    "    spd[j,0] = ['save head', 'save budget','print budget']\n",
    "    \n",
    "oc = flopy.modflow.ModflowOc(model = m_c, stress_period_data = spd, compact = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-spanish",
   "metadata": {},
   "source": [
    "# Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_mo max outer iters, ter_mi = max inner iters, close_r residual criterion for stopping iteration\n",
    "# close_h is alternate criterion for nonlinear problem, and is head closure which should be smaller than residual closer\n",
    "# ipunit =0 means no info on solver, ipunit=1 means output about solver issues is written\n",
    "# if iter_mo >1 then closer_r is used not close_h and closer_r is compared to \n",
    "# the square root of the inner product of the residuals (the residual norm)\n",
    "# adamp =0 is std damping, adamp=1 is adaptive damping that further decreases or increases damping based on picard\n",
    "# iteration sucess\n",
    "#adamp is 0.7 to resolve issues with heads oscillating near solution +1 m\n",
    "# damp_lb = lower bound, rate_d is rate of increase of damping based picard iteration success\n",
    "\n",
    "# pcgn = flopy.modflow.ModflowPcgn(m, iter_mo = 100, iter_mi=60, close_r=1e-01, close_h=1e-02, ipunit=28)\n",
    "#                                adamp=1, damp=0.7, damp_lb=0.1, rate_d=0.01)\n",
    "\n",
    "\n",
    "# mxiter = max outer iterations, iter1 = max inner iterations\n",
    "pcg = flopy.modflow.ModflowPcg(model = m_c, mxiter = 100, iter1=60, rclose=1e-01, hclose=1e-02)\n",
    "#                                adamp=1, damp=0.7, damp_lb=0.1, rate_d=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-tunnel",
   "metadata": {},
   "source": [
    "# Check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_c.check()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "running-scratch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, 1, 1, 1, 1, 1]), array([0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when coding I set the child model as convertible but reset to confined to match\n",
    "# m_p.lpf.sy.array\n",
    "# # 0 is confined, 1 is convertile for laytyp, 0 inactive, 1 active for wetting (laywet)\n",
    "# m_p.lpf.laytyp.array, m_p.lpf.laywet.array\n",
    "# m_c.lpf.laytyp.array, m_c.lpf.laywet.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "built-sailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "changing model workspace...\n",
      "   F:/WRDAPP/GWFlowModel/Cosumnes/Cosumnes_Blodgett_10yr/LGR_SFR\n"
     ]
    }
   ],
   "source": [
    "m_p.model_ws = loadpth+ 'LGR_SFR'\n",
    "m_p.write_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "parental-posting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '4', '2', '0', '36', '244857.6', '0', '0', '0', '0', '0']\n",
      "['2', '2', '3', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['3', '2', '4', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['4', '2', '5', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['5', '2', '6', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['6', '2', '7', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['7', '2', '8', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['8', '2', '9', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['9', '2', '10', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['10', '2', '11', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['11', '2', '12', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['12', '2', '13', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['13', '2', '14', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['14', '2', '15', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['15', '2', '16', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['16', '2', '17', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['17', '2', '18', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['18', '2', '19', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['19', '2', '20', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['20', '2', '21', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['21', '2', '22', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['22', '2', '23', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['23', '2', '24', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['24', '2', '25', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['25', '2', '26', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['26', '2', '27', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n",
      "['27', '2', '28', '0', '0', '0', '0', '0', '0.048', '0.083', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "# work around to output SFR file and then adjust it to account for LGRGRID and LGRSEG auxiliary variables\n",
    "filename = lgr_ws+'/MF.sfr'\n",
    "f = open(filename, \"r\")\n",
    "line = f.readline()\n",
    "line = f.readline()\n",
    "line = f.readline()\n",
    "nrch = int(line_parse(line)[0])\n",
    "for i in np.arange(0,nrch):\n",
    "    line = f.readline()\n",
    "line=f.readline()\n",
    "nseg = int(line_parse(line)[0])\n",
    "count = 1\n",
    "\n",
    "while count < nseg:\n",
    "    line = f.readline()\n",
    "    line = line_parse(line)\n",
    "    lgrgrid = str(sfr_p.segment_data[0].lgrgrid[count-1])\n",
    "    lgrseg = str(sfr_p.segement_data[0].lgrseg[count-1])\n",
    "    print(line + [lgrgrid, lgrseg])\n",
    "    icalc = int(line[1])\n",
    "    count = int(line[0])\n",
    "    if icalc == 2:\n",
    "        skip = 2\n",
    "    elif icalc ==4:\n",
    "        skip = 3\n",
    "    for i in np.arange(0,skip):\n",
    "        line = f.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-kenya",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "spoken-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the MODFLOW data files\n",
    "m_c.write_input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "accurate-anniversary",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not assign tuple of length 34 to structure with 36 fields.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22712/3615799124.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m lgr_ex = flopy.modflowlgr.ModflowLgr.load(f = lgr_ex_nam, model_ws = lgr_ex_path, \n\u001b[1;32m----> 8\u001b[1;33m                                  version = 'mflgr')\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflowlgr\\mflgr.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, f, version, exe_name, verbose, model_ws, load_only, forgive, check)\u001b[0m\n\u001b[0;32m    589\u001b[0m             \u001b[0mload_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m             \u001b[0mforgive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforgive\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m             \u001b[0mcheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m         )\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflow\\mf.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, f, version, exe_name, verbose, model_ws, load_only, forgive, check)\u001b[0m\n\u001b[0;32m    917\u001b[0m                             item.package.load(\n\u001b[0;32m    918\u001b[0m                                 \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilehandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 919\u001b[1;33m                                 \u001b[0mml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    920\u001b[0m                                 \u001b[0mext_unit_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mext_unit_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m                             )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflow\\mfsfr2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, f, model, nper, gwt, nsol, ext_unit_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m                             \u001b[0mper\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m                         )\n\u001b[1;32m-> 1006\u001b[1;33m                     \u001b[0mcurrent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_6a\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdataset_6b\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdataset_6c\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0micalc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not assign tuple of length 34 to structure with 36 fields."
     ]
    }
   ],
   "source": [
    "# lgr_ex_path = \"C://WRDAPP/MODFLOW-LGR/mflgr.1_2/test-run/sfrex2\"\n",
    "# lgr_ex_nam = \"C://WRDAPP/MODFLOW-LGR/mflgr.1_2/test-run/sfrex2/sfrex2.lgr\"\n",
    "\n",
    "lgr_ex_path = \"C:/WRDAPP/MODFLOW-LGR/mflgr.1_2/test-run/sfrex2/\"\n",
    "lgr_ex_nam =  \"C:/WRDAPP/MODFLOW-LGR/mflgr.1_2/test-run/sfrex2/sfrex2.lgr\"\n",
    "\n",
    "lgr_ex = flopy.modflowlgr.ModflowLgr.load(f = lgr_ex_nam, model_ws = lgr_ex_path, \n",
    "                                 version = 'mflgr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "shaped-behalf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not assign tuple of length 34 to structure with 36 fields.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22712/2212986366.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msfr_ex_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sfrex2_parent.nam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_ws\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgr_ex_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflow\\mf.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, f, version, exe_name, verbose, model_ws, load_only, forgive, check)\u001b[0m\n\u001b[0;32m    917\u001b[0m                             item.package.load(\n\u001b[0;32m    918\u001b[0m                                 \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilehandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 919\u001b[1;33m                                 \u001b[0mml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    920\u001b[0m                                 \u001b[0mext_unit_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mext_unit_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m                             )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflow\\mfsfr2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, f, model, nper, gwt, nsol, ext_unit_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[0msegment_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0mchannel_geometry_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m         \u001b[0mchannel_flow_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m         \u001b[0mdataset_5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m         aux_variables = (\n",
      "\u001b[1;31mValueError\u001b[0m: could not assign tuple of length 34 to structure with 36 fields."
     ]
    }
   ],
   "source": [
    "sfr_ex_p = flopy.modflow.Modflow.load('sfrex2_parent.nam', model_ws = lgr_ex_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-ministry",
   "metadata": {},
   "source": [
    "# Create LGR structure\n",
    "NPRBEG = row number of parent grid where child begins (END for end, l for   layer, c for column)  \n",
    "NCPP = num child cells spanning a parent cell, NPCPPL for layers  \n",
    "ibflg = defines interface of child and parent (unique value for each child)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-affair",
   "metadata": {},
   "source": [
    "## Lgr Child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "robust-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with 2 times refinement in both horizontal and vertical\n",
    "# max refinement is either 3-4 times in horizontal\n",
    "# identify LGR child structure\n",
    "lgr_child = flopy.modflowlgr.LgrChild(ishflg = 1, ibflg=59,\n",
    "                                      nplbeg = 0, nprbeg = beg_row, npcbeg = beg_col,\n",
    "                        nplend = 0, nprend = end_row, npcend = end_col,\n",
    "                        ncpp = 2, ncppl = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "identical-salvation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 2, 0, 0, 36, 244857.6, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0, 0)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#         for i in range(0, self.nper): #all periods\n",
    "#                 for j in range(itmp): #all segments\n",
    "# seg_dat is for one period\n",
    "np.array(sfr_p.segment_data[0])[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "hairy-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_1c(line, reachinput, transroute):\n",
    "    \"\"\"\n",
    "    Parse Data Set 1c for SFR2 package.\n",
    "    See http://water.usgs.gov/nrp/gwsoftware/modflow2000/MFDOC/index.html?sfr.htm for more info\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : str\n",
    "        line read from SFR package input file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        a list of length 13 containing all variables for Data Set 6a\n",
    "\n",
    "    \"\"\"\n",
    "    na = 0\n",
    "    # line = _get_dataset(line, [0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 1, 30, 1, 2, 0.75, 0.0001, []])\n",
    "    # line = line.strip().split()\n",
    "    line = line_parse(line)\n",
    "\n",
    "    nstrm = int(line.pop(0))\n",
    "    nss = int(line.pop(0))\n",
    "    nsfrpar = int(line.pop(0))\n",
    "    nparseg = int(line.pop(0))\n",
    "    const = float(line.pop(0))\n",
    "    dleak = float(line.pop(0))\n",
    "    ipakcb = int(line.pop(0))\n",
    "    istcb2 = int(line.pop(0))\n",
    "\n",
    "    isfropt, nstrail, isuzn, nsfrsets = na, na, na, na\n",
    "    if reachinput:\n",
    "        nstrm = abs(nstrm)  # see explanation for dataset 1c in online guide\n",
    "        isfropt = int(line.pop(0))\n",
    "        if isfropt > 1:\n",
    "            nstrail = int(line.pop(0))\n",
    "            isuzn = int(line.pop(0))\n",
    "            nsfrsets = int(line.pop(0))\n",
    "    if nstrm < 0:\n",
    "        isfropt = int(line.pop(0))\n",
    "        if isfropt > 1:\n",
    "            nstrail = int(line.pop(0))\n",
    "            isuzn = int(line.pop(0))\n",
    "            nsfrsets = int(line.pop(0))\n",
    "\n",
    "    irtflg, numtim, weight, flwtol = na, na, na, na\n",
    "    if nstrm < 0 or transroute:\n",
    "        irtflg = int(_pop_item(line))\n",
    "        if irtflg > 0:\n",
    "            numtim = int(line.pop(0))\n",
    "            weight = float(line.pop(0))\n",
    "            flwtol = float(line.pop(0))\n",
    "\n",
    "    # auxiliary variables (MODFLOW-LGR)\n",
    "    option = [\n",
    "        line[i]\n",
    "        for i in np.arange(1, len(line))\n",
    "        if \"aux\" in line[i - 1].lower()\n",
    "    ]\n",
    "\n",
    "    return (\n",
    "        nstrm,\n",
    "        nss,\n",
    "        nsfrpar,\n",
    "        nparseg,\n",
    "        const,\n",
    "        dleak,\n",
    "        ipakcb,\n",
    "        istcb2,\n",
    "        isfropt,\n",
    "        nstrail,\n",
    "        isuzn,\n",
    "        nsfrsets,\n",
    "        irtflg,\n",
    "        numtim,\n",
    "        weight,\n",
    "        flwtol,\n",
    "        option,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "figured-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pop_item(line):\n",
    "    try:\n",
    "        return float(line.pop(0))\n",
    "    except:\n",
    "        return 0.0\n",
    "    \n",
    "def _parse_6a(line, option):\n",
    "    line = line_parse(line)\n",
    "\n",
    "    xyz = []\n",
    "    # handle any aux variables at end of line\n",
    "    for s in line:\n",
    "        if s.lower() in option:\n",
    "            xyz.append(s.lower())\n",
    "\n",
    "    na = 0\n",
    "    nseg = int(_pop_item(line))\n",
    "    icalc = int(_pop_item(line))\n",
    "    outseg = int(_pop_item(line))\n",
    "    iupseg = int(_pop_item(line))\n",
    "    iprior = na\n",
    "    nstrpts = na\n",
    "\n",
    "    if iupseg > 0:\n",
    "        iprior = int(_pop_item(line))\n",
    "    if icalc == 4:\n",
    "        nstrpts = int(_pop_item(line))\n",
    "\n",
    "    flow = _pop_item(line)\n",
    "    runoff = _pop_item(line)\n",
    "    etsw = _pop_item(line)\n",
    "    pptsw = _pop_item(line)\n",
    "    roughch = na\n",
    "    roughbk = na\n",
    "\n",
    "    if icalc in [1, 2]:\n",
    "        roughch = _pop_item(line)\n",
    "    if icalc == 2:\n",
    "        roughbk = _pop_item(line)\n",
    "\n",
    "    cdpth, fdpth, awdth, bwdth = na, na, na, na\n",
    "    if icalc == 3:\n",
    "        cdpth, fdpth, awdth, bwdth = map(float, line)\n",
    "    \n",
    "    if option[0] == 'LGRGRID':\n",
    "        lgrgrid = int(_pop_item(line))\n",
    "        lgrseg = int(_pop_item(line))\n",
    "    else:\n",
    "        lgrgrid = []\n",
    "        lgrseg = []\n",
    "    return (\n",
    "        nseg,\n",
    "        icalc,\n",
    "        outseg,\n",
    "        iupseg,\n",
    "        iprior,\n",
    "        nstrpts,\n",
    "        flow,\n",
    "        runoff,\n",
    "        etsw,\n",
    "        pptsw,\n",
    "        roughch,\n",
    "        roughbk,\n",
    "        cdpth,\n",
    "        fdpth,\n",
    "        awdth,\n",
    "        bwdth,\n",
    "        lgrgrid,\n",
    "        lgrseg,\n",
    "        xyz,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-portugal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "underlying-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = lgr_ws+'/test_run_read_lgr_sfr.sfr'\n",
    "# f = open(filename, \"r\")\n",
    "\n",
    "# line = f.readline()\n",
    "# for s in line:\n",
    "#     print(s.lower())\n",
    "# print(line)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "departmental-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flopy\n",
    "from flopy.modflow import ModflowSfr2\n",
    "from flopy.utils.flopy_io import line_parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "becoming-beaver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-27"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "derived-encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43    3    0    0  1. 1.E-4    0   19   AUX LGRGRID AUX LGRSEG ;NSTRM NSS NSFRPAR NPARSEG CONST DLEAK ISTCB1  ISTCB2  [ISFROPT] [NSTRAIL] [ISUZN] [NSFRSETS]\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "add_to_dtype() missing 1 required positional argument: 'field_types'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26396/3665049553.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Item 6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m current = ModflowSfr2.get_empty_segment_data(\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mnsegments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moption\u001b[0m\u001b[1;31m# container to hold any auxiliary variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflow\\mfsfr2.py\u001b[0m in \u001b[0;36mget_empty_segment_data\u001b[1;34m(nsegments, aux_names, default_value)\u001b[0m\n\u001b[0;32m    747\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[1;34m\"thti\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[1;34m\"eps\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m                     \u001b[1;33m(\u001b[0m\u001b[1;34m\"uhc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    750\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[1;34m\"reachID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[1;34m\"outreach\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: add_to_dtype() missing 1 required positional argument: 'field_types'"
     ]
    }
   ],
   "source": [
    "lgr_ws =loadpth+ 'LGR_SFR'\n",
    "filename = lgr_ws+'/test_run_read_lgr_sfr.sfr'\n",
    "f = open(filename, \"r\")\n",
    "\n",
    "line = f.readline()\n",
    "print(line)\n",
    "(nstrm, nss,nsfrpar, nparseg,const, dleak,  ipakcb, istcb2, isfropt, \n",
    "nstrail,  isuzn,  nsfrsets, irtflg,  numtim, weight,   flwtol, \n",
    " option,) =_parse_1c(line, False, False)\n",
    "\n",
    "i=0\n",
    "itmp = 3\n",
    "# Item 6\n",
    "current = ModflowSfr2.get_empty_segment_data(\n",
    "    nsegments=itmp, aux_names=option# container to hold any auxiliary variables\n",
    ")\n",
    "print(current.shape)\n",
    "print(len(current.dtype))\n",
    "current_aux = {}\n",
    "# these could also be implemented as structured arrays with a column for segment number\n",
    "current_6d = {}\n",
    "current_6e = {}\n",
    "# print(i,icalc,nstrm,isfropt,reachinput)\n",
    "for j in range(itmp):\n",
    "    line = f.readline()\n",
    "    print(line)\n",
    "    dataset_6a = _parse_6a(line, option)\n",
    "    print(_parse_6a(line, option))\n",
    "    current_aux[j] = dataset_6a[-1]\n",
    "    dataset_6a = dataset_6a[:-1]  # drop xyz\n",
    "    icalc = dataset_6a[1]\n",
    "    # link dataset 6d, 6e by nseg of dataset_6a\n",
    "    temp_nseg = dataset_6a[0]\n",
    "    # datasets 6b and 6c aren't read under the conditions below\n",
    "    # see table under description of dataset 6c,\n",
    "    # in the MODFLOW Online Guide for a description\n",
    "    # of this logic\n",
    "    # https://water.usgs.gov/ogw/modflow-nwt/MODFLOW-NWT-Guide/sfr.htm\n",
    "    dataset_6b, dataset_6c = (0,) * 9, (0,) * 9\n",
    "    if not (\n",
    "        isfropt in [2, 3] and icalc == 1 and i > 1\n",
    "    ) and not (isfropt in [1, 2, 3] and icalc >= 2):\n",
    "        line = f.readline()\n",
    "        print(line)\n",
    "        dataset_6b = _parse_6bc(\n",
    "            line,\n",
    "            icalc,\n",
    "            nstrm,\n",
    "            isfropt,\n",
    "            reachinput,\n",
    "            per=i,\n",
    "        )\n",
    "        line = f.readline()\n",
    "        print(line)\n",
    "        dataset_6c = _parse_6bc(\n",
    "            line,\n",
    "            icalc,\n",
    "            nstrm,\n",
    "            isfropt,\n",
    "            reachinput,\n",
    "            per=i,\n",
    "        )\n",
    "    current[j] = dataset_6a + dataset_6b + dataset_6c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fifteen-mustang",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add_to_dtype() missing 1 required positional argument: 'field_types'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26396/2254749134.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m ModflowSfr2.get_empty_segment_data(\n\u001b[1;32m----> 2\u001b[1;33m                     \u001b[0mnsegments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m29\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LGRGRID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"LGRSEG\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geosp\\lib\\site-packages\\flopy\\modflow\\mfsfr2.py\u001b[0m in \u001b[0;36mget_empty_segment_data\u001b[1;34m(nsegments, aux_names, default_value)\u001b[0m\n\u001b[0;32m    747\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[1;34m\"thti\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[1;34m\"eps\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m                     \u001b[1;33m(\u001b[0m\u001b[1;34m\"uhc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    750\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[1;34m\"reachID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[1;34m\"outreach\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: add_to_dtype() missing 1 required positional argument: 'field_types'"
     ]
    }
   ],
   "source": [
    "ModflowSfr2.get_empty_segment_data(\n",
    "                    nsegments=29, aux_names=[\"LGRGRID\", \"LGRSEG\"]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "accompanied-austria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MfList',\n",
       " 'ModflowSfr2',\n",
       " 'NumpyVersion',\n",
       " 'OptionBlock',\n",
       " 'OrderedDict',\n",
       " 'Package',\n",
       " '__author__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_check_numbers',\n",
       " '_find_path',\n",
       " '_fmt_string',\n",
       " '_fmt_string_list',\n",
       " '_get_dataset',\n",
       " '_get_duplicates',\n",
       " '_get_item2_names',\n",
       " '_isnumeric',\n",
       " '_markitzero',\n",
       " '_parse_1c',\n",
       " '_parse_6a',\n",
       " '_parse_6bc',\n",
       " '_pop_item',\n",
       " '_print_rec_array',\n",
       " 'check',\n",
       " 'copy',\n",
       " 'create_empty_recarray',\n",
       " 'default_float_format',\n",
       " 'find_path',\n",
       " 'line_parse',\n",
       " 'np',\n",
       " 'numpy114',\n",
       " 'os',\n",
       " 'pd',\n",
       " 'recfunctions',\n",
       " 'sys',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from flopy.modflow.mfsfr2 import get_default_segment_dtype\n",
    "from flopy.modflow import mfsfr2\n",
    "dir(mfsfr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "agreed-fifty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 40.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.04,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.01,\n",
       " 1.5,\n",
       " 49.45189163,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.01,\n",
       " 1.5,\n",
       " 48.71357322,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0)"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_6a\n",
    "# current_aux\n",
    "dataset_6a+dataset_6b+dataset_6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "written-format",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def _parse_6a(line, option):\n",
      "    \"\"\"\n",
      "    # print(option)\n",
      "    Parse Data Set 6a for SFR2 package.\n",
      "    See http://water.usgs.gov/nrp/gwsoftware/modflow2000/MFDOC/index.html?sfr.htm for more info\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    line : str\n",
      "        line read from SFR package input file\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "        a list of length 13 containing all variables for Data Set 6a\n",
      "    \"\"\"\n",
      "    # line = line.strip().split()\n",
      "    line = line_parse(line)\n",
      "\n",
      "    xyz = []\n",
      "    # handle any aux variables at end of line\n",
      "    for s in line:\n",
      "        if s.lower() in option:\n",
      "            xyz.append(s.lower())\n",
      "\n",
      "    na = 0\n",
      "    nseg = int(_pop_item(line))\n",
      "    icalc = int(_pop_item(line))\n",
      "    outseg = int(_pop_item(line))\n",
      "    iupseg = int(_pop_item(line))\n",
      "    iprior = na\n",
      "    nstrpts = na\n",
      "\n",
      "    if iupseg > 0:\n",
      "        iprior = int(_pop_item(line))\n",
      "    if icalc == 4:\n",
      "        nstrpts = int(_pop_item(line))\n",
      "\n",
      "    flow = _pop_item(line)\n",
      "    runoff = _pop_item(line)\n",
      "    etsw = _pop_item(line)\n",
      "    pptsw = _pop_item(line)\n",
      "    roughch = na\n",
      "    roughbk = na\n",
      "\n",
      "    if icalc in [1, 2]:\n",
      "        roughch = _pop_item(line)\n",
      "    if icalc == 2:\n",
      "        roughbk = _pop_item(line)\n",
      "\n",
      "    cdpth, fdpth, awdth, bwdth = na, na, na, na\n",
      "    if icalc == 3:\n",
      "        cdpth, fdpth, awdth, bwdth = map(float, line)\n",
      "    # read in lgr parameters \n",
      "    lgrgrid = na\n",
      "    lgrseg = na\n",
      "    if 'LGRGRID' in option:\n",
      "        lgrgrid = int(_pop_item(line))\n",
      "        lgrseg = int(_pop_item(line))\n",
      "    return (\n",
      "        nseg,\n",
      "        icalc,\n",
      "        outseg,\n",
      "        iupseg,\n",
      "        iprior,\n",
      "        nstrpts,\n",
      "        flow,\n",
      "        runoff,\n",
      "        etsw,\n",
      "        pptsw,\n",
      "        roughch,\n",
      "        roughbk,\n",
      "        cdpth,\n",
      "        fdpth,\n",
      "        awdth,\n",
      "        bwdth,\n",
      "        lgrgrid,\n",
      "        lgrseg,\n",
      "        xyz,\n",
      "    )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from inspect import getsource\n",
    "print(getsource(_parse_6bc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "automated-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flopy.modflow.mfsfr2 import _parse_6bc,_isnumeric\n",
    "from flopy.modflow.mfsfr2 import _parse_6a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "radical-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flopy.modflow import ModflowSfr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "peaceful-return",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ModflowSfr2' has no attribute 'get_default_dataset_6a_dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22712/2101817560.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mModflowSfr2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_segment_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModflowSfr2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mModflowSfr2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_dataset_6a_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'ModflowSfr2' has no attribute 'get_default_dataset_6a_dtype'"
     ]
    }
   ],
   "source": [
    "# ModflowSfr2.__init__\n",
    "ModflowSfr2.get_default_segment_dtype()\n",
    "dir(ModflowSfr2)\n",
    "ModflowSfr2.get_default_dataset_6a_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "robust-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_dataset(line, dataset):\n",
    "    # interpret number supplied with decimal points as floats, rest as ints\n",
    "    # this could be a bad idea (vs. explicitly formatting values for each dataset)\n",
    "    for i, s in enumerate(line_parse(line)):\n",
    "        try:\n",
    "            n = int(s)\n",
    "        except:\n",
    "            try:\n",
    "                n = float(s)\n",
    "            except:\n",
    "                break\n",
    "        dataset[i] = n\n",
    "    return dataset\n",
    "\n",
    "def _parse_6bc(line, icalc, nstrm, isfropt, reachinput, per=0):\n",
    "    \"\"\"\n",
    "    Parse Data Set 6b for SFR2 package.\n",
    "    See http://water.usgs.gov/nrp/gwsoftware/modflow2000/MFDOC/index.html?sfr.htm for more info\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : str\n",
    "        line read from SFR package input file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        a list of length 9 containing all variables for Data Set 6b\n",
    "\n",
    "    \"\"\"\n",
    "    nvalues = sum([_isnumeric(s) for s in line_parse(line)])\n",
    "    line = _get_dataset(line, [0] * nvalues)\n",
    "\n",
    "    hcond, thickm, elevupdn, width, depth, thts, thti, eps, uhc = [0.0] * 9\n",
    "\n",
    "    if isfropt in [0, 4, 5] and icalc <= 0:\n",
    "        hcond = line.pop(0)\n",
    "        thickm = line.pop(0)\n",
    "        elevupdn = line.pop(0)\n",
    "        width = line.pop(0)\n",
    "        depth = line.pop(0)\n",
    "    elif isfropt in [0, 4, 5] and icalc == 1:\n",
    "        hcond = line.pop(0)\n",
    "        if isfropt in [4, 5] and per > 0:\n",
    "            pass\n",
    "        else:\n",
    "            thickm = line.pop(0)\n",
    "            elevupdn = line.pop(0)\n",
    "            # depth is not read if icalc == 1; see table in online guide\n",
    "            width = line.pop(0)\n",
    "            thts = _pop_item(line)\n",
    "            thti = _pop_item(line)\n",
    "            eps = _pop_item(line)\n",
    "        if isfropt == 5 and per == 0:\n",
    "            uhc = line.pop(0)\n",
    "    elif isfropt in [0, 4, 5] and icalc >= 2:\n",
    "        hcond = line.pop(0)\n",
    "        if isfropt in [4, 5] and per > 0 and icalc == 2:\n",
    "            pass\n",
    "        else:\n",
    "            thickm = line.pop(0)\n",
    "            elevupdn = line.pop(0)\n",
    "            if isfropt in [4, 5] and per == 0:\n",
    "                # table in online guide suggests that the following items should be present in this case\n",
    "                # but in the example\n",
    "                thts = _pop_item(line)\n",
    "                thti = _pop_item(line)\n",
    "                eps = _pop_item(line)\n",
    "                if isfropt == 5:\n",
    "                    uhc = _pop_item(line)\n",
    "            else:\n",
    "                pass\n",
    "    elif isfropt == 1 and icalc <= 1:\n",
    "        width = line.pop(0)\n",
    "        if icalc <= 0:\n",
    "            depth = line.pop(0)\n",
    "    elif isfropt in [2, 3]:\n",
    "        if icalc <= 0:\n",
    "            width = line.pop(0)\n",
    "            depth = line.pop(0)\n",
    "\n",
    "        elif icalc == 1:\n",
    "            if per > 0:\n",
    "                pass\n",
    "            else:\n",
    "                width = line.pop(0)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "    return hcond, thickm, elevupdn, width, depth, thts, thti, eps, uhc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to print AUX LGRGRID AUX LGRSEG in line three when defining NSTRM, NSS\n",
    "# under parse_1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "stone-needle",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22712/67371792.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_parse_6a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moption\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22712/1536731578.py\u001b[0m in \u001b[0;36m_parse_6a\u001b[1;34m(line, option)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# handle any aux variables at end of line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moption\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0mxyz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "# it's already programmed for LGR??\n",
    "# auxiliary variables (MODFLOW-LGR)\n",
    "#     option = [\n",
    "#         line[i]\n",
    "#         for i in np.arange(1, len(line))\n",
    "#         if \"aux\" in line[i - 1].lower()_parse_6a(line, option=None)\n",
    "#      ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-tampa",
   "metadata": {},
   "source": [
    "## Lgr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "found-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_ws = loadpth+'LGR_SFR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "useful-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default model_ws is the present working directory\n",
    "lgr = flopy.modflowlgr.ModflowLgr(modelname = 'Blodgett_LGR', namefile_ext = 'lgr',\n",
    "                         version = 'mflgr', exe_name = 'mflgr.exe',\n",
    "                         parent = m_p, children = [m_c], children_data = lgr_child, model_ws = lgr_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "listed-requirement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MODFLOW 8 layer(s) 64 row(s) 64 column(s) 731 stress period(s)]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.parent\n",
    "lgr.children_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "adjustable-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr.write_input()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

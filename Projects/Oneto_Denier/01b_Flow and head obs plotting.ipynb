{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317013e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "from os.path import join, basename,dirname, exists, expanduser\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# standard python plotting utilities\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "# standard geospatial python utilities\n",
    "# import pyproj # for converting proj4string\n",
    "# import shapely\n",
    "import geopandas as gpd\n",
    "# import rasterio\n",
    "\n",
    "# mapping utilities\n",
    "import contextily as ctx\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a48f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_dir = expanduser('~')\n",
    "doc_dir = join(usr_dir, 'Documents')\n",
    "    \n",
    "# dir of all gwfm data\n",
    "gwfm_dir = dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel'\n",
    "# dir of stream level data for seepage study\n",
    "proj_dir = gwfm_dir + '/Oneto_Denier/'\n",
    "dat_dir = proj_dir+'Stream_level_data/'\n",
    "\n",
    "fig_dir = proj_dir+'/Streambed_seepage/figures/'\n",
    "hob_dir = join(gwfm_dir, 'HOB_data')\n",
    "sfr_dir = gwfm_dir+'/SFR_data/'\n",
    "\n",
    "py_dir = doc_dir +'GitHub/CosumnesRiverRecharge/python_utilities/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ca969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path(fxn_dir):\n",
    "    \"\"\" Insert fxn directory into first position on path so local functions supercede the global\"\"\"\n",
    "    if fxn_dir not in sys.path:\n",
    "        sys.path.insert(0, fxn_dir)\n",
    "# flopy github path - edited\n",
    "add_path(doc_dir+'/GitHub/flopy')\n",
    "import flopy\n",
    "\n",
    "py_dir = join(doc_dir,'GitHub/CosumnesRiverRecharge/python_utilities')\n",
    "add_path(py_dir)\n",
    "\n",
    "from mf_utility import get_dates, get_layer_from_elev, clean_wb\n",
    "from map_cln import gdf_bnds, plt_cln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dir = 'F:/WRDAPP'\n",
    "c_dir = 'C:/WRDAPP'\n",
    "if os.path.exists(ext_dir):\n",
    "    loadpth = ext_dir \n",
    "elif os.path.exists(c_dir):\n",
    "    loadpth = c_dir \n",
    "loadpth +=  '/GWFlowModel/Cosumnes/Stream_seepage'\n",
    "\n",
    "\n",
    "# model_nam = 'oneto_denier_homogeneous_2014_2018'\n",
    "upscale = 'upscale4x_'\n",
    "model_nam = 'oneto_denier_'+upscale+'2014_2018'\n",
    "# model_nam = 'oneto_denier_'+upscale+'2014_2020'\n",
    "\n",
    "model_ws = join(loadpth,model_nam)\n",
    "\n",
    "# model_ws = join(loadpth,'parallel_oneto_denier','realization000')\n",
    "load_only = ['DIS','UPW','SFR','OC', 'EVT', 'BAS6']\n",
    "m = flopy.modflow.Modflow.load('MF.nam', model_ws= model_ws, \n",
    "                                exe_name='mf-owhm.exe', version='mfnwt',\n",
    "                              load_only=load_only,\n",
    "                              )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quantiles: ',[0,0.5,0.6,0.75,1])\n",
    "print('HK :',np.quantile(m.upw.hk.array,[0,0.5,0.6,0.75,1]))\n",
    "print('VKA :',np.quantile(m.upw.vka.array,[0,0.5,0.6,0.75,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa367a5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# makes it easier to load if I save a set of outputs with alternate names\n",
    "m_ver = '' # default no alternate output/input names\n",
    "# m_ver = '_vka10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc12fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grp = 'inset_oneto_denier'\n",
    "grid_dir = join(gwfm_dir, 'DIS_data/streambed_seepage/grid')\n",
    "grid_fn = join(grid_dir, model_grp,'rm_only_grid.shp')\n",
    "grid_p = gpd.read_file(grid_fn)\n",
    "grid_p.crs='epsg:32610'\n",
    "m_domain = gpd.GeoDataFrame(pd.DataFrame([0]), geometry = [grid_p.unary_union], crs=grid_p.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66813697",
   "metadata": {},
   "outputs": [],
   "source": [
    "XSg = pd.read_csv(join(model_ws,'04_XSg_filled.csv'))\n",
    "XSg = gpd.GeoDataFrame(XSg, geometry = gpd.points_from_xy(XSg.Easting, XSg.Northing), crs='epsg:32610')\n",
    "\n",
    "drop_iseg = XSg[~XSg['Logger Location'].isna()].iseg.values\n",
    "# overwrite SFR segment/reach input relevant to seepage\n",
    "# sensor_dict = pd.read_csv(join(model_ws, 'sensor_xs_dict.csv'), index_col=0)\n",
    "# XS_params = sensor_dict.join(params.set_index('Sensor'), on='Sensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159aefa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr = m.sfr\n",
    "sfrdf = pd.DataFrame(sfr.reach_data)\n",
    "grid_sfr = grid_p.set_index(['row','column']).loc[list(zip(sfrdf.i+1,sfrdf.j+1))].reset_index(drop=True)\n",
    "grid_sfr = pd.concat((grid_sfr,sfrdf),axis=1)\n",
    "\n",
    "# characterize streambed into different hydrofacies\n",
    "tprogs_quants = np.array([0.590, 0.155, 0.197, 0.058]).cumsum()\n",
    "# use facies of vka just below stream\n",
    "vka_sfr = m.upw.vka.array[sfrdf.k, sfrdf.i, sfrdf.j]\n",
    "vka_quants = pd.DataFrame(np.quantile(vka_sfr, tprogs_quants))\n",
    "vka_quants.index=['mud','sandy mud','sand','gravel']\n",
    "grid_sfr['facies'] = 'mud'\n",
    "for n in np.arange(0,len(vka_quants)-1):\n",
    "    grid_sfr.loc[vka_sfr > vka_quants.iloc[n].values[0],'facies'] = vka_quants.index[n+1]\n",
    "# remove stream segments for routing purposes only\n",
    "grid_sfr = grid_sfr[~grid_sfr.iseg.isin(drop_iseg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.read_csv(model_ws+'/ZonePropertiesInitial.csv', index_col='Zone')\n",
    "# convert from m/s to m/d\n",
    "params['K_m_d'] = params.K_m_s * 86400 \n",
    "vka = m.upw.vka.array\n",
    "tprogs_vals = np.arange(1,5)\n",
    "tprogs_hist = np.flip([0.590, 0.155, 0.197, 0.058])\n",
    "tprogs_quants = 1-np.append([0], np.cumsum(tprogs_hist)/np.sum(tprogs_hist))\n",
    "vka_quants = pd.DataFrame(tprogs_quants[1:], columns=['quant'], index=tprogs_vals)\n",
    "# dataframe summarizing dominant facies based on quantiles\n",
    "vka_quants['vka_min'] = np.quantile(vka, tprogs_quants[1:])\n",
    "vka_quants['vka_max'] = np.quantile(vka, tprogs_quants[:-1])\n",
    "vka_quants['facies'] = params.loc[tprogs_vals].Lithology.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef95387",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrdf = pd.DataFrame(sfr.reach_data)\n",
    "grid_sfr = grid_p.set_index(['row','column']).loc[list(zip(sfrdf.i+1,sfrdf.j+1))].reset_index(drop=True)\n",
    "grid_sfr = pd.concat((grid_sfr,sfrdf),axis=1)\n",
    "# group sfrdf by vka quantiles\n",
    "sfr_vka = vka[grid_sfr.k, grid_sfr.i, grid_sfr.j]\n",
    "for p in vka_quants.index:\n",
    "    facies = vka_quants.loc[p]\n",
    "    grid_sfr.loc[(sfr_vka< facies.vka_max)&(sfr_vka>= facies.vka_min),'facies'] = facies.facies\n",
    "#     # add color for facies plots\n",
    "# grid_sfr = grid_sfr.join(gel_color.set_index('geology')[['color']], on='facies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8098c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr.plot('facies', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af65bda9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# lak_shp = join(gwfm_dir,'LAK_data/floodplain_delineation')\n",
    "# lak_extent = gpd.read_file(join(lak_shp,'LCRFR_ModelDom_2017/LCRFR_2DArea_2015.shp' )).to_crs('epsg:32610')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1854c48e",
   "metadata": {},
   "source": [
    "## Sensor data and XS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50532aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_grid = pd.read_csv(join(proj_dir, 'mw_hob_cleaned.csv'))\n",
    "rm_grid = gpd.GeoDataFrame(rm_grid, geometry = gpd.points_from_xy(rm_grid.Longitude,rm_grid.Latitude), \n",
    "                           crs='epsg:4326').to_crs(grid_p.crs)\n",
    "# get model layer for heads\n",
    "hob_row = rm_grid.row.values-1\n",
    "hob_col = rm_grid.column.values-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9143d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwl_long = pd.read_csv(join(model_ws,'gwl_long.csv'), parse_dates=['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6b9dc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# XS are every 100 m\n",
    "xs_all = pd.read_csv(dat_dir+'XS_point_elevations.csv',index_col=0)\n",
    "xs_all = gpd.GeoDataFrame(xs_all,geometry = gpd.points_from_xy(xs_all.Easting,xs_all.Northing), crs='epsg:32610')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41180d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# correspond XS to sensors\n",
    "rm_elev = gpd.sjoin_nearest(XSg, rm_grid, how='right',lsuffix='xs', rsuffix='rm', distance_col='dist_m')\n",
    "#MW_11, MW_CP1 had doubles with sjoin_nearest due to XS duplicates from Oneto_Denier\n",
    "rm_elev = rm_elev.drop_duplicates(['Sensor'])\n",
    "rm_elev = rm_elev.sort_values('iseg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e111b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elevation check for Graham to show the difference between wells and the river\n",
    "# fig,ax=plt.subplots()\n",
    "# # rm_elev\n",
    "# rm_elev.plot(x='Sensor',y='z_m_min', ax=ax, kind='scatter', color='red',label='River Min')\n",
    "# rm_elev.plot(x='Sensor',y='z_m_min_cln',ax=ax, kind='scatter', color='black', label='River Min adj')\n",
    "# rm_elev.plot(x='Sensor',y='MPE (meters)',ax=ax, kind='scatter', color='brown', label='Well MPE')\n",
    "# plt.ylabel('Elevation (m AMSL)')\n",
    "# plt.xticks(rotation=90);\n",
    "# rm_elev."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c072ab9",
   "metadata": {},
   "source": [
    "## Model output - time variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca360506",
   "metadata": {},
   "outputs": [],
   "source": [
    "strt_date, end_date, dt_ref = get_dates(m.dis, ref='strt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chk_ws = join(loadpth,'parallel_oneto_denier_upscale4x_2014_2018','realization011')\n",
    "# chk_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_wb(flow_name, dt_ref):\n",
    "    # load summary water budget\n",
    "    wb = pd.read_csv(flow_name, delimiter=r'\\s+')\n",
    "\n",
    "    wb['kstpkper'] = list(zip(wb.STP-1,wb.PER-1))\n",
    "    wb = wb.merge(dt_ref, on='kstpkper').set_index('dt')\n",
    "\n",
    "    # calculate change in storage\n",
    "    wb['dSTORAGE'] = wb.STORAGE_OUT - wb.STORAGE_IN\n",
    "    wb['dSTORAGE_sum'] = wb.dSTORAGE.cumsum()\n",
    "    # calculate total gw flow, sum GHB, CHD\n",
    "    wb['GW_OUT'] = wb.GHB_OUT + wb.CHD_OUT\n",
    "    wb['GW_IN'] = wb.GHB_IN + wb.CHD_IN\n",
    "    wb = wb.loc[:,~wb.columns.str.contains('GHB|CHD')]\n",
    "    \n",
    "    wb_cols = wb.columns[wb.columns.str.contains('_IN|_OUT')]\n",
    "    wb_cols = wb_cols[~wb_cols.str.contains('STORAGE|IN_OUT')]\n",
    "    wb_out_cols= wb_cols[wb_cols.str.contains('_OUT')]\n",
    "    wb_in_cols = wb_cols[wb_cols.str.contains('_IN')]\n",
    "    # only include columns with values used\n",
    "    wb_out_cols = wb_out_cols[np.sum(wb[wb_out_cols]>0, axis=0).astype(bool)]\n",
    "    wb_in_cols = wb_in_cols[np.sum(wb[wb_in_cols]>0, axis=0).astype(bool)]\n",
    "\n",
    "    return(wb, wb_out_cols, wb_in_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3279b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb, wb_out_cols, wb_in_cols = clean_wb(model_ws+'/flow_budget.txt', dt_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57fd891",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean water budget ($m^3/day$)')\n",
    "wb[wb_out_cols].mean(), wb[wb_in_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6da7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots(3,1, sharex=True)\n",
    "wb.plot(y='PERCENT_ERROR', ax=ax[0])\n",
    "wb.plot(y=wb_out_cols, ax=ax[1], legend=True)\n",
    "wb.plot(y=wb_in_cols, ax=ax[2], legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_var = 'GW_OUT'\n",
    "# in_var = 'GW_IN'\n",
    "def wb_chk_plt(var):\n",
    "    out_var = var+'_OUT'\n",
    "    in_var = var+'_IN'\n",
    "    out_chk = (wb[out_var] - wb_chk[out_var])/((wb[out_var]+ wb_chk[out_var])/2)\n",
    "    in_chk = (wb[in_var]- wb_chk[in_var])/((wb[in_var]+ wb_chk[in_var])/2)\n",
    "    in_chk.plot(label='in'), out_chk.plot(label='out')\n",
    "    plt.legend()\n",
    "# wb_chk_plt('SFR')\n",
    "# wb_chk_plt('ET')\n",
    "# wb_chk_plt('WEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5142a113",
   "metadata": {},
   "source": [
    "The ET water budget does seem to be impacted quite a bit during the wet season because more water is available. SFR is affected on a few random dates to the extreme, but overall not too much. Since there is an impact on ET then it seems like it would make sense. Making the rainfall for GDE areas had the RMSE go from 1.66 to and NSE from 0.66 to .67 so not a major change, but slight improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3ea44",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# wb_chk.SFR_OUT.plot()\n",
    "# wb.SFR_OUT.plot(alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d567d",
   "metadata": {},
   "source": [
    "Adjusting the GHB to use heads at 500 m did reduce the baseflow magnitude and number of days, it would be interesting to see how this impacts NSE. Also the NSe went from 0.60 to 0.66 and RMSE went from 1.8 to 1.6 with the increased outflow which supports the need to re-run all realizations with the udpated GHB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1820be24",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "et_local = m.evt.evtr.array[:,0]\n",
    "ext_dp = m.evt.exdp.array[0][0]\n",
    "ievt = m.evt.ievt.array[0][0]\n",
    "surf = m.evt.surf.array[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9714d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdobj = flopy.utils.HeadFile(model_ws+'/MF.hds')\n",
    "# plt.contour(hdobj.get_data((0,0))[-1])\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c1be1",
   "metadata": {},
   "source": [
    "# Plot Groundwater Observed vs Simulated\n",
    "We need to validate that the local model of Oneto-Denier is adequately representing stream-aquifer interactions so it can be used to quantify storage changes and particle age.\n",
    "\n",
    "- field data shows fall lows around -2 to 2 m with peaks to 8m with winter\n",
    "- simulated data shows fall lows around 3-5 meters with peaks to 8 m\n",
    "- the simulated data as usual isn't showing as extreme reactions as the real data is showing which could be partly due to an issue with the initial steady state levels, the peaks match which means the stream stage is peaking close to reality. I may need to consider adding evapotranspiration as the GDEs are likely pulling water\n",
    "- adding EVT and RCH together brought the steady state conditions to match observed conditions, but way over-estimated the winter peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d9eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdobj = flopy.utils.HeadFile(model_ws+'/MF.hds')\n",
    "# # extract time series of heads for each desired location\n",
    "# mw_hds = hdobj.get_ts(list(zip(rm_grid['lay'], hob_row, hob_col)))\n",
    "# mw_hds = pd.DataFrame(mw_hds, columns=['time']+rm_grid.Sensor.tolist())\n",
    "# # convert to hourly to maintain more precision in DT\n",
    "# mw_hds['dt'] = strt_date+(mw_hds.time.values*24 ).astype('timedelta64[h]')\n",
    "# mw_gwl = mw_hds.drop(columns=['time'])\n",
    "# # long format for id join with observed dat\n",
    "# mw_long = mw_gwl.melt(id_vars='dt', var_name='Well',value_name='sim')\n",
    "# mw_long = mw_long[mw_long.sim != -1e30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347badb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# mw_chk = mw_long.join(gwl_long.set_index(['Well','dt']), on=['Well','dt'], how='inner')\n",
    "# mw_chk = mw_chk.melt(id_vars=['dt', 'Well'],value_vars=['sim','obs'], value_name='gwe', var_name='type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa482fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.relplot(mw_chk,x='dt',y='gwe',col='Well', hue='type', col_wrap=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed6362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def nse(targets,predictions):\n",
    "    return 1-(np.sum((targets-predictions)**2)/np.sum((targets-np.mean(predictions))**2))\n",
    "\n",
    "def clean_hob(model_ws, name='MF.hob.out'):\n",
    "    hobout = pd.read_csv(join(model_ws,name),delimiter=r'\\s+', header = 0,names = ['sim_val','obs_val','obs_nam'],\n",
    "                         dtype = {'sim_val':float,'obs_val':float,'obs_nam':object})\n",
    "    hobout[['Sensor', 'spd']] = hobout.obs_nam.str.split('p',n=2, expand=True)\n",
    "    hobout['kstpkper'] = list(zip(np.full(len(hobout),0), hobout.spd.astype(int)))\n",
    "    hobout = hobout.join(dt_ref.set_index('kstpkper'), on='kstpkper')\n",
    "    hobout.loc[hobout.sim_val.isin([-1e30, -999.99, -9999]), 'sim_val'] = np.nan\n",
    "    hobout = hobout.dropna(subset='sim_val')\n",
    "    hobout['error'] = hobout.obs_val - hobout.sim_val\n",
    "    hobout['sq_error'] = hobout.error**2\n",
    "    \n",
    "    return(hobout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52490ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hobout = clean_hob(chk_ws)\n",
    "hobout = clean_hob(model_ws, 'MF.hob.out')\n",
    "\n",
    "# removing oneto ag because of large depth offset\n",
    "hobout = hobout[hobout.Sensor != 'MW_OA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# technically the RMSE is MSE unless I square root it\n",
    "\n",
    "# summary stats by well\n",
    "mw_stats = hobout[['Sensor','sq_error']].groupby('Sensor').sum()\n",
    "mw_stats['r2'] = 0\n",
    "for s in hobout.Sensor.unique():\n",
    "    df_s = hobout[hobout.Sensor==s]\n",
    "    mw_stats.loc[s,'r2'] = r2_score(df_s.obs_val, df_s.sim_val)\n",
    "    mw_stats.loc[s,'RMSE'] = mean_squared_error(df_s.obs_val, df_s.sim_val, squared=False) # false returns RMSE instead of MSE\n",
    "    mw_stats.loc[s,'NSE'] = nse(df_s.obs_val, df_s.sim_val)\n",
    "\n",
    "t=0\n",
    "sum_stats = pd.DataFrame(columns=['r2','RMSE','NSE'])\n",
    "# summary statistics\n",
    "sum_stats.loc[t,'r2'] = r2_score(hobout.obs_val, hobout.sim_val)\n",
    "sum_stats.loc[t,'RMSE'] = np.sqrt(hobout.sq_error.sum()/len(hobout))\n",
    "sum_stats.loc[t,'NSE'] = nse(hobout.obs_val, hobout.sim_val)\n",
    "\n",
    "sum_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e4ab76",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "hob_long = hobout.melt(id_vars=['dt', 'Sensor'],value_vars=['sim_val','obs_val'], value_name='gwe', var_name='type')\n",
    "# hob_long\n",
    "# hob_long = hobout.melt(id_vars=['dt', 'Sensor'],value_vars=['sim_val','obs_val','sim_4x'], value_name='gwe', var_name='type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b6ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hob_long, x='dt',y='\n",
    "g = sns.relplot(hob_long, x='dt',y='gwe',col='Sensor',hue = 'type',  col_wrap=4)\n",
    "\n",
    "axes = g.axes.flatten()\n",
    "mw = hob_long.Sensor.unique()\n",
    "\n",
    "for n in np.arange(0,len(axes)):\n",
    "    mw_dat = rm_elev[rm_elev.Sensor ==mw[n]]\n",
    "    axes[n].axhline(mw_dat['MPE (meters)'].values[0], ls='--', linewidth=3, color='brown')\n",
    "    axes[n].axhline(mw_dat['z_m_min_cln'].values[0]-1, ls='--', linewidth=3, color='blue')\n",
    "    et_bot = (surf-ext_dp)[mw_dat.row_rm.iloc[0], mw_dat.column_rm.iloc[0]]\n",
    "    axes[n].axhline(et_bot, ls='--', linewidth=3, color='green')\n",
    "#     axes[n].axhline(mw_dat['bot_screen_m'].values[0]-1, ls='--', linewidth=3, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cdb066",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_chk = 'MW_19'\n",
    "fig,ax = plt.subplots(1+len(wb_out_cols),1, figsize=(6.5, 8), sharex=True)\n",
    "sns.lineplot(hob_long[hob_long.Sensor== mw_chk], x='dt',y='gwe', hue='type', ax=ax[0])\n",
    "\n",
    "for n, wb_n in enumerate(wb_out_cols):\n",
    "    wb.plot(y=wb_n, ax=ax[n+1], legend=False)\n",
    "    ax[n+1].set_ylabel(wb_out_cols[n].split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec934e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate error for spatial plotting by month average?\n",
    "\n",
    "hob_diff = hob_long.pivot_table(index=['dt','Sensor'],values='gwe',columns='type')\n",
    "hob_diff['h_diff'] = hob_diff.sim_val - hob_diff.obs_val\n",
    "\n",
    "hob_diff_mon = hob_diff.reset_index().set_index('dt').groupby('Sensor').resample('MS').mean()\n",
    "hob_diff_mon = hob_diff_mon[['h_diff']].reset_index()\n",
    "# hob_diff_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e8b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flopy.utils.binaryfile as bf\n",
    "hdobj = bf.HeadFile(join(model_ws,'MF.hds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_plt = '2017-11-01'\n",
    "# t_plt = '2018-06-01'\n",
    "t_plt = '2018-02-01'\n",
    "\n",
    "diff_plt = hob_diff_mon[hob_diff_mon.dt == t_plt]\n",
    "# diff_plt['sign'] = np.sign(diff_plt.h_diff)\n",
    "diff_plt = rm_grid.join(diff_plt.set_index('Sensor'),on='Sensor')\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(8, 8))\n",
    "mapview = flopy.plot.PlotMapView(model=m,ax=ax)\n",
    "\n",
    "spd = dt_ref[dt_ref.dt==t_plt].kstpkper.values[0]\n",
    "avg_sfr_lay = int(np.round(grid_sfr.k.mean()))\n",
    "head = hdobj.get_data((0,spd[-1]))[avg_sfr_lay] #m.dis.top.array - \n",
    "# head = np.ma.masked_where(head==-1e30, head)\n",
    "head[head==-1e30] = np.nan\n",
    "# m_domain.plot(ax=ax_n,color='none')\n",
    "im = mapview.contour_array(head, masked_values=[-999.99, -1e30], ax=ax)\n",
    "plt.colorbar(im, ax=ax, shrink = 0.4)\n",
    "plt.clabel(im)\n",
    "\n",
    "mapview.plot_array(ext_dp, ax=ax)\n",
    "grid_sfr.plot(color='blue', ax=ax)\n",
    "# lak_extent.plot(color='none', ax=ax)\n",
    "diff_plt.plot('h_diff', scheme='Quantiles', k = 6, ax=ax,\n",
    "                  legend=True,cmap='bwr', legend_kwds={'loc':'lower right' ,'title':'Error (Sim - Obs)'})\n",
    "\n",
    "rm_grid.apply(lambda x: ax.annotate(x.Sensor.replace('MW_',''), xy=x.geometry.coords[0], ha='center', fontsize=6,\n",
    "                                    xytext = (5,10), textcoords='offset pixels',\n",
    "                                    bbox=dict(boxstyle=\"square,pad=0.3\", fc=\"lightgrey\", ec=\"black\", lw=2)\n",
    "                                                        ),axis=1);\n",
    "gdf_bnd = gdf_bnds(rm_grid,buf=100, ax=ax)\n",
    "\n",
    "ax.set_title(t_plt)\n",
    "\n",
    "ctx.add_basemap(ax=ax, source = ctx.providers.Esri.WorldImagery, attribution=False, attribution_size=6,\n",
    "                crs = 'epsg:26910', alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d17660",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_d = pd.read_csv(sfr_dir+'MCC_flow_obs_all.csv', parse_dates = ['DATE TIME'], index_col='DATE TIME')\n",
    "mcc_d = mcc_d[(mcc_d.index>strt_date)&(mcc_d.index<end_date)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48773408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local stream stage data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d1c12c",
   "metadata": {},
   "source": [
    "## Lake plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elevSteps, volArray, saArray\n",
    "bathtxt = np.loadtxt(m.model_ws+'/MF.bath', delimiter = '\\t')\n",
    "bath = pd.DataFrame(bathtxt, columns=['elev','vol','area'])\n",
    "# bath.plot(x='elev',y='vol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef86b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_cols = ['time','stage','volume','conc','inflows','outflows','conductance','error']\n",
    "\n",
    "def read_gage(gagenam):\n",
    "    gage = pd.read_csv(gagenam,skiprows=1, delimiter = r'\\s+', engine='python')\n",
    "    cols = gage.columns[1:-1]\n",
    "    gage = gage.dropna(axis=1)\n",
    "    gage.columns = cols\n",
    "    strt_date = pd.to_datetime(m.dis.start_datetime)\n",
    "    gage['dt'] = strt_date+(gage.Time*24).astype('timedelta64[h]')\n",
    "    gage = gage.set_index('dt')\n",
    "    gage['dVolume'] = gage.Volume.diff()\n",
    "    gage['Total_In'] = gage[['Precip.','Runoff','GW-Inflw','SW-Inflw']].sum(axis=1)\n",
    "    gage['Total_Out'] = gage[['Evap.','Withdrawal','GW-Outflw','SW-Outflw']].sum(axis=1)\n",
    "    gage['In-Out'] = gage.Total_In - gage.Total_Out\n",
    "#     gage['name'] = run\n",
    "    return(gage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6bb936",
   "metadata": {},
   "outputs": [],
   "source": [
    "lak_out = read_gage(join(model_ws, 'MF_lak.go'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37551c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lak_out[lak_out['Percent-Err']>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf3813",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# model troubleshooting\n",
    "# fig,ax = plt.subplots(4,1, sharex=True)\n",
    "# lak_out.plot(y=['Total_In','Total_Out'], ax=ax[0])\n",
    "# # plt.yscale('log')\n",
    "# lak_out.plot(y=['In-Out','dVolume'],ax=ax[1])\n",
    "# # (lak_out['In-Out']-lak_out.dVolume\n",
    "# lak_out.plot(y='Volume',ax=ax[2])\n",
    "# lak_out.plot(y=['Percent-Err'],ax=ax[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb40075",
   "metadata": {},
   "outputs": [],
   "source": [
    "lak_out['2015-1-1':'2015-10-1']['Stage(H)'].min()\n",
    "# min lake stage for lake out is 2.95\n",
    "# outflow is zero in summer, stage is never 0, volume is zero in summer\n",
    "# gw inflow is zero in 2015, 2016 summers\n",
    "# np.sign(lak_out['SW-Outflw']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd66f55",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,1, sharex=True)\n",
    "lak_out.plot(y=['Stage(H)'], ax = ax[0]) #dry all the time\n",
    "# lak_out.columns # GW-Inflw, GW-Outflw, SW-Inflw, SW-Outflw\n",
    "lak_out.plot(y=['GW-Inflw', 'GW-Outflw'], ax=ax[2]) # there is gw inflow\n",
    "lak_out.plot(y=['SW-Inflw', 'SW-Outflw'], ax=ax[1]) # there is sw inflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67669cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(5,1, sharex=True, layout='constrained')\n",
    "for n, wb_n in enumerate(wb_out_cols):\n",
    "    wb.plot(y=wb_n, ax=ax[n], legend=False)\n",
    "    ax[n].set_ylabel(wb_out_cols[n].split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d7013d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42119847",
   "metadata": {},
   "source": [
    "## SFR Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f91b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_sfr = pd.DataFrame().from_records(m.sfr.reach_data).rename(columns={'i':'row','j':'column'})\n",
    "# grid_sfr[['row','column']] += 1 # convert to 1 based to match with SFR output\n",
    "pd_sfr = grid_sfr.set_index(['iseg','ireach'])[['rchlen','strtop', 'facies']]\n",
    "pd_sfr['Total distance (m)'] = pd_sfr['rchlen'].cumsum()\n",
    "\n",
    "def clean_sfr_df(model_ws):\n",
    "    sfrout = flopy.utils.SfrFile(join(model_ws, m.name+m_ver+'.sfr.out'))\n",
    "    sfrdf = sfrout.get_dataframe()\n",
    "    sfrdf = sfrdf.join(dt_ref.set_index('kstpkper'), on='kstpkper').set_index('dt')\n",
    "    # convert from sub-daily to daily using mean, lose kstpkper\n",
    "    sfrdf = sfrdf.groupby('segment').resample('D').mean(numeric_only=True)\n",
    "    sfrdf = sfrdf.reset_index('segment', drop=True)\n",
    "    sfrdf[['row','column']]-=1 # convert to python\n",
    "    cmd2cfs = 1/((0.3048**3)*86400) # cubic meters per day to cfs\n",
    "    sfrdf['month'] = sfrdf.index.month\n",
    "    sfrdf['WY'] = sfrdf.index.year\n",
    "    sfrdf.loc[sfrdf.month>=10, 'WY'] +=1\n",
    "    # add column to track days with flow\n",
    "    sfrdf['flowing'] = 1\n",
    "    sfrdf.loc[sfrdf.Qout <= 0, 'flowing'] = 0\n",
    "#     sfrdf = pd_sfr.join(sfrdf.set_index(['row','column']),on=['row','column'],how='inner',lsuffix='_all')\n",
    "    sfrdf = sfrdf.join(pd_sfr ,on=['segment','reach'],how='inner',lsuffix='_all')\n",
    "    # dependent on number of time steps\n",
    "    sfrdf['Qin_cfs'] = sfrdf.Qin * cmd2cfs\n",
    "    sfrdf['Qout_cfs'] = sfrdf.Qout * cmd2cfs\n",
    "    sfrdf['Qaquifer_cfs'] = sfrdf.Qaquifer * cmd2cfs\n",
    "    \n",
    "    # create different column for stream losing vs gaining seeapge\n",
    "    sfrdf['Qrech'] = np.where(sfrdf.Qaquifer>0, sfrdf.Qaquifer,0)\n",
    "    sfrdf['Qbase'] = np.where(sfrdf.Qaquifer<0, sfrdf.Qaquifer*-1,0 )\n",
    "    # booleans for plotting\n",
    "    sfrdf['gaining'] = (sfrdf.gradient == 0)\n",
    "    sfrdf['losing'] = (sfrdf.gradient >= 0)\n",
    "    sfrdf['connected'] = (sfrdf.gradient < 1)\n",
    "    return(sfrdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64aeb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrdf =  clean_sfr_df(model_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623171f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find last day of flow\n",
    "\n",
    "# start simple with just year by segment ,'month','facies'\n",
    "sns.relplot(sfrdf.groupby(['WY','segment']).sum(numeric_only=True), x='segment',y='flowing', hue='WY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_sfr[['iseg','ireach','facies']]\n",
    "sfr_facies_sum = sfrdf.groupby(['dt','facies']).sum(numeric_only=True)\n",
    "seep_facies_sum = sfr_facies_sum[['Qrech','Qbase']].melt(ignore_index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4c1e3",
   "metadata": {},
   "source": [
    "The gaining/losing work I did with Stephen Maples shows periods of connection and disconnection and if we assume that the magnitude of stream stage is higher in the wet years then likely the groundwater system is losing in those years as well. What is likely true about floodplains is that the system is predominantly losing except during flood periods when there are more complex local scale gaining/losing conditions. \n",
    "\n",
    "What this work shows is that gravels/sands are more active during these extreme wet periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac2c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# som eissue with sharex is hiding mud probably issue of dt type, difference between mud and sandy mud\n",
    "fig,ax = plt.subplots(2,2, figsize=(12,8), sharex=True, sharey=True)#\n",
    "\n",
    "df_rech= seep_facies_sum[seep_facies_sum.variable=='Qrech'].reset_index('facies')\n",
    "for n, f in enumerate(df_rech.facies.unique()):\n",
    "    ax_n = ax[int(n/2), n%2]\n",
    "    df_plt = df_rech[df_rech.facies==f]\n",
    "    df_plt.index = pd.to_datetime(df_plt.index)\n",
    "    df_plt.plot(y='value', ax=ax_n, legend=False)\n",
    "    ax_n.set_title(f)\n",
    "    ax_n.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5786fbf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# sfr_facies_sum[sfr_facies_sum['Qbase']>0]\n",
    "# sfr_facies_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951bd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(sfr_facies_sum.melt(value_vars=['Qbase','Qrech'], ignore_index=False),\n",
    "                x='dt',y='value',hue='variable', kind='line',\n",
    "            col = 'facies', col_wrap=2)\n",
    "g.set(yscale='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c4cf7",
   "metadata": {},
   "source": [
    "### Plot stream discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447dff9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d07912",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# spd_hd = dt_ref[dt_ref.dt == '2020-05-21'].kstpkper.values[0]\n",
    "# head = hdobj.get_data(spd_hd)[0][0]\n",
    "\n",
    "for t in dt_ref.kstpkper.values[0::90]: # every 7 days \n",
    "#     spd_hd = dt_ref[dt_ref.dt == t].kstpkper.values[0]\n",
    "    head = hdobj.get_data(t)[grid_sfr.k, grid_sfr.i, grid_sfr.j]\n",
    "    head = head[head!=-1e30]\n",
    "    plt.plot(head, color='lightgray')\n",
    "plt.plot(head,label = 'GWE',  color='lightgray')\n",
    "plt.plot(m.dis.top.array[grid_sfr.i, grid_sfr.j], label='Model Top', ls='--',color='black')\n",
    "plt.plot(m.sfr.reach_data.strtop, label= 'Stream Top', ls=':',color='black')\n",
    "plt.plot(m.sfr.reach_data.strtop-m.sfr.reach_data.strthick, label= 'Stream Bottom', ls=':',color='black')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d529d6",
   "metadata": {},
   "source": [
    "## Grid wide head distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34919156",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sfr_lay = int(np.round(grid_sfr.k.mean()))\n",
    "\n",
    "nx = 2\n",
    "ny = 4\n",
    "fig,ax = plt.subplots(ny,nx, figsize=(12,12),sharex=True, sharey=True)\n",
    "\n",
    "# fig.tight_layout()\n",
    "for n,t in enumerate(dt_ref.kstpkper.values[::180][1:]):\n",
    "    head = hdobj.get_data(t)[avg_sfr_lay] #m.dis.top.array - \n",
    "        \n",
    "    ax_n = ax[int(n / nx), n % nx]\n",
    "    mapview = flopy.plot.PlotMapView(model=m,ax=ax_n)\n",
    "    m_domain.plot(ax=ax_n,color='none')\n",
    "    im = mapview.contour_array(head, masked_values=[-999.99], ax=ax_n)\n",
    "    grid_sfr.plot(ax=ax_n)\n",
    "# vmin, vmax from visual inspection but could be added with code\n",
    "#     im = ax_n.contour(head[avg_sfr_lay])\n",
    "\n",
    "    ax_n.set_aspect(1)\n",
    "    plt.colorbar(im, ax=ax_n, shrink = 0.4)\n",
    "# fig.subplots_adjust(wspace=0.2, hspace=-.5)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb9e6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

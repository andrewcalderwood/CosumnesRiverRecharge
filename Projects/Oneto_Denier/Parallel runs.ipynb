{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14317004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "import sys\n",
    "from os.path import basename, dirname, join, exists\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import gmean\n",
    "\n",
    "\n",
    "# standard geospatial python utilities\n",
    "# import pyproj # for converting proj4string\n",
    "import shapely\n",
    "import shapefile\n",
    "import geopandas as gpd\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "\n",
    "import flopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157e3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fffe889",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dir = 'F:/WRDAPP'\n",
    "c_dir = 'C:/WRDAPP'\n",
    "if os.path.exists(ext_dir):\n",
    "    loadpth = ext_dir \n",
    "elif os.path.exists(c_dir):\n",
    "    loadpth = c_dir \n",
    "loadpth +=  '/GWFlowModel/Cosumnes/Stream_seepage'\n",
    "model_nam = 'inset_oneto_denier'\n",
    "\n",
    "model_ws = join(loadpth,model_nam)\n",
    "\n",
    "m = flopy.modflow.Modflow.load('MF.nam', model_ws= model_ws, \n",
    "                                exe_name='mf-owhm.exe', version='mfnwt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a24afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_ws = join(loadpth, 'parallel_oneto_denier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c3c7bb",
   "metadata": {},
   "source": [
    "# Copy files independent of geology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly copy files not impacted by changing geology\n",
    "pks = ['nam','dis','nwt','bas','oc','evt', 'gage', 'hob', 'tab','wel','bath']\n",
    "files = [glob.glob(model_ws+'/*'+p)[0] for p in pks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde1971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "for n in np.arange(0,100).astype(str):\n",
    "    for f in files:\n",
    "        folder = '/realization'+ n.zfill(3)+'/'\n",
    "        os.makedirs(all_model_ws+folder,exist_ok=True)\n",
    "        shutil.copy(f, model_ws+folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c72e619",
   "metadata": {},
   "source": [
    "# Create files dependent on geology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ed6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ws\n",
    "\n",
    "mf_tprogs_dir = gwfm_dir+'/UPW_data/tprogs_final'+tprogs_id+'/'\n",
    "tprogs_files = glob.glob(mf_tprogs_dir+'*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde4a51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90876a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gwfm_dir = 'C:/Users/ajcalder/Box/research_cosumnes/GWFlowModel/'\n",
    "proj_dir = gwfm_dir+'Levee_setback/'\n",
    "\n",
    "# save modflow workspace file to WRDAPP sub folder to improve runtime calculations\n",
    "loadpth = 'F:/WRDAPP/GWFlowModel/Cosumnes/levee_setback/streamflow/'\n",
    "# load model with only DIS to reduce load time\n",
    "# the model will run off of the .nam file connection so flopy doesn't need them\n",
    "all_model_ws = loadpth + '/setback_streamflow'\n",
    "\n",
    "tprogs_fxn_dir = 'C:/Users/'+getuser()+'/Documents/GitHub/CosumnesRiverRecharge/tprogs_utilities'\n",
    "if tprogs_fxn_dir not in sys.path:\n",
    "    sys.path.append(tprogs_fxn_dir)\n",
    "        \n",
    "for model_nam in basename(all_model_ws)+pd.Series([0,33,89]).astype(str).str.zfill(3).values:\n",
    "    # in the case this runs in the basefolder then the current working directory\n",
    "    # is the same as the all working directory - useful now with weird naming between realizations\n",
    "    # if basename(model_ws).__contains__('historical'):\n",
    "    #     all_model_ws = model_ws\n",
    "    model_ws = loadpth +'/'+model_nam\n",
    "    m = flopy.modflow.Modflow.load('MF.nam', model_ws=model_ws, \n",
    "                                    exe_name='mf-owhm.exe', version='mfnwt')\n",
    "\n",
    "    nrow = m.dis.nrow\n",
    "    ncol = m.dis.ncol\n",
    "    nlay = m.dis.nlay\n",
    "\n",
    "    botm = m.dis.botm.array\n",
    "    # num_tprogs = 120 (max available below levelling), upscaling\n",
    "    max_num_layers =148 # based on thickness from -6m (1 m below DEM min) to -80m\n",
    "    upscale = 8\n",
    "    num_tprogs = int(max_num_layers/upscale)\n",
    "\n",
    "    ###############################################################################\n",
    "    ## LPF Package ##\n",
    "    deep_geology = np.loadtxt(model_ws+'/input_data/deep_geology.tsv', delimiter ='\\t')\n",
    "    deep_geology = np.reshape(deep_geology, (m.dis.nlay,m.dis.nrow,m.dis.ncol))\n",
    "    # initial guess for hydraulic parameters\n",
    "    params = pd.read_csv(model_ws+'/ZonePropertiesInitial.csv')\n",
    "    params = params.set_index('Zone')\n",
    "    # convert from m/s to m/d\n",
    "    params['K_m_d'] = params.K_m_s * 86400    \n",
    "\n",
    "    import tprogs_cleaning as tc\n",
    "\n",
    "    # load tprogs facies array and convert to values based on params\n",
    "    masked_tprogs = np.reshape(np.loadtxt(model_ws+'/input_data/tprogs_facies_array.tsv', delimiter='\\t'), (320,100,230))\n",
    "    K, Sy, Ss= tc.int_to_param(masked_tprogs, params)\n",
    "\n",
    "    Kx_upscaled = np.zeros((num_tprogs,nrow,ncol))\n",
    "    Kz_upscaled = np.zeros((num_tprogs,nrow,ncol))\n",
    "    Sy_upscaled = np.zeros((num_tprogs,nrow,ncol))\n",
    "    Ss_upscaled = np.zeros((num_tprogs,nrow,ncol))\n",
    "\n",
    "    for k in np.arange(1,num_tprogs+1):\n",
    "        # calculate upscale from bottom up\n",
    "        Kx_upscaled[-k,:,:] = np.nanmean(K[(-k*upscale):(-k*upscale-upscale):-1,:,:],axis=0)\n",
    "        Kz_upscaled[-k,:,:] = hmean(K[(-k*upscale):(-k*upscale-upscale):-1,:,:],axis=0)\n",
    "        Sy_upscaled[-k,:,:] = np.nanmean(Sy[(-k*upscale):(-k*upscale-upscale):-1,:,:],axis=0)\n",
    "        Ss_upscaled[-k,:,:] = np.nanmean(Ss[(-k*upscale):(-k*upscale-upscale):-1,:,:],axis=0)\n",
    "\n",
    "    # allocate arrays for Kx, Ky\n",
    "    hk = np.zeros(botm.shape)\n",
    "    vka = np.zeros(botm.shape)\n",
    "    sy = np.zeros(botm.shape)\n",
    "    ss = np.zeros(botm.shape)\n",
    "    # # take of 2 for the bottom layers and 1 for the unsat zone layer up top\n",
    "    hk[1:-2,:,:] = Kx_upscaled\n",
    "    vka[1:-2,:,:] = Kz_upscaled\n",
    "    sy[1:-2,:,:] = Sy_upscaled\n",
    "    ss[1:-2,:,:] = Ss_upscaled\n",
    "\n",
    "    tprogs_info = [80, -80, 320]\n",
    "    top = m.dis.top.array\n",
    "    bot1 = m.dis.botm.array[0,:,:]\n",
    "    # set parameters based on upscaled unsaturated zone\n",
    "    hk[0,:,:] = np.mean(tc.get_tprogs_for_elev(K, top, bot1,tprogs_info),axis=0)\n",
    "    vka[0,:,:] = hmean(tc.get_tprogs_for_elev(K, top, bot1,tprogs_info),axis=0)\n",
    "    sy[0,:,:] = np.mean(tc.get_tprogs_for_elev(Sy, top, bot1,tprogs_info),axis=0)\n",
    "    ss[0,:,:] = np.mean(tc.get_tprogs_for_elev(Ss, top, bot1,tprogs_info),axis=0)\n",
    "\n",
    "\n",
    "    # set values for second to bottom layer, Laguna formation\n",
    "    hk[-2,:,:] = params.loc[5,'K_m_d']\n",
    "    vka[-2,:,:] = params.loc[5,'K_m_d']/100 # assume 1/100 for Kx to Kz\n",
    "    sy[-2,:,:] = params.loc[5,'Sy']\n",
    "    ss[-2,:,:] = params.loc[5,'Ss']\n",
    "\n",
    "    # the deep_geology array shows where the mehrten formation comes out of the surface\n",
    "    hk[deep_geology[:,:,:].astype(bool)] = params.loc[6,'K_m_d']\n",
    "    vka[deep_geology[:,:,:].astype(bool)] = params.loc[6,'K_m_d']/100 # assume 1/100 for Kx to Kz\n",
    "    sy[deep_geology[:,:,:].astype(bool)] = params.loc[6,'Sy']\n",
    "    ss[deep_geology[:,:,:].astype(bool)] = params.loc[6,'Ss']\n",
    "\n",
    "    # set values for bottom layer, Mehrten formation\n",
    "    hk[-1,:,:] = params.loc[6,'K_m_d']\n",
    "    vka[-1,:,:] = params.loc[6,'K_m_d']/100 # assume 1/100 for Kx to Kz\n",
    "    sy[-1,:,:] = params.loc[6,'Sy']\n",
    "    ss[-1,:,:] = params.loc[6,'Ss']\n",
    "\n",
    "    # 0â€”indicates VKA is vertical hydraulic conductivity\n",
    "    layvka = 0\n",
    "    # no defined anisotropy between kx and ky, could set a value based on stream deposition\n",
    "    hani = 1 \n",
    "\n",
    "    # LAYTYP MUST BE GREATER THAN ZERO WHEN IUZFOPT IS 2\n",
    "    # 0 is confined, >0 convertible, <0 convertible unless the THICKSTRT option is in effect\n",
    "    # laytyp = [1,1,1,0,0,0,0,0]\n",
    "    laytyp = np.zeros(m.dis.nlay,dtype=int).tolist()\n",
    "\n",
    "    laywet=laytyp[:]\n",
    "    # Laywet must be 0 if laytyp is confined laywet = [1,1,1,1,1]\n",
    "    # laywet = 1 means layers can be rewetted.\n",
    "    #ipakcb = 53 means cell-by-cell budget is saved because it is non zero (default is 53)\n",
    "    # indicates that variable Ss and SS parameters are read as storage coefficient rather than specific storage. (default is False).\n",
    "    # removed sy while ss is active as storage coefficient rather than specific storage\n",
    "    # ss= sy for storage coefficient run\n",
    "    # using storage coefficient drastically increased run time from 10 to 25 minutes, storagecoefficient =True\n",
    "    lpf = flopy.modflow.ModflowLpf(model = m, hk =hk, chani = 0, hani = hani,\n",
    "                                   layvka = layvka, vka = vka, ss=ss, sy=sy,\n",
    "                                   laytyp=laytyp, laywet = laywet, ipakcb=53)\n",
    "    # overwrite the previous lpf file with updated version\n",
    "    lpf.write_file()\n",
    "\n",
    "    print('LPF done')\n",
    "    #################################################################\n",
    "    ## SFR K update ##\n",
    "    sfr = m.sfr\n",
    "\n",
    "    sfr_rows = sfr.reach_data['i']\n",
    "    sfr_cols = sfr.reach_data['j']\n",
    "    strbd_thick = 4\n",
    "    top = m.dis.top.array\n",
    "    bot_str_arr = m.dis.top.array- strbd_thick\n",
    "    # get_tprogs_for_elev(K, m_c.dis.top.array, m_c.dis.top.array- np.linspace(1,4,m_c.dis.ncol), rows = sfr_rows, cols = sfr_cols)\n",
    "    strbd_tprogs = tc.get_tprogs_for_elev(K, top, bot_str_arr, tprogs_info,rows = sfr_rows, cols = sfr_cols)\n",
    "    sfr_K = gmean(strbd_tprogs,axis=0)/100 # divide by 100 to ease convergence, but variability is still there\n",
    "    sfr.reach_data.strhc1 = sfr_K\n",
    "\n",
    "    sfr.write_file()\n",
    "\n",
    "\n",
    "    print('SFR done')\n",
    "\n",
    "    #################################################################\n",
    "    ## GHB, RCH, WEL scaling factors ##\n",
    "    scaling_factors = pd.read_csv(model_ws+'/GHB_UZF_WEL_scaling.csv', delimiter = ',')\n",
    "\n",
    "    ###############################################################################\n",
    "    ## GHB Package ##\n",
    "    # join top and botm for easier array referencing for elevations\n",
    "    top_botm = np.zeros((m.dis.nlay+1,m.dis.nrow,m.dis.ncol))\n",
    "    top_botm[0,:,:] = m.dis.top.array\n",
    "    top_botm[1:,:,:] = m.dis.botm.array\n",
    "    # load ghb dataframes\n",
    "    ghbse_spd = pd.read_csv(model_ws+'/input_data/ghbse_spd.csv')\n",
    "    ghbnw_spd = pd.read_csv(model_ws+'/input_data/ghbnw_spd.csv')\n",
    "    ghbdelta_spd = pd.read_csv(model_ws+'/input_data/ghbdelta_spd.csv')\n",
    "    # edit GHB conductance by scaling with the new K vs original\n",
    "    # ghb_hk_nw = scaling_factors.loc[0,'K_nw']*86400\n",
    "    # ghb_hk_se = scaling_factors.loc[0,'K_se']*86400\n",
    "    K_delta = scaling_factors.loc[0,'K_delta']*86400\n",
    "\n",
    "    # only need to recalculate conductance in ucode\n",
    "    def recalc_cond(i,j,k,hk):\n",
    "        distance = 5000\n",
    "        delr = m.dis.delr.array.mean()\n",
    "        cond = hk*(top_botm[k,i,j]-top_botm[k+1,i,j])*delr/distance\n",
    "        return(cond)\n",
    "\n",
    "    ##########################################################\n",
    "    ## NW, SE GHB ##\n",
    "\n",
    "    ghb_hk_se = hk[ghbse_spd.k.values, ghbse_spd.i.values,ghbse_spd.j.values]\n",
    "    ghbse_spd.cond = recalc_cond(ghbse_spd.i.values,ghbse_spd.j.values,ghbse_spd.k.values, ghb_hk_se)\n",
    "    ghb_hk_nw = hk[ghbnw_spd.k.values, ghbnw_spd.i.values,ghbnw_spd.j.values]\n",
    "    ghbnw_spd.cond = recalc_cond(ghbnw_spd.i.values,ghbnw_spd.j.values,ghbnw_spd.k.values, ghb_hk_nw)\n",
    "    ghbdelta_spd.cond = recalc_cond(ghbdelta_spd.i.values,ghbdelta_spd.j.values,ghbdelta_spd.k.values, K_delta)\n",
    "\n",
    "    # lay, row, col for delta ghb\n",
    "    zxy = ghbdelta_spd.values[:,:3].astype(int)\n",
    "    # drop any delta ghb cells where cell bottom is below sea level\n",
    "    ghbdn_spd =  ghbdelta_spd.values[botm[zxy[:,0],zxy[:,1],zxy[:,2]]<0]\n",
    "    # join dataframes of 3 ghb boundaries together\n",
    "    ghb_spd = np.vstack((ghbdn_spd, ghbse_spd.values, ghbnw_spd.values))\n",
    "\n",
    "\n",
    "    # allocate empty dictionary\n",
    "    ghb_dict = {}\n",
    "    ghb_dict[0] = ghb_spd\n",
    "\n",
    "    # create GHB for flopy\n",
    "    ghb = flopy.modflow.ModflowGhb(model = m,stress_period_data =  ghb_dict)\n",
    "    # overwrite the previous ghb file with updated version\n",
    "    ghb.write_file()\n",
    "\n",
    "    print('GHB done')\n",
    "\n",
    "\n",
    "    ###############################################################################\n",
    "    ## Update LAK Package ##\n",
    "    if basename(all_model_ws)=='setback_streamflow':\n",
    "        lak = m.lak\n",
    "        lak_grid_clip = gpd.read_file(proj_dir+'lak_grid_clip/lak_grid_clip.shp')\n",
    "\n",
    "        # look at shallower TPROGs data, should be near conductivity of unsat zone\n",
    "        bdlknc = np.zeros(( lak.bdlknc.shape))\n",
    "\n",
    "        tprogs_info = [80, -80, 320]\n",
    "        lak_rows = (lak_grid_clip.row-1).values\n",
    "        lak_cols = (lak_grid_clip.column-1).values\n",
    "        lkbd_thick = 4\n",
    "        top = m.dis.top.array\n",
    "        bot_str_arr = m.dis.top.array- lkbd_thick\n",
    "        # get_tprogs_for_elev(K, m_c.dis.top.array, m_c.dis.top.array- np.linspace(1,4,m_c.dis.ncol), rows = sfr_rows, cols = sfr_cols)\n",
    "        lkbd_tprogs = tc.get_tprogs_for_elev(K, top, bot_str_arr, tprogs_info,rows = lak_rows, cols = lak_cols)\n",
    "        lk_K = gmean(lkbd_tprogs,axis=0)/100 # divide by 100 to ease convergence, but variability is still there\n",
    "        #     # set blodgett dam Ksat same as stream Ksat at same location, leakance is K/lakebed thickness\n",
    "        #     lkbd_thick = sfr.reach_data.strthick[XSg.loc[XSg.Site==16.5].reach]\n",
    "        bdlknc[:,:,lak_rows,lak_cols] = lk_K/lkbd_thick\n",
    "\n",
    "        lak.bdlknc = bdlknc\n",
    "\n",
    "        lak.write_file()\n",
    "\n",
    "        print('LAK done')\n",
    "\n",
    "\n",
    "    ###############################################################################\n",
    "    ## Run the model ##\n",
    "\n",
    "    # run the modflow model\n",
    "#     success, buff = m.run_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ad636-0b1f-4513-a41c-35645bc411c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "import sys\n",
    "from os.path import basename, dirname, join, exists\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import gmean\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import geopandas as gpd\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "\n",
    "# import flopy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3eeb25-8242-432b-808a-2ab32b43280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel'\n",
    "# dir of stream level data for seepage study\n",
    "proj_dir = gwfm_dir + '/Oneto_Denier/'\n",
    "dat_dir = proj_dir+'Stream_level_data/'\n",
    "\n",
    "sfr_dir = gwfm_dir+'/SFR_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57668e8-c162-42cf-b487-3a02fbbe0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = join(proj_dir, 'output')\n",
    "fig_dir = join(proj_dir, 'figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9765f-c768-46ad-bbb3-a8e8cbdcdae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flopy_dir = doc_dir+'/GitHub/flopy'\n",
    "if flopy_dir not in sys.path:\n",
    "    sys.path.insert(0, flopy_dir)\n",
    "    \n",
    "import flopy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7ff9e-9362-4c27-b280-c8754e838110",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dir = 'F:/WRDAPP'\n",
    "c_dir = 'C:/WRDAPP'\n",
    "if os.path.exists(ext_dir):\n",
    "    loadpth = ext_dir \n",
    "elif os.path.exists(c_dir):\n",
    "    loadpth = c_dir \n",
    "loadpth +=  '/GWFlowModel/Cosumnes/Stream_seepage'\n",
    "\n",
    "upscale = 4 \n",
    "upscale_txt = 'upscale'+str(upscale)+'x_'\n",
    "# model_nam = 'inset_oneto_denier'\n",
    "model_nam = 'oneto_denier_'+upscale_txt+'2014_2018'\n",
    "\n",
    "base_model_ws = join(loadpth,model_nam)\n",
    "\n",
    "# all_model_ws = join(loadpth, 'parallel_oneto_denier')\n",
    "all_model_ws = join(loadpth, 'parallel_'+model_nam)\n",
    "\n",
    "# may want to skip loading rch, evt and wel which take up a lot of memory with stress period data\n",
    "load_only = ['DIS','UPW','SFR','OC']\n",
    "m = flopy.modflow.Modflow.load('MF.nam', model_ws= base_model_ws, \n",
    "                                exe_name='mf-owhm.exe', version='mfnwt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a16bd-e2cf-4515-ae48-38a5901e8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write modelgrid to get updated row and col numbers specific to the child grid\n",
    "grid_dir = join(gwfm_dir, 'DIS_data/streambed_seepage/grid')\n",
    "grid_fn = join(grid_dir, 'inset_oneto_denier','rm_only_grid.shp')\n",
    "\n",
    "# m.modelgrid.write_shapefile(grid_fn)\n",
    "grid_p = gpd.read_file(grid_fn)\n",
    "grid_p.crs = 'epsg:32610'\n",
    "# elevation to grid for reference to land surface\n",
    "dem_data = np.loadtxt(join(proj_dir, 'GIS','local_subset_dem_52_9_200m_mean.tsv'))\n",
    "grid_p['dem_elev'] = dem_data[grid_p.row-1, grid_p.column-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8a3d10-51a0-49b6-ad2c-da2540cffc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_facies_all = pd.read_hdf(join(out_dir, 'sfrdf_facies_sum.hdf5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83178008-8089-4836-a057-eb4c8fd97cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_last_all = pd.read_hdf(join(out_dir, 'sfrdf_last_seg.hdf5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deabab9-a55b-4a4d-a501-bb549718ba5e",
   "metadata": {},
   "source": [
    "Graham suggested we individually disect some of these results to better understand the impact of outcropping HCPs. A good presentation would be picking a realization that has low, middle, or high streamflow or by looking at the number of coarse segments since that is what is used as an independent variable in the correlation statistics. From there we can investigate the spatial aspects in some ways. Filter by looking at overall average streamflow at the outlet.\n",
    "\n",
    "- look at location of coarse segments vs where baseflow/recharge happen.\n",
    "- plot XS of channel to show heads in aquifer and stream and perhaps fluctuate over time to show how gravels change conditions\n",
    "\n",
    "also looking at the best fit realization to show what reality is then diving into these other realizations to show how differences in spatial distribution can significantly alter stream function. The baseflow below here is a great example of how excess gravel scattered in the channel greatly increases connectivity and baseflow. We should demonstrate as well how this then plays into the timing and duration of in-stream flows to support the ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd82171f-383d-4fdf-9b2f-8c8f050a1245",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_done = pd.read_csv(join(out_dir, 'hob_fit_stats.csv'),index_col=0)\n",
    "top_rmse = stats_done[stats_done.RMSE<=stats_done.RMSE.quantile(0.03)]\n",
    "top_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af7d19-6f2a-4da4-a5aa-441662791c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_out = pd.read_csv(join(proj_dir, 'coarse_reference.csv'), index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61f9a5-70f2-43c3-8dfd-482d404634ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_last_mean = sfr_last_all.groupby('realization').mean(numeric_only=True)['Qout']\n",
    "# realizations to review\n",
    "def per_idx(sfr_last_mean, per):\n",
    "    idx = sfr_last_mean[sfr_last_mean.isin(np.percentile(sfr_last_mean, per, method='nearest'))].sort_values().index.values\n",
    "    return idx\n",
    "quants = [5, 25, 50, 75, 95]\n",
    "# categorize by streamflow\n",
    "r_review = per_idx(sfr_last_mean, quants)\n",
    "\n",
    "# categorize by the number of coarse segments\n",
    "r_review = ref_out[ref_out.num_sfr.isin(np.percentile(ref_out.num_sfr, quants, method='nearest'))]\n",
    "r_review = r_review.drop_duplicates('num_sfr').sort_values('num_sfr').index.values\n",
    "\n",
    "# consider the best fit as well\n",
    "r_review = pd.DataFrame(np.append(r_review, top_rmse.index.values), columns=['realization'])\n",
    "r_review['variable'] = np.append(['quant']*len(quants), ['fit']*len(top_rmse))\n",
    "r_review['value'] = np.append(quants, top_rmse.RMSE).round(4)\n",
    "r_review['num_coarse'] = ref_out.loc[r_review.realization, 'num_sfr'].values\n",
    "# r_review\n",
    "# coarse_ref.loc[r_review], sfr_last_mean[r_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27029d09-cc19-44cf-81ec-94db20d594d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_out.loc[r_review.realization, 'num_lak'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b4b64-8ee8-46f8-b8cc-07188aa55d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr_all = pd.DataFrame()\n",
    "for r in r_review.realization: #100\n",
    "    folder = 'realization'+ str(r).zfill(3)\n",
    "    # update model workspace so outputs to right directory\n",
    "    model_ws = join(all_model_ws, folder)\n",
    "    grid_sfr = pd.read_csv(model_ws+'/grid_sfr.csv',index_col=0)\n",
    "    grid_sfr = grid_sfr.drop(columns=['node','geometry','node.1'])\n",
    "    grid_p_sfr = grid_p.set_index(['row','column']).loc[list(zip(grid_sfr.i+1,grid_sfr.j+1))].reset_index(drop=True)\n",
    "    grid_sfr = pd.concat((grid_p_sfr,grid_sfr),axis=1)\n",
    "    grid_sfr_all = pd.concat((grid_sfr_all, grid_sfr.assign(realization=r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f9179-984c-42bc-ac2f-c413e1b593e1",
   "metadata": {},
   "source": [
    "Looking at the quantiles for the number of coarse stream segments it seems that the best fit realizations span the 5th to 75th percentile which means that we have multiple realizations with different stream segment connections but equal model fit which means that the larger subsurface distribution might account for the fit more than stream segments that outcrop.\n",
    "- the top best fit realizations both had a higher number of coarse lake cells\n",
    "- the other variable to plot would be the number of distinct connected bodies that outcrop or that are in the domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9318acd-c639-4dc7-856e-a9cf4ee02d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_review = r_review[r_review.variable=='quant']\n",
    "fig,ax = plt.subplots(1, len(q_review), sharex=True, sharey=True, figsize=(12, 6.5))\n",
    "for nr, r in enumerate(q_review.realization):\n",
    "    grid_sfr_all[grid_sfr_all.realization==r].plot('facies', ax=ax[nr], legend=True, legend_kwds={'loc':'upper left'})\n",
    "    ax[nr].set_title(str(r)+' - '+str(q_review.value.iloc[nr])+'\\nNo. Coarse:'+str(q_review.num_coarse.iloc[nr]))\n",
    "# grid_sfr_all[grid_sfr_all.realization==r].plot('facies', legend=True, ax=ax[-1])\n",
    "\n",
    "q_review = r_review[r_review.variable=='fit']\n",
    "fig,ax = plt.subplots(1, len(q_review), sharex=True, sharey=True, figsize=(12, 6.5))\n",
    "for nr, r in enumerate(q_review.realization):\n",
    "    grid_sfr_all[grid_sfr_all.realization==r].plot('facies', ax=ax[nr], legend=True, legend_kwds={'loc':'upper left'})\n",
    "    ax[nr].set_title(str(r)+' - '+str(q_review.value.iloc[nr])+'\\nNo. Coarse:'+str(q_review.num_coarse.iloc[nr]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f59241-72dd-4243-a39d-f4593e2551ac",
   "metadata": {},
   "source": [
    "## Segment facies review\n",
    "Three of the five realizations show the expected behavior of primarily mud with patches of sand, sandy mud and gravel. The outlier is a realization that is probably half gravel and sand as the stream bed facies which is the same realization where there was a huge amount of baseflow in the gravel. There is also a realization that is almost entirely mud with a section of NAs for some reason.  \n",
    "\n",
    "The realizations with best fit all tend to have dominantly mud in the upper and lower sections with a gravel pocket along the middle section. The other realizations tend to keep this pattern with variability in the length of the gravel section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a5e6f-85ee-4e80-8217-b0e32ecfc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakrow, lakcol = np.where(m.lak.lakarr.array[0].mean(axis=0) >0)\n",
    "grid_lak = grid_p.set_index(['row','column']).loc[list(zip(lakrow+1,lakcol+1))].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f120e6e-3a85-4697-92b8-6b4c8e69bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = gpd.read_file(join(proj_dir, 'GIS', 'plotting_cross_section_lines.shp'))\n",
    "grid_xs = gpd.sjoin(grid_p, xs) # grid cells for each XS\n",
    "# set standard cell numbers for XS plotting\n",
    "for n in  np.arange(0, len(xs)):\n",
    "    grid_xs.loc[grid_xs.id==n, 'xs_cell']  = np.arange(0, (grid_xs.id==n).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec803c4-7028-49b6-a16c-5b39e5a3490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr[['row','column']] = grid_sfr[['i','j']]+1\n",
    "# grid_sfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4f8542-25cb-4d9c-8d64-4ede7c416ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find sfr, lak cells that are in the xs\n",
    "sfr_xs = grid_xs.join(grid_sfr.set_index(['row','column']).drop(columns=['geometry','node']), on=['row','column'], how='inner')\n",
    "lak_xs = grid_xs.join(grid_lak.set_index('node').drop(columns=['geometry', 'dem_elev']), on='node', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1248a1-c4e8-4be8-a97c-d7f2fe815c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_xs.plot('xs_cell', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f2781-df14-4944-8803-6f03a16654b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=grid_lak.plot()\n",
    "grid_sfr.plot('facies', ax=ax)\n",
    "grid_xs.plot(ax=ax)\n",
    "grid_xs.plot('xs_cell', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0464eb-20c3-4f2b-bb60-6815e56500aa",
   "metadata": {},
   "source": [
    "It would make sense to have a XS in the middle of the floodplain, at the bottom edge where the gravel patch tends to be in the river and a little further downstream near the outlet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc42019e-a17d-48b7-aa39-7ae2acffdddf",
   "metadata": {},
   "source": [
    "## Deeper geologic review\n",
    "Following the segment facies review, there are geologic features that may be adjacent to the channel but not outcrop that could impact flow but this is more difficult to represent. I think plotting these XS with head values and geologic facies are a good way to dive a little deeper at a 2D level. It would also be worthwhile presenting groundwater contours at key points (flood peak, recession and summer low)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba32d8-a9a6-439c-8fd7-cd1e24cb8952",
   "metadata": {},
   "outputs": [],
   "source": [
    "## identify XS line to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d156a34-1b89-4e1a-8f3c-78cf864a6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e11e7-13a0-476a-a95f-f077b9f8c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'realization'+ str(r).zfill(3)\n",
    "# update model workspace so outputs to right directory\n",
    "model_ws = join(all_model_ws, folder)\n",
    "# m.model_ws = model_ws\n",
    "upw_r = flopy.modflow.ModflowUpw.load(model_ws+'/MF.upw', model=m)\n",
    "# model_ws+'/MF.upw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898616b-3279-4d5f-95eb-1b6a5df4e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdobj = flopy.utils.HeadFile(model_ws+'/MF.hds')\n",
    "spd_stp = hdobj.get_kstpkper()\n",
    "times = hdobj.get_times()\n",
    "\n",
    "# get ALL stress periods and time steps list, not just those in the output\n",
    "kstpkper = []\n",
    "for n,stps in enumerate(m.dis.nstp.array):\n",
    "    kstpkper += list(zip(np.arange(0,stps),np.full(stps,n)))\n",
    "\n",
    "# dt_ref = pd.DataFrame(dates_stps, columns=['dt'])\n",
    "# dt_ref['kstpkper'] = kstpkper\n",
    "# dt_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ee2ae-4349-4e68-b9fd-f59b4ed971a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in xs.id:\n",
    "for n in [2]:\n",
    "    xs_n = grid_xs[grid_xs.id==n]\n",
    "    xs_hk = upw_r.hk.array[:, xs_n.row-1, xs_n.column-1]\n",
    "    \n",
    "    sfr_xs_n = sfr_xs[sfr_xs.id==n]\n",
    "    lak_xs_n = lak_xs[lak_xs.id==n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c343386d-759d-445a-911d-e4b33fe53fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(xs_hk)\n",
    "xs_hk[0]\n",
    "ymax = m.dis.top.array.max()\n",
    "ymin = m.dis.botm.array.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05704423-affc-41e6-8411-66427270dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygon = ax.fill_between(x, y1, y2, lw=0, color='none')\n",
    "# ax.margins(x=0.02)\n",
    "# xlim = ax.get_xlim()\n",
    "# ylim = ax.get_ylim()\n",
    "# verts = np.vstack([p.vertices for p in polygon.get_paths()])\n",
    "plt.imshow(xs_hk, cmap='viridis', aspect='auto',\n",
    "                    extent=[xs_n.xs_cell.min(), xs_n.xs_cell.max(), ymin, ymax]\n",
    "                    # extent=[verts[:, 0].min(), verts[:, 0].max(), verts[:, 1].min(), verts[:, 1].max()]\n",
    "                   )\n",
    "# filling.set_clip_path(polygon.get_paths()[0], transform=ax.transData)\n",
    "# ax.set_xlim(xlim) # the limits need to be set again because imshow sets zero margins\n",
    "# ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41002893-95a1-43b8-b96e-66f91c711969",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "head = hdobj.get_data(spd_stp[1200])[:, xs_n.row-1, xs_n.column-1] \n",
    "head = np.ma.masked_where(head==-999.99, head)\n",
    "\n",
    "# when considering how to plot head we should focus on the upper layers where the river interacts\n",
    "# it appears the heads under the river/lake stay constant\n",
    "# for n in np.arange(head.shape[0]):\n",
    "#     plt.plot(xs_n.xs_cell, head[n]);\n",
    "\n",
    "def plt_xs_spd(head, sfr_xs_n, lak_xs_n, xs_n, ax):\n",
    "    # plot head in sfr layer only\n",
    "    head_sfr = head[sfr_xs_n.k.values[0]]\n",
    "    ax.plot(head_sfr, color='blue', label='Head in SFR layer')\n",
    "    # plot average head as well\n",
    "    head_avg = head[0:10].mean(axis=0)\n",
    "    ax.plot(head_avg, color='blue', linestyle='--', label='Average Head - Upper')\n",
    "    head_avg = head[10:-1].mean(axis=0)\n",
    "    ax.plot(head_avg, color='blue', linestyle='-.', label='Average Head - Lower')\n",
    "    head_avg = head[-1]\n",
    "    ax.plot(head_avg, color='blue', linestyle=':', label='Head - Deep')\n",
    "\n",
    "    # plot sfr and lak stages\n",
    "    ax.scatter(sfr_xs_n.xs_cell, sfr_xs_n.strtop, zorder= -1, color='tab:blue', label='Stream Top')\n",
    "    ax.scatter(lak_xs_n.xs_cell, lak_xs_n.dem_elev, zorder= -2, color='brown', label='Lake')\n",
    "    ax.plot(xs_n.xs_cell, xs_n.dem_elev, zorder= -3, color='black', label='Land Surface')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea3419-1fd7-4de7-a9c3-6c51305eb08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505f276-46d4-4176-80a8-a21f86a9bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(xs.id), figsize=(6,6), sharex=True, sharey=True)\n",
    "for n in xs.id:\n",
    "    xs_n = grid_xs[grid_xs.id==n]\n",
    "    xs_hk = upw_r.hk.array[:, xs_n.row-1, xs_n.column-1]\n",
    "    \n",
    "    sfr_xs_n = sfr_xs[sfr_xs.id==n]\n",
    "    lak_xs_n = lak_xs[lak_xs.id==n]\n",
    "\n",
    "    \n",
    "    head = hdobj.get_data(spd_stp[1200])[:, xs_n.row-1, xs_n.column-1] \n",
    "    head = np.ma.masked_where(head==-999.99, head)\n",
    "\n",
    "    plt_xs_spd(head, sfr_xs_n, lak_xs_n, xs_n, ax=ax[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2049ec-b96d-4077-8786-dbb3b01b1be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71c06c-4c15-4419-a7b1-20a5ba2831b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(xs.id), figsize=(6,6), sharex=True, sharey=True)\n",
    "for n in xs.id:\n",
    "    xs_n = grid_xs[grid_xs.id==n]\n",
    "    xs_hk = upw_r.hk.array[:, xs_n.row-1, xs_n.column-1]\n",
    "    \n",
    "    sfr_xs_n = sfr_xs[sfr_xs.id==n]\n",
    "    lak_xs_n = lak_xs[lak_xs.id==n]\n",
    "\n",
    "    \n",
    "    head = hdobj.get_data(spd_stp[1200])[:, xs_n.row-1, xs_n.column-1] \n",
    "    head = np.ma.masked_where(head==-999.99, head)\n",
    "\n",
    "    plt_xs_spd(head, sfr_xs_n, lak_xs_n, xs_n, ax=ax[n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

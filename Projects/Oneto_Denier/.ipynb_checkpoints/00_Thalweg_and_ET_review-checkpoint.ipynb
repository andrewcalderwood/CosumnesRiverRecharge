{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c3cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "import sys\n",
    "from os.path import basename, dirname, join, exists\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "# standard python plotting utilities\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import geopandas as gpd\n",
    "# from osgeo import gdal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while os.path.basename(doc_dir) != 'Documents':\n",
    "    doc_dir = os.path.dirname(doc_dir)\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = os.path.dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel'\n",
    "# dir of stream level data for seepage study\n",
    "proj_dir = gwfm_dir + '/Oneto_Denier/'\n",
    "dat_dir = proj_dir+'Stream_level_data/'\n",
    "\n",
    "sfr_dir = gwfm_dir+'/SFR_data/'\n",
    "uzf_dir = gwfm_dir+'/UZF_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c9c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = pd.to_datetime('2020-9-30') # end time for analysis\n",
    "strt_date = pd.to_datetime('2014-10-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99555ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_match = gpd.read_file(join(proj_dir, 'GIS','grid_match.shp'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80708168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write modelgrid to get updated row and col numbers specific to the child grid\n",
    "grid_dir = join(gwfm_dir, 'DIS_data/streambed_seepage/grid')\n",
    "grid_fn = join(grid_dir, 'inset_oneto_denier','rm_only_grid.shp')\n",
    "\n",
    "# m.modelgrid.write_shapefile(grid_fn)\n",
    "grid_p = gpd.read_file(grid_fn)\n",
    "grid_p.crs = 'epsg:32610'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fbc183",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_match['id'] = 0\n",
    "m_domain = grid_match.dissolve('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bcef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow_p, ncol_p = (100, 230)\n",
    "nrow, ncol = grid_match.row.max(), grid_match.column.max()\n",
    "delr, delc = (100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4feb1a5-78a4-447c-9344-78fae571b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dir = 'F:/WRDAPP'\n",
    "c_dir = 'C:/WRDAPP'\n",
    "if os.path.exists(ext_dir):\n",
    "    loadpth = ext_dir \n",
    "elif os.path.exists(c_dir):\n",
    "    loadpth = c_dir \n",
    "loadpth +=  '/GWFlowModel/Cosumnes/Stream_seepage'\n",
    "\n",
    "upscale = 'upscale4x_'\n",
    "# model_nam = 'oneto_denier_'+upscale+'2014_2018'\n",
    "model_nam = 'oneto_denier_'+upscale+'2014_2020'\n",
    "model_ws = join(loadpth,model_nam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e088c23-d065-4e03-84ba-cab28b643228",
   "metadata": {},
   "outputs": [],
   "source": [
    "XSg = pd.read_csv(join(model_ws,'04_XSg_filled.csv'))\n",
    "XSg = gpd.GeoDataFrame(XSg, geometry = gpd.points_from_xy(XSg.Easting, XSg.Northing), crs='epsg:32610')\n",
    "\n",
    "gwl_long = pd.read_csv(join(model_ws,'gwl_long.csv'), parse_dates=['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fdab5a-652c-49e2-b1ef-7212e1f46bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lak_shp = join(gwfm_dir,'LAK_data/floodplain_delineation')\n",
    "lak_extent = gpd.read_file(join(lak_shp,'LCRFR_ModelDom_2017/LCRFR_2DArea_2015.shp' )).to_crs('epsg:32610')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac09e6-1a0c-4345-a512-2c3822a7474f",
   "metadata": {},
   "source": [
    "## Check thalweg elevations and gaining vs losing\n",
    "Plot the thalweg for the 10 m and 2m DEM to compare differences with some expected increases in the 10 m due to sampling size. Compare against the Constantine 2001 XS surveys, with again the potential for further incision since this but shouldn't be much.  \n",
    "To validate the gaining conditions we should recreate the plots I made previously except with the groundwater elevation plotted against the nearest thalweg elevation. One additional plot we could make is to krige groundwater elevations from the wells and sample it along the river.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b71449-b506-4575-8f25-ce0a179ff4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = gpd.read_file(join(proj_dir, 'GIS', 'plotting_cross_section_lines.shp'))\n",
    "grid_xs = gpd.sjoin(grid_p, xs) # grid cells for each XS\n",
    "# set standard cell numbers for XS plotting\n",
    "for n in  np.arange(0, len(xs)):\n",
    "    grid_xs.loc[grid_xs.id==n, 'xs_cell']  = np.arange(0, (grid_xs.id==n).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731ffa3-711c-494f-a4b7-3a85c32a67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_grid = pd.read_csv(join(proj_dir, 'mw_hob_cleaned.csv'))\n",
    "rm_grid = gpd.GeoDataFrame(rm_grid, geometry = gpd.points_from_xy(rm_grid.Longitude,rm_grid.Latitude), \n",
    "                           crs='epsg:4326').to_crs(grid_p.crs)\n",
    "# get model layer for heads\n",
    "hob_row = rm_grid.row.values-1\n",
    "hob_col = rm_grid.column.values-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f632e1-9e09-49d8-99ae-d94625587a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# correspond XS to sensors\n",
    "rm_elev = gpd.sjoin_nearest(XSg, rm_grid, how='right',lsuffix='xs', rsuffix='rm')\n",
    "#MW_11, MW_CP1 had doubles with sjoin_nearest due to XS duplicates from Oneto_Denier\n",
    "rm_elev = rm_elev.drop_duplicates(['xs_num','Sensor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d3a2ed-8c21-4cc4-aa0c-e9e546d723e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify segments with 100 m of the lake\n",
    "lak_segs = gpd.sjoin_nearest(XSg.drop(columns=['index_right']), lak_extent, max_distance=100)\n",
    "print('Extent of lake segments:', lak_segs.iseg.min(), '-', lak_segs.iseg.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f876eb-da78-45c9-87b6-d37f951c9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "rm_grid.plot(ax=ax)\n",
    "lak_extent.plot(ax=ax, alpha=0.5)\n",
    "lak_segs.plot(ax=ax)\n",
    "# XSg.plot(ax=ax, markersize=0.5)\n",
    "rm_grid.apply(lambda x: ax.annotate(x.Sensor.replace('MW_',''), xy=x.geometry.coords[0], ha='center', fontsize=6,\n",
    "                                    xytext = (5,10), textcoords='offset pixels',\n",
    "                                    bbox=dict(boxstyle=\"square,pad=0.3\", fc=\"lightgrey\", ec=\"black\", lw=2)\n",
    "                                                        ),axis=1);# ax.annotate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbde512-3b99-469c-9a37-1591d4c2dd24",
   "metadata": {},
   "source": [
    "## Plot select wells near the river\n",
    "\n",
    "MW5, MW14, MW19 on the east  \n",
    "MW2, MW13, MW17 on the west"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5acc019-c8c1-47af-be88-e08c8b3a174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0],color='tab:blue',label='Groundwater'),\n",
    "    Line2D([0], [0], linestyle='--', color='blue', label='Nearest Thalweg'),\n",
    "    # Line2D([0], [0],linestyle='--', color='brown', label='Well Head Reference Point'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279442f9-61d6-4e6b-8aa4-b1d98a71fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just realized that with the sns relplot that the results aren't ordered as expected if specify them\n",
    "mw = gwl_long.Well.unique()\n",
    "mw = ['MW_5','MW_14', 'MW_19', 'MW_2', 'MW_13', 'MW_17']\n",
    "\n",
    "# hob_long, x='dt',y='\n",
    "# g = sns.relplot(gwl_long[gwl_long.Well.isin(mw)], x='dt',y='obs',col='Well', col_wrap=4, kind='line')\n",
    "# axes = g.axes.flatten()\n",
    "ny=3\n",
    "nx=2\n",
    "fig,ax = plt.subplots(nx,ny, sharex=True, sharey=True, figsize=(6.5, 4),dpi=600)\n",
    "\n",
    "for n in np.arange(0,len(axes)):\n",
    "    # ax_n = ax[n%nx, int(n/nx)]\n",
    "    ax_n = ax[int(n/ny), n%ny]\n",
    "    gwl_long[gwl_long.Well==mw[n]].plot(x='dt',y='obs', ax=ax_n, legend=False)\n",
    "    ax_n.set_xlabel(None)\n",
    "    # ax_n.set_title(mw[n])\n",
    "    mw_dat = rm_elev[rm_elev.Sensor ==mw[n]]\n",
    "    # ax_n.axhline(mw_dat['MPE (meters)'].values[0], ls='--', linewidth=1, color='brown')\n",
    "    ax_n.axhline(mw_dat['z_m_min_cln'].values[0]-1, ls='--', linewidth=1, color='blue')\n",
    "fig.supylabel('Elevation (m)')\n",
    "fig.supxlabel('Date')\n",
    "# alternate title scheme\n",
    "gen_reach = ['Upper', 'Middle', 'Lower']\n",
    "gen_side = [ 'East', 'West']\n",
    "for n in np.arange(0,ny):\n",
    "    ax[0,n].set_title(gen_reach[n])\n",
    "for n in np.arange(0,nx):\n",
    "    ax[n,0].set_ylabel(gen_side[n])\n",
    "\n",
    "\n",
    "fig.tight_layout(h_pad=0.1, w_pad =-0.1)\n",
    "\n",
    "fig.legend(handles=legend_elements, loc='outside upper center', ncol=2, bbox_to_anchor=(0.5, 1.05),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9371fd-5010-457f-811e-fab3ef93b3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e8dfea3-672a-441c-8bfc-89bf58c00b03",
   "metadata": {},
   "source": [
    "# SWB review\n",
    "Check to see impact of double counting ETc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def dwr_etc(strt_date, end_date):\n",
    "    nper_tr = (end_date-strt_date).days+1\n",
    "    natETc = np.zeros((nper_tr,nrow_p,ncol_p))\n",
    "    agETc = np.zeros((nper_tr,nrow_p,ncol_p))\n",
    "\n",
    "    per_n = 0 \n",
    "    for y in np.arange(strt_date.year, end_date.year+1):\n",
    "        # set start and end date for range for the year to be iterated over\n",
    "        yr_strt = pd.to_datetime(str(y)+'-01-01')\n",
    "        yr_end = pd.to_datetime(str(y)+'-12-31')\n",
    "        # get the length of the date range needed for that year\n",
    "        yearlen = len(pd.date_range(yr_strt, yr_end))\n",
    "        if yr_strt < strt_date:\n",
    "            yr_strt = strt_date\n",
    "        if yr_end > end_date:\n",
    "            yr_end = end_date\n",
    "        yr_len = len(pd.date_range(yr_strt, yr_end))\n",
    "        # load hdf5 files\n",
    "        f_irr = h5py.File(join(uzf_dir, \"dwr_ETc/irrigated_\"+str(y)+\".hdf5\"), \"r\")\n",
    "        agETc[per_n:per_n+yr_len,:,:] = f_irr['array'][str(y)][:][yr_strt.dayofyear-1:yr_end.dayofyear,:,:]\n",
    "        f_irr.close()\n",
    "        f_nat = h5py.File(join(uzf_dir, \"dwr_ETc/native_\"+str(y)+\".hdf5\"), \"r\")\n",
    "        natETc[per_n:per_n+yr_len,:,:] = f_nat['array'][str(y)][:][yr_strt.dayofyear-1:yr_end.dayofyear,:,:]\n",
    "        f_nat.close()\n",
    "        per_n += yr_len\n",
    "    # make sure the return value is separate from the loop\n",
    "    return(agETc, natETc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad3ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agETc, natETc = dwr_etc(strt_date, end_date)\n",
    "# net ETc should be ETc from ag and native plants joined\n",
    "ETc = agETc + natETc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1922f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nper_tr = (end_date-strt_date).days+1\n",
    "# subset data to local model\n",
    "et_local = np.zeros((nper_tr, nrow, ncol))\n",
    "et_local[:, grid_match.row-1, grid_match.column-1] = ETc[:,grid_match.p_row-1, grid_match.p_column-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb18a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "uzf_dir = join(gwfm_dir, 'UZF_data')\n",
    "gde_dir = join(uzf_dir,'shp_GDE_TFT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee650d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDE_cell = gpd.read_file(join(gde_dir,'Oneto_Denier','GDE_cell.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a062084",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_native = gpd.read_file(join(uzf_dir, 'county_landuse', 'domain_native_lu_2018.shp'))\n",
    "lu_native = gpd.overlay(lu_native, m_domain)\n",
    "# simplify columns\n",
    "lu_native = lu_native[['name','p_row','p_column','geometry']]\n",
    "\n",
    "# join polygon to grid and keep cells with more than 0.5 in grid\n",
    "nat_grid = gpd.overlay(lu_native.to_crs(grid_p.crs), grid_p)\n",
    "nat_grid = nat_grid[nat_grid.geometry.area > delr*delc*0.5]\n",
    "# default rooting depth as 4m for native vegetation\n",
    "nat_grid['rtg_dp'] = 2\n",
    "# riparian vegation gets deeper roots\n",
    "nat_grid.loc[nat_grid.name=='Native riparian vegetation', 'rtg_dp'] = 3\n",
    "nat_grid = nat_grid.drop(columns=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f27cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the native land use map to this really helps fill it in \n",
    "GDE_all = pd.concat((GDE_cell, nat_grid)).dissolve(['row','column'], aggfunc='mean').reset_index()\n",
    "GDE_all.plot('rtg_dp', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9351228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rooting depth to array format for modflow input\n",
    "# ext_dp = np.full((nrow,ncol),2)\n",
    "# ext_dp[(GDE_cell.row-1).astype(int), (GDE_cell.column-1).astype(int)] = GDE_cell.rtg_dp\n",
    "\n",
    "# convert rooting depth to array format for modflow input, hydrographs in wells show drawdown to about 10 m\n",
    "# below ground so should use 10 m for all gde\n",
    "ext_dp = np.full((nrow,ncol),2)\n",
    "# ext_dp[(GDE_cell.row-1).astype(int), (GDE_cell.column-1).astype(int)] = 10\n",
    "# ext_dp[(GDE_all.row-1).astype(int), (GDE_all.column-1).astype(int)] = 10\n",
    "ext_dp[(GDE_all.row-1).astype(int), (GDE_all.column-1).astype(int)] = GDE_all.rtg_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c206ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_perc(strt_date, end_date):\n",
    "    nper_tr = (end_date-strt_date).days+1\n",
    "    # years and array index \n",
    "    years = pd.date_range(strt_date,end_date,freq='AS-Oct')\n",
    "    yr_ind = (years-strt_date).days\n",
    "    perc = np.zeros((nper_tr, nrow_p,ncol_p))\n",
    "    # need separte hdf5 for each year because total is 300MB\n",
    "    for n in np.arange(0,len(yr_ind)-1):\n",
    "    #     arr = pc[yr_ind[n]:yr_ind[n+1]]\n",
    "        fn = join(uzf_dir, 'basic_soil_budget',\"percolation_WY\"+str(years[n].year+1)+\".hdf5\")\n",
    "        f = h5py.File(fn, \"r\")\n",
    "        arr = f['array']['WY'][:]\n",
    "        perc[yr_ind[n]:yr_ind[n+1]] = arr\n",
    "    #     arr_to_h5(arr, fn)\n",
    "        f.close()\n",
    "    return(perc)\n",
    "\n",
    "finf = load_perc(strt_date, end_date)\n",
    "# ss_finf = load_perc(ss_strt, strt_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data to local model\n",
    "finf_local = np.zeros((nper_tr, nrow, ncol))\n",
    "finf_local[:, grid_match.row-1, grid_match.column-1] = finf[:,grid_match.p_row-1, grid_match.p_column-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db54473",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Potential ETo spatial interpolation from CIMIS\n",
    "fn = glob.glob(join(uzf_dir,'CIMIS','Cosumnes_dailyET_precip*.csv'))\n",
    "daily_data = pd.DataFrame()\n",
    "for file in fn:\n",
    "    new_data = pd.read_csv(file, index_col = ['Date'], parse_dates = True)\n",
    "    daily_data = pd.concat((daily_data, new_data))\n",
    "# units of mm\n",
    "data_in = daily_data[daily_data['Stn Name']=='Fair Oaks']\n",
    "# clean up data so columns are by location, units of Precip are in mm\n",
    "rain_in = data_in.pivot_table(index = 'Date', columns = 'Stn Name', values = 'Precip (mm)')\n",
    "rain_m = rain_in/1000\n",
    "\n",
    "# create array for every period of rainfall\n",
    "rain_df = rain_m[strt_date:end_date].resample('D').interpolate('zero')['Fair Oaks']\n",
    "rain = np.repeat(np.repeat(np.reshape(rain_df.values, (rain_df.shape[0],1,1)), nrow, axis=1),ncol, axis=2)\n",
    "\n",
    "# rain_df = rain_m[ss_strt:strt_date].resample('D').interpolate('zero')['Fair Oaks']\n",
    "# ss_rain = np.repeat(np.repeat(np.reshape(rain_df.values, (rain_df.shape[0],1,1)), nrow, axis=1),ncol, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483fc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(ext_dp)\n",
    "finf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd364cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "finf_gde = finf_local[:,ext_dp>2].mean(axis=1)\n",
    "rain_gde = rain[:,ext_dp>2].mean(axis=1)\n",
    "\n",
    "plt.plot(finf_gde, label='Percolation')\n",
    "plt.plot(rain_gde, alpha=0.5, label='Rain')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ffde82",
   "metadata": {},
   "source": [
    "First few observations are that the soil water budget smooths out the rate of percolation is dependent on the saturation and there is a limiting conductivity that slows down seepage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa82a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(finf_gde.cumsum(), label='Percolation')\n",
    "plt.plot(rain_gde.cumsum(), alpha=0.5, label='Rain')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a20ed2",
   "metadata": {},
   "source": [
    "As a designed for in the regional model, the total percolation is about 1/3 of the rainfall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

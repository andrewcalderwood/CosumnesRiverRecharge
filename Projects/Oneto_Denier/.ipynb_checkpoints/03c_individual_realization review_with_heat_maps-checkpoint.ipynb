{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ad636-0b1f-4513-a41c-35645bc411c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "import sys\n",
    "from os.path import basename, dirname, join, exists\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import gmean\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import geopandas as gpd\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "\n",
    "# import flopy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3eeb25-8242-432b-808a-2ab32b43280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel'\n",
    "# dir of stream level data for seepage study\n",
    "proj_dir = gwfm_dir + '/Oneto_Denier/'\n",
    "dat_dir = proj_dir+'Stream_level_data/'\n",
    "\n",
    "sfr_dir = gwfm_dir+'/SFR_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57668e8-c162-42cf-b487-3a02fbbe0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = join(proj_dir, 'output')\n",
    "fig_dir = join(proj_dir, 'figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e444a7f9-c544-4da3-9c59-219aa62720b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path(fxn_dir):\n",
    "    \"\"\" Insert fxn directory into first position on path so local functions supercede the global\"\"\"\n",
    "    if fxn_dir not in sys.path:\n",
    "        sys.path.insert(0, fxn_dir)\n",
    "        \n",
    "add_path(doc_dir+'/GitHub/CosumnesRiverRecharge/python_utilities')\n",
    "\n",
    "from mf_utility import get_dates, get_layer_from_elev, clean_wb\n",
    "from map_cln import gdf_bnds, plt_cln, pnt_2_tup, lab_pnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9765f-c768-46ad-bbb3-a8e8cbdcdae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flopy_dir = doc_dir+'/GitHub/flopy'\n",
    "add_path(flopy_dir)\n",
    "    \n",
    "import flopy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e204a3-4644-4195-bd63-526118cc249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_sfr_df(model_ws, m_name,  drop_iseg):\n",
    "    ## load sfr reach data ##\n",
    "    grid_sfr = pd.read_csv(model_ws+'/grid_sfr.csv')\n",
    "    # remove stream segments for routing purposes only\n",
    "    grid_sfr = grid_sfr[~grid_sfr.iseg.isin(drop_iseg)]\n",
    "    pd_sfr = grid_sfr.set_index(['iseg','ireach'])[['rchlen','strtop', 'facies', 'color']]\n",
    "    pd_sfr['Total distance (m)'] = pd_sfr['rchlen'].cumsum()\n",
    "    num_coarse = int(grid_sfr.facies.isin(['Gravel','Sand']).sum())\n",
    "    \n",
    "    ## load sfr out file ##\n",
    "    sfrout = flopy.utils.SfrFile(join(model_ws, m_name+'.sfr.out'))\n",
    "    sfrdf = sfrout.get_dataframe()\n",
    "    sfrdf = sfrdf.join(dt_ref.set_index('kstpkper'), on='kstpkper').set_index('dt')\n",
    "    # convert from sub-daily to daily using mean, lose kstpkper\n",
    "    sfrdf = sfrdf.groupby('segment').resample('D').mean(numeric_only=True)\n",
    "    sfrdf = sfrdf.reset_index('segment', drop=True)\n",
    "    sfrdf[['row','column']] = sfrdf[['row','column']].astype(int) - 1 # convert to python\n",
    "    \n",
    "    ## join sfr out to reach data ##\n",
    "    sfrdf = sfrdf.join(pd_sfr ,on=['segment','reach'],how='inner',lsuffix='_all')\n",
    "    sfrdf['num_coarse'] = num_coarse\n",
    "    \n",
    "    ## data transformation for easier manipulation ##\n",
    "    sfrdf['month'] = sfrdf.index.month\n",
    "    sfrdf['WY'] = sfrdf.index.year\n",
    "    sfrdf.loc[sfrdf.month>=10, 'WY'] +=1\n",
    "    # create column to calculate days flowing\n",
    "    sfrdf['flowing'] = 1\n",
    "    sfrdf.loc[sfrdf.Qout <= 0, 'flowing'] = 0\n",
    "    \n",
    "    # create different column for stream losing vs gaining seeapge\n",
    "    sfrdf['Qrech'] = np.where(sfrdf.Qaquifer>0, sfrdf.Qaquifer,0)\n",
    "    sfrdf['Qbase'] = np.where(sfrdf.Qaquifer<0, sfrdf.Qaquifer*-1,0 )\n",
    "    # booleans for plotting\n",
    "    sfrdf['gaining'] = (sfrdf.gradient <= 0)\n",
    "    sfrdf['losing'] = (sfrdf.gradient >= 0)\n",
    "    sfrdf['connected'] = (sfrdf.gradient < 1)\n",
    "    return(sfrdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7ff9e-9362-4c27-b280-c8754e838110",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dir = 'F:/WRDAPP'\n",
    "c_dir = 'C:/WRDAPP'\n",
    "if os.path.exists(ext_dir):\n",
    "    loadpth = ext_dir \n",
    "elif os.path.exists(c_dir):\n",
    "    loadpth = c_dir \n",
    "loadpth +=  '/GWFlowModel/Cosumnes/Stream_seepage'\n",
    "\n",
    "upscale = 4 \n",
    "upscale_txt = 'upscale'+str(upscale)+'x_'\n",
    "# model_nam = 'inset_oneto_denier'\n",
    "model_nam = 'oneto_denier_'+upscale_txt+'2014_2018'\n",
    "\n",
    "base_model_ws = join(loadpth,model_nam)\n",
    "\n",
    "# all_model_ws = join(loadpth, 'parallel_oneto_denier')\n",
    "all_model_ws = join(loadpth, 'parallel_'+model_nam)\n",
    "\n",
    "# may want to skip loading rch, evt and wel which take up a lot of memory with stress period data\n",
    "load_only = ['DIS','UPW','SFR','OC']\n",
    "m = flopy.modflow.Modflow.load('MF.nam', model_ws= base_model_ws, \n",
    "                                exe_name='mf-owhm.exe', version='mfnwt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523db979-4813-475e-98ae-5a1084d3726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "strt_date, end_date, dt_ref = get_dates(m.dis, ref='strt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a16bd-e2cf-4515-ae48-38a5901e8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write modelgrid to get updated row and col numbers specific to the child grid\n",
    "grid_dir = join(gwfm_dir, 'DIS_data/streambed_seepage/grid')\n",
    "grid_fn = join(grid_dir, 'inset_oneto_denier','rm_only_grid.shp')\n",
    "\n",
    "# m.modelgrid.write_shapefile(grid_fn)\n",
    "grid_p = gpd.read_file(grid_fn)\n",
    "grid_p.crs = 'epsg:32610'\n",
    "# elevation to grid for reference to land surface\n",
    "dem_data = np.loadtxt(join(proj_dir, 'GIS','local_subset_dem_52_9_200m_mean.tsv'))\n",
    "grid_p['dem_elev'] = dem_data[grid_p.row-1, grid_p.column-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8a3d10-51a0-49b6-ad2c-da2540cffc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_facies_all = pd.read_hdf(join(out_dir, 'sfrdf_facies_sum.hdf5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83178008-8089-4836-a057-eb4c8fd97cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_last_all = pd.read_hdf(join(out_dir, 'sfrdf_last_seg.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af254fe2-063d-4c61-902e-5c7cf14239b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "XSg = pd.read_csv(join(base_model_ws,'04_XSg_filled.csv'))\n",
    "XSg = gpd.GeoDataFrame(XSg, geometry = gpd.points_from_xy(XSg.Easting, XSg.Northing), crs='epsg:32610')\n",
    "\n",
    "drop_iseg = XSg[~XSg['Logger Location'].isna()].iseg.values\n",
    "# overwrite SFR segment/reach input relevant to seepage\n",
    "# sensor_dict = pd.read_csv(join(model_ws, 'sensor_xs_dict.csv'), index_col=0)\n",
    "# XS_params = sensor_dict.join(params.set_index('Sensor'), on='Sensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deabab9-a55b-4a4d-a501-bb549718ba5e",
   "metadata": {},
   "source": [
    "Graham suggested we individually disect some of these results to better understand the impact of outcropping HCPs. A good presentation would be picking a realization that has low, middle, or high streamflow or by looking at the number of coarse segments since that is what is used as an independent variable in the correlation statistics. From there we can investigate the spatial aspects in some ways. Filter by looking at overall average streamflow at the outlet.\n",
    "\n",
    "- look at location of coarse segments vs where baseflow/recharge happen.\n",
    "- plot XS of channel to show heads in aquifer and stream and perhaps fluctuate over time to show how gravels change conditions\n",
    "\n",
    "also looking at the best fit realization to show what reality is then diving into these other realizations to show how differences in spatial distribution can significantly alter stream function. The baseflow below here is a great example of how excess gravel scattered in the channel greatly increases connectivity and baseflow. We should demonstrate as well how this then plays into the timing and duration of in-stream flows to support the ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd82171f-383d-4fdf-9b2f-8c8f050a1245",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_done = pd.read_csv(join(out_dir, 'hob_fit_stats.csv'),index_col=0)\n",
    "top_rmse = stats_done[stats_done.RMSE<=stats_done.RMSE.quantile(0.03)]\n",
    "top_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af7d19-6f2a-4da4-a5aa-441662791c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_out = pd.read_csv(join(proj_dir, 'coarse_reference.csv'), index_col=0)\n",
    "ref_out = pd.read_csv(join(proj_dir, 'num_sfr_coarse.csv'), index_col=0)\n",
    "ref_out=ref_out.rename(columns={'num_coarse':'num_sfr'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61f9a5-70f2-43c3-8dfd-482d404634ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_last_mean = sfr_last_all.groupby('realization').mean(numeric_only=True)['Qout']\n",
    "# realizations to review\n",
    "def per_idx(sfr_last_mean, per):\n",
    "    idx = sfr_last_mean[sfr_last_mean.isin(np.percentile(sfr_last_mean, per, method='nearest'))].sort_values().index.values\n",
    "    return idx\n",
    "quants = [5, 25, 50, 75, 95]\n",
    "# categorize by streamflow\n",
    "r_review = per_idx(sfr_last_mean, quants)\n",
    "\n",
    "# categorize by the number of coarse segments\n",
    "r_review = ref_out[ref_out.num_sfr.isin(np.percentile(ref_out.num_sfr, quants, method='nearest'))]\n",
    "r_review = r_review.drop_duplicates('num_sfr').sort_values('num_sfr').index.values\n",
    "\n",
    "# consider the best fit as well\n",
    "r_review = pd.DataFrame(np.append(r_review, top_rmse.index.values), columns=['realization'])\n",
    "r_review['variable'] = np.append(['quant']*len(quants), ['fit']*len(top_rmse))\n",
    "r_review['value'] = np.append(quants, top_rmse.RMSE).round(4)\n",
    "r_review['num_coarse'] = ref_out.loc[r_review.realization, 'num_sfr'].values\n",
    "# r_review\n",
    "# coarse_ref.loc[r_review], sfr_last_mean[r_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27029d09-cc19-44cf-81ec-94db20d594d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_out.loc[r_review.realization, 'num_lak'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b4b64-8ee8-46f8-b8cc-07188aa55d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr_all = pd.DataFrame()\n",
    "for r in r_review.realization: #100\n",
    "    folder = 'realization'+ str(r).zfill(3)\n",
    "    # update model workspace so outputs to right directory\n",
    "    model_ws = join(all_model_ws, folder)\n",
    "    grid_sfr = pd.read_csv(model_ws+'/grid_sfr.csv',index_col=0)\n",
    "    grid_sfr = grid_sfr.drop(columns=['node','geometry','node.1'])\n",
    "    grid_p_sfr = grid_p.set_index(['row','column']).loc[list(zip(grid_sfr.i+1,grid_sfr.j+1))].reset_index(drop=True)\n",
    "    grid_sfr = pd.concat((grid_p_sfr,grid_sfr),axis=1)\n",
    "    grid_sfr_all = pd.concat((grid_sfr_all, grid_sfr.assign(realization=r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f9179-984c-42bc-ac2f-c413e1b593e1",
   "metadata": {},
   "source": [
    "Looking at the quantiles for the number of coarse stream segments it seems that the best fit realizations span the 5th to 75th percentile which means that we have multiple realizations with different stream segment connections but equal model fit which means that the larger subsurface distribution might account for the fit more than stream segments that outcrop.\n",
    "- the top best fit realizations both had a higher number of coarse lake cells\n",
    "- the other variable to plot would be the number of distinct connected bodies that outcrop or that are in the domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9318acd-c639-4dc7-856e-a9cf4ee02d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_review = r_review[r_review.variable=='quant']\n",
    "fig,ax = plt.subplots(1, len(q_review), sharex=True, sharey=True, figsize=(12, 6.5))\n",
    "for nr, r in enumerate(q_review.realization):\n",
    "    grid_sfr_all[grid_sfr_all.realization==r].plot('facies', ax=ax[nr], legend=True, legend_kwds={'loc':'upper left'})\n",
    "    ax[nr].set_title(str(r)+' - '+str(q_review.value.iloc[nr])+'\\nNo. Coarse:'+str(q_review.num_coarse.iloc[nr]))\n",
    "# grid_sfr_all[grid_sfr_all.realization==r].plot('facies', legend=True, ax=ax[-1])\n",
    "\n",
    "q_review = r_review[r_review.variable=='fit']\n",
    "fig,ax = plt.subplots(1, len(q_review), sharex=True, sharey=True, figsize=(12, 6.5))\n",
    "for nr, r in enumerate(q_review.realization):\n",
    "    grid_sfr_all[grid_sfr_all.realization==r].plot('facies', ax=ax[nr], legend=True, legend_kwds={'loc':'upper left'})\n",
    "    ax[nr].set_title(str(r)+' - '+str(q_review.value.iloc[nr])+'\\nNo. Coarse:'+str(q_review.num_coarse.iloc[nr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1213013-899d-4be0-831e-a54429550f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# grid_sfr_all[grid_sfr_all.realization==11]\n",
    "# m.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92934ae7-7761-44c7-bbad-84d7e24b46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=11\n",
    "folder = 'realization'+ str(r).zfill(3)\n",
    "# update model workspace so outputs to right directory\n",
    "model_ws = join(all_model_ws, folder)\n",
    "sfrdf =  clean_sfr_df(model_ws, m.name, drop_iseg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb34ff-5017-41f1-ba8e-facbeb176839",
   "metadata": {},
   "source": [
    "The baseflow is too inconsistent to show as a time series since it is dominantly a 0 value. The seepage heat map is able to show how between realizations the days with 0 seepage expands across segments and time with more coarse segments generally.  \n",
    "The streamflow values tend to be large such that you don't see much variability in the streamflow across segments unless the segment goes dry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ac2bf-83a5-43c0-b89f-030b22b4f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrdf_all = pd.DataFrame()\n",
    "q_review = r_review[r_review.variable=='quant']\n",
    "# q_review = r_review[r_review.variable=='fit']\n",
    "for nr, r in enumerate(q_review.realization):\n",
    "    folder = 'realization'+ str(r).zfill(3)\n",
    "    # update model workspace so outputs to right directory\n",
    "    model_ws = join(all_model_ws, folder)\n",
    "    sfrdf =  clean_sfr_df(model_ws, m.name, drop_iseg)\n",
    "    sfrdf_all = pd.concat((sfrdf_all, sfrdf.assign(realization=r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a0e43a-d118-46c6-a946-80bd0743b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_segs = sfrdf.segment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0cf206-4860-43fa-99a3-28a7704aab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude(x):\n",
    "    return int(np.log10(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf55b2-859b-4d7c-a66e-f52f912cc2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_map(sfrdf_all, variable, var_name, q_review):\n",
    "    fig,ax = plt.subplots(len(variable)+1, len(q_review), figsize=(12, 8), \n",
    "                          gridspec_kw={'height_ratios':(1,1,0.1)},\n",
    "                          sharex='col', sharey='row',  dpi=300)\n",
    "    for nv, v in enumerate(variable):\n",
    "        for nr, r in enumerate(q_review.realization):\n",
    "            sfrdf = sfrdf_all[sfrdf_all.realization==r]\n",
    "            plt_arr = sfrdf.pivot(columns='segment', values=v).values\n",
    "            vmax = 10**(1+magnitude(sfrdf_all[v].max()))\n",
    "            vmin = np.max((sfrdf_all[v].min(), 1E-2))\n",
    "            plt_arr[plt_arr==0] = vmin\n",
    "            im = ax[nv, nr].imshow(plt_arr,  aspect=1/10,\n",
    "                       norm = mpl.colors.LogNorm(vmin=vmin, vmax=vmax)\n",
    "                      )\n",
    "    # for nr, r in enumerate(q_review.realization):\n",
    "    #     # ax[0, nr].set_title(str(r)+' - '+str(q_review.value.iloc[nr])+'\\nNo. Coarse:'+str(q_review.num_coarse.iloc[nr]))\n",
    "    #     ax[0, nr].set_title('No. Coarse:'+str(q_review.num_coarse.iloc[nr]))\n",
    "        \n",
    "    fig.tight_layout(h_pad=-0.1, w_pad=0.5);\n",
    "    for nv, v in enumerate(var_name):\n",
    "        cbar_ax=ax[nv].ravel().tolist()\n",
    "        fig.colorbar(im, ax=cbar_ax, orientation='vertical', label=v+' ($m^3/day$)', shrink=0.5, location='right')\n",
    "        ax[nv,0].set_ylabel('Days from start')\n",
    "        # plt.colorbar()\n",
    "        # plt.show()\n",
    "    ax[-1,0].set_ylabel(' ') # set blank ylabel to get proper spacing\n",
    "    ## plot VKA for streambed  \n",
    "    vmin = sfr_hk_plt.strhc1.min()\n",
    "    vmax = sfr_hk_plt.strhc1.max()\n",
    "    for nr, r in enumerate(q_review.realization):\n",
    "        ax_n = ax[-1, nr]\n",
    "        vka_line = np.repeat(np.reshape(sfr_hk_plt[sfr_hk_plt.realization==r].strhc1.values, (1,-1)), 1, axis=0)\n",
    "        im = ax[-1, nr].imshow(vka_line,  norm = mpl.colors.LogNorm(vmin=vmin, vmax=vmax), aspect='auto') #aspect=10,\n",
    "        # im = ax[-1, nr].imshow(np.reshape(sfr_hk_plt[sfr_hk_plt.realization==r].strhc1.values, (1,-1)), aspect=10, norm = mpl.colors.LogNorm(vmin=vmin, vmax=vmax))\n",
    "        # plt.xticks([]);\n",
    "        ax_n.set_ylabel('');\n",
    "        ax_n.set_yticks([]);\n",
    "        ax_n.set_xticks(ticks = np.arange(0, len(plt_segs),10), labels=np.arange(0, len(plt_segs),10), rotation=90)\n",
    "    cbar_ax=ax[-1].ravel().tolist()\n",
    "    fig.colorbar(im, ax=cbar_ax, orientation='vertical', label='VKA\\n($m/day$)', shrink=1.5, location='right')    \n",
    "    # ax[0].set_ylabel('Days from Start')\n",
    "    # fig.supylabel('Days from Start');\n",
    "    # fig.supxlabel('Segment');\n",
    "    ax[-1,2].set_xlabel('Segment');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63dd81-c8e7-4672-8829-e74aa81d99e2",
   "metadata": {},
   "source": [
    "Note the lake is fed at segment 31/32 and returns flow at segment 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b430f20-1ae7-42c3-8158-f9f498450f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of plotting just the VKA at the streambed we could plot the 2D slice? Problem is that this can infer that 2D connectivity\n",
    "# shows 3D while at 1D we must rely on 3D totally?? overhtinking it? Just try 2D and see\n",
    "sfr_hk_plt = grid_sfr_all[~grid_sfr_all.iseg.isin(drop_iseg)]\n",
    "fig,ax = plt.subplots(1, len(q_review), figsize=(12, 1), sharex=True, sharey=True, layout='constrained', dpi=300)\n",
    "vmin = sfr_hk_plt.strhc1.min()\n",
    "vmax = sfr_hk_plt.strhc1.max()\n",
    "for nr, r in enumerate(q_review.realization):\n",
    "    vka_line = np.repeat(np.reshape(sfr_hk_plt[sfr_hk_plt.realization==r].strhc1.values, (1,-1)), 1, axis=0)\n",
    "    im = ax[nr].imshow(vka_line,  norm = mpl.colors.LogNorm(vmin=vmin, vmax=vmax), aspect='auto') #aspect=10,\n",
    "    # plt.xticks([]);\n",
    "    plt.yticks([]);\n",
    "    ax[nr].set_xticks(ticks = np.arange(0, len(plt_segs),10), labels=np.arange(0, len(plt_segs),10), rotation=90)\n",
    "\n",
    "cbar_ax=ax.ravel().tolist()\n",
    "fig.colorbar(im, ax=cbar_ax, orientation='vertical', label='VKA\\n($m/day$)', shrink=1, location='right')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c719a836-9db1-4951-8b06-3b8839c2c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vka(r, ax, sfr_nodata):\n",
    "    folder = 'realization'+ str(r).zfill(3)\n",
    "    # update model workspace so outputs to right directory\n",
    "    model_ws = join(all_model_ws, folder)\n",
    "    # m.model_ws = model_ws\n",
    "    upw_r = flopy.modflow.ModflowUpw.load(model_ws+'/MF.upw', model=m)\n",
    "    sfr_hk = upw_r.vka.array[:k_max][:, sfr_rows, sfr_cols]\n",
    "    sfr_hk = np.ma.masked_where(sfr_nodata, sfr_hk)\n",
    "    im = ax.imshow(sfr_hk, norm = mpl.colors.LogNorm(vmin=vmin, vmax=vmax), aspect='auto')\n",
    "    # plt.xticks([]);\n",
    "    ax.set_yticks(ticks = np.arange(1,k_max,5), labels=m.dis.botm.array[:,0,0][:-1:5]);\n",
    "    ax.set_xticks(ticks = np.arange(0, len(plt_segs),10), labels=np.arange(0, len(plt_segs),10), rotation=90)\n",
    "    return sfr_hk, im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad8b0d-b7a0-4501-a716-901640a70256",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_seg = sfr_hk_plt.drop_duplicates('node')\n",
    "sfr_rows = sfr_seg.i.values\n",
    "sfr_cols = sfr_seg.j.values\n",
    "sfr_lays = sfr_seg.k.values\n",
    "fig,ax = plt.subplots(1, len(q_review), figsize=(12, 1), sharex=True, sharey=True, layout='constrained', dpi=300)\n",
    "\n",
    "k_max = int(sfr_hk_plt.k.max())\n",
    "k_max = m.dis.nlay-1\n",
    "\n",
    "# define by active cells\n",
    "sfr_ibound = ~m.bas6.ibound.array[:-1, sfr_rows, sfr_cols].astype(bool)\n",
    "# identify where data should be removed becaues it's above land\n",
    "sfr_nodata = np.zeros((k_max, len(sfr_lays)), dtype=bool)\n",
    "for n in np.arange(0,len(sfr_lays)):    \n",
    "    sfr_nodata[:sfr_lays[n], n] = True\n",
    "\n",
    "# plot only data below ground\n",
    "for nr, r in enumerate(q_review.realization):\n",
    "    sfr_hk, im = plot_vka(r, ax[nr], sfr_nodata)\n",
    "\n",
    "\n",
    "fig.supylabel('Layer')\n",
    "cbar_ax=ax.ravel().tolist()\n",
    "fig.colorbar(im, ax=cbar_ax, orientation='vertical', label='VKA\\n($m/day$)', shrink=1, location='right')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e58b8e-cfb4-40a2-ae47-5955cbf3fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map(sfrdf_all, ['Qrech', 'Qbase'], ['Seepage', 'Baseflow'], q_review)\n",
    "plt.savefig(join(fig_dir, 'heat_map_seepage.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e70587-a0e4-4b30-95a9-c5ac1cb20d41",
   "metadata": {},
   "source": [
    "When it comes to seepage the zones of high streambed conductance align with zones of greater seepage. Downstream zones of higher seepage there are more uniform zones of dry channel proceeding downstream because as flow comes into that zone of high seepage it tends to be used up entirely and their is no downstream baseflow in the dry season to improve flow. We find with the realizations with more coarse segments that the area of dry channel tends to extend further upstream and increase the duration of no streamflow. The periods during the wet season that come across as no seepage are segments with baseflow to the stream.  \n",
    "The baseflow predominantly occurs along the reconnected floodplain and upstream with a few pockets of baseflow down stream where there is a pocket of high coarse facies, although the duration of baseflow at these pockets is very intermittent. \n",
    "\n",
    "- these plots are useful in mapping out how spatial heterogeneity plays a role and the number of facies plays a role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b147bb-4aa6-45e8-af12-c9acce97fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat_map(sfrdf_all, ['Qbase'], ['Baseflow'], q_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065aa8c-a0ed-402b-b7fc-5ce6250ef921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat map of flow is pretty consitent across segments event with log scale\n",
    "# heat_map(sfrdf_all, 'Qout', 'Flow', q_review)\n",
    "# sfrdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e68ef-a82f-4027-ad29-bef2870259a6",
   "metadata": {},
   "source": [
    "# Conceptual Framework plots\n",
    "- Ultimately the heads under the stream channel were found to remain relatively consistent because of the constant source of recharge so it is not a helpful indicator. However, the seepage should still be plotted longitudinally with VKA to show that relationship.  \n",
    "- The baseflow on the other hand requires demonstration of the head in the aquifer building up so we should plot the cross-section view to show the floodplain storage and variability among realizatoins and the build up in lower reaches due to coarse facies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43786ec7-968d-4ee1-9653-2bb95e2373a6",
   "metadata": {},
   "source": [
    "## Longitudinal view\n",
    "Heat maps can be confusing to a reader so start by presenting simpler line plots of seepage and baseflow for one realizaton with the groundwater level at key points highlighted (pick the last day of big recharge events or spring recession for 2017 or 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43de80c7-5a28-4fb6-9029-3bd56cff30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_r(r):\n",
    "    folder = 'realization'+ str(r).zfill(3)\n",
    "    # update model workspace so outputs to right directory\n",
    "    model_ws = join(all_model_ws, folder)\n",
    "    # m.model_ws = model_ws\n",
    "    upw_r = flopy.modflow.ModflowUpw.load(model_ws+'/MF.upw', model=m)  \n",
    "    hdobj = flopy.utils.HeadFile(model_ws+'/MF.hds')\n",
    "    return(hdobj, upw_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef5241-3b01-45f9-b68f-c4769da82f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the median coarse for example figures\n",
    "# r = q_review[q_review.value==50].realization.values[0]\n",
    "\n",
    "r = 36 # the best fit realizatoins 36, 47 show baseflow in lower reaches. The lowest quantile (r49) shows it as well\n",
    "\n",
    "folder = 'realization'+ str(r).zfill(3)\n",
    "# update model workspace so outputs to right directory\n",
    "model_ws = join(all_model_ws, folder)\n",
    "sfrdf =  clean_sfr_df(model_ws, m.name, drop_iseg)\n",
    "\n",
    "grid_sfr = grid_sfr_all[grid_sfr_all.realization==r].copy()\n",
    "grid_sfr = grid_sfr[~grid_sfr.iseg.isin(drop_iseg)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b835f740-48dc-4e5c-ba9d-01ba40f00ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdobj = flopy.utils.HeadFile(model_ws+'/MF.hds')\n",
    "hdobj, upw_r = load_r(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc657f-e960-47dd-bfab-19294d2d9c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add color for facies plots\n",
    "gel_color = pd.read_csv(join(gwfm_dir,'UPW_data', 'mf_geology_color_dict.csv'), comment='#')\n",
    "gel_color=gel_color.set_index('geology')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca571bff-b34d-4256-ab2e-26f664fd1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr['vka'] = upw_r.vka.array[grid_sfr.k, grid_sfr.i, grid_sfr.j]\n",
    "grid_sfr[grid_sfr.iseg.isin([1,60,91, 25])]\n",
    "ax=grid_sfr.plot(x='iseg',y='vka', kind='line')\n",
    "for f in grid_sfr.facies.unique():\n",
    "    ax.fill_between(grid_sfr.iseg, 0, grid_sfr['vka'].max(), where = grid_sfr.facies==f,\n",
    "                    color=[gel_color.loc[f,'color']], alpha=0.5)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f61a87-4330-403e-b3b5-9c7934fbc09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt_dates = pd.date_range('2018-3-1','2018-6-1')\n",
    "# plt_dates = pd.date_range('2017-1-1','2017-3-1')\n",
    "plt_dates = pd.date_range('2017-1-15','2017-1-17')\n",
    "plt_dates='2017-1-16'\n",
    "\n",
    "plt_dates='2017-9-16'\n",
    "# plt_dates = pd.date_range('2017-9-15','2017-9-17')\n",
    "df_last = sfrdf[sfrdf.segment==sfrdf.segment.max()]\n",
    "# df_last.loc[plt_dates].plot(y='Qout')\n",
    "# plt.plot(df_last.loc[plt_dates].Qout.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09a8e8-353a-48be-9cc8-fc124e950d0f",
   "metadata": {},
   "source": [
    "So far it seems that because the systems is nearly always connected that the groundwater elevations below the thalweg are not very helpful. This means we have to use the GWE at some offset or not use this view for groundwater elevation\n",
    "\n",
    "the gradient we plot doesn't align with the stage so need to plot all GWE to determine if MODFLOW is using a different layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d853423-aa1d-4b56-8aa9-47462b87fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg_idx = list(zip(sfr_lays, sfr_rows, sfr_cols))\n",
    "# extract heads from the SFR layer to 5 below\n",
    "seg_idx = []\n",
    "for n in np.arange(0, len(sfr_lays)):\n",
    "    seg_add = list(zip(np.arange(sfr_lays[n], sfr_lays[n]+5), np.repeat(sfr_rows[n], 5), np.repeat(sfr_cols[n],5)))\n",
    "    seg_idx += seg_add\n",
    "# slow to load\n",
    "# seg_ts = hdobj.get_ts(seg_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db50d4e-b33a-4112-bea7-1f192409d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates to days from start for hdobj time-series\n",
    "plt_days = (plt_dates-strt_date).days.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0085831f-f6d9-454f-b568-22766706e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfrdf[sfrdf.segment==34].loc[plt_dates].plot(y='Qbase')\n",
    "# plt.plot(sfrdf[sfrdf.segment==34].loc[plt_dates].Qbase.values)\n",
    "# sfrdf[sfrdf.segment==67].loc[plt_dates].plot(y='Qbase')\n",
    "out_d = pd.to_datetime('2017-1-16')\n",
    "out_d = pd.to_datetime('2017-6-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2ce766-e696-4672-b36d-b414c1c33356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "profile_legend_elements = [\n",
    "    # Patch(facecolor='tab:blue', alpha=0.5, label='Floodplain'),\n",
    "    Line2D([0], [0],color='tab:blue',label='2017-1-16'),\n",
    "    Line2D([0], [0], color='tab:orange',  linestyle='-', label='2017-9-16'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66b782-3544-4690-8ebf-a0ee348351cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaged across all time we see baseflow only in the floodplain, but within that it is variable\n",
    "# and seeapage shows hotter spots\n",
    "# df_mean = sfrdf.groupby('segment').mean(numeric_only=True).reset_index()\n",
    "fig,ax = plt.subplots(5,1,sharex=True, sharey=False, layout='constrained',\n",
    "                      gridspec_kw={'height_ratios':(3,2,2, 2, 2)}, dpi=300)\n",
    "\n",
    "sfr_hk, im = plot_vka(r, ax[0], sfr_nodata) #sfr_nodata, sfr_ibound \n",
    "ax[0].set_ylabel('Elevation\\n(m AMSL)')\n",
    "grid_sfr.vka.plot(ax=ax[1], color='black')\n",
    "ax[1].set_ylabel('Stream\\nVKA (m/d)')\n",
    "\n",
    "def plt_profile(sfrdf, plt_dates, ax, color):\n",
    "    df_mean = sfrdf.loc[plt_dates].groupby('segment').mean(numeric_only=True).reset_index()\n",
    "    df_mean.plot(y='Qrech', ax=ax[-2], legend=False, color=color)\n",
    "    ax[-2].set_ylabel('Recharge\\n($m^3/day$)')\n",
    "    df_mean.plot(y='Qbase', ax=ax[-1], legend=False, color=color)\n",
    "    ax[-1].set_ylabel('Baseflow\\n($m^3/day$)')\n",
    "    ax[2].axhline(y=0, color='black', alpha=0.5) # show transition from gaining to losing\n",
    "    df_mean.plot(y='gradient', ax=ax[2], legend=False, color=color)\n",
    "    ax[2].set_ylabel('Gradient')\n",
    "\n",
    "plt_profile(sfrdf, '2017-1-16', ax, color='tab:blue')\n",
    "# plt_profile(sfrdf, '2017-3-16', ax)\n",
    "# plt_profile(sfrdf, '2017-5-16', ax)\n",
    "plt_profile(sfrdf, '2017-9-16', ax, color='tab:orange')\n",
    "\n",
    "fig.tight_layout(h_pad=0.1)\n",
    "\n",
    "# fig.legend(handles=profile_legend_elements, loc='outside upper center', ncol = 2)\n",
    "# ax[-2].legend(handles=profile_legend_elements, loc='best', ncol = 2)\n",
    "fig.legend(handles=profile_legend_elements, loc='center', bbox_to_anchor=[0.3, 0.99], ncol=1)\n",
    "# cbar_ax=ax.ravel().tolist()\n",
    "fig.colorbar(im, orientation = 'horizontal', location='top', label='VKA ($m/day$)', shrink=0.3)\n",
    "# fig.colorbar(im, ax=cbar_ax, orientation='vertical', label='VKA\\n($m/day$)', shrink=1, location='right')    \n",
    "\n",
    "\n",
    "# sfrdf.loc[out_d].plot(x='segment',y='gradient')\n",
    "# for n in np.arange(1,3):\n",
    "#     ax[n].set_yscale('log')\n",
    "# fig.tight_layout(h_pad=0.1)\n",
    "\n",
    "plt.savefig(join(fig_dir, 'longitudinal_profile_stream_aquifer.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37efee87-aae1-453b-9963-3f79a239c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_df = pd.DataFrame(seg_idx, columns=['k','i','j'])\n",
    "plt_seg = seg_df.groupby(['i','j']).idxmin()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa18bd-ce0f-421f-a1ca-b716ddc46c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns (kij) and rows (dates)\n",
    "d= (out_d-strt_date).days\n",
    "plt_seg_ts = seg_ts[:, plt_seg.k.values+1][d]\n",
    "plt_seg_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9451d1-c3e1-42e9-ae83-477ae0b78626",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = m.dis.top.array[0,0]\n",
    "botm = m.dis.botm.array[:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae3539-9f3c-4ab2-8f6c-56b98d7db364",
   "metadata": {},
   "outputs": [],
   "source": [
    "## after reviewing it doesn't seem worth showing this since the head gradients aren't a clear indicator\n",
    "# rather the seepage with VKA should be enough\n",
    "fig,ax_n = plt.subplots(figsize=(12,12))\n",
    "max_k = 8\n",
    "ax_n.plot(sfr_seg.strtop.values, color='brown', label='Stream Top')\n",
    "\n",
    "ax_n.plot(plt_seg_ts, color='blue', label='GWE')\n",
    "# plot stage\n",
    "ax_n.plot(sfrdf.loc[out_d, 'stage'].values, color='darkgreen', label='Stream Stage')\n",
    "ax_n.plot(sfrdf.loc[out_d, 'depth'].values+sfrdf.loc[out_d, 'strtop'].values, color='pink', label='Stream Stage')\n",
    "\n",
    "ax_n.set_xticks(ticks = np.arange(0,90,10), labels = np.arange(0,9000,1000));\n",
    "ax_n.set_xlabel('Distance downstream (m)')\n",
    "ax_n.set_aspect(10) # which 1 segment = 100 m so it is 1:100)\n",
    "\n",
    "im = ax_n.imshow(sfr_hk[1:max_k], extent = [0, len(sfr_rows), botm[max_k-1], botm[0]], \n",
    "          norm=mpl.colors.LogNorm(vmin=vmin, vmax=vmax), alpha=0.3)\n",
    "# plt.colorbar(im, shrink=0.3)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ef587-b6d2-48a3-97b1-4cce3df269cd",
   "metadata": {},
   "source": [
    "I don't think there is going to be an interesting connection right at the stream channel because it is consistently connected so we need to look at the near bank storage.\n",
    "- seepage plot longitudinally with VKA map while baseflow is going to require a XS or two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25d256-631d-4be0-9086-b8c1543e946f",
   "metadata": {},
   "source": [
    "Changing the plotted dates for averaging from the entire simulation to just spring 2018 didn't change the pattern of results which is good in a way if it means it helps show consistency\n",
    "\n",
    "- the distinction found by Frei of seepage vs perching is less prevalent here because the water table is elevated so that zones where recharge takes place then see slightly reduced seepage. It could be that the 1/10 strhc1 scaling is having an effect as well\n",
    "\n",
    "- plotting the deeper heads (5 layers below) sfr showed the same pattern with heads consistently above the stream bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f59241-72dd-4243-a39d-f4593e2551ac",
   "metadata": {},
   "source": [
    "## Cross-section plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a5e6f-85ee-4e80-8217-b0e32ecfc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakrow, lakcol = np.where(m.lak.lakarr.array[0].mean(axis=0) >0)\n",
    "grid_lak = grid_p.set_index(['row','column']).loc[list(zip(lakrow+1,lakcol+1))].reset_index(drop=True)\n",
    "grid_lak['lake']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f120e6e-3a85-4697-92b8-6b4c8e69bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = gpd.read_file(join(proj_dir, 'GIS', 'plotting_cross_section_lines.shp'))\n",
    "grid_xs = gpd.sjoin(grid_p, xs) # grid cells for each XS\n",
    "\n",
    "grid_xs = grid_xs.join(grid_lak.set_index('node')['lake'], how='left')\n",
    "grid_xs = grid_xs.join(grid_sfr.set_index('node')[['iseg','strtop','facies', 'k']], how='left')\n",
    "\n",
    "# set standard cell numbers for XS plotting\n",
    "for n in  np.arange(0, len(xs)):\n",
    "    xs_n = grid_xs.loc[grid_xs.id==n].copy().reset_index()\n",
    "    sfr_cell = xs_n[~xs_n.strtop.isna()].index[0]\n",
    "    grid_xs.loc[grid_xs.id==n, 'xs_cell']  = np.arange(0, (grid_xs.id==n).sum())\n",
    "    grid_xs.loc[grid_xs.id==n, 'xs_cell']  = np.arange(-sfr_cell, len(xs_n)-sfr_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e59f0-3a6d-45ca-8fa3-15f7e4c2c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_pts = grid_xs[~grid_xs.iseg.isna()].drop_duplicates('id')\n",
    "sfr_iseg = sfr_pts.iseg.astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa1285-1e53-417b-ab1a-da12b0b519d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "map_legend_elements = [\n",
    "    Patch(facecolor='tab:blue', alpha=0.5, label='Floodplain'),\n",
    "    Patch(facecolor='tab:blue', label='Cosumnes River'),\n",
    "    Patch(facecolor='grey', label='Cross-sections'),\n",
    "    # Line2D([0], [0],color='tab:blue',label='Cosumnes River'),\n",
    "    # Line2D([0], [0], marker='.', linestyle='', color='blue', label='Monitoring Well'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f2781-df14-4944-8803-6f03a16654b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plt_xs_map(ax, lab_col = 'iseg'):\n",
    "    grid_lak.plot(ax=ax, alpha=0.5)\n",
    "    grid_sfr.plot(ax=ax)\n",
    "    # grid_xs.plot(ax=ax)\n",
    "    grid_xs.plot(color='gray', ax=ax)\n",
    "    n_add=0\n",
    "    if lab_col=='id':\n",
    "        n_add = 1\n",
    "    sfr_pts.apply(lambda x: ax.annotate(str(int(x[lab_col])+n_add), \n",
    "                                        xy=(x.geometry.centroid.x, x.geometry.centroid.y), ha='right', fontsize=8,\n",
    "                                       bbox=dict(boxstyle=\"square,pad=0.1\", fc=\"lightgrey\", ec=\"black\", lw=0.5)),axis=1);\n",
    "    \n",
    "fig,ax = plt.subplots()\n",
    "plt_xs_map(ax=ax)\n",
    "# plt_cln(ax=ax)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0464eb-20c3-4f2b-bb60-6815e56500aa",
   "metadata": {},
   "source": [
    "It would make sense to have a XS in the middle of the floodplain, at the bottom edge where the gravel patch tends to be in the river and a little further downstream near the outlet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc42019e-a17d-48b7-aa39-7ae2acffdddf",
   "metadata": {},
   "source": [
    "## Deeper geologic review\n",
    "Following the segment facies review, there are geologic features that may be adjacent to the channel but not outcrop that could impact flow but this is more difficult to represent. I think plotting these XS with head values and geologic facies are a good way to dive a little deeper at a 2D level. It would also be worthwhile presenting groundwater contours at key points (flood peak, recession and summer low)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d156a34-1b89-4e1a-8f3c-78cf864a6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898616b-3279-4d5f-95eb-1b6a5df4e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "spd_stp = hdobj.get_kstpkper()\n",
    "times = hdobj.get_times()\n",
    "\n",
    "# get ALL stress periods and time steps list, not just those in the output\n",
    "kstpkper = []\n",
    "for n,stps in enumerate(m.dis.nstp.array):\n",
    "    kstpkper += list(zip(np.arange(0,stps),np.full(stps,n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ee2ae-4349-4e68-b9fd-f59b4ed971a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in xs.id:\n",
    "for n in [2]:\n",
    "    xs_n = grid_xs[grid_xs.id==n]\n",
    "    xs_hk = upw_r.hk.array[:-1, xs_n.row-1, xs_n.column-1]\n",
    "    \n",
    "    sfr_xs_n = sfr_xs[sfr_xs.id==n]\n",
    "    lak_xs_n = lak_xs[lak_xs.id==n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41002893-95a1-43b8-b96e-66f91c711969",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "head = hdobj.get_data(dt_ref[dt_ref.dt=='2017-1-16'].kstpkper.values[0])[:, xs_n.row-1, xs_n.column-1] \n",
    "# head = hdobj.get_data(spd_stp[1200])[:, xs_n.row-1, xs_n.column-1] \n",
    "head = np.ma.masked_where(head==-999.99, head)\n",
    "\n",
    "def plt_xs_spd(head, xs_n, ax):\n",
    "    sfr_xs_n = xs_n[~xs_n.iseg.isna()] \n",
    "    lak_xs_n = xs_n[xs_n.lake==True]\n",
    "    # plot head in sfr layer only\n",
    "    head_sfr = head[sfr_xs_n.k.astype(int).values[0]]\n",
    "    # ax.plot(head_sfr, color='blue', label='Head in SFR layer')\n",
    "    # plot average head as well\n",
    "    head_avg = head[0:10].max(axis=0)\n",
    "    ax.plot(xs_n.xs_cell, head_avg, color='blue', linestyle='--', label='Water Table')\n",
    "    head_avg = head[0:10].mean(axis=0)\n",
    "    ax.plot(xs_n.xs_cell, head_avg, color='blue', linestyle='-.', label='Average Head - Upper')\n",
    "    # head_avg = head[10:-1].mean(axis=0)\n",
    "    # ax.plot(xs_n.xs_cell, head_avg, color='blue', linestyle='-.', label='Average Head - Lower')\n",
    "    head_avg = head[-1]\n",
    "    ax.plot(xs_n.xs_cell, head_avg, color='blue', linestyle=':', label='Head - Deep')\n",
    "\n",
    "    # plot sfr and lak stages\n",
    "    ax.scatter(sfr_xs_n.xs_cell, sfr_xs_n.strtop, zorder= -1, color='tab:blue', label='Stream Top')\n",
    "    ax.scatter(lak_xs_n.xs_cell, lak_xs_n.dem_elev, zorder= -2, color='brown', label='Lake')\n",
    "    ax.plot(xs_n.xs_cell, xs_n.dem_elev, zorder= -3, color='black', label='Land Surface')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c176eb2e-ca4c-4156-9f19-2536ebfa06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='black', label='Land Surface'),\n",
    "    Line2D([0], [0], color='blue', linestyle='--',label='Water Table'),\n",
    "    Line2D([0], [0], color='blue', linestyle='-.', label='Average Head\\n(Layers 1-10)'),\n",
    "    Line2D([0], [0], color='blue', linestyle=':', label='Head - Deep'),\n",
    "    Line2D([0], [0], color='brown', marker='.', linestyle='', label='Floodplain'),\n",
    "    Line2D([0], [0], color='tab:blue',  marker='.', linestyle='', label='Stream top'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505f276-46d4-4176-80a8-a21f86a9bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plt_xs_hk(xs_n, upw_r, ax):\n",
    "    xs_hk = upw_r.hk.array[:-1, xs_n.row-1, xs_n.column-1]\n",
    "    xs_ibound = ~m.bas6.ibound.array[:-1, xs_n.row-1, xs_n.column-1].astype(bool)\n",
    "    xs_hk = np.ma.masked_where(xs_ibound, xs_hk)\n",
    "    im = ax.imshow(xs_hk[1:max_k], extent = [xs_n.xs_cell.min(), xs_n.xs_cell.max(), botm[max_k-1], botm[0]], \n",
    "              norm=mpl.colors.LogNorm(vmin=vmin, vmax=vmax), alpha=0.3)\n",
    "fig, ax = plt.subplots(len(xs.id), figsize=(6.5,6.5), sharex=True, sharey=True, dpi=300)\n",
    "max_k=10\n",
    "\n",
    "for n in xs.id:\n",
    "    xs_n = grid_xs[grid_xs.id==n]\n",
    "    ax[n].annotate(text='('+str(n+1)+')',xy=(0.85,0.85),  xycoords='axes fraction', fontsize=12) # add figure label\n",
    "    plt_xs_hk(xs_n, upw_r, ax[n])\n",
    "    head = hdobj.get_data(spd_stp[1200])[:, xs_n.row-1, xs_n.column-1] \n",
    "    head = np.ma.masked_where(head==-999.99, head)\n",
    "\n",
    "    plt_xs_spd(head, xs_n, ax=ax[n])\n",
    "    ax[n].set_aspect(1)\n",
    "# plt.colorbar(im, shrink=0.3)\n",
    "fig.tight_layout(h_pad=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7970cb97-3c18-4a83-a9a5-283f6eb34927",
   "metadata": {},
   "source": [
    "## Cross-sections across different realizations\n",
    "When comparing across the best fit of realizations there are really not clear differences due to heterogeneity.  \n",
    "With the 5 quantiles you can distinguish a few more changes but nothing that would be immediately obvious like a much higher water table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73320b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_r = r_review[r_review.variable=='quant'].realization\n",
    "fig, ax = plt.subplots(len(xs.id), len(plt_r), figsize=(12,12), sharex=True, sharey=True)\n",
    "\n",
    "    \n",
    "for nr, r in enumerate(plt_r):\n",
    "    hdobj, upw_r = load_r(r)\n",
    "\n",
    "    # head = hdobj.get_data(spd_stp[900])\n",
    "    head = hdobj.get_data(dt_ref[dt_ref.dt=='2017-1-16'].kstpkper.values[0])\n",
    "\n",
    "    head = np.ma.masked_where(head==-999.99, head)\n",
    "    for n in xs.id:\n",
    "        xs_n = grid_xs[grid_xs.id==n]\n",
    "        xs_hd = head[:, xs_n.row-1, xs_n.column-1] \n",
    "        plt_xs_hk(xs_n, upw_r, ax[n,nr])\n",
    "\n",
    "        plt_xs_spd(xs_hd, xs_n, ax=ax[ n, nr ])\n",
    "        \n",
    "fig.tight_layout(h_pad=0.1, w_pad=-0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d69daf9-b82f-4843-8250-9a0ce1f8cee4",
   "metadata": {},
   "source": [
    "The last XS might be one spot where it more obvious that elevations around the stream are mo elevated due to the presence of connected paths. The third XS sort of shows this as well where the two XS with more coarse have a larger distance from the channel with elevated levels on the right because the coarse facies are passing the recharge over than in fines where a steeper gradient must form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d155a8a-2c0c-457b-8538-bd227318998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ax_xs(r, ax, col=''):\n",
    "    hdobj, upw_r = load_r(r)\n",
    "\n",
    "    # head = hdobj.get_data(spd_stp[900])\n",
    "    head = hdobj.get_data(dt_ref[dt_ref.dt=='2017-1-16'].kstpkper.values[0])\n",
    "\n",
    "    head = np.ma.masked_where(head==-999.99, head)\n",
    "    for n in xs.id:\n",
    "        xs_n = grid_xs[grid_xs.id==n]\n",
    "        ax[n].annotate(text='('+col+str(n+1)+')',xy=(0.75,0.85),  xycoords='axes fraction', fontsize=12) # add figure label\n",
    "\n",
    "        xs_hd = head[:, xs_n.row-1, xs_n.column-1] \n",
    "        plt_xs_hk(xs_n, upw_r, ax[n])\n",
    "\n",
    "        plt_xs_spd(xs_hd, xs_n, ax=ax[ n])\n",
    "        \n",
    "# fig.tight_layout(h_pad=0.1, w_pad=-0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba4f97-99a2-4fb3-8d19-25ee0a1da272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xs_plt_labels(ax):\n",
    "    ax[2].set_ylabel('Elevation (m)')\n",
    "    ax[-1].set_xlabel('Distance from channel (m)')\n",
    "    ticks = np.arange(-10,15, 10)\n",
    "    ax[-1].set_xticks(ticks = ticks, labels = ticks*100);\n",
    "    ticks = np.arange(-10,15, 5)\n",
    "    ax[-1].set_xticks(ticks = ticks, minor=True);\n",
    "\n",
    "    ticks = np.arange(-5,15, 5)\n",
    "    ax[-1].set_yticks(ticks = ticks, minor=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd843dc-a858-4add-a724-b4965979210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a06099-c72b-4363-bb37-a7fa5488ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create subfigures to ease plotting/have different style\n",
    "# gridspec inside gridspec\n",
    "fig = plt.figure(layout='constrained', figsize=(6.5, 6.5), dpi=300)\n",
    "subfigs = fig.subfigures(1, 3)\n",
    "\n",
    "r = 10\n",
    "axsLeft = subfigs[0].subplots(6, 1, sharey=True, sharex=True)\n",
    "ax_xs(r, axsLeft, col='A')\n",
    "# subfigs[0].suptitle('Left plots', fontsize='x-large')\n",
    "xs_plt_labels(axsLeft)\n",
    "\n",
    "## map figure in center\n",
    "ax1 = subfigs[1].subplots(1, 1)\n",
    "plt_xs_map(ax=ax1, lab_col='id')\n",
    "# plt_cln(ax=ax)\n",
    "ax1.axis('off')\n",
    "subfigs[1].legend(handles=legend_elements, loc='upper center', ncol = 1)\n",
    "subfigs[1].legend(handles=map_legend_elements, loc='lower center', ncol = 1)\n",
    "\n",
    "r = 12\n",
    "axsRight = subfigs[2].subplots(6, 1, sharey=True, sharex=True)\n",
    "# subfigs[0].set_facecolor('0.75')\n",
    "ax_xs(r, axsRight, col='B')\n",
    "xs_plt_labels(axsRight)\n",
    "\n",
    "\n",
    "plt.savefig(join(fig_dir, 'head_xs_with_map.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e299e11-4e1b-442e-a1ca-0e497a2d8ea3",
   "metadata": {},
   "source": [
    "# Time series at select segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df66fd0-f5ed-418f-a9c8-868363b3b099",
   "metadata": {},
   "source": [
    "The time series plots of stream budget at each XS:\n",
    "- the base only shows for the first XS significantly\n",
    "- the seepage plot shows some differences between realizations for all XS in either timing or shift up/down\n",
    "- the difference in Qout is most noticeable with log scale where we can see the difference in dates where flow goes to near 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e72b91-0a07-4cd1-b6fb-212f7e25073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(len(xs.id), figsize=(6,6), sharex=True, sharey=True)\n",
    "# for n in xs.id:\n",
    "#     xs_n = grid_xs[grid_xs.id==n]\n",
    "#     xs_hk = upw_r.hk.array[:, xs_n.row-1, xs_n.column-1]\n",
    "sfr_idx = list(zip(np.repeat(int(xs_n[~xs_n.k.isna()].k), len(xs_n)), xs_n.row.values-1, xs_n.column.values-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a292e7b-a2bc-4c43-a116-640ea4dd3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert seg_ts here\n",
    "def seg_ts(sfrdf_all, variable):\n",
    "    fig,ax = plt.subplots(len(sfr_iseg), figsize=(10,6), sharex=True, sharey=True)\n",
    "    for ns, s in enumerate(sfr_iseg):\n",
    "        ax_n = ax[ns]\n",
    "        if variable in ['Qout']:\n",
    "            ax_n.set_yscale('log')\n",
    "        ax_n.set_ylabel('SEG:'+str(s))\n",
    "        for r in q_review.realization:\n",
    "            sfrdf = sfrdf_all[sfrdf_all.realization==r]\n",
    "            sfrdf[sfrdf.segment==s].plot(y=variable, ax=ax_n, legend=False)\n",
    "\n",
    "    ax[-1].set_xlabel(None)\n",
    "    fig.supxlabel('Date')\n",
    "    fig.supylabel('Flux ($m^3/d$)')\n",
    "    \n",
    "seg_ts(sfrdf_all, 'Qout')\n",
    "seg_ts(sfrdf_all, 'Qrech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a58073-ac10-4f0d-ad77-47b36614bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 5ish seconds\n",
    "hds_ts = hdobj.get_ts(sfr_idx)\n",
    "hds_ts = np.ma.masked_where(hds_ts==-999.99, hds_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9254fb47-e7bd-467e-a75b-406893d5ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hds_ts[:,1:]);\n",
    "# need to pick out specific dates of interest\n",
    "plt_date = np.array([100, 150, 200, 300, 400, 500, 600, 700, 850, 900, 1000, 1100, 1200, 1300, 1400])\n",
    "for x in plt_date:\n",
    "    plt.axvline(x)\n",
    "    \n",
    "    sfr_xs_n = sfr_xs[sfr_xs.id==n]\n",
    "    lak_xs_n = lak_xs[lak_xs.id==n]\n",
    "plt.show()\n",
    "plt.plot(hds_ts[plt_date,1:].transpose()); # 1400 lines is a lot to visualize, would need to pick specific dates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

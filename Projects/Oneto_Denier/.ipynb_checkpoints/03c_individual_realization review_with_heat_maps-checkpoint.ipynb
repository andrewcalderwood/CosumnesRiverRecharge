{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ad636-0b1f-4513-a41c-35645bc411c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "import sys\n",
    "from os.path import basename, dirname, join, exists\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import gmean\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import geopandas as gpd\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "\n",
    "# import flopy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3eeb25-8242-432b-808a-2ab32b43280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel'\n",
    "# dir of stream level data for seepage study\n",
    "proj_dir = gwfm_dir + '/Oneto_Denier/'\n",
    "dat_dir = proj_dir+'Stream_level_data/'\n",
    "\n",
    "sfr_dir = gwfm_dir+'/SFR_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57668e8-c162-42cf-b487-3a02fbbe0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = join(proj_dir, 'output')\n",
    "fig_dir = join(proj_dir, 'figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e444a7f9-c544-4da3-9c59-219aa62720b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path(fxn_dir):\n",
    "    \"\"\" Insert fxn directory into first position on path so local functions supercede the global\"\"\"\n",
    "    if fxn_dir not in sys.path:\n",
    "        sys.path.insert(0, fxn_dir)\n",
    "        \n",
    "add_path(doc_dir+'/GitHub/CosumnesRiverRecharge/python_utilities')\n",
    "\n",
    "from mf_utility import get_dates, get_layer_from_elev, clean_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e204a3-4644-4195-bd63-526118cc249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_sfr_df(model_ws, m_name,  drop_iseg):\n",
    "    ## load sfr reach data ##\n",
    "    grid_sfr = pd.read_csv(model_ws+'/grid_sfr.csv')\n",
    "    # remove stream segments for routing purposes only\n",
    "    grid_sfr = grid_sfr[~grid_sfr.iseg.isin(drop_iseg)]\n",
    "    pd_sfr = grid_sfr.set_index(['iseg','ireach'])[['rchlen','strtop', 'facies', 'color']]\n",
    "    pd_sfr['Total distance (m)'] = pd_sfr['rchlen'].cumsum()\n",
    "    num_coarse = int(grid_sfr.facies.isin(['Gravel','Sand']).sum())\n",
    "    \n",
    "    ## load sfr out file ##\n",
    "    sfrout = flopy.utils.SfrFile(join(model_ws, m_name+'.sfr.out'))\n",
    "    sfrdf = sfrout.get_dataframe()\n",
    "    sfrdf = sfrdf.join(dt_ref.set_index('kstpkper'), on='kstpkper').set_index('dt')\n",
    "    # convert from sub-daily to daily using mean, lose kstpkper\n",
    "    sfrdf = sfrdf.groupby('segment').resample('D').mean(numeric_only=True)\n",
    "    sfrdf = sfrdf.reset_index('segment', drop=True)\n",
    "    sfrdf[['row','column']] = sfrdf[['row','column']].astype(int) - 1 # convert to python\n",
    "    \n",
    "    ## join sfr out to reach data ##\n",
    "    sfrdf = sfrdf.join(pd_sfr ,on=['segment','reach'],how='inner',lsuffix='_all')\n",
    "    sfrdf['num_coarse'] = num_coarse\n",
    "    \n",
    "    ## data transformation for easier manipulation ##\n",
    "    sfrdf['month'] = sfrdf.index.month\n",
    "    sfrdf['WY'] = sfrdf.index.year\n",
    "    sfrdf.loc[sfrdf.month>=10, 'WY'] +=1\n",
    "    # create column to calculate days flowing\n",
    "    sfrdf['flowing'] = 1\n",
    "    sfrdf.loc[sfrdf.Qout <= 0, 'flowing'] = 0\n",
    "    \n",
    "    # create different column for stream losing vs gaining seeapge\n",
    "    sfrdf['Qrech'] = np.where(sfrdf.Qaquifer>0, sfrdf.Qaquifer,0)\n",
    "    sfrdf['Qbase'] = np.where(sfrdf.Qaquifer<0, sfrdf.Qaquifer*-1,0 )\n",
    "    # booleans for plotting\n",
    "    sfrdf['gaining'] = (sfrdf.gradient <= 0)\n",
    "    sfrdf['losing'] = (sfrdf.gradient >= 0)\n",
    "    sfrdf['connected'] = (sfrdf.gradient < 1)\n",
    "    return(sfrdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9765f-c768-46ad-bbb3-a8e8cbdcdae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flopy_dir = doc_dir+'/GitHub/flopy'\n",
    "add_path(flopy_dir)\n",
    "    \n",
    "import flopy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7ff9e-9362-4c27-b280-c8754e838110",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dir = 'F:/WRDAPP'\n",
    "c_dir = 'C:/WRDAPP'\n",
    "if os.path.exists(ext_dir):\n",
    "    loadpth = ext_dir \n",
    "elif os.path.exists(c_dir):\n",
    "    loadpth = c_dir \n",
    "loadpth +=  '/GWFlowModel/Cosumnes/Stream_seepage'\n",
    "\n",
    "upscale = 4 \n",
    "upscale_txt = 'upscale'+str(upscale)+'x_'\n",
    "# model_nam = 'inset_oneto_denier'\n",
    "model_nam = 'oneto_denier_'+upscale_txt+'2014_2018'\n",
    "\n",
    "base_model_ws = join(loadpth,model_nam)\n",
    "\n",
    "# all_model_ws = join(loadpth, 'parallel_oneto_denier')\n",
    "all_model_ws = join(loadpth, 'parallel_'+model_nam)\n",
    "\n",
    "# may want to skip loading rch, evt and wel which take up a lot of memory with stress period data\n",
    "load_only = ['DIS','UPW','SFR','OC']\n",
    "m = flopy.modflow.Modflow.load('MF.nam', model_ws= base_model_ws, \n",
    "                                exe_name='mf-owhm.exe', version='mfnwt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a16bd-e2cf-4515-ae48-38a5901e8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write modelgrid to get updated row and col numbers specific to the child grid\n",
    "grid_dir = join(gwfm_dir, 'DIS_data/streambed_seepage/grid')\n",
    "grid_fn = join(grid_dir, 'inset_oneto_denier','rm_only_grid.shp')\n",
    "\n",
    "# m.modelgrid.write_shapefile(grid_fn)\n",
    "grid_p = gpd.read_file(grid_fn)\n",
    "grid_p.crs = 'epsg:32610'\n",
    "# elevation to grid for reference to land surface\n",
    "dem_data = np.loadtxt(join(proj_dir, 'GIS','local_subset_dem_52_9_200m_mean.tsv'))\n",
    "grid_p['dem_elev'] = dem_data[grid_p.row-1, grid_p.column-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8a3d10-51a0-49b6-ad2c-da2540cffc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_facies_all = pd.read_hdf(join(out_dir, 'sfrdf_facies_sum.hdf5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83178008-8089-4836-a057-eb4c8fd97cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_last_all = pd.read_hdf(join(out_dir, 'sfrdf_last_seg.hdf5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deabab9-a55b-4a4d-a501-bb549718ba5e",
   "metadata": {},
   "source": [
    "Graham suggested we individually disect some of these results to better understand the impact of outcropping HCPs. A good presentation would be picking a realization that has low, middle, or high streamflow or by looking at the number of coarse segments since that is what is used as an independent variable in the correlation statistics. From there we can investigate the spatial aspects in some ways. Filter by looking at overall average streamflow at the outlet.\n",
    "\n",
    "- look at location of coarse segments vs where baseflow/recharge happen.\n",
    "- plot XS of channel to show heads in aquifer and stream and perhaps fluctuate over time to show how gravels change conditions\n",
    "\n",
    "also looking at the best fit realization to show what reality is then diving into these other realizations to show how differences in spatial distribution can significantly alter stream function. The baseflow below here is a great example of how excess gravel scattered in the channel greatly increases connectivity and baseflow. We should demonstrate as well how this then plays into the timing and duration of in-stream flows to support the ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd82171f-383d-4fdf-9b2f-8c8f050a1245",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_done = pd.read_csv(join(out_dir, 'hob_fit_stats.csv'),index_col=0)\n",
    "top_rmse = stats_done[stats_done.RMSE<=stats_done.RMSE.quantile(0.03)]\n",
    "top_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af7d19-6f2a-4da4-a5aa-441662791c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_out = pd.read_csv(join(proj_dir, 'coarse_reference.csv'), index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61f9a5-70f2-43c3-8dfd-482d404634ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_last_mean = sfr_last_all.groupby('realization').mean(numeric_only=True)['Qout']\n",
    "# realizations to review\n",
    "def per_idx(sfr_last_mean, per):\n",
    "    idx = sfr_last_mean[sfr_last_mean.isin(np.percentile(sfr_last_mean, per, method='nearest'))].sort_values().index.values\n",
    "    return idx\n",
    "quants = [5, 25, 50, 75, 95]\n",
    "# categorize by streamflow\n",
    "r_review = per_idx(sfr_last_mean, quants)\n",
    "\n",
    "# categorize by the number of coarse segments\n",
    "r_review = ref_out[ref_out.num_sfr.isin(np.percentile(ref_out.num_sfr, quants, method='nearest'))]\n",
    "r_review = r_review.drop_duplicates('num_sfr').sort_values('num_sfr').index.values\n",
    "\n",
    "# consider the best fit as well\n",
    "r_review = pd.DataFrame(np.append(r_review, top_rmse.index.values), columns=['realization'])\n",
    "r_review['variable'] = np.append(['quant']*len(quants), ['fit']*len(top_rmse))\n",
    "r_review['value'] = np.append(quants, top_rmse.RMSE).round(4)\n",
    "r_review['num_coarse'] = ref_out.loc[r_review.realization, 'num_sfr'].values\n",
    "# r_review\n",
    "# coarse_ref.loc[r_review], sfr_last_mean[r_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27029d09-cc19-44cf-81ec-94db20d594d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_out.loc[r_review.realization, 'num_lak'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b4b64-8ee8-46f8-b8cc-07188aa55d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr_all = pd.DataFrame()\n",
    "for r in r_review.realization: #100\n",
    "    folder = 'realization'+ str(r).zfill(3)\n",
    "    # update model workspace so outputs to right directory\n",
    "    model_ws = join(all_model_ws, folder)\n",
    "    grid_sfr = pd.read_csv(model_ws+'/grid_sfr.csv',index_col=0)\n",
    "    grid_sfr = grid_sfr.drop(columns=['node','geometry','node.1'])\n",
    "    grid_p_sfr = grid_p.set_index(['row','column']).loc[list(zip(grid_sfr.i+1,grid_sfr.j+1))].reset_index(drop=True)\n",
    "    grid_sfr = pd.concat((grid_p_sfr,grid_sfr),axis=1)\n",
    "    grid_sfr_all = pd.concat((grid_sfr_all, grid_sfr.assign(realization=r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f9179-984c-42bc-ac2f-c413e1b593e1",
   "metadata": {},
   "source": [
    "Looking at the quantiles for the number of coarse stream segments it seems that the best fit realizations span the 5th to 75th percentile which means that we have multiple realizations with different stream segment connections but equal model fit which means that the larger subsurface distribution might account for the fit more than stream segments that outcrop.\n",
    "- the top best fit realizations both had a higher number of coarse lake cells\n",
    "- the other variable to plot would be the number of distinct connected bodies that outcrop or that are in the domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9318acd-c639-4dc7-856e-a9cf4ee02d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_review = r_review[r_review.variable=='quant']\n",
    "fig,ax = plt.subplots(1, len(q_review), sharex=True, sharey=True, figsize=(12, 6.5))\n",
    "for nr, r in enumerate(q_review.realization):\n",
    "    grid_sfr_all[grid_sfr_all.realization==r].plot('facies', ax=ax[nr], legend=True, legend_kwds={'loc':'upper left'})\n",
    "    ax[nr].set_title(str(r)+' - '+str(q_review.value.iloc[nr])+'\\nNo. Coarse:'+str(q_review.num_coarse.iloc[nr]))\n",
    "# grid_sfr_all[grid_sfr_all.realization==r].plot('facies', legend=True, ax=ax[-1])\n",
    "\n",
    "q_review = r_review[r_review.variable=='fit']\n",
    "fig,ax = plt.subplots(1, len(q_review), sharex=True, sharey=True, figsize=(12, 6.5))\n",
    "for nr, r in enumerate(q_review.realization):\n",
    "    grid_sfr_all[grid_sfr_all.realization==r].plot('facies', ax=ax[nr], legend=True, legend_kwds={'loc':'upper left'})\n",
    "    ax[nr].set_title(str(r)+' - '+str(q_review.value.iloc[nr])+'\\nNo. Coarse:'+str(q_review.num_coarse.iloc[nr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1213013-899d-4be0-831e-a54429550f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# grid_sfr_all[grid_sfr_all.realization==11]\n",
    "# m.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92934ae7-7761-44c7-bbad-84d7e24b46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=11\n",
    "folder = 'realization'+ str(r).zfill(3)\n",
    "# update model workspace so outputs to right directory\n",
    "model_ws = join(all_model_ws, folder)\n",
    "sfrdf =  clean_sfr_df(model_ws, m.name, drop_iseg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb34ff-5017-41f1-ba8e-facbeb176839",
   "metadata": {},
   "source": [
    "The baseflow is too inconsistent to show as a time series since it is dominantly a 0 value. The seepage heat map is able to show how between realizations the days with 0 seepage expands across segments and time with more coarse segments generally.  \n",
    "The streamflow values tend to be large such that you don't see much variability in the streamflow across segments unless the segment goes dry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ac2bf-83a5-43c0-b89f-030b22b4f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrdf_all = pd.DataFrame()\n",
    "q_review = r_review[r_review.variable=='quant']\n",
    "for nr, r in enumerate(q_review.realization):\n",
    "    folder = 'realization'+ str(r).zfill(3)\n",
    "    # update model workspace so outputs to right directory\n",
    "    model_ws = join(all_model_ws, folder)\n",
    "    sfrdf =  clean_sfr_df(model_ws, m.name, drop_iseg)\n",
    "    sfrdf_all = pd.concat((sfrdf_all, sfrdf.assign(realization=r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0cf206-4860-43fa-99a3-28a7704aab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude(x):\n",
    "    return int(np.log10(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf55b2-859b-4d7c-a66e-f52f912cc2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_map(sfrdf_all, variable, var_name, q_review):\n",
    "    fig,ax = plt.subplots(len(variable)+1, len(q_review), figsize=(12, 8), sharex=True, sharey='row', layout='constrained', dpi=300)\n",
    "    for nv, v in enumerate(variable):\n",
    "        for nr, r in enumerate(q_review.realization):\n",
    "            sfrdf = sfrdf_all[sfrdf_all.realization==r]\n",
    "            plt_arr = sfrdf.pivot(columns='segment', values=v).values\n",
    "            vmax = 10**(1+magnitude(sfrdf_all[v].max()))\n",
    "            vmin = np.max((sfrdf_all[v].min(), 1E-2))\n",
    "            plt_arr[plt_arr==0] = vmin\n",
    "            im = ax[nv, nr].imshow(plt_arr,  aspect=1/10,\n",
    "                       norm = mpl.colors.LogNorm(vmin=vmin, vmax=vmax)\n",
    "                      )\n",
    "    for nr, r in enumerate(q_review.realization):\n",
    "        ax[0, nr].set_title(str(r)+' - '+str(q_review.value.iloc[nr])+'\\nNo. Coarse:'+str(q_review.num_coarse.iloc[nr]))\n",
    "    for nv, v in enumerate(var_name):\n",
    "        cbar_ax=ax[nv].ravel().tolist()\n",
    "        fig.colorbar(im, ax=cbar_ax, orientation='vertical', label=v+' ($m^3/day$)', shrink=0.5, location='right')\n",
    "        ax[nv,0].set_ylabel('Days from start')\n",
    "        # plt.colorbar()\n",
    "        # plt.show()\n",
    "    ## plot VKA for streambed  \n",
    "    vmin = sfr_hk_plt.strhc1.min()\n",
    "    vmax = sfr_hk_plt.strhc1.max()\n",
    "    for nr, r in enumerate(q_review.realization):\n",
    "        ax_n = ax[-1, nr]\n",
    "        im = ax[-1, nr].imshow(np.reshape(sfr_hk_plt[sfr_hk_plt.realization==r].strhc1.values, (1,-1)), aspect=10, norm = mpl.colors.LogNorm(vmin=vmin, vmax=vmax))\n",
    "        # plt.xticks([]);\n",
    "        ax_n.set_ylabel('');\n",
    "        ax_n.set_yticks([]);\n",
    "    cbar_ax=ax[-1].ravel().tolist()\n",
    "    fig.colorbar(im, ax=cbar_ax, orientation='vertical', label='VKA\\n($m/day$)', shrink=0.3, location='right')    \n",
    "    # ax[0].set_ylabel('Days from Start')\n",
    "    # fig.supylabel('Days from Start');\n",
    "    fig.supxlabel('Segment');\n",
    "    # fig.tight_layout(h_pad=-.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63dd81-c8e7-4672-8829-e74aa81d99e2",
   "metadata": {},
   "source": [
    "Note the lake is fed at segment 31/32 and returns flow at segment 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b430f20-1ae7-42c3-8158-f9f498450f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_hk_plt = grid_sfr_all[~grid_sfr_all.iseg.isin(drop_iseg)]\n",
    "fig,ax = plt.subplots(1, len(q_review), figsize=(12, 4), sharex=True, sharey=True, layout='constrained', dpi=300)\n",
    "vmin = sfr_hk_plt.strhc1.min()\n",
    "vmax = sfr_hk_plt.strhc1.max()\n",
    "for nr, r in enumerate(q_review.realization):\n",
    "\n",
    "    im = ax[nr].imshow(np.reshape(sfr_hk_plt[sfr_hk_plt.realization==r].strhc1.values, (1,-1)), aspect=10, norm = mpl.colors.LogNorm(vmin=vmin, vmax=vmax))\n",
    "    # plt.xticks([]);\n",
    "    plt.yticks([]);\n",
    "cbar_ax=ax.ravel().tolist()\n",
    "fig.colorbar(im, ax=cbar_ax, orientation='vertical', label='VKA\\n($m/day$)', shrink=0.3, location='right')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca9f0d-eedf-4938-acc6-0fdb3f992254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean hydraulic conductivity does increase slightly as we go up in the number of coarse segments\n",
    "# sfr_hk_plt.groupby('realization').mean(numeric_only=True).strhc1.loc[q_review.realization]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e58b8e-cfb4-40a2-ae47-5955cbf3fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map(sfrdf_all, ['Qrech', 'Qbase'], ['Seepage', 'Baseflow'], q_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e70587-a0e4-4b30-95a9-c5ac1cb20d41",
   "metadata": {},
   "source": [
    "When it comes to seepage the zones of high streambed conductance align with zones of greater seepage. Downstream zones of higher seepage there are more uniform zones of dry channel proceeding downstream because as flow comes into that zone of high seepage it tends to be used up entirely and their is no downstream baseflow in the dry season to improve flow. We find with the realizations with more coarse segments that the area of dry channel tends to extend further upstream and increase the duration of no streamflow. The periods during the wet season that come across as no seepage are segments with baseflow to the stream.  \n",
    "The baseflow predominantly occurs along the reconnected floodplain and upstream with a few pockets of baseflow down stream where there is a pocket of high coarse facies, although the duration of baseflow at these pockets is very intermittent. \n",
    "\n",
    "- these plots are useful in mapping out how spatial heterogeneity plays a role and the number of facies plays a role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b147bb-4aa6-45e8-af12-c9acce97fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map(sfrdf_all, ['Qbase'], ['Baseflow'], q_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065aa8c-a0ed-402b-b7fc-5ce6250ef921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat map of flow is pretty consitent across segments event with log scale\n",
    "# heat_map(sfrdf_all, 'Qout', 'Flow', q_review)\n",
    "# sfrdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f59241-72dd-4243-a39d-f4593e2551ac",
   "metadata": {},
   "source": [
    "## Segment facies review\n",
    "Three of the five realizations show the expected behavior of primarily mud with patches of sand, sandy mud and gravel. The outlier is a realization that is probably half gravel and sand as the stream bed facies which is the same realization where there was a huge amount of baseflow in the gravel. There is also a realization that is almost entirely mud with a section of NAs for some reason.  \n",
    "\n",
    "The realizations with best fit all tend to have dominantly mud in the upper and lower sections with a gravel pocket along the middle section. The other realizations tend to keep this pattern with variability in the length of the gravel section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a5e6f-85ee-4e80-8217-b0e32ecfc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakrow, lakcol = np.where(m.lak.lakarr.array[0].mean(axis=0) >0)\n",
    "grid_lak = grid_p.set_index(['row','column']).loc[list(zip(lakrow+1,lakcol+1))].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f120e6e-3a85-4697-92b8-6b4c8e69bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = gpd.read_file(join(proj_dir, 'GIS', 'plotting_cross_section_lines.shp'))\n",
    "grid_xs = gpd.sjoin(grid_p, xs) # grid cells for each XS\n",
    "# set standard cell numbers for XS plotting\n",
    "for n in  np.arange(0, len(xs)):\n",
    "    grid_xs.loc[grid_xs.id==n, 'xs_cell']  = np.arange(0, (grid_xs.id==n).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec803c4-7028-49b6-a16c-5b39e5a3490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr[['row','column']] = grid_sfr[['i','j']]+1\n",
    "# grid_sfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4f8542-25cb-4d9c-8d64-4ede7c416ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find sfr, lak cells that are in the xs\n",
    "sfr_xs = grid_xs.join(grid_sfr.set_index(['row','column']).drop(columns=['geometry','node']), on=['row','column'], how='inner')\n",
    "lak_xs = grid_xs.join(grid_lak.set_index('node').drop(columns=['geometry', 'dem_elev']), on='node', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1248a1-c4e8-4be8-a97c-d7f2fe815c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_xs.plot('xs_cell', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f2781-df14-4944-8803-6f03a16654b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=grid_lak.plot()\n",
    "grid_sfr.plot('facies', ax=ax)\n",
    "grid_xs.plot(ax=ax)\n",
    "grid_xs.plot('xs_cell', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0464eb-20c3-4f2b-bb60-6815e56500aa",
   "metadata": {},
   "source": [
    "It would make sense to have a XS in the middle of the floodplain, at the bottom edge where the gravel patch tends to be in the river and a little further downstream near the outlet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc42019e-a17d-48b7-aa39-7ae2acffdddf",
   "metadata": {},
   "source": [
    "## Deeper geologic review\n",
    "Following the segment facies review, there are geologic features that may be adjacent to the channel but not outcrop that could impact flow but this is more difficult to represent. I think plotting these XS with head values and geologic facies are a good way to dive a little deeper at a 2D level. It would also be worthwhile presenting groundwater contours at key points (flood peak, recession and summer low)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba32d8-a9a6-439c-8fd7-cd1e24cb8952",
   "metadata": {},
   "outputs": [],
   "source": [
    "## identify XS line to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d156a34-1b89-4e1a-8f3c-78cf864a6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e11e7-13a0-476a-a95f-f077b9f8c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'realization'+ str(r).zfill(3)\n",
    "# update model workspace so outputs to right directory\n",
    "model_ws = join(all_model_ws, folder)\n",
    "# m.model_ws = model_ws\n",
    "upw_r = flopy.modflow.ModflowUpw.load(model_ws+'/MF.upw', model=m)\n",
    "# model_ws+'/MF.upw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898616b-3279-4d5f-95eb-1b6a5df4e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdobj = flopy.utils.HeadFile(model_ws+'/MF.hds')\n",
    "spd_stp = hdobj.get_kstpkper()\n",
    "times = hdobj.get_times()\n",
    "\n",
    "# get ALL stress periods and time steps list, not just those in the output\n",
    "kstpkper = []\n",
    "for n,stps in enumerate(m.dis.nstp.array):\n",
    "    kstpkper += list(zip(np.arange(0,stps),np.full(stps,n)))\n",
    "\n",
    "# dt_ref = pd.DataFrame(dates_stps, columns=['dt'])\n",
    "# dt_ref['kstpkper'] = kstpkper\n",
    "# dt_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ee2ae-4349-4e68-b9fd-f59b4ed971a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in xs.id:\n",
    "for n in [2]:\n",
    "    xs_n = grid_xs[grid_xs.id==n]\n",
    "    xs_hk = upw_r.hk.array[:, xs_n.row-1, xs_n.column-1]\n",
    "    \n",
    "    sfr_xs_n = sfr_xs[sfr_xs.id==n]\n",
    "    lak_xs_n = lak_xs[lak_xs.id==n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c343386d-759d-445a-911d-e4b33fe53fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(xs_hk)\n",
    "xs_hk[0]\n",
    "ymax = m.dis.top.array.max()\n",
    "ymin = m.dis.botm.array.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05704423-affc-41e6-8411-66427270dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygon = ax.fill_between(x, y1, y2, lw=0, color='none')\n",
    "# ax.margins(x=0.02)\n",
    "# xlim = ax.get_xlim()\n",
    "# ylim = ax.get_ylim()\n",
    "# verts = np.vstack([p.vertices for p in polygon.get_paths()])\n",
    "plt.imshow(xs_hk, cmap='viridis', aspect='auto',\n",
    "                    extent=[xs_n.xs_cell.min(), xs_n.xs_cell.max(), ymin, ymax]\n",
    "                    # extent=[verts[:, 0].min(), verts[:, 0].max(), verts[:, 1].min(), verts[:, 1].max()]\n",
    "                   )\n",
    "# filling.set_clip_path(polygon.get_paths()[0], transform=ax.transData)\n",
    "# ax.set_xlim(xlim) # the limits need to be set again because imshow sets zero margins\n",
    "# ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41002893-95a1-43b8-b96e-66f91c711969",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "head = hdobj.get_data(spd_stp[1200])[:, xs_n.row-1, xs_n.column-1] \n",
    "head = np.ma.masked_where(head==-999.99, head)\n",
    "\n",
    "# when considering how to plot head we should focus on the upper layers where the river interacts\n",
    "# it appears the heads under the river/lake stay constant\n",
    "# for n in np.arange(head.shape[0]):\n",
    "#     plt.plot(xs_n.xs_cell, head[n]);\n",
    "\n",
    "def plt_xs_spd(head, sfr_xs_n, lak_xs_n, xs_n, ax):\n",
    "    # plot head in sfr layer only\n",
    "    head_sfr = head[sfr_xs_n.k.values[0]]\n",
    "    ax.plot(head_sfr, color='blue', label='Head in SFR layer')\n",
    "    # plot average head as well\n",
    "    head_avg = head[0:10].mean(axis=0)\n",
    "    ax.plot(head_avg, color='blue', linestyle='--', label='Average Head - Upper')\n",
    "    head_avg = head[10:-1].mean(axis=0)\n",
    "    ax.plot(head_avg, color='blue', linestyle='-.', label='Average Head - Lower')\n",
    "    head_avg = head[-1]\n",
    "    ax.plot(head_avg, color='blue', linestyle=':', label='Head - Deep')\n",
    "\n",
    "    # plot sfr and lak stages\n",
    "    ax.scatter(sfr_xs_n.xs_cell, sfr_xs_n.strtop, zorder= -1, color='tab:blue', label='Stream Top')\n",
    "    ax.scatter(lak_xs_n.xs_cell, lak_xs_n.dem_elev, zorder= -2, color='brown', label='Lake')\n",
    "    ax.plot(xs_n.xs_cell, xs_n.dem_elev, zorder= -3, color='black', label='Land Surface')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea3419-1fd7-4de7-a9c3-6c51305eb08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505f276-46d4-4176-80a8-a21f86a9bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(xs.id), figsize=(6,6), sharex=True, sharey=True)\n",
    "for n in xs.id:\n",
    "    xs_n = grid_xs[grid_xs.id==n]\n",
    "    xs_hk = upw_r.hk.array[:, xs_n.row-1, xs_n.column-1]\n",
    "    \n",
    "    sfr_xs_n = sfr_xs[sfr_xs.id==n]\n",
    "    lak_xs_n = lak_xs[lak_xs.id==n]\n",
    "\n",
    "    \n",
    "    head = hdobj.get_data(spd_stp[1200])[:, xs_n.row-1, xs_n.column-1] \n",
    "    head = np.ma.masked_where(head==-999.99, head)\n",
    "\n",
    "    plt_xs_spd(head, sfr_xs_n, lak_xs_n, xs_n, ax=ax[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2049ec-b96d-4077-8786-dbb3b01b1be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71c06c-4c15-4419-a7b1-20a5ba2831b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(xs.id), figsize=(6,6), sharex=True, sharey=True)\n",
    "for n in xs.id:\n",
    "    xs_n = grid_xs[grid_xs.id==n]\n",
    "    xs_hk = upw_r.hk.array[:, xs_n.row-1, xs_n.column-1]\n",
    "    \n",
    "    sfr_xs_n = sfr_xs[sfr_xs.id==n]\n",
    "    lak_xs_n = lak_xs[lak_xs.id==n]\n",
    "\n",
    "    \n",
    "    head = hdobj.get_data(spd_stp[1200])[:, xs_n.row-1, xs_n.column-1] \n",
    "    head = np.ma.masked_where(head==-999.99, head)\n",
    "\n",
    "    plt_xs_spd(head, sfr_xs_n, lak_xs_n, xs_n, ax=ax[n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eba905e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "import sys\n",
    "from os.path import basename, dirname, join, exists\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "# from scipy.stats import gmean\n",
    "\n",
    "# standard python plotting utilities\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import geopandas as gpd\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "\n",
    "# mapping utilities\n",
    "# import contextily as ctx\n",
    "# from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "# from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "# import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50eb04c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel'\n",
    "# dir of stream level data for seepage study\n",
    "proj_dir = gwfm_dir + '/Oneto_Denier/'\n",
    "dat_dir = proj_dir+'Stream_level_data/'\n",
    "\n",
    "sfr_dir = gwfm_dir+'/SFR_data/'\n",
    "uzf_dir = gwfm_dir+'/UZF_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "036ddc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_path(fxn_dir):\n",
    "    \"\"\" Insert fxn directory into first position on path so local functions supercede the global\"\"\"\n",
    "    if fxn_dir not in sys.path:\n",
    "        sys.path.insert(0, fxn_dir)\n",
    "\n",
    "# other functions\n",
    "py_dir = join(doc_dir,'GitHub/CosumnesRiverRecharge/python_utilities')\n",
    "add_path(py_dir)\n",
    "\n",
    "from mf_utility import get_layer_from_elev\n",
    "from map_cln import gdf_bnds, plt_cln"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff23f3aa",
   "metadata": {},
   "source": [
    "# Load general files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d64cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dem_data = np.loadtxt(gwfm_dir+'\\DIS_data\\dem_52_9_200m_mean.tsv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1f6f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model grid as geopandas object\n",
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3ca84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_area = grid_p.area.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7194792",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_elev = gpd.read_file(join(gwfm_dir,'DIS_data','grid_elevation_m_statistics.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74d74c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sfr = gpd.read_file(sfr_dir+'/final_grid_sfr/grid_sfr.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd9746c",
   "metadata": {},
   "source": [
    "## Prepare Lake bathymetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad13322",
   "metadata": {},
   "outputs": [],
   "source": [
    "lak_shp = join(gwfm_dir,'LAK_data/floodplain_delineation')\n",
    "# ifp = gpd.read_file(join(lak_shp,'inner_floodplain_domain/inner_floodplain_domain.shp' )).to_crs('epsg:32610')\n",
    "# lfp = gpd.read_file(join(lak_shp,'lower_floodplain_approximate_area/lower_floodplain_approximate_area.shp' )).to_crs('epsg:32610')\n",
    "lak_extent = gpd.read_file(join(lak_shp,'LCRFR_ModelDom_2017/LCRFR_2DArea_2015.shp' )).to_crs('epsg:32610')\n",
    "\n",
    "fp_logger = pd.read_csv(join(gwfm_dir,'LAK_data','floodplain_logger_metadata.csv'))\n",
    "fp_logger = gpd.GeoDataFrame(fp_logger, geometry = gpd.points_from_xy(fp_logger.Easting, fp_logger.Northing), crs='epsg:32610')\n",
    "# find grid cell it is within\n",
    "fp_grid = gpd.sjoin(fp_logger, grid_p, how='left',predicate='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2118a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min bottom elevation 3.03 m., max bottom elevation 11.57 m.\n",
      "Lake volume in million of cubic meters 9.52\n"
     ]
    }
   ],
   "source": [
    "fn = join(lak_shp,\"floodplain_crop.tif\")\n",
    "if not exists(fn):\n",
    "    # create clipped raster of just lake area\n",
    "    dem_dir = join(gwfm_dir,'DEM_data')\n",
    "    raster_name = dem_dir+'/mwt_peri_2_3.tif/mwt_peri_2_3_clipped.tif'\n",
    "    import rasterio.mask\n",
    "    with rasterio.open(raster_name) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, lak_extent.geometry.values, crop=True)\n",
    "        out_meta = src.meta\n",
    "    # write output\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_image.shape[1],\n",
    "                     \"width\": out_image.shape[2],\n",
    "                     \"transform\": out_transform})\n",
    "\n",
    "    with rasterio.open(join(lak_shp,\"floodplain_crop.tif\"), \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "\n",
    "# prepare bathymetry file\n",
    "lakeRst = rasterio.open(join(lak_shp,\"floodplain_crop.tif\"))\n",
    "lakeBottom = lakeRst.read(1)\n",
    "noDataValue = np.copy(lakeBottom[0,0])\n",
    "#replace value for np.nan\n",
    "lakeBottom[lakeBottom==noDataValue]= np.nan\n",
    "\n",
    "# get raster minimum and maximum \n",
    "minElev = np.nanmin(lakeBottom)\n",
    "maxElev = np.nanmax(lakeBottom)\n",
    "print('Min bottom elevation %.2f m., max bottom elevation %.2f m.'%(minElev,maxElev))\n",
    "\n",
    "# steps for calculation\n",
    "nSteps = 151\n",
    "# lake bottom elevation intervals\n",
    "elevSteps = np.round(np.linspace(minElev,maxElev,nSteps),2)\n",
    "\n",
    "# definition of volume function\n",
    "def calculateVol_A(elevStep,elevDem,lakeRst, conv=1):\n",
    "    tempDem = elevStep - elevDem[elevDem<elevStep]\n",
    "    tempArea = len(tempDem)*lakeRst.res[0]*conv*lakeRst.res[1]*conv\n",
    "    tempVol = tempDem.sum()*lakeRst.res[0]*conv*lakeRst.res[1]*conv\n",
    "    return(tempVol, tempArea)\n",
    "# calculate volumes, areas for each elevation\n",
    "volArray = [0]\n",
    "saArray = [0]\n",
    "for elev in elevSteps[1:]:\n",
    "    tempVol,tempArea = calculateVol_A(elev,lakeBottom,lakeRst)\n",
    "    volArray.append(tempVol)\n",
    "    saArray.append(tempArea)\n",
    "\n",
    "# print(\"Lake bottom elevations %s\"%elevSteps)\n",
    "volArrayMCM = round(volArray[-1]/1000000,2) \n",
    "print(\"Lake volume in million of cubic meters %s\"%volArrayMCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5759623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify grid cells in the lake area\n",
    "lak_grid = gpd.overlay(grid_p, lak_extent[['OID_','geometry']], how='intersection')\n",
    "# check if more than 50% of cell is covered by the lake, avoid conflicts with sfr\n",
    "lak_grid = lak_grid.loc[lak_grid.geometry.area > (cell_area*0.5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91955834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove lake grid cells that overlap with sfr cells\n",
    "lak_grid_cln = lak_grid.join(grid_sfr.set_index(['row','column'])[['reach']], on=['row','column'])\n",
    "lak_grid_cln = lak_grid_cln[lak_grid_cln.reach.isna()]\n",
    "\n",
    "lak_grid_cln.to_file(join(lak_shp, 'lak_grid_cln.shp'))\n",
    "# lak_row, lak_col = lak_grid_cln.row.values-1, lak_grid_cln.column.values-1\n",
    "\n",
    "# the lakarr and bdlknc are dependent on the model layer and geology \n",
    "# and so are not defined here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3707eff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lake stage (elevation), volume, and area (3 numbers per line)\n",
    "bathtxt = np.column_stack((elevSteps, volArray, saArray))\n",
    "np.savetxt(join(gwfm_dir,'LAK_data', 'oneto-denier.bath'), bathtxt, delimiter = '\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690a31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254c1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a597cc42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python utilities\n",
    "import os\n",
    "from os.path import basename, dirname,join\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# standard python plotting utilities\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard geospatial python utilities\n",
    "import pyproj # for converting proj4string\n",
    "import geopandas as gpd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5065545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "    \n",
    "# dir of all gwfm data\n",
    "gwfm_dir = os.path.dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel'\n",
    "# dir of stream level data for seepage study\n",
    "proj_dir = gwfm_dir + '/Oneto_Denier/'\n",
    "dat_dir = proj_dir+'Stream_level_data/'\n",
    "\n",
    "fig_dir = proj_dir+'/Streambed_seepage/figures/'\n",
    "hob_dir = join(gwfm_dir, 'HOB_data')\n",
    "sfr_dir = gwfm_dir+'/SFR_data/'\n",
    "\n",
    "py_dir = doc_dir +'GitHub/CosumnesRiverRecharge/python_utilities/'\n",
    "\n",
    "out_dir = join(proj_dir, 'output')\n",
    "fig_dir = join(proj_dir, 'figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c46b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flopy_dir = doc_dir+'/GitHub/flopy'\n",
    "if flopy_dir not in sys.path:\n",
    "#     sys.path.append(flopy_dir)\n",
    "    sys.path.insert(0, flopy_dir)\n",
    "# sys.path\n",
    "import flopy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set box directory for output figures and data\n",
    "box_dir = gwfm_dir+'/Levee_setback/levee_setback_distance_analysis/'\n",
    "\n",
    "tprogs_id = '' # original tprogs with conditioning data in output tsim\n",
    "# tprogs_id = '_no_conditioning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acafc158",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dir = 'F:/WRDAPP'\n",
    "c_dir = 'C:/WRDAPP'\n",
    "\n",
    "if os.path.exists(ext_dir):\n",
    "    loadpth = ext_dir \n",
    "elif os.path.exists(c_dir):\n",
    "    loadpth = c_dir \n",
    "\n",
    "loadpth = loadpth +'/GWFlowModel/Cosumnes/levee_setback/setback_distance_analysis/'\n",
    "model_ws = loadpth+'Permeameter_for_velocity' + tprogs_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f86c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'MF.nam'\n",
    "# # name = 'MF_child.nam'\n",
    "# m = flopy.modflow.Modflow.load(name, model_ws=model_ws, \n",
    "#                                 exe_name='mf2005', version='mf2005')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926cd1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dem data for cropping above land surface\n",
    "dem_data = np.loadtxt(gwfm_dir+'/DIS_data/dem_52_9_200m_mean.tsv') #linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6165e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regional model grid\n",
    "grid_p = gpd.read_file(gwfm_dir+'/DIS_data/grid/grid.shp')\n",
    "# local model grid\n",
    "grid_match = gpd.read_file(join(proj_dir, 'GIS','grid_match.shp'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pyvista as pv\n",
    "from pyvista import examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcc8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv.set_jupyter_backend('trame')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db92da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tprogs_fxn_dir = doc_dir +'/GitHub/CosumnesRiverRecharge/tprogs_utilities'\n",
    "if tprogs_fxn_dir not in sys.path:\n",
    "    sys.path.append(tprogs_fxn_dir)\n",
    "# import cleaning functions for tprogs\n",
    "import tprogs_cleaning as tc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd2cb3",
   "metadata": {},
   "source": [
    "## TPROGs coarse connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc30dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_tprogs_dir = gwfm_dir+'/UPW_data/tprogs_final' + tprogs_id+'/'\n",
    "tprogs_files = glob.glob(mf_tprogs_dir+'*')\n",
    "# tprogs_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bb9d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprogs_info = [80, -80, 320]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.read_csv(model_ws+'/ZonePropertiesInitial.csv', index_col='Zone')\n",
    "# convert from m/s to m/d\n",
    "params['K_m_d'] = params.K_m_s * 86400   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t=0\n",
    "tprogs_line = np.loadtxt(tprogs_files[t])\n",
    "tprogs_arr = np.reshape(tprogs_line, (320, 100,230))\n",
    "# switch conditioning data to be consistent\n",
    "tprogs_arr = np.where(tprogs_arr<0, tprogs_arr*-1, tprogs_arr)\n",
    "\n",
    "K, Sy, Ss= tc.int_to_param(tprogs_arr, params)\n",
    "K_r = np.copy(K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow,ncol = grid_match.row.max(), grid_match.column.max()\n",
    "dem_data_p = np.loadtxt(gwfm_dir+'\\DIS_data\\dem_52_9_200m_mean.tsv')\n",
    "\n",
    "dem_data = np.zeros((nrow,ncol))\n",
    "dem_data[grid_match.row-1, grid_match.column-1] = dem_data_p[grid_match.p_row-1, grid_match.p_column-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b05550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tprogs_arr_local = np.zeros((320, nrow, ncol))\n",
    "# tprogs_arr_local[:, grid_match.row-1, grid_match.column-1] = tprogs_arr[:, grid_match.p_row-1, grid_match.p_column-1]\n",
    "K_local = np.zeros((320, nrow, ncol))\n",
    "K_local[:, grid_match.row-1, grid_match.column-1] = K_r[:, grid_match.p_row-1, grid_match.p_column-1]\n",
    "\n",
    "# crop vertically to model top and bottom maximum extent\n",
    "strt_layer = int((80 - dem_data.max())*2) # includes max extent of trpogs\n",
    "strt_layer = int((80 - dem_data.min())*2) # includes layer with all tprogs cells\n",
    "\n",
    "min_elev = int(np.floor((dem_data-40).min()))\n",
    "end_layer = int((80 - min_elev)*2)\n",
    "K_local = K_local[strt_layer:end_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf2ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_ws = 'F:/WRDAPP/GWFlowModel/Cosumnes/Stream_seepage/parallel_oneto_denier_2014_2018'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb2ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_ws =  'F:/WRDAPP/GWFlowModel/Cosumnes/Stream_seepage/oneto_denier_2014_2018'\n",
    "\n",
    "load_only=['DIS','UPW','BAS6']\n",
    "m = flopy.modflow.Modflow.load('MF.nam', model_ws= base_model_ws, \n",
    "                                exe_name='mf-owhm.exe', version='mfnwt',\n",
    "                              load_only = load_only\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f107a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "botm = m.dis.botm.array\n",
    "\n",
    "nlay = m.dis.nlay\n",
    "# nrow = m.dis.nrow\n",
    "# ncol = m.dis.ncol\n",
    "upscale = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d12ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscaled tprogs\n",
    "folder = 'realization'+ str(t).zfill(3)\n",
    "# update model workspace so outputs to right directory\n",
    "model_ws = join(all_model_ws, folder)\n",
    "tfn = join(model_ws, 'tprogs_local.csv')\n",
    "tprogs_local = np.reshape(np.loadtxt(tfn),(tprogs_info[-1], nrow, ncol))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.read_csv(model_ws+'/ZonePropertiesInitial.csv', index_col='Zone')\n",
    "# convert from m/s to m/d\n",
    "params['K_m_d'] = params.K_m_s * 86400   \n",
    "K, Sy, Ss,porosity = tc.int_to_param(tprogs_local, params, porosity=True)\n",
    "\n",
    "hk = np.zeros(botm.shape)\n",
    "vka = np.zeros(botm.shape)\n",
    "sy = np.zeros(botm.shape)\n",
    "ss = np.zeros(botm.shape)\n",
    "por = np.zeros(botm.shape)\n",
    "\n",
    "top = np.copy(m.dis.top.array)\n",
    "bot1 = np.copy(botm[-1,:,:])\n",
    "# tprogs_info = ()\n",
    "from scipy.stats import hmean, gmean\n",
    "\n",
    "# I need to verify if a flattening layer is needed (e.g., variable thickness to maintain TPROGs connectivity)\n",
    "# pull out the TPROGS data for the corresponding depths\n",
    "K_c = tc.get_tprogs_for_elev(K, top, bot1,tprogs_info)\n",
    "Ss_c = tc.get_tprogs_for_elev(Ss, top, bot1,tprogs_info)\n",
    "Sy_c = tc.get_tprogs_for_elev(Sy, top, bot1,tprogs_info)\n",
    "n_c = tc.get_tprogs_for_elev(porosity, top, bot1,tprogs_info)\n",
    "\n",
    "# upscale as preset\n",
    "for k in np.arange(0,nlay):\n",
    "    hk[k,:] = np.mean(K_c[upscale*k:upscale*(k+1)], axis=0)\n",
    "    vka[k,:] = hmean(K_c[upscale*k:upscale*(k+1)], axis=0)\n",
    "    ss[k,:] = np.mean(Ss_c[upscale*k:upscale*(k+1)], axis=0)\n",
    "    sy[k,:] = np.mean(Sy_c[upscale*k:upscale*(k+1)], axis=0)\n",
    "    por[k,:] = np.mean(n_c[upscale*k:upscale*(k+1)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ab88eb",
   "metadata": {},
   "source": [
    "- K to K_local aligns as expected\n",
    "- the mismatch is with the un upscaled data keeping original layers and the upscaled data has different layers sampled based on elevation at the dem to 40m\n",
    "- after changing the top layer to be in line with the tprogs top there was more consistency\n",
    "- it looks like it is worth checking whether 0.5 upscaling would work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccafe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K[strt_layer:end_layer].shape, K_local.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3, figsize=(8,6))\n",
    "ax[0].imshow(K[strt_layer:end_layer][0])\n",
    "ax[1].imshow(K_local[0])\n",
    "ax[2].imshow(hk[0,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfarr2grid(arr, dz = 0.5):\n",
    "    grid = pv.UniformGrid()\n",
    "    # Set the grid dimensions: shape because we want to inject our values on the\n",
    "    #   POINT data\n",
    "    # I have to add 1 to each dimension to have it be built on the cells\n",
    "    nz, ny, nx = arr.shape\n",
    "    grid.dimensions = [ny+1, nx+1, nz+1]\n",
    "    # real origin, but incorrect because of no rotation\n",
    "#     grid.origin = (645500.0, 4227700.0, -80) # bottom left corner of the dataset\n",
    "# simple origin that allows easier data output cleaning\n",
    "    grid.origin = (0, 0, -80) # bottom left corner of the dataset\n",
    "    grid.spacing = (200,200, dz)\n",
    "    arr_in = np.moveaxis(arr,0,2).flatten(order='F').astype(int)\n",
    "    # grid.point_data[\"facies\"] = arr_in\n",
    "    grid.cell_data[\"facies\"] = arr_in\n",
    "    return(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350fef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_plt(grid, fig_nam):\n",
    "    plotter = pv.Plotter(notebook=False, lighting=None, off_screen=True) # \n",
    "    plotter.background_color='white'\n",
    "    mesh = plotter.add_mesh(grid, scalars=\"facies\", cmap='viridis',\n",
    "#                      show_edges=True, \n",
    "                    )\n",
    "#     axes = pv.Axes(show_actor=True, actor_scale=2.0, line_width=5)\n",
    "    plotter.set_scale(1, 1, 50)\n",
    "# found ideal position by manual adjustment\n",
    "    mesh.rotate_z(90)\n",
    "    mesh.rotate_x(20)\n",
    "    mesh.rotate_y(10)\n",
    "#     grid = plotter.show_grid()\n",
    "    print(join(fig_dir, fig_nam + '.png'))\n",
    "    plotter.show(screenshot=join(fig_dir, fig_nam + '.png'))\n",
    "    # plotting looks the same when built on cells instead of points\n",
    "    \n",
    "# grid_plt(grid, 'tprogs_facies')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a75614",
   "metadata": {},
   "source": [
    "## Create and plot TPROGs grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e28881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = mfarr2grid(tprogs_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = mfarr2grid(K_local)\n",
    "grid_plt(grid, 'tprogs_K')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K[strt_layer-1:end_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be0827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the file loaded from tprogs, add 1 to avoid any nan values\n",
    "grid = mfarr2grid(K[strt_layer+1:end_layer], dz = 0.5)\n",
    "\n",
    "grid_plt(grid, 'preprocessed_K_local')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ee6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = mfarr2grid(hk, dz = 4)\n",
    "\n",
    "grid_plt(grid, 'hk_upscaled_8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69cb50d",
   "metadata": {},
   "source": [
    "# Create and plot Connec3d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed680572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dem data for cropping above land surface\n",
    "dem_data = np.loadtxt(gwfm_dir+'/DIS_data/dem_52_9_200m_mean.tsv')\n",
    "\n",
    "model_ws = loadpth+'Connec3d' + tprogs_id\n",
    "\n",
    "cco_in = np.loadtxt(join(model_ws, 'r000.CCO'))\n",
    "# reshape to array format\n",
    "cco = np.reshape(cco_in, (320, 100,230))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589d7e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cco_vert(cco, dem_data):\n",
    "    z,y,x = np.where(cco>0)\n",
    "    val = cco[z,y,x]\n",
    "    # np.transpose((z,y,x,val))\n",
    "    df = pd.DataFrame(np.transpose((z,y,x,val)),columns=['z','y','x','cc'])\n",
    "    # find ground elevation at each connected point\n",
    "    df['dem'] = dem_data[df.y.astype(int),df.x.astype(int)]\n",
    "    # calculate elevation from tprogs layer\n",
    "    df['elev'] = 80-z*0.5\n",
    "    # check whether max is above land and below\n",
    "    df['above_gse'] = (df.elev > df.dem) \n",
    "    df['below_30'] = (df.elev < df.dem-30)\n",
    "    df_sum = df.groupby('cc').sum()\n",
    "    # find connected components that are above ground and connect deeper than 30m below\n",
    "    df_conn = df_sum[(df_sum.above_gse>0).values & (df_sum.below_30 >0).values].index\n",
    "    # check if top and bottom connected is in cco array\n",
    "    cco_vert = np.isin(cco, df_conn)\n",
    "    return(cco_vert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cco_vert = get_cco_vert(cco, dem_data)\n",
    "# tprogs_cleaning.get_tprogs_for_elev(dem_data)\n",
    "# tprogs_lay = tp.elev_to_tprogs_layers(elev=dem_data,tprogs_top_elev=80, tprogs_bot_elev=-80, num_lays=320)\n",
    "# # elev_to_tprogs_layers?\n",
    "# rows = np.where(np.ones(tprogs_lay.shape)==1)[0]\n",
    "# cols = np.where(np.ones(tprogs_lay.shape)==1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d81fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the coarse connected doesn't show anything unique\n",
    "grid = mfarr2grid(cco_vert.astype(int))\n",
    "coarse = grid.threshold(value = [0.9, 1.1], scalars='facies') #, preference='cell'\n",
    "grid_plt(coarse, 'connec3d_coarse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45675ba",
   "metadata": {},
   "source": [
    "The mesh is looking pretty close. The side view looks correct for part of it but there is a weird extension that is continuous, maybe an issue with the way I repeated data to make x,y,z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6bf77e",
   "metadata": {},
   "source": [
    "If value is a single value, when invert is True cells are kept when their values are below parameter \"value\". When invert is False cells are kept when their value is above the threshold \"value\". Default is False: yielding above the threshold \"value\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79995ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter mesh by facies (1,2 gravel and sand)\n",
    "coarse = grid.threshold(value = [0.9, 2.1], scalars='facies') #, preference='cell'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "largest = coarse.connectivity(largest=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d838ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very long process\n",
    "\n",
    "bodies = coarse.split_bodies(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b6ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now remove all bodies with a small volume\n",
    "for key in bodies.keys():\n",
    "    b = bodies[key]\n",
    "    vol = b.volume\n",
    "    # originally used 4.4E6 next up is 63.6E6\n",
    "    if vol < 63.E6:\n",
    "        del bodies[key]\n",
    "        continue\n",
    "    # Now lets add a volume array to all blocks\n",
    "    b.cell_data[\"TOTAL VOLUME\"] = np.full(b.n_cells, vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc052c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = bodies.keys()[0]\n",
    "# print(k)\n",
    "bodies.keys()\n",
    "# 0 still looks like it contains every cells\n",
    "# most don't look like they extend vertically\n",
    "# while reviewing the connected segments I found that they consider connectivity to be any face, vertex, or corner in touch\n",
    "# while connec3d offers an option of 6 vs 16\n",
    "# 2160, 3687 looks a little more substantial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521749fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_plt(largest, 'tprogs_coarse_largest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508bc5d",
   "metadata": {},
   "source": [
    "## Permeameter connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9884736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_model_ws = loadpth+'Permeameter_for_velocity' + tprogs_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4e5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in np.arange(0,1): #100\n",
    "#     print('Realization', r, ' time since start ',(time.time()-tic)/60)\n",
    "    folder = '/realization'+ str(r).zfill(3)+'/'\n",
    "    run_ws = all_model_ws+folder\n",
    "        \n",
    "cbb = flopy.utils.CellBudgetFile(run_ws+'/MF.cbc')\n",
    "# load velocity in z direction\n",
    "extcbb = flopy.utils.postprocessing.get_extended_budget(cbb)\n",
    "(qx, qy, qz) = flopy.utils.postprocessing.get_specific_discharge(vectors = extcbb, model=m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a43d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare using flow_percentile for individual layer versus entire domain\n",
    "\n",
    "# tprogs_cleaning.get_tprogs_for_elev(dem_data)\n",
    "# tprogs_lay = tc.elev_to_tprogs_layers(elev=dem_data,tprogs_top_elev=80, tprogs_bot_elev=-80, num_lays=320)\n",
    "# elev_to_tprogs_layers?\n",
    "# rows = np.where(np.ones(tprogs_lay.shape)==1)[0]\n",
    "# cols = np.where(np.ones(tprogs_lay.shape)==1)[1]\n",
    "# get high conductivity at ground surface\n",
    "# qz_plt = np.zeros((100,230))\n",
    "# qz_plt[rows,cols] = qz[tprogs_lay[rows,cols],rows,cols] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first plan, use vertical flow rate to identify high flow recharge cells\n",
    "# hf_id = 'qz'\n",
    "# q = np.copy(qz)* -1\n",
    "\n",
    "# look at flow vector magnitude\n",
    "hf_id = 'squared'\n",
    "q = np.sqrt(qz**2 + qx**2 + qy**2)\n",
    "\n",
    "flow_percentile = 87 #95\n",
    "# q_hf = np.zeros(q.shape)\n",
    "# q_hf[q>= np.percentile(q,flow_percentile)] = 1\n",
    "\n",
    "# alternative array of VKA where there is high flow to see distribution between coarse and fine\n",
    "q_hf = np.copy(tprogs_arr)\n",
    "q_hf[q<= np.percentile(q,flow_percentile)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try home made connectivity\n",
    "# allocate array\n",
    "# arr = np.zeros(tprogs_arr.shape)\n",
    "# # assign coarse facies as unique numbers\n",
    "# arr[tprogs_arr<=2] = np.arange(1,np.sum(tprogs_arr<=2)+1)\n",
    "# x,y,z = np.where(arr>0)\n",
    "# arr\n",
    "# # iterate across row, then col then z\n",
    "# for i in x:\n",
    "#     for j in y:\n",
    "#         for k in z:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c58687",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = mfarr2grid(q_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af55210",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_plt(grid, hf_id+'_highflow_'+str(flow_percentile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29296b69",
   "metadata": {},
   "source": [
    "Looks like limited number of high flow cells on top and bottom, a few vertical sections along the sides when using qz alone.\n",
    "\n",
    "Use geometry mean of qz, qx, qy seems to show more mixed direction. It almost looks like a random distribution and doesn't look very connected and the bodies that do exist are fairly small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc52350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter mesh by flow type (1 = high flow, 0 = low flow) based on qz threshold\n",
    "coarse = grid.threshold(value = [0.9, 1.1], scalars='facies') #, preference='cell'\n",
    "\n",
    "# for plotting all connected facies\n",
    "coarse = grid.threshold(value = [0.9, 4.1], scalars='facies') #, preference='cell'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aa22ee",
   "metadata": {},
   "source": [
    "1. Identify high flow cells with some cutoff flow\n",
    "2. Apply split_bodies (connectivity) to identify unique units\n",
    "3. Remove bodies with volumes less than typical minimum volume needed to span from land surface to deeper aquifer\n",
    "4. Check whether max and min elevation of each body are above land and below deep aquifer cutoff depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1620971",
   "metadata": {},
   "outputs": [],
   "source": [
    "largest = coarse.connectivity(largest=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b805140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very long process\n",
    "\n",
    "bodies = coarse.split_bodies(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9122562",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of distinct bodies:', len(bodies.keys()))\n",
    "# # Now remove all bodies with a small volume\n",
    "for key in bodies.keys():\n",
    "    b = bodies[key]\n",
    "    vol = b.volume\n",
    "    # originally used 4.4E6 next up is 63.6E6\n",
    "    if vol < 4.E6:\n",
    "        del bodies[key]\n",
    "        continue\n",
    "    # Now lets add a volume array to all blocks\n",
    "    b.cell_data[\"TOTAL VOLUME\"] = np.full(b.n_cells, vol)\n",
    "print('Total number of distinct bodies:', len(bodies.keys()))\n",
    "# using the minimum cells cutoff approximation we reduce from 5721 to 314 bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 4E6 min volume approximate from vert\n",
    "# the largest volume is 4.27E8 so the cutoff might be able to be safely raised to 1E7 so that we are within an order of mag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77038876",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "\n",
    "\n",
    "\n",
    "print('Volume %.2E' %bodies[bodies.keys()[n]].volume, ' m^3')\n",
    "grid_plt(bodies[bodies.keys()[n]], hf_id + '_highflow_' + str(flow_percentile) + '_testing_'+str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c03d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exterior coords of 0\n",
    "# maxes\n",
    "# largest\n",
    "# largest.extract_cells(range(0,368000-1))\n",
    "# coarse.cell_points(368000-1)\n",
    "\n",
    "# coarse['facies'].shape\n",
    "# largest.cell_connectivity\n",
    "# largest.elevation()\n",
    "# largest['RegionId'].shape\n",
    "# largest['vtkOriginalCellIds'].shape\n",
    "# largest\n",
    "# largest['facies'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4085d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# g = largest\n",
    "connected = np.zeros((320, 100,230))\n",
    "\n",
    "# iterate across all\n",
    "rid = 3\n",
    "t0 = time.time()\n",
    "# took 7 minutes for a run with 13 bodies\n",
    "for rid in np.arange(0,len(bodies.keys())):\n",
    "    g = bodies[bodies.keys()[rid]]\n",
    "\n",
    "    df = pd.DataFrame(np.zeros((g['facies'].shape[0],3)), columns=['RegionId', 'geometry','zbot'])\n",
    "    df['RegionId'] = rid\n",
    "    # iterate across all cells in the body\n",
    "    for n in np.arange(0,g['facies'].shape[0]):\n",
    "        # extract cell boundary points\n",
    "        p_arr = g.cell_points(n)\n",
    "        # create polygon from cell boundary points, need to reorder\n",
    "    #     df.loc[n, 'geometry'] = Polygon(p_arr[[0,1,3,2],0:2])\n",
    "        df.loc[n, 'zbot'] = np.min(p_arr[:,2]) # bottom elevation\n",
    "        df.loc[n,['x', 'y']] = p_arr[:,0:2].mean(axis=0)\n",
    "    # with simple grid I can easily ID row,column\n",
    "    df['row'] = (df.x/200 - 0.5).astype(int)\n",
    "    df['col'] = (df.y/200 - 0.5).astype(int)\n",
    "    df['layer'] = ((80 - df.zbot)*2 - 1).astype(int)\n",
    "\n",
    "    # if the connected channel is above land surface and connects to at least 30m (98.4 ft)below ground surface\n",
    "    if any(dem_data[df.row, df.col] < df.zbot) & any(dem_data[df.row, df.col]-30 > df.zbot):\n",
    "        print(rid, end=' ')\n",
    "        connected[df.layer, df.row, df.col] = 1\n",
    "t1 = time.time()\n",
    "print((t1-t0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5730541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_g = mfarr2grid(connected)\n",
    "connected_g = connected_g.threshold([0.9, 1.1])\n",
    "grid_plt(connected_g, 'highflow_'+str(flow_percentile)+'_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0130a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_plt(coarse, hf_id + '_highflow_' + str(flow_percentile) + '_coarse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847bb3a",
   "metadata": {},
   "source": [
    "Most of these vertical high flow connected pathways are fairly straight from top to bottom which suggests that water is traveling in a straighter path through the sandy mud/mud to get to the coarse facies rather than a sinuous path only through sand/gravel. (95th percentile)\n",
    "\n",
    "Going to the 99th percentile the pathways were still mainly vertical, but I noticed more partial vertical pathways that should be removed by checking if the top and bottom of each connected component are above ground surface and at least to the water table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfc8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "1433*26, 197483\n",
    "largest['facies'].shape\n",
    "# centroid of these\n",
    "largest.cell_points(21357-1)\n",
    "largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7bbe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_plt(largest, hf_id + '_highflow_' + str(flow_percentile) + '_coarse_largest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to find a way to extract the locations of these cells to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57812e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# largest.get_array('facies')\n",
    "# cell_data = shows cell data info\n",
    "# points returns x, y, z for all N points\n",
    "# cells gives a single value for each cell? Length doesn't match number of cells\n",
    "largest.cells #['facies']\n",
    "# 320*100*230\n",
    "# largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a299101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very long process\n",
    "\n",
    "bodies = coarse.split_bodies(progress_bar=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

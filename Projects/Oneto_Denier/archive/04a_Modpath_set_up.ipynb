{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9eee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "from os.path import basename, dirname, join, exists\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from osgeo import gdal\n",
    "import contextily as ctx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c294398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "    \n",
    "# dir of all gwfm data\n",
    "gwfm_dir = os.path.dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel'\n",
    "# dir of stream level data for seepage study\n",
    "proj_dir = gwfm_dir + '/Oneto_Denier/'\n",
    "dat_dir = proj_dir+'Stream_level_data/'\n",
    "\n",
    "fig_dir = proj_dir+'/Streambed_seepage/figures/'\n",
    "hob_dir = join(gwfm_dir, 'HOB_data')\n",
    "sfr_dir = gwfm_dir+'/SFR_data/'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950a53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_path(fxn_dir):\n",
    "    \"\"\" Insert fxn directory into first position on path so local functions supercede the global\"\"\"\n",
    "    if fxn_dir not in sys.path:\n",
    "        sys.path.insert(0, fxn_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e312518",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "add_path(doc_dir+'/GitHub/flopy')\n",
    "import flopy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb233010",
   "metadata": {},
   "outputs": [],
   "source": [
    "py_dir = join(doc_dir,'GitHub/CosumnesRiverRecharge/python_utilities')\n",
    "\n",
    "add_path(py_dir)\n",
    "\n",
    "from mf_utility import get_dates, get_layer_from_elev, clean_wb\n",
    "from map_cln import gdf_bnds, plt_cln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_nodes(locs):\n",
    "    ''' Converts layer, row, column into model node number '''\n",
    "    nodes = []\n",
    "    for k, i, j in locs:\n",
    "        nodes.append(k * m.dis.nrow * m.dis.ncol + i * m.dis.ncol + j)\n",
    "    return nodes\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dae156",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = '' # baseline, levee removal occurred in 2014\n",
    "# create identifier for scenario if levee removal didn't occur\n",
    "# scenario = 'no_reconnection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97df386",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadpth = 'C:/WRDAPP/GWFlowModel/Cosumnes/Stream_seepage/'\n",
    "model_nam = 'oneto_denier_upscale4x_2014_2020'\n",
    "\n",
    "\n",
    "model_ws = join(loadpth,model_nam)\n",
    "if scenario != '':\n",
    "    model_ws += '_' + scenario\n",
    "    \n",
    "# model_ws = join(loadpth,'parallel_oneto_denier','realization000')\n",
    "load_only = ['DIS','UPW','SFR','OC', \"EVT\",'BAS6','LAK']\n",
    "m = flopy.modflow.Modflow.load('MF.nam', model_ws= model_ws, \n",
    "                                exe_name='mf-owhm.exe', version='mfnwt',\n",
    "                              load_only=load_only,\n",
    "                              )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa4c59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlay = m.dis.nlay\n",
    "nrow = m.dis.nrow\n",
    "ncol = m.dis.ncol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc85b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nper = m.dis.nper # number of months\n",
    "# m.dis.nstp.array[1:] # number of steps\n",
    "perlen = m.dis.perlen.array # days per period\n",
    "\n",
    "strt_date = np.datetime64(m.start_datetime)\n",
    "# strt_date = np.datetime64('1990-10-01')\n",
    "end_date = strt_date + np.timedelta64(int(perlen.sum()-1),'D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdobj = flopy.utils.HeadFile(model_ws+'/MF.hds')\n",
    "spd_stp = hdobj.get_kstpkper()\n",
    "cbb = flopy.utils.CellBudgetFile(model_ws+'/MF.cbc')\n",
    "\n",
    "times = hdobj.get_times()\n",
    "# subtract 1 to have start of each period\n",
    "dt_ref = pd.DataFrame(np.asarray(times), columns=['time']) \n",
    "dt_ref['timedelta'] = pd.to_timedelta(dt_ref.time, 'D').round('H')\n",
    "dt_ref['dt'] = strt_date+dt_ref.timedelta\n",
    "dt_ref['kstpkper'] = spd_stp\n",
    "dt_ref[['kstp','kper']] = dt_ref.kstpkper.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071bd355",
   "metadata": {},
   "source": [
    "## Identify locations for particle release\n",
    "\n",
    "We are interested in identify whether particles recharged from the streambed and floodplain remain near the channel, return to the stream or exit the system through pumping, ET or lateral boundaries.  \n",
    "\n",
    "To reduce the number of particles injected we should only inject during flow events when the floodplain is active as we care about the ultimate fate of that water and the stream water entering in the winter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b6d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflow_in = pd.read_csv(sfr_dir+'MB_daily_flow_cfs_2010_2019.csv', index_col = 'datetime', parse_dates = True)\n",
    "\n",
    "# covnert flow from cubic feet per second to cubic meters per day\n",
    "inflow_in['flow_cmd'] = inflow_in.flow_cfs * (86400/(3.28**3))\n",
    "# filter out data between the stress period dates\n",
    "inflow = inflow_in.loc[strt_date:end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c7f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the stress periods when the lake will be active\n",
    "flood_flow = inflow[inflow.flow_cfs> 27/(0.3048**3)]\n",
    "flood_ref = dt_ref.join(flood_flow, on='dt',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77323438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f76084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfr dataframe\n",
    "sfrdf = pd.DataFrame(m.sfr.reach_data.copy())\n",
    "# layer, row, column to identify particle release\n",
    "sfr_kij = sfrdf[['k','i','j']].copy()\n",
    "# try starting in deeper layer\n",
    "sfr_kij['k'] = 4\n",
    "# sfr_kij.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e4b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfr_kij.transform(lambda x: list(zip(x, df[2])))\n",
    "sfr_hd  = hdobj.get_ts(list(zip(sfr_kij.k+1, sfr_kij.i, sfr_kij.j)))\n",
    "# sfr_0 = hdobj.get_ts(list(zip(np.zeros(len(sfr_kij)), sfr_kij.i, sfr_kij.j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_grid = np.zeros((nrow,ncol))\n",
    "sfr_grid[sfrdf.i, sfrdf.j]= 1\n",
    "# plt.imshow(sfr_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee451f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp_chk = dt_ref[dt_ref.dt.dt.month==4].kstpkper.values[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's identify which cells are active\n",
    "# hd = hdobj.get_data(sp_chk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7af1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(sfr_0).set_index(0).plot(legend=False)\n",
    "pd.DataFrame(sfr_hd).set_index(0).plot(legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cacde4f",
   "metadata": {},
   "source": [
    "We are interested in comparing how the age of water in the hyporheic zone below the stream is changing as this shows how the water is mixing from the stream and lateral flow from the floodplain. We also want to track where water from the floodplain and river go/end up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6791b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.lak.lakarr.array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e5df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Num particles \n",
    "# ParticleID, GroupNumber, Grid, Layer, Row, Column, LocalX, LocalY, LocalZ, ReleaseTime Label\n",
    "# find location of all active cells for forward tracking\n",
    "ibound = m.bas6.ibound.array\n",
    "# adjust forward tracking start cells to focus on expected Big Springs source area\n",
    "# particle should also start in layer 1 only\n",
    "ibound[sfr_kij.k, sfr_kij.i, sfr_kij.j] += 1\n",
    "# ibound[1:3,:] +=1\n",
    "ibound[ibound<2] = 0\n",
    "\n",
    "k_all,i_all, j_all = np.where(ibound !=0)\n",
    "\n",
    "kij_arr = np.transpose((k_all,i_all, j_all))\n",
    "kij_all = list(zip(k_all,i_all, j_all))\n",
    "\n",
    "nodes_all = get_nodes(kij_all)\n",
    "print('Cells ', len(nodes_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb70a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_dates = pd.date_range(strt_date, end_date, freq=\"MS\")\n",
    "\n",
    "# nnodes = m.modelgrid.nnodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c2a8b1",
   "metadata": {},
   "source": [
    "# Modpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e6dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run shorter MODPATH simulation to reduce run time\n",
    "n_days = (dt_ref.dt.max()-dt_ref.dt.min()).days # full time period\n",
    "# stoptime is related to the reftime set in modpath as zero and is same in both directions\n",
    "stoptime = dt_ref.time.max()- dt_ref.time.min()\n",
    "print(n_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e30a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'Modpath7'\n",
    "exe_name = 'mpath7.exe'\n",
    "\n",
    "tracking = 'forward'\n",
    "# tracking = 'backward'\n",
    "\n",
    "mp_ws = join(model_ws,'mp',tracking, 'mp_'+str(n_days)+'days')\n",
    "\n",
    "mp = flopy.modpath.Modpath7(modelname= modelname, version='modpath7',exe_name= exe_name, flowmodel=m,  \n",
    "                             headfilename = join(model_ws,'MF.hds'), \n",
    "                            budgetfilename = join(model_ws,'MF.cbc'), model_ws = mp_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce53621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.copy(model_ws+'/MF.dis', mp_ws+'/MF.dis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new porosity variable added to zone properties based on approximate literature values\n",
    "porosity = np.reshape(np.loadtxt(model_ws+'/porosity_arr.tsv', delimiter='\\t'),(nlay,nrow,ncol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get times for first time step in each stress period to release particles\n",
    "times_tr = dt_ref.time[1:]\n",
    "\n",
    "# reference time represent the starting time\n",
    "if tracking=='backward':\n",
    "    reftime = [dt_ref.time.values[-1]]\n",
    "    # get stress period that gives the end \n",
    "    spd_ref = np.min(np.where(times_tr>=reftime[0]-stoptime)) \n",
    "elif tracking =='forward':\n",
    "    reftime = [dt_ref.time.values[1]]\n",
    "    #     reftime = [1] # don't start in steady state\n",
    "    # get stress period that start the simulation given the reference time\n",
    "    spd_ref = np.min(np.where(times>=reftime[0])) \n",
    "\n",
    "print(reftime, spd_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc460b59",
   "metadata": {},
   "source": [
    "## Release time info\n",
    "releasestarttime is the release time (modpath time) for starting particles in a particle group.  \n",
    "*ReleaseStartTime* is a value of tracking time; therefore, it is always greater than or equal to 0.  \n",
    "*Release Option*:  \n",
    "1. a single release time,  \n",
    "2. particles released over a period of time beginning at relase time for a length  \n",
    "3. particles in a group are released at specified time values  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a81725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release data from reference time (0) used by modpath\n",
    "# head is measured at end of each stress period, particles should be released at same time so results are comparable\n",
    "# release particles at day end that corresponds to end of stress period\n",
    "releasetimes = dt_ref[dt_ref.kstp==0].time.values[1:]\n",
    "\n",
    "# the releasedata is specified in the sloc loop\n",
    "# releasedata = [len(releasedata), releasedata.tolist()]\n",
    "# flopy interprets release option 2 to have length of 3 [ReleaseEventCount, specified time, release interval]\n",
    "# releasedata = [len(releasetimes),  releasetimes[0], 30.4375] # interval results in year length of 365.25\n",
    "# and release option to have length of 2 [ReleaseEventCount, specified times]\n",
    "# releasedata = [len(releasetimes),  releasetimes] # interval results in year length of 365.25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 372, \n",
    "# coded for forward tracking\n",
    "spd = 0\n",
    "print('Total time: ',reftime[0], 'spd ', spd+1, 'release time', reftime[0] - releasetimes[spd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c077e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drape = 1 places particles in the uppermost active cell, but with modflow NWT cells do not become inactive \n",
    "# they are just set with a specified head value (e.g., -9999.9)\n",
    "\n",
    "# need to set release layer as those identified as saturated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7fa1a6",
   "metadata": {},
   "source": [
    "To simplify things for now, we only release one particle per SFR cell, but ideally we would release 100 to capture the variability in flow path possible and reduce uncertainty. The downside is that running modpath takes several hours (at least ~2.5 hrs since at the start it is about 4 sec per spd). It might be of interest to look at other contaminant transport softwares like RWhet which are designed for heterogeneous media with high particle counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583dd8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(mp_ws+'/sloc',exist_ok=True)\n",
    "from datetime import datetime\n",
    "# takes .34 seconds to write out one particle group, avg of first 10 is 0.5 seconds so 150 minutes\n",
    "particlegroups = []\n",
    "# useful in determing how many particles to release on a cell by cell basis\n",
    "simple_particles = np.ones((nper,m.dis.nrow,m.dis.ncol)).astype(int)\n",
    "for spd in np.arange(spd_ref, nper-1): #spd_ref + 1\n",
    "    tic = datetime.now()\n",
    "#   1 particle per cell, scale influence in post-processing\n",
    " # forward tracking uses source area\n",
    "    if tracking == 'forward':\n",
    "#         scale particles by recharge rate\n",
    "        ij_spd = np.repeat(kij_arr, 10, axis=0)\n",
    "#         ij_spd = np.repeat(bs_ij.values, simple_particles[spd, bs_ij.HRU_ROW, bs_ij.HRU_COL], axis=0)\n",
    "    # backward tracking uses sink area\n",
    "#     elif tracking == 'backward':\n",
    "#  # repeat for 10 by 10 over cell face over 5 cell faces\n",
    "# #         ij_spd = np.repeat(bs_arr.values, 10*10*5, axis=0)\n",
    "#         # pull out layer, row, column to repeat for number of particles then across cells\n",
    "#         ij_spd = np.repeat(np.reshape(bs_arr.values[0], (1,-1)), 10*10*len(faces[0]), axis=0)\n",
    "#         for f in np.arange(1,len(faces)):\n",
    "#             ij_spd = np.vstack((ij_spd, np.repeat(np.reshape(bs_arr.values[f], (1,-1)), 10*10*len(faces[f]),axis=0)))\n",
    "\n",
    "    # compile row, column data\n",
    "#     kij_all = list(zip(ij_spd[:,0],ij_spd[:,1], ij_spd[:,2]))\n",
    "    # layer is defined as top layer where head > laybot\n",
    "#     kij_all = list(zip(layer[spd, ij_spd[:,1], ij_spd[:,2]],ij_spd[:,1], ij_spd[:,2])) \n",
    "#     ij_spd = pd.DataFrame(ij_spd).assign(spd=spd)\n",
    "    pg_spd = str(spd+1).zfill(4)\n",
    "    # due to number of spd need to only zfill to 3\n",
    "    pid = pg_spd + (pd.Series(np.arange(0,len(kij_all)).astype(str)).str.zfill(3))\n",
    "    pid = pid.astype(np.int64)\n",
    "    # drape is 0 means not released if 0, drape is 1 means set in next layer below\n",
    "    # drape =1 can't be used for NWT because of UPW\n",
    "    part1 = flopy.modpath.ParticleData(\n",
    "        kij_all, drape=0, structured=True, particleids=pid,\n",
    "#         localx = localx_all, localy = localy_all, localz = localz_all,\n",
    "    )\n",
    "    if tracking == 'forward':\n",
    "        releasedata = [releasetimes[spd] - reftime[0]]\n",
    "    elif tracking == 'backward':\n",
    "        releasedata = [reftime[0] - releasetimes[spd]]\n",
    "    pg1 = flopy.modpath.ParticleGroup(\n",
    "        particlegroupname=\"PG_SPD\"+pg_spd, particledata=part1, filename=\"sloc/Modpath7.pg_spd\"+pg_spd+\".sloc\",\n",
    "        releasedata = releasedata \n",
    "    )\n",
    "    # list of particle groups to write\n",
    "    particlegroups += [pg1]\n",
    "    toc = datetime.now()\n",
    "    if spd == np.round(spd, -1):\n",
    "        print('SPD '+str(spd+1) +' %.3f' %((tic-toc).microseconds/1E6), end=\"   \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ba4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_ref[dt_ref.kstp==0].time.values[1:]\n",
    "dt_months = dt_ref.iloc[1:].resample('MS', on='dt').first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e8ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if release particles in every cell it takes a long time to write sloc\n",
    "# testing particles in layers 2-4 doesn't take as long (7k vs 35k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25229bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default iface for MODFLOW-2005 and MODFLOW 6\n",
    "defaultiface = { \"RECHARGE\": 6, \"EVT\":6} #, \"RECHARGE\": 6, \"ET\": 6\n",
    "\n",
    "tic = datetime.now()\n",
    "mpbas = flopy.modpath.Modpath7Bas(mp, porosity=porosity, defaultiface=defaultiface)\n",
    "mpsim = flopy.modpath.Modpath7Sim(\n",
    "    mp,\n",
    "    simulationtype= 'timeseries', #'timeseries', #\"pathline\" always fails to write\n",
    "    trackingdirection=tracking,\n",
    "    weaksinkoption='pass_through', #pass_through, \"stop_at\"\n",
    "    weaksourceoption=\"pass_through\",\n",
    "#     Valid budget output options are ‘no’ - individual cell water balance errors are not computed and budget record headers \n",
    "#     are not printed, ‘summary’  - a summary of individual cell water balance errors for each time step is printed in the\n",
    "#     listing file without record headers\n",
    "    budgetoutputoption=\"summary\",\n",
    "#     budgetcellnumbers=[1049, 1259], #Cell numbers (zero-based) for which detailed water budgets are computed. \n",
    "    # List or tuple with two ints that define the particle group and particle id (zero-based) of the specified\n",
    "    # particle that is followed in detail. \n",
    "#     traceparticledata=[1, 1000], \n",
    "#     referencetime=[0, 0, 0.0],\n",
    "    referencetime=reftime, # important to start mid way in through flow model to run last 10 or 20 years\n",
    "    stoptimeoption=\"extend\", # 'total' = full run time, or 'specified' to specify stop, 'extend' is continue until termination\n",
    "    stoptime = stoptime,\n",
    "#     timepointdata= [dt_months.time.values.shape[0], dt_months.time.values], # try sampling points once per month\n",
    "    timepointdata= [releasetimes[::7].shape[0], releasetimes[::7]], # try sampling points once per week\n",
    "#     zonedataoption=\"on\",\n",
    "#     zones=zones,\n",
    "    particlegroups=particlegroups,\n",
    ")\n",
    "\n",
    "# write modpath datasets\n",
    "mp.write_input()\n",
    "\n",
    "toc = datetime.now()\n",
    "print((tic-toc).microseconds/1E6)\n",
    "# run modpath\n",
    "# mp.run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259a389",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "The initial attempt had a unit 116 error which I found with modpath at shasta originally where there are too many particles for the pathline output. I will switch to timepoint tracking, weekly timepoints were enough to allow a file to write.\n",
    "\n",
    "Still having issues getting the particles to not immediately terminate. The aquifer is generally saturated below the particles for at least the winter so it is not clear why they are terminating immediately. ET maybe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1d1754",
   "metadata": {},
   "source": [
    "# Scientific thoughts\n",
    "## Particle tracking - Where does river recharge go?\n",
    "Rather than thinking about the hyporheic zone specifically I can look at the end points of the river's recharge in terms of deep groundwater, lateral outflow, return to streamflow, storage as these help answer the questions surrounding the benefits of levee setback. Where does the water go?\n",
    "## Streamflow and storage - When does river recharge provide benefit?\n",
    "This is more related to the modeling effort looking at how a local levee setback provides recharge benefits. It could also be posed to the Oneto-Denier site.\n",
    "\n",
    "If I apply the same model to the Oneto-Denier site I will have the calibration data to validate making the results more interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a85ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

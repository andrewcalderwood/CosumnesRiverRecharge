{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ffe5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import dirname, basename,join, exists\n",
    "import glob\n",
    "\n",
    "# operations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "# import flopy\n",
    "\n",
    "# plotting\n",
    "# from PIL import Image\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from osgeo import gdal\n",
    "import contextily as ctx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e149e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = os.getcwd()\n",
    "while basename(doc_dir) != 'Documents':\n",
    "    doc_dir = dirname(doc_dir)\n",
    "# dir of all gwfm data\n",
    "gwfm_dir = dirname(doc_dir)+'/Box/research_cosumnes/GWFlowModel'\n",
    "# dir of stream level data for seepage study\n",
    "proj_dir = gwfm_dir + '/Stream_seepage/'\n",
    "dat_dir = proj_dir+'Stream_level_data/'\n",
    "\n",
    "sfr_dir = gwfm_dir+'/SFR_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "flopy_dir = doc_dir+'/GitHub/flopy/'\n",
    "if flopy_dir not in sys.path:\n",
    "    sys.path.append(flopy_dir)\n",
    "# sys.path\n",
    "import flopy \n",
    "\n",
    "from importlib import reload\n",
    "# importlib.reload\n",
    "reload(flopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b3fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes(locs):\n",
    "    ''' Converts layer, row, column into model node number '''\n",
    "    nodes = []\n",
    "    for k, i, j in locs:\n",
    "        nodes.append(k * m.dis.nrow * m.dis.ncol + i * m.dis.ncol + j)\n",
    "    return nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba7a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epd_2_df(epd, rot = 0, crs=None):\n",
    "    \"\"\" Provide an Endpoint recarray and rotation of grid (degrees) if one exists\"\"\"\n",
    "    epd_df = pd.DataFrame().from_records(epd)\n",
    "    # status meaning\n",
    "    status_dict = {0:'Pending',1:'Active',2:'NormallyTerminated',3:'ZoneTerminated',4:'Unreleased',5:'Stranded'}\n",
    "    epd_df['status_name'] = [status_dict.get(key) for key in epd_df.status]\n",
    "    # return particle status\n",
    "    for sn in epd_df.status_name.unique():\n",
    "        if (epd_df.status_name==sn).sum() >0:\n",
    "            print(str((epd_df.status_name==sn).sum())+' particles '+ sn)\n",
    "    # present age in days\n",
    "    epd_df['age_days'] = epd_df.time - epd_df.time0\n",
    "    # age in years\n",
    "    epd_df['age_years'] = epd_df.age_days/365\n",
    "    if tracking == 'forward':\n",
    "        loc_id = '' # with backward tracking final location is source\n",
    "    elif tracking =='backward':\n",
    "        loc_id = '0' # with forward tracking initial location is source\n",
    "    # identify source row/column \n",
    "    epd_df['j'] = (epd_df['x'+loc_id]/delr-0.5).astype(int)\n",
    "    epd_df['i'] = (epd_df['y'+loc_id]/delc-0.5).astype(int)\n",
    "    # group by elevation rounded\n",
    "    epd_df['elev_m'] = m.dis.top.array[epd_df.i.astype(int), epd_df.j.astype(int)]\n",
    "    epd_df['elev_m_grp'] = ((epd_df['elev_m'] *0.5).round(-2))/0.5 # every 200 meters\n",
    "    # convert the grid referenced x,y to a coordinate system referenced grid\n",
    "    rot *= (np.pi/180) # convert degrees to radians\n",
    "    lx = epd_df['x'+loc_id]\n",
    "    ly = epd_df['y'+loc_id]\n",
    "    x = lx*np.cos(rot) - ly*np.sin(rot)\n",
    "    y = ly*np.cos(rot) + lx*np.sin(rot)\n",
    "    epd_gdf = gpd.GeoDataFrame(epd_df, geometry = gpd.points_from_xy(x+xll, y+yll), crs=crs)\n",
    "    # summarize by modflow node\n",
    "    epd_df_mean = epd_df.groupby('node'+loc_id).mean(numeric_only=True).reset_index()\n",
    "    lx = epd_df_mean['x'+loc_id]\n",
    "    ly = epd_df_mean['y'+loc_id]\n",
    "    x = lx*np.cos(rot) - ly*np.sin(rot)\n",
    "    y = ly*np.cos(rot) + lx*np.sin(rot)\n",
    "    epd_mean_gdf = gpd.GeoDataFrame(epd_df_mean, geometry = gpd.points_from_xy(x+xll, y+yll), crs=crs)\n",
    "\n",
    "    return(epd_gdf, epd_mean_gdf)\n",
    "#     return(epd_gdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b5d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def src_area_bnds(epd, aoi):\n",
    "    if tracking == 'forward':\n",
    "        loc_id = '0' # with forward tracking initial location is source\n",
    "    elif tracking =='backward':\n",
    "        loc_id = '' # with backward tracking final location is source\n",
    "    from shapely.geometry import box\n",
    "    outx = xll+epd['x'+loc_id]\n",
    "    outy = yll+epd['y'+loc_id]\n",
    "    src_box = box(outx.min(), outy.min(), outx.max() ,  outy.max())\n",
    "    src_area = aoi[['Name','Hydrologic','geometry']].copy()\n",
    "    src_area.geometry = [src_box]\n",
    "    src_area.crs='epsg:3310'\n",
    "    return(src_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29818475",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = '' # baseline, levee removal occurred in 2014\n",
    "# create identifier for scenario if levee removal didn't occur\n",
    "scenario = 'no_reconnection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58a7a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadpth = 'C:/WRDAPP/GWFlowModel/Cosumnes/Stream_seepage/'\n",
    "model_nam = 'oneto_denier_upscale4x_2014_2020'\n",
    "\n",
    "model_ws = join(loadpth,model_nam)\n",
    "if scenario != '':\n",
    "    model_ws += '_' + scenario\n",
    "    \n",
    "    \n",
    "m = flopy.modflow.Modflow.load('MF.nam', model_ws=model_ws, \n",
    "                                exe_name='mf-owhm', version='mfnwt') #, load_only = load_only)\n",
    "\n",
    "nlay = m.dis.nlay\n",
    "nrow = m.dis.nrow\n",
    "ncol = m.dis.ncol\n",
    "xll,yll = m.modelgrid.xoffset,m.modelgrid.yoffset\n",
    "\n",
    "delr = m.dis.delr.array[0]\n",
    "delc = m.dis.delc.array[0]\n",
    "\n",
    "nper = m.dis.nper # number of months\n",
    "perlen = m.dis.perlen.array # days per period\n",
    "\n",
    "strt_date = np.datetime64(m.start_datetime)\n",
    "end_date = strt_date + np.timedelta64(int(perlen.sum()-1),'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdobj = flopy.utils.HeadFile(model_ws+'/MF.hds')\n",
    "spd_stp = hdobj.get_kstpkper()\n",
    "cbb = flopy.utils.CellBudgetFile(model_ws+'/MF.cbc')\n",
    "\n",
    "times = hdobj.get_times()\n",
    "# subtract 1 to have start of each period\n",
    "dt_ref = pd.DataFrame(np.asarray(times), columns=['time']) \n",
    "dt_ref['timedelta'] = pd.to_timedelta(dt_ref.time, 'D').round('H')\n",
    "dt_ref['dt'] = strt_date+dt_ref.timedelta\n",
    "dt_ref['kstpkper'] = spd_stp\n",
    "dt_ref[['kstp','kper']] = dt_ref.kstpkper.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run shorter MODPATH simulation to reduce run time\n",
    "n_days = (dt_ref.dt.max()-dt_ref.dt.min()).days # full time period\n",
    "tracking = 'forward'\n",
    "# tracking = 'backward'\n",
    "\n",
    "mp_ws = join(model_ws,'mp',tracking, 'mp_'+str(n_days)+'days')\n",
    "modelname = 'Modpath7'\n",
    "print(basename(mp_ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d93261",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grp = 'inset_oneto_denier'\n",
    "grid_dir = join(gwfm_dir, 'DIS_data/streambed_seepage/grid')\n",
    "grid_fn = join(grid_dir, model_grp,'rm_only_grid.shp')\n",
    "grid_p = gpd.read_file(grid_fn)\n",
    "grid_p.crs = 'epsg:32610'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrdf = pd.DataFrame(m.sfr.reach_data)\n",
    "# get geodataframe for sfr\n",
    "grid_sfr = grid_p.set_index(['row','column']).loc[list(zip(sfrdf.i+1, sfrdf.j+1))]\n",
    "grid_sfr = pd.concat((grid_sfr.reset_index(), sfrdf), axis=1)\n",
    "# gdf for lak\n",
    "lak_row, lak_col = np.where(m.lak.lakarr.array[0,0]>0)\n",
    "grid_lak = grid_p.set_index(['row','column']).loc[list(zip(lak_row+1, lak_col+1))].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76938fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nodes for Big Springs at the area of interest scale\n",
    "\n",
    "aoi_arr = sfrdf[['k','i','j']]\n",
    "aoi_arr = aoi_arr-1 # convert to 0 based\n",
    "aoi_ids = list(zip(aoi_arr.k, aoi_arr.i, aoi_arr.j))\n",
    "\n",
    "nodes_aoi = get_nodes(aoi_ids) # get nodes\n",
    "print(len(nodes_aoi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the issue that occurred in modpath was that the modpath particle id got so long that in the output file \n",
    "# modpath couldn't put a space between it and the particle release number and so it became a bunch of ***\n",
    "# need to shorten pid or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a02b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the last rows have **** appended into the name of column 1\n",
    "# error checking\n",
    "# pd.read_csv(join(mp_ws, modelname + \".mpend\"), skiprows=2195, delimiter=r'\\s+',engine='python',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2fb29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = flopy.utils.PathlineFile(mp_ws + modelname+'.mppth')\n",
    "e = flopy.utils.EndpointFile(join(mp_ws, modelname + \".mpend\"))\n",
    "\n",
    "# big springs iso\n",
    "# p_bs = p.get_destination_pathline_data(nodes_bs, to_recarray=True)\n",
    "# p_bs = p.get_destination_pathline_data(nodes_bs_sfr, to_recarray=True)\n",
    "\n",
    "# if tracking == 'forward':\n",
    "#     epd_src = e.get_alldata() # returns the same result because backward tracking is a small initial area\n",
    "# if tracking == 'backward':\n",
    "#     epd_src = e.get_destination_endpoint_data(dest_cells=nodes_aoi)\n",
    "# # epd_src = e.get_destination_endpoint_data(dest_cells=nodes_aoi, source=True)\n",
    "    \n",
    "epd_src = e.get_alldata() # returns the same result because backward tracking is a small initial area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f38ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((pd.DataFrame(epd_src).time - pd.DataFrame(epd_src).time0).unique())\n",
    "# print(np.unique(epd_src.status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed95fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_gdf, epd_mean_gdf = epd_2_df(epd_src, rot=52.9, crs=grid_p.crs)\n",
    "# epd_gdf = epd_2_df(epd_src, rot=52.9, crs=grid_p.crs)\n",
    "\n",
    "# bs_src_area = src_area_bnds(epd_src, bs_aoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e7ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_gdf.status_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8450aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# particles instantly terminated\n",
    "# even setting the start layer to 4 all of the particles instantly terminate, may be due to leakage face?\n",
    "# layer 2 same issue so there is a problem with model set up\n",
    "# before changing from stop_at to pass_through\n",
    "# epd_gdf[['k0','xloc0','yloc0','k','xloc','yloc']]\n",
    "# epd_gdf.status.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b2d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epd_gdf[epd_gdf.age_days>0] # 3 stress periods had non zero times, groups 0-2 for times 2.83 to 4.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be55252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most are weakly terminated\n",
    "fig,ax = plt.subplots(figsize=(4,4))\n",
    "epd_gdf.plot('age_days', ax=ax, legend=True, legend_kwds = {'shrink':0.6,'orientation':'vertical'})\n",
    "grid_sfr.plot(ax=ax)\n",
    "grid_lak.plot(ax=ax,color='none',linewidth=0.3)\n",
    "# plt_cln(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52016fa8",
   "metadata": {},
   "source": [
    "To do:\n",
    "Look at travel distance in vertical and horizontal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b2a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_gdf['date'] = strt_date + epd_gdf.time0.astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e41763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = flopy.utils.TimeseriesFile(mp_ws+ modelname + \".timeseries\")\n",
    "\n",
    "# # file is 1.3 Gb\n",
    "# # ts = t.get_data() # loads nothing\n",
    "# ts = t.get_destination_timeseries_data(dest_cells=nodes_bs_aoi)\n",
    "# # create dataframe\n",
    "# ts_df = pd.DataFrame().from_records(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1497c5",
   "metadata": {},
   "source": [
    "# Cumulative age plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a338d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db52bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because there are so many days this code takes a long time\n",
    "\n",
    "\n",
    "# old code from shasta that needs to be updated\n",
    "#normalize item number values to colormap\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=len(epd_flow.date.unique()))\n",
    "\n",
    "# plot a cumulative age plot for the cumulative three cells\n",
    "# for each time step\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "# plt.cmap = 'gray'\n",
    "\n",
    "epd_flow = epd_gdf.copy()\n",
    "for n, t in enumerate(epd_flow.date.unique()):\n",
    "    t_epd = pd.DataFrame(epd_flow[epd_flow.date==t].copy())\n",
    "#     t_epd['weight'] = t_epd.flow/t_epd.flow.sum()\n",
    "    t_epd = t_epd.sort_values('age_years')\n",
    "    # temporary weight to decide if need\n",
    "    t_epd['weight_cum'] = np.linspace(0,1, len(t_epd))\n",
    "#     t_epd['weight_cum'] = t_epd.weight.cumsum()\n",
    "    t_epd.plot(x='age_years',y='weight_cum', ax=ax,  label=str(t), color=cm.gray(norm(n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be16c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_epd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b08e441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b8307",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# old code from shasta that needs to be updated\n",
    "#normalize item number values to colormap\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=len(epd_flow.date.unique()))\n",
    "\n",
    "# plot a cumulative age plot for the cumulative three cells\n",
    "# for each time step\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "plt.cmap = 'gray'\n",
    "\n",
    "for n, t in enumerate(epd_flow.date.unique()):\n",
    "    t_epd = pd.DataFrame(epd_flow[epd_flow.date==t].copy())\n",
    "    t_epd['weight'] = t_epd.flow/t_epd.flow.sum()\n",
    "    t_epd = t_epd.sort_values('age_years')\n",
    "    t_epd['weight_cum'] = t_epd.weight.cumsum()\n",
    "\n",
    "    t_epd.plot(x='age_years',y='weight_cum', ax=ax,  label=str(t), color=cm.gray(norm(n)))\n",
    "ax.set_xlabel('Age (years)')\n",
    "ax.set_xscale('log') \n",
    "ax.set_ylabel('Flow Weighted Fraction of Particles')\n",
    "ax.set_title('Cumulative Age Distribution\\nby Stress Period')\n",
    "\n",
    "\n",
    "custom_lines = [Line2D([0], [0], color=cm.gray(norm(0)), lw=4),\n",
    "                Line2D([0], [0], color=cm.gray(norm(n)), lw=4)]\n",
    "ax.legend(custom_lines, [epd_dates[0], epd_dates[n]], facecolor='lightgray', framealpha=1)\n",
    "\n",
    "# plt.savefig(fig_dir+'/'+tracking+'/big springs cumulative age average' +  mp_info['strt_date'].values[0]+ '.png',\n",
    "#             dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d279f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
